{"nodes": [{"ID": "732", "Name": "Incorrect Permission Assignment for Critical Resource", "Description": "When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to disable public access.", "Extended_Description": "When a resource is given a permission setting that provides access to a wider range of actors than required, it could lead to the exposure of sensitive information, or the modification of that resource by unintended parties. This is especially dangerous when the resource is related to program configuration, execution, or sensitive user data. For example, consider a misconfigured storage account for the cloud that can be read or written by a public or anonymous user.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.The developer might make certain assumptions about the environment in which the product operates - e.g., that the software is running on a single-user system, or the software is only accessible to trusted administrators. When the software is running in a different environment, the permissions become a problem.Installation: The developer may set loose permissions in order to minimize problems when the user first runs the program, then create documentation stating that permissions should be tightened. Since system administrators and users do not always read the documentation, this can result in insecure permissions being left unchanged.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Files or Directories. Note: An attacker may be able to read sensitive information from the associated resource, such as credentials or configuration information stored in a file.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker may be able to modify critical properties of the associated resource to gain privileges, such as replacing a world-writable executable with a Trojan horse.Scopes: IntegrityOther. Impacts: Modify Application DataOther. Note: An attacker may be able to destroy or corrupt critical data in the associated resource, such as deletion of records from a database.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis may be effective in detecting permission problems for system resources such as files, directories, shared memory, device interfaces, etc. Automated techniques may be able to detect the use of library functions that modify permissions, then analyze function calls for arguments that contain potentially insecure values.However, since the software's intended security policy might allow loose permissions for certain operations (such as publishing a file on a web server), automated static analysis may produce some false positives - i.e., warnings that do not have any security consequences or require any code changes.When custom permissions models are used - such as defining who can read messages in a particular forum in a bulletin board system - these can be difficult to detect using automated static analysis. It may be possible to define custom signatures that identify any custom functions that implement the permission checks and assignments. Method Name: Automated Dynamic Analysis. Description: Automated dynamic analysis may be effective in detecting permission problems for system resources such as files, directories, shared memory, device interfaces, etc.However, since the software's intended security policy might allow loose permissions for certain operations (such as publishing a file on a web server), automated dynamic analysis may produce some false positives - i.e., warnings that do not have any security consequences or require any code changes.When custom permissions models are used - such as defining who can read messages in a particular forum in a bulletin board system - these can be difficult to detect using automated dynamic analysis. It may be possible to define custom signatures that identify any custom functions that implement the permission checks and assignments. Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. Method Name: Manual Static Analysis. Description: Manual static analysis may be effective in detecting the use of custom permissions models and functions. The code could then be examined to identifying usage of the related functions. Then the human analyst could evaluate permission assignments in the context of the intended security model of the software. Method Name: Manual Dynamic Analysis. Description: Manual dynamic analysis may be effective in detecting the use of custom permissions models and functions. The program could then be executed with a focus on exercising code paths that are related to the custom permissions. Then the human analyst could evaluate permission assignments in the context of the intended security model of the software. Method Name: Fuzzing. Description: Fuzzing is not effective in detecting this weakness. Method Name: Black Box. Description: Use monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.Attach the monitor to the process and watch for library functions or system calls on OS resources such as files, directories, and shared memory. Examine the arguments to these calls to infer which permissions are being used. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Implementation : When using a critical resource such as a configuration file, check to see if the resource has insecure permissions (such as being modifiable by any regular user) [REF-62], and generate an error or even exit the software if there is a possibility that the resource could have been modified by an unauthorized party.Architecture and Design : Divide the software into anonymous, normal, privileged, and administrative areas. Reduce the attack surface by carefully defining distinct user groups, privileges, and/or roles. Map these against data, functionality, and the related resources. Then set the permissions accordingly. This will allow you to maintain more fine-grained control over your resources. [REF-207]Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.Implementation : During program startup, explicitly set the default permissions or umask to the most restrictive setting possible. Also set the appropriate permissions during program installation. This will prevent you from inheriting insecure permissions from any user who installs or runs the program.System Configuration : For all configuration files, executables, and libraries, make sure that they are only readable and writable by the software's administrator.Documentation : Do not suggest insecure configuration changes in documentation, especially if those configurations can extend to resources and other programs that are outside the scope of the application.Installation : Do not assume that a system administrator will manually change the configuration to the settings that are recommended in the software's manual.Operation : Ensure that the software runs properly under the United States Government Configuration Baseline (USGCB) [REF-199] or an equivalent hardening configuration guide, which many organizations use to limit the attack surface and potential risk of deployed software.Implementation : When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to disable public access.", "Demonstrative_Examples": "The following code sets the umask of the process to 0 before creating a file and writing \"Hello world\" into the file.. After running this program on a UNIX system, running the \"ls -l\" command might return the following output:This code creates a home directory for a new user, and makes that user the owner of the directory. If the new directory cannot be owned by the user, the directory is deleted.. Because the optional \"mode\" argument is omitted from the call to mkdir(), the directory is created with the default permissions 0777. Simply setting the new user as the owner of the directory does not explicitly change the permissions of the directory, leaving it with the default. This default allows any user to read and write to the directory, allowing an attack on the user's files. The code also fails to change the owner group of the directory, which may result in access by unexpected groups.The following code snippet might be used as a monitor to periodically record whether a web site is alive. To ensure that the file can always be modified, the code uses chmod() to make the file world-writable.. The first time the program runs, it might create a new file that inherits the permissions from its environment. A file listing might look like:This program creates and reads from an admin file to determine privilege information.. If the admin file doesn't exist, the program will create one. In order to create the file, the program must have write privileges to write to the file. After the file is created, the permissions need to be changed to read only.The following command recursively sets world-readable permissions for a directory and all of its children:. If this command is run from a program, the person calling the program might not expect that all the files under the directory will be world-readable. If the directory is expected to contain private data, this could become a security problem.The following Azure command updates the settings for a storage account:. However, \"Allow Blob Public Access\" is set to true, meaning that anonymous/public users can access blobs.The following Google Cloud Storage command gets the settings for a storage account named 'BUCKET_NAME':. Suppose the command returns the following result:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1004", "Name": "Sensitive Cookie Without 'HttpOnly' Flag", "Description": "Leverage the HttpOnly flag when setting a sensitive cookie in a response.", "Extended_Description": "The HttpOnly flag directs compatible browsers to prevent client-side script from accessing cookies. Including the HttpOnly flag in the Set-Cookie HTTP response header helps mitigate the risk associated with Cross-Site Scripting (XSS) where an attacker's script code might attempt to read the contents of a cookie and exfiltrate information obtained. When set, browsers that support the flag will not reveal the contents of the cookie to a third party via client-side script executed via XSS.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: If the HttpOnly flag is not set, then sensitive information stored in the cookie may be exposed to unintended parties.Scopes: Integrity. Impacts: Gain Privileges or Assume Identity. Note: If the cookie in question is an authentication cookie, then not setting the HttpOnly flag may allow an adversary to steal authentication data (e.g., a session ID) and assume the identity of the user.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Leverage the HttpOnly flag when setting a sensitive cookie in a response.", "Demonstrative_Examples": "In this example, a cookie is used to store a session ID for a client's interaction with a website. The intention is that the cookie will be sent to the website with each request made by the client.. The snippet of code below establishes a new cookie to hold the sessionID.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "451", "Name": "User Interface (UI) Misrepresentation of Critical Information", "Description": "Create a strategy for presenting information, and plan for how to display unusual characters.", "Extended_Description": "If an attacker can cause the UI to display erroneous data, or to otherwise convince the user to display information that appears to come from a trusted source, then the attacker could trick the user into performing the wrong action. This is often a component in phishing attacks, but other kinds of problems exist. For example, if the UI is used to monitor the security state of a system or network, then omitting or obscuring an important indicator could prevent the user from detecting and reacting to a security-critical event.UI misrepresentation can take many forms:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Perform data validation (e.g. syntax, length, etc.) before interpreting the data.Architecture and Design : Create a strategy for presenting information, and plan for how to display unusual characters.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "684", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "221", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "346", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1007", "Name": "Insufficient Visual Distinction of Homoglyphs Presented to User", "Description": "Use an email client that has strict filters and prevents messages that mix character sets to end up in a user's inbox.\n                  Certain email clients such as Google's GMail prevent the use of non-Latin characters in email addresses or in links contained within emails. This helps prevent homoglyph attacks by flagging these emails and redirecting them to a user's spam folder.", "Extended_Description": "Some glyphs, pictures, or icons can be semantically distinct to a program, while appearing very similar or identical to a human user. These are referred to as homoglyphs. For example, the lowercase \"l\" (ell) and uppercase \"I\" (eye) have different character codes, but these characters can be displayed in exactly the same way to a user, depending on the font. This can also occur between different character sets. For example, the Latin capital letter \"A\" and the Greek capital letter \"\u0391\" (Alpha) are treated as distinct by programs, but may be displayed in exactly the same way to a user. Accent marks may also cause letters to appear very similar, such as the Latin capital letter grave mark \"\u00c0\" and its equivalent \"\u00c1\" with the acute accent.Adversaries can exploit this visual similarity for attacks such as phishing, e.g. by providing a link to an attacker-controlled hostname that looks like a hostname that the victim trusts. In a different use of homoglyphs, an adversary may create a back door username that is visually similar to the username of a regular user, which then makes it more difficult for a system administrator to detect the malicious username while reviewing logs.", "Modes_Of_Introduction": "Architecture and Design: This weakness may occur when characters from various character sets are allowed to be interchanged within a URL, username, email address, etc. without any notification to the user or underlying system being used.", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Other. Note: An attacker may ultimately redirect a user to a malicious website, by deceiving the user into believing the URL they are accessing is a trusted domain. However, the attack can also be used to forge log entries by using homoglyphs in usernames. Homoglyph manipulations are often the first step towards executing advanced attacks such as stealing a user's credentials, Cross-Site Scripting (XSS), or log forgery. If an attacker redirects a user to a malicious site, the attacker can mimic a trusted domain to steal account credentials and perform actions on behalf of the user, without the user's knowledge. Similarly, an attacker could create a username for a website that contains homoglyph characters, making it difficult for an admin to review logs and determine which users performed which actions.", "Detection_Methods": "Method Name: Manual Dynamic Analysis. Description: If utilizing user accounts, attempt to submit a username that contains homoglyphs. Similarly, check to see if links containing homoglyphs can be sent via email, web browsers, or other mechanisms.", "Potential_Mitigations": "Implementation : Use a browser that displays Punycode for IDNs in the URL and status bars, or which color code various scripts in URLs.\n                  Due to the prominence of homoglyph attacks, several browsers now help safeguard against this attack via the use of Punycode. For example, Mozilla Firefox and Google Chrome will display IDNs as Punycode if top-level domains do not restrict which characters can be used in domain names or if labels mix scripts for different languages.Implementation : Use an email client that has strict filters and prevents messages that mix character sets to end up in a user's inbox.\n                  Certain email clients such as Google's GMail prevent the use of non-Latin characters in email addresses or in links contained within emails. This helps prevent homoglyph attacks by flagging these emails and redirecting them to a user's spam folder.", "Demonstrative_Examples": "The following looks like a simple, trusted URL that a user may frequently access.. However, the URL above is comprised of Cyrillic characters that look identical to the expected ASCII characters. This results in most users not being able to distinguish between the two and assuming that the above URL is trusted and safe. The \"e\" is actually the \"CYRILLIC SMALL LETTER IE\" which is represented in HTML as the character &#x435, while the \"a\" is actually the \"CYRILLIC SMALL LETTER A\" which is represented in HTML as the character &#x430.  The \"p\", \"c\", and \"o\" are also Cyrillic characters in this example. Viewing the source reveals a URL of \"http://www.&#x435;x&#x430;m&#x440;l&#x435;.&#x441;&#x43e;m\". An adversary can utilize this approach to perform an attack such as a phishing attack in order to drive traffic to a malicious website.The following displays an example of how creating usernames containing homoglyphs can lead to log forgery.. Assume an adversary visits a legitimate, trusted domain and creates an account named \"admin\", except the 'a' and 'i' characters are Cyrillic characters instead of the expected ASCII. Any actions the adversary performs will be saved to the log file and look like they came from a legitimate administrator account.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "451", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "694", "Name": "Use of Multiple Resources with Duplicate Identifier", "Description": "Where possible, use unique identifiers. If non-unique identifiers are detected, then do not operate any resource with a non-unique identifier and report the error appropriately.", "Extended_Description": "If the product assumes that each resource has a unique identifier, the product could operate on the wrong resource if attackers can cause multiple resources to be associated with the same identifier.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If unique identifiers are assumed when protecting sensitive resources, then duplicate identifiers might allow attackers to bypass the protection.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Where possible, use unique identifiers. If non-unique identifiers are detected, then do not operate any resource with a non-unique identifier and report the error appropriately.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "99", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": null}]}, {"ID": "102", "Name": "Struts: Duplicate Validation Forms", "Description": "The DTD or schema validation will not catch the duplicate occurrence of the same form name. To find the issue in the implementation, manual checks or automated static analysis could be applied to the xml configuration files.", "Extended_Description": "If two validation forms have the same name, the Struts Validator arbitrarily chooses one of the forms to use for input validation and discards the other. This decision might not correspond to the programmer's expectations, possibly leading to resultant weaknesses. Moreover, it indicates that the validation logic is not up-to-date, and can indicate that other, more subtle validation errors are present.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : The DTD or schema validation will not catch the duplicate occurrence of the same form name. To find the issue in the implementation, manual checks or automated static analysis could be applied to the xml configuration files.", "Demonstrative_Examples": "Two validation forms with the same name.. It is critically important that validation logic be maintained and kept in sync with the rest of the product.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "694", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1173", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1173", "Name": "Improper Use of Validation Framework", "Description": "Properly use provided input validation frameworks.", "Extended_Description": "Many modern coding languages provide developers with input validation frameworks to make the task of input validation easier and less error-prone. These frameworks will automatically check all input against specified criteria and direct execution to error handlers when invalid input is received. The improper use (i.e., an incorrect implementation or missing altogether) of these frameworks is not directly exploitable, but can lead to an exploitable condition if proper input validation is not performed later in the product. Not using provided input validation frameworks can also hurt the maintainability of code as future developers may not recognize the downstream input validation being used in the place of the validation framework.", "Modes_Of_Introduction": "Architecture and Design: This weakness may occur when software designers choose to not leverage input validation frameworks provided by the source language.Implementation: This weakness may occur when developers do not correctly use a provided input validation framework.", "Common_Consequences": "Scopes: Integrity. Impacts: Unexpected State. Note: Unchecked input leads to cross-site scripting, process control, and SQL injection vulnerabilities, among others.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Some instances of improper input validation can be detected using automated static analysis.A static analysis tool might allow the user to specify which application-specific methods or functions perform input validation; the tool might also have built-in knowledge of validation frameworks such as Struts. The tool may then suppress or de-prioritize any associated warnings. This allows the analyst to focus on areas of the software in which input validation does not appear to be present.Except in the cases described in the previous paragraph, automated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or require any code changes.", "Potential_Mitigations": "Implementation : Properly use provided input validation frameworks.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "20", "Name": "Improper Input Validation", "Description": "When exchanging data between components, ensure that both components are using the same character encoding. Ensure that the proper encoding is applied at each interface. Explicitly set the encoding you are using whenever the protocol allows you to do so.", "Extended_Description": "Input validation is a frequently-used technique\n\t   for checking potentially dangerous inputs in order to\n\t   ensure that the inputs are safe for processing within the\n\t   code, or when communicating with other components.  When\n\t   software does not validate input properly, an attacker is\n\t   able to craft the input in a form that is not expected by\n\t   the rest of the application. This will lead to parts of the\n\t   system receiving unintended input, which may result in\n\t   altered control flow, arbitrary control of a resource, or\n\t   arbitrary code execution.Input validation is not the only technique for\n\t   processing input, however.  Other techniques attempt to\n\t   transform potentially-dangerous input into something safe, such\n\t   as filtering (CWE-790) - which attempts to remove dangerous\n\t   inputs - or encoding/escaping (CWE-116), which attempts to\n\t   ensure that the input is not misinterpreted when it is included\n\t   in output to another component. Other techniques exist as well\n\t   (see CWE-138 for more examples.)Input validation can be applied to:Data can be simple or structured.  Structured data\n\t   can be composed of many nested layers, composed of\n\t   combinations of metadata and raw data, with other simple or\n\t   structured data.Many properties of raw data or metadata may need\n\t   to be validated upon entry into the code, such\n\t   as:Implied or derived properties of data must often\n\t   be calculated or inferred by the code itself.  Errors in\n\t   deriving properties may be considered a contributing factor\n\t   to improper input validation.Note that \"input validation\" has very different\n\t   meanings to different people, or within different\n\t   classification schemes.  Caution must be used when\n\t   referencing this CWE entry or mapping to it.  For example,\n\t   some weaknesses might involve inadvertently giving control\n\t   to an attacker over an input when they should not be able\n\t   to provide an input at all, but sometimes this is referred\n\t   to as input validation.Finally, it is important to emphasize that the\n\t   distinctions between input validation and output escaping\n\t   are often blurred, and developers must be careful to\n\t   understand the difference, including how input validation\n\t   is not always sufficient to prevent vulnerabilities,\n\t   especially when less stringent data types must be\n\t   supported, such as free-form text. Consider a SQL injection\n\t   scenario in which a person's last name is inserted into a\n\t   query. The name \"O'Reilly\" would likely pass the validation\n\t   step since it is a common last name in the English\n\t   language. However, this valid name cannot be directly\n\t   inserted into the database because it contains the \"'\"\n\t   apostrophe character, which would need to be escaped or\n\t   otherwise transformed. In this case, removing the\n\t   apostrophe might reduce the risk of SQL injection, but it\n\t   would produce incorrect behavior because the wrong name\n\t   would be recorded.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.If a programmer believes that an attacker cannot modify certain inputs, then the programmer might not perform any input validation at all. For example, in web applications, many programmers believe that cookies and hidden form fields can not be modified from a web browser (CWE-472), although they can be altered using a proxy or a custom program. In a client-server architecture, the programmer might assume that client-side security checks cannot be bypassed, even when a custom client could be written that skips those checks (CWE-602).", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: An attacker could provide unexpected values and cause a program crash or excessive consumption of resources, such as memory and CPU.Scopes: Confidentiality. Impacts: Read MemoryRead Files or Directories. Note: An attacker could read confidential data if they are able to control resource references.Scopes: IntegrityConfidentialityAvailability. Impacts: Modify MemoryExecute Unauthorized Code or Commands. Note: An attacker could use malicious input to modify data or possibly alter control flow in unexpected ways, including arbitrary command execution.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Some instances of improper input validation can be detected using automated static analysis.A static analysis tool might allow the user to specify which application-specific methods or functions perform input validation; the tool might also have built-in knowledge of validation frameworks such as Struts. The tool may then suppress or de-prioritize any associated warnings. This allows the analyst to focus on areas of the software in which input validation does not appear to be present.Except in the cases described in the previous paragraph, automated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or require any code changes. Method Name: Manual Static Analysis. Description: When custom input validation is required, such as when enforcing business rules, manual analysis is necessary to ensure that the validation is properly implemented. Method Name: Fuzzing. Description: Fuzzing techniques can be useful for detecting input validation errors. When unexpected inputs are provided to the software, the software should not crash or otherwise become unstable, and it should generate application-controlled error messages. If exceptions or interpreter-generated error messages occur, this indicates that the input was not detected and handled within the application logic itself. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Consider using language-theoretic security (LangSec) techniques that characterize inputs using a formal language and build \"recognizers\" for that language.  This effectively requires parsing to be a distinct layer that effectively enforces a boundary between raw input and internal data representations, instead of allowing parser code to be scattered throughout the program, where it could be subject to errors or inconsistencies that create weaknesses. [REF-1109] [REF-1110] [REF-1111]Architecture and Design : Use an input validation framework such as Struts or the OWASP ESAPI Validation API. Note that using a framework does not automatically address all input validation problems; be mindful of weaknesses that could arise from misusing the framework itself (CWE-1173).Architecture and Design : Understand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n                  Even though client-side checks provide minimal benefits with respect to server-side security, they are still useful. First, they can support intrusion detection. If the server receives input that should have been rejected by the client, then it may be an indication of an attack. Second, client-side error-checking can provide helpful feedback to the user about the expectations for valid input. Third, there may be a reduction in server-side processing time for accidental input errors, although this is typically a small savings.Implementation : When your application combines data from multiple sources, perform the validation after the sources have been combined. The individual data elements may pass the validation step but violate the intended restrictions after they have been combined.Implementation : Be especially careful to validate all input when invoking code that crosses language boundaries, such as from an interpreted language to native code. This could create an unexpected interaction between the language boundaries. Ensure that you are not violating any of the expectations of the language with which you are interfacing. For example, even though Java may not be susceptible to buffer overflows, providing a large argument in a call to native code might trigger an overflow.Implementation : Directly convert your input type into the expected data type, such as using a conversion function that translates a string into a number. After converting to the expected data type, ensure that the input's values fall within the expected range of allowable values and that multi-field consistencies are maintained.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180, CWE-181). Make sure that your application does not inadvertently decode the same input twice (CWE-174). Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization control.\n                  Consider performing repeated canonicalization until your input does not change any more. This will avoid double-decoding and similar scenarios, but it might inadvertently modify inputs that are allowed to contain properly-encoded dangerous content.Implementation : When exchanging data between components, ensure that both components are using the same character encoding. Ensure that the proper encoding is applied at each interface. Explicitly set the encoding you are using whenever the protocol allows you to do so.", "Demonstrative_Examples": "This example demonstrates a shopping interaction in which the user is free to specify the quantity of items to be purchased and a total is calculated.. The user has no control over the price variable, however the code does not prevent a negative value from being specified for quantity. If an attacker were to provide a negative value, then the user would have their account credited instead of debited.This example asks the user for a height and width of an m X n game board with a maximum dimension of 100 squares.. While this code checks to make sure the user cannot specify large, positive integers and consume too much memory, it does not check for negative values supplied by the user. As a result, an attacker can perform a resource consumption (CWE-400) attack against this program by specifying two, large negative values that will not overflow, resulting in a very large memory allocation (CWE-789) and possibly a system crash. Alternatively, an attacker can provide very large negative values which will cause an integer overflow (CWE-190) and unexpected behavior will follow depending on how the values are treated in the remainder of the program.The following example shows a PHP application in which the programmer attempts to display a user's birthday and homepage.. The programmer intended for $birthday to be in a date format and $homepage to be a valid URL. However, since the values are derived from an HTTP request, if an attacker can trick a victim into clicking a crafted URL with <script> tags providing the values for birthday and / or homepage, then the script will run on the client's browser when the web server echoes the content. Notice that even if the programmer were to defend the $birthday variable by restricting input to integers and dashes, it would still be possible for an attacker to provide a string of the form:The following example takes a user-supplied value to allocate an array of objects and then operates on the array.. This example attempts to build a list from a user-specified value, and even checks to ensure a non-negative value is supplied. If, however, a 0 value is provided, the code will build an array of size 0 and then try to store a new Widget in the first location, causing an exception to be thrown.This Android application has registered to handle a URL when sent an intent:. The application assumes the URL will always be included in the intent. When the URL is not present, the call to getStringExtra() will return null, thus causing a null pointer exception when length() is called.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "22", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "41", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "74", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "770", "View_ID": "1000", "Ordinal": null}]}, {"ID": "441", "Name": "Unintended Proxy or Intermediary ('Confused Deputy')", "Description": "Whenever a product is an intermediary or proxy for\n                   transactions between two other components, the proxy core\n                   should not drop the identity of the initiator of the\n                   transaction. The immutability of the identity of the\n                   initiator must be maintained and should be forwarded all the\n                   way to the target.", "Extended_Description": "If an attacker cannot directly contact a target, but the product has access to the target, then the attacker can send a request to the product and have it be forwarded to the target. The request would appear to be coming from the product's system, not the attacker's system. As a result, the attacker can bypass access controls (such as firewalls) or hide the source of malicious requests, since the requests would not be coming directly from the attacker.Since proxy functionality and message-forwarding often serve a legitimate purpose, this issue only becomes a vulnerability when:", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Enforce the use of strong mutual authentication mechanism between the two parties.Architecture and Design : Whenever a product is an intermediary or proxy for\n                   transactions between two other components, the proxy core\n                   should not drop the identity of the initiator of the\n                   transaction. The immutability of the identity of the\n                   initiator must be maintained and should be forwarded all the\n                   way to the target.", "Demonstrative_Examples": "A SoC contains a microcontroller (running ring-3\n                     (least trusted ring) code), a Memory Mapped Input Output\n                     (MMIO) mapped IP core (containing design-house secrets),\n                     and a Direct Memory Access (DMA) controller, among several\n                     other compute elements and peripherals. The SoC implements\n                     access control to protect the registers in the IP core\n                     (which registers store the design-house secrets) from\n                     malicious, ring-3 (least trusted ring) code executing on\n                     the microcontroller.  The DMA controller, however, is not\n                     blocked off from accessing the IP core for functional\n                     reasons.. The weakness here is that the intermediary or the\n                     proxy agent did not ensure the immutability of the\n                     identity of the microcontroller initiating the\n                     transaction.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "668", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1021", "Name": "Improper Restriction of Rendered UI Layers or Frames", "Description": "This defense-in-depth technique can be used to prevent the improper usage of frames in web applications. It prioritizes the valid sources of data to be loaded into the application through the usage of declarative policies. Based on which implementation of Content Security Policy is in use, the developer should use the \"frame-ancestors\" directive or the \"frame-src\" directive to mitigate this weakness. Both directives allow for the placement of restrictions when it comes to allowing embedded content.", "Extended_Description": "A web application is expected to place restrictions on whether it is allowed to be rendered within frames, iframes, objects, embed or applet elements. Without the restrictions, users can be tricked into interacting with the application when they were not intending to.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume IdentityBypass Protection MechanismRead Application DataModify Application Data. Note: An attacker can trick a user into performing actions that are masked and hidden from the user's view. The impact varies widely, depending on the functionality of the underlying application. For example, in a social media application, clickjacking could be used to trik the user into changing privacy settings.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : The use of X-Frame-Options allows developers of web content to restrict the usage of their application within the form of overlays, frames, or iFrames. The developer can indicate from which domains can frame the content.\n                  The concept of X-Frame-Options is well documented, but implementation of this protection mechanism is in development to cover gaps. There is a need for allowing frames from multiple domains.Implementation : A developer can use a \"frame-breaker\" script in each page that should not be framed. This is very helpful for legacy browsers that do not support X-Frame-Options security feature previously mentioned.\n                  It is also important to note that this tactic has been circumvented or bypassed. Improper usage of frames can persist in the web application through nested frames. The \"frame-breaking\" script does not intuitively account for multiple nested frames that can be presented to the user.Implementation : This defense-in-depth technique can be used to prevent the improper usage of frames in web applications. It prioritizes the valid sources of data to be loaded into the application through the usage of declarative policies. Based on which implementation of Content Security Policy is in use, the developer should use the \"frame-ancestors\" directive or the \"frame-src\" directive to mitigate this weakness. Both directives allow for the placement of restrictions when it comes to allowing embedded content.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "441", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "451", "View_ID": "1000", "Ordinal": null}]}, {"ID": "610", "Name": "Externally Controlled Reference to a Resource in Another Sphere", "Description": "The product uses an externally controlled name or reference that resolves to a resource that is outside of the intended control sphere.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "266", "Name": "Incorrect Privilege Assignment", "Description": "Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: A user can access restricted functionality and/or sensitive information that may include administrative functionality and user accounts.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.", "Demonstrative_Examples": ". The following example demonstrates the weakness.. The following example demonstrates the weakness.This application sends a special intent with a flag that allows the receiving application to read a data file for backup purposes.. Any malicious application can register to receive this intent. Because of the FLAG_GRANT_READ_URI_PERMISSION included with the intent, the malicious receiver code can read the user's data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "269", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "286", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1022", "Name": "Use of Web Link to Untrusted Target with window.opener Access", "Description": "Do not use \"_blank\" targets. However, this can affect the usability of the application.", "Extended_Description": "When a user clicks a link to an external site (\"target\"), the target=\"_blank\" attribute causes the target site's contents to be opened in a new window or tab, which runs in the same process as the original page. The window.opener object records information about the original page that offered the link.  If an attacker can run script on the target page, then they could read or modify certain properties of the window.opener object, including the location property - even if the original and target site are not the same origin.  An attacker can modify the location property to automatically redirect the user to a malicious site, e.g. as part of a phishing attack. Since this redirect happens in the original window/tab - which is not necessarily visible, since the browser is focusing the display on the new target page - the user might not notice any suspicious redirection.", "Modes_Of_Introduction": "Architecture and Design: This weakness is introduced during the design of an application when the architect does not specify that a linked external document should not be able to alter the location of the calling page.Implementation: This weakness is introduced during the coding of an application when the developer does not include the noopener and/or noreferrer value for the rel attribute.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Alter Execution Logic. Note: The user may be redirected to an untrusted page that contains undesired content or malicious script code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Specify in the design that any linked external document must not be granted access to the location object of the calling page.Implementation : When creating a link to an external document using the <a> tag with a defined target, for example \"_blank\" or a named frame, provide the rel attribute with a value \"noopener noreferrer\".\n                  If opening the external document in a new window via javascript, then reset the opener by setting it equal to null.Implementation : Do not use \"_blank\" targets. However, this can affect the usability of the application.", "Demonstrative_Examples": "In this example, the application opens a link in a named window/tab without taking precautions to prevent the called page from tampering with the calling page's location in the browser.. There are two ways that this weakness is commonly seen. The first is when the application generates an <a> tag is with target=\"_blank\" to point to a target site:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "266", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "697", "Name": "Incorrect Comparison", "Description": "The product compares two entities in a security-relevant context, but the comparison is incorrect, which may lead to resultant weaknesses.", "Extended_Description": "This Pillar covers several possibilities:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "Consider an application in which Truck objects are defined to be the same if they have the same make, the same model, and were manufactured in the same year.. Here, the equals() method only checks the make and model of the Truck objects, but the year of manufacture is not included.This example defines a fixed username and password. The AuthenticateUser() function is intended to accept a username and a password from an untrusted user, and check to ensure that it matches the username and password. If the username and password match, AuthenticateUser() is intended to indicate that authentication succeeded.. In AuthenticateUser(), the strncmp() call uses the string length of an attacker-provided inPass parameter in order to determine how many characters to check in the password. So, if the attacker only provides a password of length 1, the check will only examine the first byte of the application's password before determining success.", "Related_Weaknesses": []}, {"ID": "1023", "Name": "Incomplete Comparison with Missing Factors", "Description": "Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.", "Extended_Description": "An incomplete comparison can lead to resultant weaknesses, e.g., by operating on the wrong object or making a security decision without considering a required factor.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.", "Demonstrative_Examples": "Consider an application in which Truck objects are defined to be the same if they have the same make, the same model, and were manufactured in the same year.. Here, the equals() method only checks the make and model of the Truck objects, but the year of manufacture is not included.This example defines a fixed username and password. The AuthenticateUser() function is intended to accept a username and a password from an untrusted user, and check to ensure that it matches the username and password. If the username and password match, AuthenticateUser() is intended to indicate that authentication succeeded.. In AuthenticateUser(), the strncmp() call uses the string length of an attacker-provided inPass parameter in order to determine how many characters to check in the password. So, if the attacker only provides a password of length 1, the check will only examine the first byte of the application's password before determining success.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1024", "Name": "Comparison of Incompatible Types", "Description": "Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.", "Extended_Description": "In languages that are strictly typed but support casting/conversion, such as C or C++, the programmer might assume that casting one entity to the same type as another entity will ensure that the comparison will be performed correctly, but this cannot be guaranteed.  In languages that are not strictly typed, such as PHP or JavaScript, there may be implicit casting/conversion to a type that the programmer is unaware of, causing unexpected results; for example, the string \"123\" might be converted to a number type.  See examples.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1025", "Name": "Comparison Using Wrong Factors", "Description": "Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.", "Extended_Description": "This can lead to incorrect results and resultant weaknesses.  For example, the code might inadvertently compare references to objects, instead of the relevant contents of those objects, causing two \"equal\" objects to be considered unequal.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.", "Demonstrative_Examples": "In the example below, two Java String objects are declared and initialized with the same string values. An if statement is used to determine if the strings are equivalent.. However, the if statement will not be executed as the strings are compared using the \"==\" operator. For Java objects, such as String objects, the \"==\" operator compares object references, not object values. While the two String objects above contain the same string values, they refer to different object references, so the System.out.println statement will not be executed. To compare object values, the previous code could be modified to use the equals method:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "573", "Name": "Improper Following of Specification by Caller", "Description": "The product does not follow or incorrectly follows the specifications as required by the implementation language, environment, framework, protocol, or platform.", "Extended_Description": "When leveraging external functionality, such as an API, it is important that the caller does so in accordance with the requirements of the external functionality or else unintended behaviors may result, possibly leaving the system vulnerable to any number of exploits.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "103", "Name": "Struts: Incomplete validate() Method Definition", "Description": "Implement the validate() method and call super.validate() within that method.", "Extended_Description": "If the code does not call super.validate(), the Validation Framework cannot check the contents of the form against a validation form. In other words, the validation framework will be disabled for the given form.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Other. Note: Disabling the validation framework for a form exposes the product to numerous types of attacks. Unchecked input is the root cause of vulnerabilities like cross-site scripting, process control, and SQL injection.Scopes: ConfidentialityIntegrityAvailabilityOther. Impacts: Other. Note: Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Implement the validate() method and call super.validate() within that method.", "Demonstrative_Examples": "In the following Java example the class RegistrationForm is a Struts framework ActionForm Bean that will maintain user input data from a registration webpage for an online business site. The user will enter registration data and the RegistrationForm bean in the Struts framework will maintain the user data. Tthe RegistrationForm class implements the validate method to validate the user input entered into the form.. Although the validate method is implemented in this example the method does not call the validate method of the ValidatorForm parent class with a call super.validate(). Without the call to the parent validator class only the custom validation will be performed and the default validation will not be performed. The following example shows that the validate method of the ValidatorForm class is called within the implementation of the validate method.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1038", "Name": "Insecure Automated Optimizations", "Description": "The product uses a mechanism that automatically optimizes code, e.g. to improve a characteristic such as performance, but the optimizations can have an unintended side effect that might violate an intended security assumption.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: Optimizations built into the design of a product can have unintended consequences during execution.", "Common_Consequences": "Scopes: Integrity. Impacts: Alter Execution Logic. Note: The optimizations alter the order of execution resulting in side effects that were not intended by the original developer.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "435", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "758", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1037", "Name": "Processor Optimization Removal or Modification of Security-critical Code", "Description": "In theory this weakness can be detected through the use of white box testing techniques where specifically crafted test cases are used in conjunction with debuggers to verify the order of statements being executed.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: Optimizations built into the design of the processor can have unintended consequences during the execution of an application.", "Common_Consequences": "Scopes: Integrity. Impacts: Bypass Protection Mechanism. Note: A successful exploitation of this weakness will change the order of an application's execution and will likely be used to bypass specific protection mechanisms. This bypass can be exploited further to potentially read data that should otherwise be unaccessible.", "Detection_Methods": "Method Name: White Box. Description: In theory this weakness can be detected through the use of white box testing techniques where specifically crafted test cases are used in conjunction with debuggers to verify the order of statements being executed.", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1038", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "435", "Name": "Improper Interaction Between Multiple Correctly-Behaving Entities", "Description": "An interaction error occurs when two entities have correct behavior when running independently of each other, but when they are integrated as components in a larger system or process, they introduce incorrect behaviors that may cause resultant weaknesses.", "Extended_Description": "When a system or process combines multiple independent components, this often produces new, emergent behaviors at the system level.  However, if the interactions between these components are not fully accounted for, some of the emergent behaviors can be incorrect or even insecure.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": []}, {"ID": "758", "Name": "Reliance on Undefined, Unspecified, or Implementation-Defined Behavior", "Description": "Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Extended_Description": "This can lead to resultant weaknesses when the required properties change, such as when the product is ported to a different platform or if an interaction error (CWE-435) occurs.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "693", "Name": "Protection Mechanism Failure", "Description": "The product does not use or incorrectly uses a protection mechanism that provides sufficient defense against directed attacks against the product.", "Extended_Description": "This weakness covers three distinct situations. A \"missing\" protection mechanism occurs when the application does not define any mechanism against a certain class of attack. An \"insufficient\" protection mechanism might provide some defenses - for example, against the most common attacks - but it does not protect against everything that is intended. Finally, an \"ignored\" mechanism occurs when a mechanism is available and in active use within the product, but the developer has not applied it in some code path.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": []}, {"ID": "1039", "Name": "Automated Recognition Mechanism with Inadequate Detection or Handling of Adversarial Input Perturbations", "Description": "The product uses an automated mechanism such as machine learning to recognize complex data inputs (e.g. image or audio) as a particular concept or category, but it does not properly detect or handle inputs that have been modified or constructed in a way that causes the mechanism to detect a different, incorrect concept.", "Extended_Description": "When techniques such as machine learning are used to automatically classify input streams, and those classifications are used for security-critical decisions, then any mistake in classification can introduce a vulnerability that allows attackers to cause the product to make the wrong security decision.  If the automated mechanism is not developed or \"trained\" with enough input data, then attackers may be able to craft malicious input that intentionally triggers the incorrect classification.Targeted technologies include, but are not necessarily limited to:For example, an attacker might modify road signs or road surface markings to trick autonomous vehicles into misreading the sign/marking and performing a dangerous action.", "Modes_Of_Introduction": "Architecture and Design: This issue can be introduced into the automated algorithm itself.", "Common_Consequences": "Scopes: Integrity. Impacts: Bypass Protection Mechanism. Note: When the automated recognition is used in a protection mechanism, an attacker may be able to craft inputs that are misinterpreted in a way that grants excess privileges.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": null}]}, {"ID": "104", "Name": "Struts: Form Bean Does Not Extend Validation Class", "Description": "Ensure that all forms extend one of the Validation Classes.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Other. Note: Bypassing the validation framework for a form exposes the application to numerous types of attacks. Unchecked input is an important component of vulnerabilities like cross-site scripting, process control, and SQL injection.Scopes: ConfidentialityIntegrityAvailabilityOther. Impacts: Other. Note: Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Ensure that all forms extend one of the Validation Classes.", "Demonstrative_Examples": "In the following Java example the class RegistrationForm is a Struts framework ActionForm Bean that will maintain user information from a registration webpage for an online business site. The user will enter registration data and through the Struts framework the RegistrationForm bean will maintain the user data.. However, the RegistrationForm class extends the Struts ActionForm class which does not allow the RegistrationForm class to use the Struts validator capabilities. When using the Struts framework to maintain user data in an ActionForm Bean, the class should always extend one of the validator classes, ValidatorForm, ValidatorActionForm, DynaValidatorForm or DynaValidatorActionForm. These validator classes provide default validation and the validate method for custom validation for the Bean object to use for validating input data. The following Java example shows the RegistrationForm class extending the ValidatorForm class and implementing the validate method for validating input data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "710", "Name": "Improper Adherence to Coding Standards", "Description": "Where possible, use automated tools to enforce the standards.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Document and closely follow coding standards.Testing : Where possible, use automated tools to enforce the standards.", "Demonstrative_Examples": "", "Related_Weaknesses": []}, {"ID": "1041", "Name": "Use of Redundant Code", "Description": "Merge common functionality into a single function and then call that function from across the entire code base.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  For example, if there are two copies of the same code, the programmer might fix a weakness in one copy while forgetting to fix the same weakness in another copy.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Merge common functionality into a single function and then call that function from across the entire code base.", "Demonstrative_Examples": "In the following Java example the code performs some complex math when specific test conditions are met. The math is the same in each case and the equations are repeated within the code. Unfortunately if a future change needs to be made then that change needs to be made in all locations. This opens the door to mistakes being made and the changes not being made in the same way in each instance.. It is recommended to place the complex math into its own function and then call that function whenever necessary.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1176", "Name": "Inefficient CPU Computation", "Description": "The product performs CPU computations using\n         algorithms that are not as efficient as they could be for the\n         needs of the developer, i.e., the computations can be\n         optimized further.", "Extended_Description": "This issue can make the product perform more slowly, possibly in ways that are noticeable to the users.  If an attacker can influence the amount of computation that must be performed, e.g. by triggering worst-case complexity, then this performance problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1042", "Name": "Static Member Data Element outside of a Singleton Class Element", "Description": "The code contains a member element that is declared as static (but not final), in which\n\t\t\t\t\tits parent class element \n\t\t\t\t\tis not a singleton class - that is, a class element that can be used only once in\n\t\t\t\t\tthe 'to' association of a Create action.", "Extended_Description": "This issue can make the product perform more slowly.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1176", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1093", "Name": "Excessively Complex Data Representation", "Description": "The product uses an unnecessarily complex internal representation for its data structures or interrelationships between those structures.", "Extended_Description": "This issue makes it more difficult to understand or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1043", "Name": "Data Element Aggregating an Excessively Large Number of Non-Primitive Elements", "Description": "The product uses a data element that has an excessively large\n\t\t\t\t\tnumber of sub-elements with non-primitive data types such as structures or aggregated objects.", "Extended_Description": "This issue can make the product perform more slowly.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.While the interpretation of \"excessively large\" may vary for each product or developer, CISQ recommends a default of 5 sub-elements.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1093", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1044", "Name": "Architecture with Number of Horizontal Layers Outside of Expected Range", "Description": "The product's architecture contains too many - or too few -\n\t\t\t\t\thorizontal layers.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.While the interpretation of \"expected range\" may vary for each product or developer, CISQ recommends a default minimum of 4 layers and maximum of 8 layers.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1076", "Name": "Insufficient Adherence to Expected Conventions", "Description": "The product's architecture, source code, design, documentation,\n\t\t\t\t\tor other artifact does not follow required conventions.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1045", "Name": "Parent Class with a Virtual Destructor and a Child Class without a Virtual Destructor", "Description": "A parent class has a virtual destructor method, but the parent has a child class that does not have a virtual destructor.", "Extended_Description": "This issue can prevent the product from running reliably, since the child might not perform essential destruction operations.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability, such as a memory leak (CWE-401).", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1046", "Name": "Creation of Immutable Text Using String Concatenation", "Description": "The product creates an immutable text string using string concatenation operations.", "Extended_Description": "When building a string via a looping feature (e.g., a FOR or WHILE loop), the use of += to append to the existing string will result in the creation of a new object with each iteration. This programming pattern can be inefficient in comparison with use of text buffer data elements. This issue can make the product perform more slowly. If the relevant code is reachable by an attacker, then this could be influenced to create performance problem.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1176", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1120", "Name": "Excessive Code Complexity", "Description": "The code is too complex, as calculated using a well-defined,\n\t\t\t\t\tquantitative measure.", "Extended_Description": "This issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.This issue can make the product perform more slowly.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1047", "Name": "Modules with Circular Dependencies", "Description": "The product contains modules in which one module has references that cycle back to itself, i.e., there are circular dependencies.", "Extended_Description": "As an example, with Java, this weakness might indicate cycles between packages.This issue makes it more difficult to maintain the product due to insufficient modularity, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1048", "Name": "Invokable Control Element with Large Number of Outward Calls", "Description": "The code contains callable control elements that\n         contain an excessively large number of references to other\n         application objects external to the context of the callable,\n         i.e. a Fan-Out value that is excessively large.", "Extended_Description": "While the interpretation of \"excessively large Fan-Out value\" may vary for each product or developer, CISQ recommends a default of 5 referenced objects.This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1049", "Name": "Excessive Data Query Operations in a Large Data Table", "Description": "The product performs a data query with a large number of joins\n\t\t\t\t\tand sub-queries on a large data table.", "Extended_Description": "This issue can make the product perform more slowly.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.While the interpretation of \"large data table\" and \"large number of joins or sub-queries\" may vary for each product or developer, CISQ recommends a default of 1 million rows for a \"large\" data table, a default minimum of 5 joins, and a default minimum of 3 sub-queries.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1176", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "105", "Name": "Struts: Form Field Without Validator", "Description": "Validate all form fields. If a field is unused, it is still important to constrain it so that it is empty or undefined.", "Extended_Description": "Omitting validation for even a single input field may give attackers the leeway they need to compromise the product. Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.", "Modes_Of_Introduction": "Implementation: Some products use the same ActionForm for more than one purpose. In situations like this, some fields may go unused under some action mappings.", "Common_Consequences": "Scopes: Integrity. Impacts: Bypass Protection Mechanism. Note: If unused fields are not validated, shared business logic in an action may allow attackers to bypass the validation checks that are performed for other uses of the form.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Validate all form fields. If a field is unused, it is still important to constrain it so that it is empty or undefined.", "Demonstrative_Examples": "In the following example the Java class RegistrationForm is a Struts framework ActionForm Bean that will maintain user input data from a registration webpage for an online business site. The user will enter registration data and, through the Struts framework, the RegistrationForm bean will maintain the user data in the form fields using the private member variables. The RegistrationForm class uses the Struts validation capability by extending the ValidatorForm class and including the validation for the form fields within the validator XML file, validator.xml.. The validator XML file, validator.xml, provides the validation for the form fields of the RegistrationForm.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1173", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "405", "Name": "Asymmetric Resource Consumption (Amplification)", "Description": "Consider disabling resource-intensive algorithms on the server side, such as Diffie-Hellman key exchange.", "Extended_Description": "This can lead to poor performance due to \"amplification\" of resource consumption, typically in a non-linear fashion.  This situation is worsened if the product allows malicious users or attackers to consume more resources than their access level permits.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: AmplificationDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Resource Consumption (Other). Note: Sometimes this is a factor in \"flood\" attacks, but other types of amplification exist.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : An application must make resources available to a client commensurate with the client's access level.Architecture and Design : An application must, at all times, keep track of allocated resources and meter their usage appropriately.System Configuration : Consider disabling resource-intensive algorithms on the server side, such as Diffie-Hellman key exchange.", "Demonstrative_Examples": "This code listens on a port for DNS requests and sends the result to the requesting address.. This code sends a DNS record to a requesting IP address. UDP allows the source IP address to be easily changed ('spoofed'), thus allowing an attacker to redirect responses to a target, which may be then be overwhelmed by the network traffic.This data prints the contents of a specified file requested by a user.. This code first reads a specified file into memory, then prints the file if the user is authorized to see its contents. The read of the file into memory may be resource intensive and is unnecessary if the user is not allowed to see the file anyway.. The DTD and the very brief XML below illustrate what is meant by an XML bomb. The ZERO entity contains one character, the letter A. The choice of entity name ZERO is being used to indicate length equivalent to that exponent on two, that is, the length of ZERO is 2^0. Similarly, ONE refers to ZERO twice, therefore the XML parser will expand ONE to a length of 2, or 2^1. Ultimately, we reach entity THIRTYTWO, which will expand to 2^32 characters in length, or 4 GB, probably consuming far more data than expected.This example attempts to check if an input string is a \"sentence\" [REF-1164].. The regular expression has a vulnerable backtracking clause inside (\\w+\\s?)*$ which can be triggered to cause a Denial of Service by processing particular phrases.To fix the backtracking problem, backtracking is removed with the ?= portion of the expression which changes it to a lookahead and the \\2 which prevents the backtracking. The modified example is:. An adversary can cause significant resource\n\t     consumption on a server by filtering the cryptographic\n\t     algorithms offered by the client to the ones that are the\n\t     most resource-intensive on the server side. After\n\t     discovering which cryptographic algorithms are supported\n\t     by the server, a malicious client can send the initial\n\t     cryptographic handshake messages that contains only the\n\t     resource-intensive algorithms. For some cryptographic\n\t     protocols, these messages can be completely\n\t     prefabricated, as the resource-intensive part of the\n\t     handshake happens on the server-side first (such as TLS),\n\t     rather than on the client side. In the case of\n\t     cryptographic protocols where the resource-intensive part\n\t     should happen on the client-side first (such as SSH), a\n\t     malicious client can send a forged/precalculated\n\t     computation result, which seems correct to the server, so\n\t     the resource-intensive part of the handshake is going to\n\t     happen on the server side. A malicious client is required\n\t     to send only the initial messages of a cryptographic\n\t     handshake to initiate the resource-consuming part of the\n\t     cryptographic handshake. These messages are usually\n\t     small, and generating them requires minimal computational\n\t     effort, enabling a denial-of-service attack. An\n\t     additional risk is the fact that higher key size\n\t     increases the effectiveness of the attack. Cryptographic\n\t     protocols where the clients have influence over the size\n\t     of the used key (such as TLS 1.3 or SSH) are most at\n\t     risk, as the client can enforce the highest key size\n\t     supported by the server.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1050", "Name": "Excessive Platform Resource Consumption within a Loop", "Description": "The product has a loop body or loop condition that contains a control element that directly or\n\t\t\t\t\tindirectly consumes platform resources, e.g. messaging, sessions, locks, or file\n\t\t\t\t\tdescriptors.", "Extended_Description": "This issue can make the product perform more slowly.  If an attacker can influence the number of iterations in the loop, then this performance problem might allow a denial of service by consuming more platform resources than intended.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "665", "Name": "Improper Initialization", "Description": "Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.", "Extended_Description": "This can have security implications when the associated resource is expected to have certain properties or values, such as a variable that determines whether a user has been authenticated or not.", "Modes_Of_Introduction": "Implementation: This weakness can occur in code paths that are not well-tested, such as rare error conditions. This is because the use of uninitialized data would be noticed as a bug during frequently-used functionality.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read MemoryRead Application Data. Note: When reusing a resource such as memory or a program variable, the original contents of that resource may not be cleared before it is sent to an untrusted party.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If security-critical decisions rely on a variable having a \"0\" or equivalent value, and the programming language performs this initialization on behalf of the programmer, then a bypass of security may occur.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: The uninitialized data may contain values that cause program flow to change in ways that the programmer did not intend. For example, if an uninitialized variable is used as an array index in C, then its previous contents may produce an index that is outside the range of the array, possibly causing a crash or an exit in other environments.", "Detection_Methods": "Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.Initialization problems may be detected with a stress-test by calling the software simultaneously from a large number of threads or processes, and look for evidence of any unexpected behavior. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Dynamic Analysis. Description: Identify error conditions that are not likely to occur during normal usage and trigger them. For example, run the program under low memory conditions, run with insufficient privileges or permissions, interrupt a transaction before it is completed, or disable connectivity to basic network services such as DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled exception or similar error that was discovered and handled by the application's environment, it may still indicate unexpected conditions that were not handled by the application itself. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, in Java, if the programmer does not explicitly initialize a variable, then the code could produce a compile-time error (if the variable is local) or automatically initialize the variable to the default value for the variable's type. In Perl, if explicit initialization is not performed, then a default value of undef is assigned, which is interpreted as 0, false, or an equivalent value depending on the context in which the variable is accessed.Architecture and Design : Identify all variables and data stores that receive information from external sources, and apply input validation to make sure that they are only initialized to expected values.Implementation : Explicitly initialize all your variables and other data stores, either during declaration or just before the first usage.Implementation : Pay close attention to complex conditionals that affect initialization, since some conditions might not perform the initialization.Implementation : Avoid race conditions (CWE-362) during initialization routines.Build and Compilation : Run or compile your product with settings that generate warnings about uninitialized variables or data.Testing : Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.", "Demonstrative_Examples": ". Here, a boolean initiailized field is consulted to ensure that initialization tasks are only completed once. However, the field is mistakenly set to true during static initialization, so the initialization code is never reached.The following code intends to limit certain operations to the administrator only.. If the application is unable to extract the state information - say, due to a database timeout - then the $uid variable will not be explicitly set by the programmer. This will cause $uid to be regarded as equivalent to \"0\" in the conditional, allowing the original user to perform administrator actions. Even if the attacker cannot directly influence the state data, unexpected errors could cause incorrect privileges to be assigned to a user just by accident.The following code intends to concatenate a string to a variable and print the string.. This might seem innocent enough, but str was not initialized, so it contains random memory. As a result, str[0] might not contain the null terminator, so the copy might start at an offset other than 0. The consequences can vary, depending on the underlying memory.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1051", "Name": "Initialization with Hard-Coded Network Resource Configuration Data", "Description": "The product initializes data using hard-coded values that act as network resource identifiers.", "Extended_Description": "This issue can prevent the product from running reliably, e.g. if it runs in an environment does not use the hard-coded network resource identifiers. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1052", "Name": "Excessive Use of Hard-Coded Literals in Initialization", "Description": "The product initializes a data element using a hard-coded\n\t\t\t\t\tliteral that is not a simple integer or static constant element.", "Extended_Description": "This issue makes it more difficult to modify or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1059", "Name": "Insufficient Technical Documentation", "Description": "Ensure that design documentation is detailed enough to allow for post-manufacturing verification.", "Extended_Description": "When technical documentation is limited or lacking, products are more difficult to maintain.  This indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.When using time-limited or labor-limited third-party/in-house security consulting services (such as threat modeling, vulnerability discovery, or pentesting), insufficient documentation can force those consultants to invest unnecessary time in learning how the product is organized, instead of focusing their expertise on finding the flaws or suggesting effective mitigations.With respect to hardware design, the lack of a formal, final manufacturer reference can make it difficult or impossible to evaluate the final product, including post-manufacture verification. One cannot ensure that design functionality or operation is within acceptable tolerances, conforms to specifications, and is free from unexpected behavior. Hardware-related documentation may include engineering artifacts such as hardware description language (HDLs), netlists, Gerber files, Bills of Materials, EDA (Electronic Design Automation) tool files, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Varies by ContextHide ActivitiesReduce ReliabilityQuality DegradationReduce Maintainability. Note: Without a method of verification, one cannot be sure that everything only functions as expected.", "Detection_Methods": "", "Potential_Mitigations": "Documentation : Ensure that design documentation is detailed enough to allow for post-manufacturing verification.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1053", "Name": "Missing Documentation for Design", "Description": "The product does not have documentation that represents how it is designed.", "Extended_Description": "This issue can make it more difficult to understand and maintain the product. It can make it more difficult and time-consuming to detect and/or fix vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1059", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1061", "Name": "Insufficient Encapsulation", "Description": "The product does not sufficiently hide the internal representation and implementation details of data or methods, which might allow external components or modules to modify data unexpectedly, invoke unexpected functionality, or introduce dependencies that the programmer did not intend.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1054", "Name": "Invocation of a Control Element at an Unnecessarily Deep Horizontal Layer", "Description": "The code at one architectural layer invokes code that resides\n\t\t\t\t\tat a deeper layer than the adjacent layer, i.e., the invocation skips at least one\n\t\t\t\t\tlayer, and the invoked code is not part of a vertical utility layer that can be referenced from any horizontal layer.", "Extended_Description": "This issue makes it more difficult to understand and maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1061", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1055", "Name": "Multiple Inheritance from Concrete Classes", "Description": "The product contains a class with inheritance from more than\n\t\t\t\t\tone concrete class.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1093", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1056", "Name": "Invokable Control Element with Variadic Parameters", "Description": "A named-callable or method control element has a signature that\n\t\t\t\t\tsupports a variable (variadic) number of parameters or arguments.", "Extended_Description": "This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.With variadic arguments, it can be difficult or inefficient for manual analysis to be certain of which function/method is being invoked.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1057", "Name": "Data Access Operations Outside of Expected Data Manager Component", "Description": "The product uses a dedicated, central data manager component as required by design, but it contains code that performs data-access operations that do not use this data manager.", "Extended_Description": "This issue can make the product perform more slowly than intended, since the intended central data manager may have been explicitly optimized for performance or other quality characteristics.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1061", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "662", "Name": "Improper Synchronization", "Description": "Use industry standard APIs to synchronize your code.", "Extended_Description": "Synchronization refers to a variety of behaviors and mechanisms that allow two or more independently-operating processes or threads to ensure that they operate on shared resources in predictable ways that do not interfere with each other.  Some shared resource operations cannot be executed atomically; that is, multiple steps must be guaranteed to execute sequentially, without any interference by other processes.  Synchronization mechanisms vary widely, but they may include locking, mutexes, and semaphores.  When a multi-step operation on a shared resource cannot be guaranteed to execute independent of interference, then the resulting behavior can be unpredictable. Improper synchronization could lead to data or memory corruption, denial of service, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use industry standard APIs to synchronize your code.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "362", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1058", "Name": "Invokable Control Element in Multi-Thread Context with non-Final Static Storable or Member Element", "Description": "The code contains a function or method that\n\t\t operates in a multi-threaded environment but owns an unsafe non-final\n\t\t                     static storable or member data element.", "Extended_Description": "This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "106", "Name": "Struts: Plug-in Framework not in Use", "Description": "Use the Struts Validator to validate all program input before it is processed by the application. Ensure that there are no holes in the configuration of the Struts Validator. Example uses of the validator include checking to ensure that:\n                     \n                        Phone number fields contain only valid characters in phone numbers\n                        Boolean values are only \"T\" or \"F\"\n                        Free-form strings are of a reasonable length and composition", "Extended_Description": "Unchecked input is the leading cause of vulnerabilities in J2EE applications. Unchecked input leads to cross-site scripting, process control, and SQL injection vulnerabilities, among others.Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use an input validation framework such as Struts.Architecture and Design : Use an input validation framework such as Struts.Implementation : Use the Struts Validator to validate all program input before it is processed by the application. Ensure that there are no holes in the configuration of the Struts Validator. Example uses of the validator include checking to ensure that:\n                     \n                        Phone number fields contain only valid characters in phone numbers\n                        Boolean values are only \"T\" or \"F\"\n                        Free-form strings are of a reasonable length and compositionImplementation : Use the Struts Validator to validate all program input before it is processed by the application. Ensure that there are no holes in the configuration of the Struts Validator. Example uses of the validator include checking to ensure that:\n                     \n                        Phone number fields contain only valid characters in phone numbers\n                        Boolean values are only \"T\" or \"F\"\n                        Free-form strings are of a reasonable length and composition", "Demonstrative_Examples": "In the following Java example the class RegistrationForm is a Struts framework ActionForm Bean that will maintain user input data from a registration webpage for an online business site. The user will enter registration data and, through the Struts framework, the RegistrationForm bean will maintain the user data.. However, the RegistrationForm class extends the Struts ActionForm class which does use the Struts validator plug-in to provide validator capabilities. In the following example, the RegistrationForm Java class extends the ValidatorForm and Struts configuration XML file, struts-config.xml, instructs the application to use the Struts validator plug-in.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1173", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1060", "Name": "Excessive Number of Inefficient Server-Side Data Accesses", "Description": "The product performs too many data queries without using efficient data processing functionality such as stored procedures.", "Extended_Description": "This issue can make the product perform more slowly due to computational expense.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.While the interpretation of \"too many data queries\" may vary for each product or developer, CISQ recommends a default maximum of 5 data queries for an inefficient function/procedure.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1062", "Name": "Parent Class with References to Child Class", "Description": "The code has a parent class that contains references to a child class, its methods, or its members.", "Extended_Description": "This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1061", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1063", "Name": "Creation of Class Instance within a Static Code Block", "Description": "A static code block creates an instance of a class.", "Extended_Description": "This pattern identifies situations where a storable data element or member data element is initialized with a value in a block of code which is declared as static.This issue can make the product perform more slowly by performing initialization before it is needed.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1176", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1064", "Name": "Invokable Control Element with Signature Containing an Excessive Number of Parameters", "Description": "The product contains a function, subroutine, or method whose signature has an unnecessarily large number of\n\t\t\t\t\tparameters/arguments.", "Extended_Description": "This issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.While the interpretation of \"large number of parameters.\" may vary for each product or developer, CISQ recommends a default maximum of 7 parameters/arguments.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1065", "Name": "Runtime Resource Management Control Element in a Component Built to Run on Application Servers", "Description": "The product uses deployed components from application servers, but it also uses low-level functions/methods for management of resources, instead of the API provided by the application server.", "Extended_Description": "This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1066", "Name": "Missing Serialization Control Element", "Description": "The product contains a serializable data element that does not\n\t\t\t\t\thave an associated serialization method.", "Extended_Description": "This issue can prevent the product from running reliably, e.g. by triggering an exception.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.As examples, the serializable nature of a data element comes from a serializable SerializableAttribute attribute in .NET and the inheritance from the java.io.Serializable interface in Java.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1067", "Name": "Excessive Execution of Sequential Searches of Data Resource", "Description": "The product contains a data query against an SQL table or view\n\t\t\t\t\tthat is configured in a way that does not utilize an index and may cause\n\t\t\t\t\tsequential searches to be performed.", "Extended_Description": "This issue can make the product perform more slowly.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1176", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1068", "Name": "Inconsistency Between Implementation and Documented Design", "Description": "The implementation of the product is not consistent with the\n\t\t\t\t\tdesign as described within the relevant documentation.", "Extended_Description": "This issue makes it more difficult to maintain the product due to inconsistencies, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1071", "Name": "Empty Code Block", "Description": "The source code contains a block that does not contain any code, i.e., the block is empty.", "Extended_Description": "Empty code blocks can occur in the bodies of conditionals, function or method definitions, exception handlers, etc.  While an empty code block might be intentional, it might also indicate incomplete implementation, accidental code deletion, unexpected macro expansion, etc.  For some programming languages and constructs, an empty block might be allowed by the syntax, but the lack of any behavior within the block might violate a convention or API in such a way that it is an error.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1164", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1069", "Name": "Empty Exception Block", "Description": "For every exception block add code that handles the specific exception in the way intended by the application.", "Extended_Description": "When an exception handling block (such as a Catch and Finally block) is used, but that block is empty, this can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : For every exception block add code that handles the specific exception in the way intended by the application.", "Demonstrative_Examples": "In the following Java example, the code catches an ArithmeticException.. Since the exception block is empty, no action is taken.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1071", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1164", "Name": "Irrelevant Code", "Description": "The product contains code that is not essential for execution,\n\t     i.e. makes no state changes and has no side effects that alter\n\t     data or control flow, such that removal of the code would have no impact\n\t     to functionality or correctness.", "Extended_Description": "Irrelevant code could include dead code,\n\t     initialization that is not used, empty blocks, code that could be entirely\n\t     removed due to optimization, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "107", "Name": "Struts: Unused Validation Form", "Description": "Remove the unused Validation Form from the validation.xml file.", "Extended_Description": "It is easy for developers to forget to update validation logic when they remove or rename action form mappings. One indication that validation logic is not being properly maintained is the presence of an unused validation form.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Remove the unused Validation Form from the validation.xml file.", "Demonstrative_Examples": "In the following example the class RegistrationForm is a Struts framework ActionForm Bean that will maintain user input data from a registration webpage for an online business site. The user will enter registration data and, through the Struts framework, the RegistrationForm bean will maintain the user data in the form fields using the private member variables. The RegistrationForm class uses the Struts validation capability by extending the ValidatorForm class and including the validation for the form fields within the validator XML file, validator.xml.. However, the validator XML file, validator.xml, for the RegistrationForm class includes the validation form for the user input form field \"phone\" that is no longer used by the input form and the RegistrationForm class. Any validation forms that are no longer required should be removed from the validator XML file, validator.xml.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1164", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1070", "Name": "Serializable Data Element Containing non-Serializable Item Elements", "Description": "The product contains a serializable, storable data element such as a field or member,\n\t\t\t\t\tbut the data element contains member elements that are not\n\t\t\t\t\tserializable.", "Extended_Description": "This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.As examples, the serializable nature of a data element comes from a serializable SerializableAttribute attribute in .NET and the inheritance from the java.io.Serializable interface in Java.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1072", "Name": "Data Resource Access without Use of Connection Pooling", "Description": "The product accesses a data resource through a database without using a\n\t\t\t\t\tconnection pooling capability.", "Extended_Description": "This issue can make the product perform more slowly, as connection pools allow connections to be reused without the overhead and time consumption of opening and closing a new connection.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1073", "Name": "Non-SQL Invokable Control Element with Excessive Number of Data Resource Accesses", "Description": "The product contains a client with a function or method that contains a large number of data accesses/queries that are sent through a data manager, i.e., does not use efficient database capabilities.", "Extended_Description": "This issue can make the product perform more slowly.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.While the interpretation of \"large number of data accesses/queries\" may vary for each product or developer, CISQ recommends a default maximum of 2 data accesses per function/method.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1074", "Name": "Class with Excessively Deep Inheritance", "Description": "A class has an inheritance level that is too high, i.e., it\n\t\t\t\t\thas a large number of parent classes.", "Extended_Description": "This issue makes it more difficult to understand and maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.While the interpretation of \"large number of parent classes\" may vary for each product or developer, CISQ recommends a default maximum of 7 parent classes.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1093", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1075", "Name": "Unconditional Control Flow Transfer outside of Switch Block", "Description": "The product performs unconditional control transfer (such as a\n\t\t\t\t\t\"goto\") in code outside of a branching structure such as a switch\n\t\t\t\t\tblock.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1077", "Name": "Floating Point Comparison with Incorrect Operator", "Description": "The code performs a comparison such as an\n        equality test between two float (floating point) values, but\n        it uses comparison operators that do not account for the\n        possibility of loss of precision.", "Extended_Description": "Numeric calculation using floating point values\n\t   can generate imprecise results because of rounding errors.\n\t   As a result, two different calculations might generate\n\t   numbers that are mathematically equal, but have slightly\n\t   different bit representations that do not translate to the\n\t   same mathematically-equal values.  As a result, an equality\n\t   test or other comparison might produce unexpected\n\t   results.This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1078", "Name": "Inappropriate Source Code Style or Formatting", "Description": "The source code does not follow\n\t\t\t\tdesired style or formatting for indentation, white\n\t\t\t\tspace, comments, etc.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1079", "Name": "Parent Class without Virtual Destructor Method", "Description": "A parent class contains one or more child classes, but the parent class does not have a virtual destructor method.", "Extended_Description": "This issue can prevent the product from running reliably due to undefined or unexpected behaviors.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "108", "Name": "Struts: Unvalidated Action Form", "Description": "Map every Action Form to a corresponding validation form.\n                  An action or a form may perform validation in other ways, but the Struts Validator provides an excellent way to verify that all input receives at least a basic level of validation. Without this approach, it is difficult, and often impossible, to establish with a high level of confidence that all input is validated.", "Extended_Description": "If a Struts Action Form Mapping specifies a form, it must have a validation form defined under the Struts Validator.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Other. Note: If an action form mapping does not have a validation form defined, it may be vulnerable to a number of attacks that rely on unchecked input. Unchecked input is the root cause of some of today's worst and most common software security problems. Cross-site scripting, SQL injection, and process control vulnerabilities all stem from incomplete or absent input validation.Scopes: ConfidentialityIntegrityAvailabilityOther. Impacts: Other. Note: Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Map every Action Form to a corresponding validation form.\n                  An action or a form may perform validation in other ways, but the Struts Validator provides an excellent way to verify that all input receives at least a basic level of validation. Without this approach, it is difficult, and often impossible, to establish with a high level of confidence that all input is validated.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1173", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1080", "Name": "Source Code File with Excessive Number of Lines of Code", "Description": "A source code file has too many lines of\n\t\t\t\t\tcode.", "Extended_Description": "This issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.While the interpretation of \"too many lines of code\" may vary for each product or developer, CISQ recommends a default threshold value of 1000.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1082", "Name": "Class Instance Self Destruction Control Element", "Description": "The code contains a class instance that calls the method or function to delete or destroy itself.", "Extended_Description": "For example, in C++, \"delete this\" will cause the object to delete itself.This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1083", "Name": "Data Access from Outside Expected Data Manager Component", "Description": "The product is intended to manage data access through a particular data manager component such as a relational or non-SQL database, but it contains code that performs data access operations without using that component.", "Extended_Description": "When the product has a data access component, the design may be intended to handle all data access operations through that component.  If a data access operation is performed outside of that component, then this may indicate a violation of the intended design.This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1061", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1084", "Name": "Invokable Control Element with Excessive File or Data Access Operations", "Description": "A function or method contains too many\n\t\t\t\t\toperations that utilize a data manager or file resource.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.While the interpretation of \"too many operations\" may vary for each product or developer, CISQ recommends a default maximum of 7 operations for the same data manager or file.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1085", "Name": "Invokable Control Element with Excessive Volume of Commented-out Code", "Description": "A function, method, procedure, etc. contains an excessive amount of code that has been\n\t\t\t\t\tcommented out within its body.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.While the interpretation of \"excessive volume\" may vary for each product or developer, CISQ recommends a default threshold of 2% of commented code.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1086", "Name": "Class with Excessive Number of Child Classes", "Description": "A class contains an unnecessarily large number of\n\t\t\t\t\tchildren.", "Extended_Description": "This issue makes it more difficult to understand and maintain the software, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.While the interpretation of \"large number of children\" may vary for each product or developer, CISQ recommends a default maximum of 10 child classes.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1093", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1087", "Name": "Class with Virtual Method without a Virtual Destructor", "Description": "A class contains a virtual method, but the method does not have an associated virtual destructor.", "Extended_Description": "This issue can prevent the product from running reliably, e.g. due to undefined behavior.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "821", "Name": "Incorrect Synchronization", "Description": "The product utilizes a shared resource in a concurrent manner, but it does not correctly synchronize access to the resource.", "Extended_Description": "If access to a shared resource is not correctly synchronized, then the resource may not be in a state that is expected by the product. This might lead to unexpected or insecure behaviors, especially if an attacker can influence the shared resource.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1088", "Name": "Synchronous Access of Remote Resource without Timeout", "Description": "The code has a synchronous call to a remote resource, but there is no timeout for the call, or the timeout is set to infinite.", "Extended_Description": "This issue can prevent the product from running reliably, since an outage for the remote resource can cause the product to hang.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "821", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1089", "Name": "Large Data Table with Excessive Number of Indices", "Description": "The product uses a large data table that contains an excessively large number of\n\t\t\t\t\tindices.", "Extended_Description": "This issue can make the product perform more slowly.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.While the interpretation of \"large data table\" and \"excessively large number of indices\" may vary for each product or developer, CISQ recommends a default threshold of 1000000 rows for a \"large\" table and a default threshold of 3 indices.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "109", "Name": "Struts: Validator Turned Off", "Description": "Ensure that an action form mapping enables validation. Set the validate field to true.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Ensure that an action form mapping enables validation. Set the validate field to true.", "Demonstrative_Examples": "This mapping defines an action for a download form:. This mapping has disabled validation. Disabling validation exposes this action to numerous types of attacks.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1173", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1090", "Name": "Method Containing Access of a Member Element from Another Class", "Description": "A method for a class performs an operation that directly\n\t\t\t\t\taccesses a member element from another class.", "Extended_Description": "This issue suggests poor encapsulation and makes it more difficult to understand and maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1061", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "772", "Name": "Missing Release of Resource after Effective Lifetime", "Description": "Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Extended_Description": "When a resource is not released after use, it can allow attackers to cause a denial of service by causing the allocation of resources without triggering their release. Frequently-affected resources include memory, CPU, disk space, power or battery, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: An attacker that can influence the allocation of resources that are not properly released could deplete the available resource pool and prevent all other processes from accessing the same type of resource.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, languages such as Java, Ruby, and Lisp perform automatic garbage collection that releases memory for objects that have been deallocated.Implementation : It is good practice to be responsible for freeing all resources you allocate and to be consistent with how and where you free resources in a function. If you allocate resources that you intend to free upon completion of the function, you must be sure to free the resources at all exit points for that function including error conditions.Operation : Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Demonstrative_Examples": "The following method never closes the new file handle. Given enough time, the Finalize() method for BufferReader should eventually call Close(), but there is no guarantee as to how long this action will take. In fact, there is no guarantee that Finalize() will ever be invoked. In a busy environment, the Operating System could use up all of the available file handles before the Close() function is called.. The good code example simply adds an explicit call to the Close() function when the system is done using the file. Within a simple example such as this the problem is easy to see and fix. In a real system, the problem may be considerably more obscure.The following code attempts to open a new connection to a database, process the results returned by the database, and close the allocated SqlConnection object.. The problem with the above code is that if an exception occurs while executing the SQL or processing the results, the SqlConnection object is not closed. If this happens often enough, the database will run out of available cursors and not be able to execute any more SQL queries.This code attempts to open a connection to a database and catches any exceptions that may occur.. If an exception occurs after establishing the database connection and before the same connection closes, the pool of database connections may become exhausted. If the number of available connections is exceeded, other users cannot access this resource, effectively denying access to the application.. Under normal conditions the following C# code executes a database query, processes the results returned by the database, and closes the allocated SqlConnection object. But if an exception occurs while executing the SQL or processing the results, the SqlConnection object is not closed. If this happens often enough, the database will run out of available cursors and not be able to execute any more SQL queries.. The following C function does not close the file handle it opens if an error occurs. If the process is long-lived, the process can run out of file handles.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1091", "Name": "Use of Object without Invoking Destructor Method", "Description": "The product contains a method that accesses an object but does not later invoke\n\t\t\t\t\tthe element's associated finalize/destructor method.", "Extended_Description": "This issue can make the product perform more slowly by retaining memory and/or other resources longer than necessary.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "772", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1092", "Name": "Use of Same Invokable Control Element in Multiple Architectural Layers", "Description": "The product uses the same control element across multiple\n\t\t\t\t\tarchitectural layers.", "Extended_Description": "This issue makes it more difficult to understand and maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1094", "Name": "Excessive Index Range Scan for a Data Resource", "Description": "The product contains an index range scan for a large data table,\n\t\t\t\t\tbut the scan can cover a large number of rows.", "Extended_Description": "This issue can make the product perform more slowly.  If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.While the interpretation of \"large data table\" and \"excessive index range\" may vary for each product or developer, CISQ recommends a threshold of 1000000 table rows and a threshold of 10 for the index range.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1095", "Name": "Loop Condition Value Update within the Loop", "Description": "The product uses a loop with a control flow condition based on\n\t\t\t\t\ta value that is updated within the body of the loop.", "Extended_Description": "This issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "820", "Name": "Missing Synchronization", "Description": "The product utilizes a shared resource in a concurrent manner but does not attempt to synchronize access to the resource.", "Extended_Description": "If access to a shared resource is not synchronized, then the resource may not be in a state that is expected by the product. This might lead to unexpected or insecure behaviors, especially if an attacker can influence the shared resource.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code intends to fork a process, then have both the parent and child processes print a single line.. One might expect the code to print out something like:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1096", "Name": "Singleton Class Instance Creation without Proper Locking or Synchronization", "Description": "The product implements a Singleton design pattern but does not use appropriate locking or other synchronization mechanism to ensure that the singleton class is only instantiated once.", "Extended_Description": "This issue can prevent the product from running reliably, e.g. by making the instantiation process non-thread-safe and introducing deadlock (CWE-833) or livelock conditions.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "820", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1097", "Name": "Persistent Storable Data Element without Associated Comparison Control Element", "Description": "The product uses a storable data element that does not have\n\t\t\t\t\tall of the associated functions or methods that are necessary to support\n\t\t\t\t\tcomparison.", "Extended_Description": "For example, with Java, a class that is made persistent requires both hashCode() and equals() methods to be defined.This issue can prevent the product from running reliably, due to incorrect or unexpected comparison results.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "595", "View_ID": "1305", "Ordinal": "Primary"}]}, {"ID": "595", "Name": "Comparison of Object References Instead of Object Contents", "Description": "In Java, use the equals() method to compare objects instead of the == operator. If using ==, it is important for performance reasons that your objects are created by a static factory, not by a constructor.", "Extended_Description": "For example, in Java, comparing objects using == usually produces deceptive results, since the == operator compares object references rather than values; often, this means that using == for strings is actually comparing the strings' references, not their values.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Varies by Context. Note: This weakness can lead to erroneous results that can cause unexpected application behaviors.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : In Java, use the equals() method to compare objects instead of the == operator. If using ==, it is important for performance reasons that your objects are created by a static factory, not by a constructor.", "Demonstrative_Examples": "In the example below, two Java String objects are declared and initialized with the same string values. An if statement is used to determine if the strings are equivalent.. However, the if statement will not be executed as the strings are compared using the \"==\" operator. For Java objects, such as String objects, the \"==\" operator compares object references, not object values. While the two String objects above contain the same string values, they refer to different object references, so the System.out.println statement will not be executed. To compare object values, the previous code could be modified to use the equals method:In the following Java example, two BankAccount objects are compared in the isSameAccount method using the == operator.. Using the == operator to compare objects may produce incorrect or deceptive results by comparing object references rather than values. The equals() method should be used to ensure correct results or objects should contain a member variable that uniquely identifies the object.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1025", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1098", "Name": "Data Element containing Pointer Item without Proper Copy Control Element", "Description": "The code contains a data element with a pointer that does not have an associated copy or constructor method.", "Extended_Description": "This issue can prevent the product from running reliably.  If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1099", "Name": "Inconsistent Naming Conventions for Identifiers", "Description": "The product's code, documentation, or other artifacts do not\n\t\t\t\t\tconsistently use the same naming conventions for variables, callables, groups of\n\t\t\t\t\trelated callables, I/O capabilities, data types, file names, or similar types of\n\t\t\t\t\telements.", "Extended_Description": "This issue makes it more difficult to understand and/or maintain the product due to inconsistencies, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "489", "Name": "Active Debug Code", "Description": "Remove debug code before deploying the application.", "Extended_Description": "A common development practice is to add \"back door\" code specifically designed for debugging or testing purposes that is not intended to be shipped or deployed with the product. These back door entry points create security risks because they are not considered during design or testing and fall outside of the expected operating conditions of the product.", "Modes_Of_Introduction": "Implementation: In web-based applications, debug code is used to test and modify web application properties, configuration information, and functions. If a debug application is left on a production server, this oversight during the \"software process\" allows attackers access to debug functionality.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess ControlOther. Impacts: Bypass Protection MechanismRead Application DataGain Privileges or Assume IdentityVaries by Context. Note: The severity of the exposed debug application will depend on the particular instance. At the least, it will give an attacker sensitive information about the settings and mechanics of web applications on the server. At worst, as is often the case, the debug application will allow an attacker complete control over the web application and server, as well as confidential information that either of these access.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Build and Compilation : Remove debug code before deploying the application.", "Demonstrative_Examples": "Debug code can be used to bypass authentication. For example, suppose an application has a login script that receives a username and a password. Assume also that a third, optional, parameter, called \"debug\", is interpreted by the script as requesting a switch to debug mode, and that when this parameter is given the username and password are not checked. In such a case, it is very simple to bypass the authentication process if the special behavior of the application regarding the debug parameter is known. In a case where the form is:. Then a conforming link will look like:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "215", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "11", "Name": "ASP.NET Misconfiguration: Creating Debug Binary", "Description": "Avoid releasing debug binaries into the production environment. Change the debug mode to false when the application is deployed into production.", "Extended_Description": "ASP .NET applications can be configured to produce debug binaries. These binaries give detailed debugging messages and should not be used in production environments. Debug binaries are meant to be used in a development or testing environment and can pose a security risk if they are deployed to production.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Attackers can leverage the additional information they gain from debugging output to mount attacks targeted on the framework, database, or other resources used by the application.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "System Configuration : Avoid releasing debug binaries into the production environment. Change the debug mode to false when the application is deployed into production.", "Demonstrative_Examples": "The file web.config contains the debug mode setting. Setting debug to \"true\" will let the browser display debugging information.. Change the debug mode to false when the application is deployed into production.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "489", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "110", "Name": "Struts: Validator Without Form Field", "Description": "To find the issue in the implementation, manual checks or automated static analysis could be applied to the XML configuration files.", "Extended_Description": "It is easy for developers to forget to update validation logic when they make changes to an ActionForm class. One indication that validation logic is not being properly maintained is inconsistencies between the action form and the validation form.Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Other. Note: It is critically important that validation logic be maintained and kept in sync with the rest of the application. Unchecked input is the root cause of some of today's worst and most common software security problems. Cross-site scripting, SQL injection, and process control vulnerabilities all stem from incomplete or absent input validation.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: To find the issue in the implementation, manual checks or automated static analysis could be applied to the XML configuration files. Method Name: Manual Static Analysis. Description: To find the issue in the implementation, manual checks or automated static analysis could be applied to the XML configuration files.", "Potential_Mitigations": "", "Demonstrative_Examples": "This example shows an inconsistency between an action form and a validation form. with a third field.. This first block of code shows an action form that has two fields, startDate and endDate.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1164", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1100", "Name": "Insufficient Isolation of System-Dependent Functions", "Description": "The product or code does not isolate system-dependent\n\t\t\t\t\tfunctionality into separate standalone modules.", "Extended_Description": "This issue makes it more difficult to maintain and/or port the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1061", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1101", "Name": "Reliance on Runtime Component in Generated Code", "Description": "The product uses automatically-generated code that cannot be\n\t\t\t\t\texecuted without a specific runtime support component.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1102", "Name": "Reliance on Machine-Dependent Data Representation", "Description": "The code uses a data representation that relies on low-level\n\t\t\t\t\tdata representation or constructs that may vary across different processors,\n\t\t\t\t\tphysical machines, OSes, or other physical components.", "Extended_Description": "This issue makes it more difficult to maintain and/or port the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "758", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1105", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1103", "Name": "Use of Platform-Dependent Third Party Components", "Description": "The product relies on third-party components that do\n\t\t\t\t\tnot provide equivalent functionality across all desirable\n\t\t\t\t\tplatforms.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "758", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1357", "Name": "Reliance on Insufficiently Trustworthy Component", "Description": "Continue to monitor changes in each of the product's components, especially when the changes indicate new vulnerabilities, end-of-life (EOL) plans, supplier practices that affect trustworthiness, etc.", "Extended_Description": "Many modern hardware and software products are built by combining multiple smaller components together into one larger entity, often during the design or architecture phase. For example, a hardware component might be built by a separate supplier, or the product might use an open-source software library from a third party.Regardless of the source, each component should be sufficiently trusted to ensure correct, secure operation of the product. If a component is not trustworthy, it can produce significant risks for the overall product, such as vulnerabilities that cannot be patched fast enough (if at all); hidden functionality such as malware; inability to update or replace the component if needed for security purposes; hardware components built from parts that do not meet specifications in ways that can lead to weaknesses; etc. Note that a component might not be trustworthy even if it is owned by the product vendor, such as a software component whose source code is lost and was built by developers who left the company, or a component that was developed by a separate company that was acquired and brought into the product's own company.Note that there can be disagreement as to whether a component is sufficiently trustworthy, since trust is ultimately subjective. Different stakeholders (e.g., customers, vendors, governments) have various threat models and ways to assess trust, and design/architecture choices might make tradeoffs between security, reliability, safety, privacy, cost, and other characteristics.", "Modes_Of_Introduction": "Requirements: Requirements might include criteria for which the only available solutions are provided by insufficiently trusted components.Architecture and Design: An insufficiently trusted component might be selected because it is less expensive to do in-house, requires expertise that is not available in-house, or might allow the product to reach the market faster.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : For each component, ensure that its supply chain is well-controlled with sub-tier suppliers using best practices. For third-party software components such as libraries, ensure that they are developed and actively maintained by reputable vendors.Architecture and Design : Maintain a Bill of Materials for all components and sub-components of the product. For software, maintain a Software Bill of Materials (SBOM). According to [REF-1247], \"An SBOM is a formal, machine-readable inventory of software components and dependencies, information about those components, and their hierarchical relationships.\"Operation : Continue to monitor changes in each of the product's components, especially when the changes indicate new vulnerabilities, end-of-life (EOL) plans, supplier practices that affect trustworthiness, etc.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1104", "Name": "Use of Unmaintained Third Party Components", "Description": "The product relies on third-party components that are not\n\t\t\t\t\tactively supported or maintained by the original developer or a trusted proxy\n\t\t\t\t\tfor the original developer.", "Extended_Description": "Reliance on components that are no longer maintained can make it difficult or impossible to fix significant bugs, vulnerabilities, or quality issues. In effect, unmaintained code can become obsolete.This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1357", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1105", "Name": "Insufficient Encapsulation of Machine-Dependent Functionality", "Description": "The product or code uses machine-dependent functionality, but\n\t\t\t\t\tit does not sufficiently encapsulate or isolate this functionality from\n\t\t\t\t\tthe rest of the code.", "Extended_Description": "This issue makes it more difficult to port or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "758", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1061", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1106", "Name": "Insufficient Use of Symbolic Constants", "Description": "The source code uses literal constants that may need to change\n\t\t\t\t\tor evolve over time, instead of using symbolic constants.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1107", "Name": "Insufficient Isolation of Symbolic Constant Definitions", "Description": "The source code uses symbolic constants, but it does not\n\t\t\t\t\tsufficiently place the definitions of these constants into a more centralized or\n\t\t\t\t\tisolated location.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1108", "Name": "Excessive Reliance on Global Variables", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1109", "Name": "Use of Same Variable for Multiple Purposes", "Description": "The code contains a callable, block, or other code element in\n\t\t\t\t\twhich the same variable is used to control more than one unique task or store\n\t\t\t\t\tmore than one instance of data.", "Extended_Description": "Use of the same variable for multiple purposes can make it more difficult for a person to read or understand the code, potentially hiding other quality issues.This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "695", "Name": "Use of Low-Level Functionality", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "The use of low-level functionality can violate the specification in unexpected ways that effectively disable built-in protection mechanisms, introduce exploitable inconsistencies, or otherwise expose the functionality to attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "111", "Name": "Direct Use of Unsafe JNI", "Description": "Be reluctant to use JNI calls. A Java API equivalent may exist.", "Extended_Description": "Many safety features that programmers may take for granted do not apply for native code, so you must carefully review all such code for potential problems. The languages used to implement native code may be more susceptible to buffer overflows and other attacks. Native code is unprotected by the security features enforced by the runtime environment, such as strong typing and array bounds checking.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Implement error handling around the JNI call.Implementation : Do not use JNI calls if you don't trust the native library.Implementation : Be reluctant to use JNI calls. A Java API equivalent may exist.", "Demonstrative_Examples": "The following code defines a class named Echo. The class declares one native method (defined below), which uses C to echo commands entered on the console back to the user. The following C code defines the native method implemented in the Echo class:. Because the example is implemented in Java, it may appear that it is immune to memory issues like buffer overflow vulnerabilities. Although Java does do a good job of making memory operations safe, this protection does not extend to vulnerabilities occurring in source code written in other languages that are accessed using the Java Native Interface. Despite the memory protections offered in Java, the C code in this example is vulnerable to a buffer overflow because it makes use of gets(), which does not check the length of its input.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "695", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1110", "Name": "Incomplete Design Documentation", "Description": "The product's design documentation does not adequately describe\n\t\t\t\t\tcontrol flow, data flow, system initialization, relationships between tasks,\n\t\t\t\t\tcomponents, rationales, or other important aspects of the\n\t\t\t\t\tdesign.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1059", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1111", "Name": "Incomplete I/O Documentation", "Description": "The product's documentation does not adequately define inputs,\n\t\t\t\t\toutputs, or system/software interfaces.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1059", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1112", "Name": "Incomplete Documentation of Program Execution", "Description": "The document does not fully define all mechanisms that are used\n\t\t\t\t\tto control or influence how product-specific programs are\n\t\t\t\t\texecuted.", "Extended_Description": "This includes environmental variables, configuration files, registry keys, command-line switches or options, or system settings.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1059", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1113", "Name": "Inappropriate Comment Style", "Description": "The source code uses comment styles or formats that are\n\t\t\t\t\tinconsistent or do not follow expected standards for the\n\t\t\t\t\tproduct.", "Extended_Description": "This issue makes it more difficult to maintain the product due to insufficient legibility, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1114", "Name": "Inappropriate Whitespace Style", "Description": "The source code contains whitespace that is inconsistent across\n\t\t\t\t\tthe code or does not follow expected standards for the\n\t\t\t\t\tproduct.", "Extended_Description": "This issue makes it more difficult to understand and maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1115", "Name": "Source Code Element without Standard Prologue", "Description": "The source code contains elements such as source files \n\t\t\t\t\tthat do not consistently provide a prologue or header that has been\n\t\t\t\t\tstandardized for the project.", "Extended_Description": "The lack of a prologue can make it more difficult to accurately and quickly understand the associated code. Standard prologues or headers may contain information such as module name, version number, author, date, purpose, function, assumptions, limitations, accuracy considerations, etc.This issue makes it more difficult to maintain the product due to insufficient analyzability, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1116", "Name": "Inaccurate Comments", "Description": "Verify that each comment accurately reflects what is intended to happen during execution of the code.", "Extended_Description": "When a comment does not accurately reflect the associated code elements, this can introduce confusion to a reviewer (due to inconsistencies) or make it more difficult and less efficient to validate that the code is implementing the intended behavior correctly.This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Verify that each comment accurately reflects what is intended to happen during execution of the code.", "Demonstrative_Examples": "In the following Java example the code performs a calculation to determine how much medicine to administer. A comment is provided to give insight into what the calculation shoud be doing. Unfortunately the comment does not match the actual code and thus leaves the reader to wonder which is correct.. In the correction below, the code functionality has been verified, and the comment has been corrected to reflect the proper calculation.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1117", "Name": "Callable with Insufficient Behavioral Summary", "Description": "The code contains a function or method whose signature and/or associated\n\t\t\t\t\tinline documentation does not sufficiently describe the callable's inputs, outputs,\n\t\t\t\t\tside effects, assumptions, or return codes.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1118", "Name": "Insufficient Documentation of Error Handling Techniques", "Description": "The documentation does not sufficiently describe the techniques\n\t\t\t\t\tthat are used for error handling, exception processing, or similar\n\t\t\t\t\tmechanisms.", "Extended_Description": "Documentation may need to cover error handling techniques at multiple layers, such as module, executable, compilable code unit, or callable.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1059", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1119", "Name": "Excessive Use of Unconditional Branching", "Description": "The code uses too many unconditional branches (such as\n\t\t\t\t\t\"goto\").", "Extended_Description": "This issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1286", "Name": "Improper Validation of Syntactic Correctness of Input", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "Often, complex inputs are expected to follow a particular syntax, which is either assumed by the input itself, or declared within metadata such as headers. The syntax could be for data exchange formats, markup languages, or even programming languages.  When untrusted input is not properly validated for the expected syntax, attackers could cause parsing failures, trigger unexpected errors, or expose latent vulnerabilities that might not be directly exploitable if the input had conformed to the syntax.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": "The following code loads and parses an XML file.. The XML file is loaded without validating it against a known XML Schema or DTD.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "112", "Name": "Missing XML Validation", "Description": "Always validate XML input against a known XML Schema or DTD.\n                  It is not possible for an XML parser to validate all aspects of a document's content because a parser cannot understand the complete semantics of the data. However, a parser can do a complete and thorough job of checking the document's structure and therefore guarantee to the code that processes the document that the content is well-formed.", "Extended_Description": "Most successful attacks begin with a violation of the programmer's assumptions. By accepting an XML document without validating it against a DTD or XML schema, the programmer leaves a door open for attackers to provide unexpected, unreasonable, or malicious input.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Always validate XML input against a known XML Schema or DTD.\n                  It is not possible for an XML parser to validate all aspects of a document's content because a parser cannot understand the complete semantics of the data. However, a parser can do a complete and thorough job of checking the document's structure and therefore guarantee to the code that processes the document that the content is well-formed.", "Demonstrative_Examples": "The following code loads and parses an XML file.. The XML file is loaded without validating it against a known XML Schema or DTD.The following code creates a DocumentBuilder object to be used in building an XML document.. The DocumentBuilder object does not validate an XML document against a schema, making it possible to create an invalid XML document.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1286", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1121", "Name": "Excessive McCabe Cyclomatic Complexity", "Description": "The code contains McCabe cyclomatic complexity that exceeds a\n\tdesirable maximum.", "Extended_Description": "This issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1122", "Name": "Excessive Halstead Complexity", "Description": "The code is structured in a way that a Halstead complexity\n\t\t\t\t\tmeasure exceeds a desirable maximum.", "Extended_Description": "A variety of Halstead complexity measures exist, such as program vocabulary size or volume.This issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1123", "Name": "Excessive Use of Self-Modifying Code", "Description": "The product uses too much self-modifying\n\t\t\t\t\tcode.", "Extended_Description": "This issue makes it more difficult to understand or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1124", "Name": "Excessively Deep Nesting", "Description": "The code contains a callable or other code grouping in which\n\t\t\t\t\tthe nesting / branching is too deep.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1125", "Name": "Excessive Attack Surface", "Description": "The product has an attack surface whose quantitative\n\t\t\t\t\tmeasurement exceeds a desirable maximum.", "Extended_Description": "Originating from software security, an \"attack surface\" measure typically reflects the number of input points and output points that can be utilized by an untrusted party, i.e. a potential attacker. A larger attack surface provides more places to attack, and more opportunities for developers to introduce weaknesses.  In some cases, this measure may reflect other aspects of quality besides security; e.g., a product with many inputs and outputs may require a large number of tests in order to improve code coverage.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1120", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1126", "Name": "Declaration of Variable with Unnecessarily Wide Scope", "Description": "The source code declares a variable in one scope, but the\n\t\t\t\t\tvariable is only used within a narrower scope.", "Extended_Description": "This issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1127", "Name": "Compilation with Insufficient Warnings or Errors", "Description": "The code is compiled without sufficient warnings enabled, which\n\t\t\t\t\tmay prevent the detection of subtle bugs or quality\n\t\t\t\t\tissues.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "93", "Name": "Improper Neutralization of CRLF Sequences ('CRLF Injection')", "Description": "Appropriately filter or quote CRLF sequences in user-controlled input.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Avoid using CRLF as a special sequence.Implementation : Appropriately filter or quote CRLF sequences in user-controlled input.", "Demonstrative_Examples": ". If user input data that eventually makes it to a log message isn't checked for CRLF characters, it may be possible for an attacker to forge entries in a log file.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "117", "View_ID": "1000", "Ordinal": null}]}, {"ID": "113", "Name": "Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Request/Response Splitting')", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "HTTP agents or components may include a web server, load balancer, reverse proxy, web caching proxy, application firewall, web browser, etc. Regardless of the role, they are expected to maintain coherent, consistent HTTP communication state across all components. However, including unexpected data in an HTTP header allows an attacker to specify the entirety of the HTTP message that is rendered by the client HTTP agent (e.g., web browser) or back-end HTTP agent (e.g., web server), whether the message is part of a request or a response.When an HTTP request contains unexpected CR and LF characters, the server may respond with an output stream that is interpreted as \"splitting\" the stream into two different HTTP messages instead of one. CR is carriage return, also given by %0d or \\r, and LF is line feed, also given by %0a or \\n.In addition to CR and LF characters, other valid/RFC compliant special characters and unique character encodings can be utilized, such as HT (horizontal tab, also given by %09 or \\t) and SP (space, also given as + sign or %20).These types of unvalidated and unexpected data in HTTP message headers allow an attacker to control the second \"split\" message to mount attacks such as server-side request forgery, cross-site scripting, and cache poisoning attacks.HTTP response splitting weaknesses may be present when:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityAccess Control. Impacts: Modify Application DataGain Privileges or Assume Identity. Note: CR and LF characters in an HTTP header may give attackers control of the remaining headers and body of the message that the application intends to send/receive, as well as allowing them to create additional messages entirely under their control.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Construct HTTP headers very carefully, avoiding the use of non-validated input data.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. If an input does not strictly conform to specifications, reject it or transform it into something that conforms.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "The following code segment reads the name of the author of a weblog entry, author, from an HTTP request and sets it in a cookie header of an HTTP response.. Assuming a string consisting of standard alpha-numeric characters, such as \"Jane Smith\", is submitted in the request the HTTP response including this cookie might take the following form:An attacker can make a single request to a vulnerable server that will cause the server to create two responses, the second of which may be misinterpreted as a response to a different request, possibly one made by another user sharing the same TCP connection with the server.. Cross-User Defacement can be accomplished by convincing the user to submit the malicious request themselves, or remotely in situations where the attacker and the user share a common TCP connection to the server, such as a shared proxy server.The impact of a maliciously constructed response can be magnified if it is cached, either by a web cache used by multiple users or even the browser cache of a single user.. Cache Poisoning: if a response is cached in a shared web cache, such as those commonly found in proxy servers, then all users of that cache will continue receive the malicious content until the cache entry is purged. Similarly, if the response is cached in the browser of an individual user, then that user will continue to receive the malicious content until the cache entry is purged, although the user of the local browser instance will be affected.Once attackers have control of the responses sent by an application, they have a choice of a variety of malicious content to provide users.. Cross-Site Scripting: cross-site scripting is common form of attack where malicious JavaScript or other code included in a response is executed in the user's browser.The variety of attacks based on XSS is almost limitless, but they commonly include transmitting private data like cookies or other session information to the attacker, redirecting the victim to web content controlled by the attacker, or performing other malicious operations on the user's machine under the guise of the vulnerable site.The most common and dangerous attack vector against users of a vulnerable application uses JavaScript to transmit session and authentication information back to the attacker who can then take complete control of the victim's account.In addition to using a vulnerable application to send malicious content to a user, the same weakness can also be leveraged to redirect sensitive content generated by the server to the attacker instead of the intended user.. Page Hijacking: by submitting a request that results in two responses, the intended response from the server and the response generated by the attacker, an attacker can cause an intermediate node, such as a shared proxy server, to misdirect a response generated by the server to the attacker instead of the intended user.Because the request made by the attacker generates two responses, the first is interpreted as a response to the attacker's request, while the second remains in limbo. When the user makes a legitimate request through the same TCP connection, the attacker's request is already waiting and is interpreted as a response to the victim's request. The attacker then sends a second request to the server, to which the proxy server responds with the server generated request intended for the victim, thereby compromising any sensitive information in the headers or body of the response intended for the victim.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "93", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "79", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": null}]}, {"ID": "436", "Name": "Interpretation Conflict", "Description": "Product A handles inputs or steps differently than Product B, which causes A to perform incorrect actions based on its perception of B's state.", "Extended_Description": "This is generally found in proxies, firewalls, anti-virus software, and other intermediary devices that monitor, allow, deny, or modify traffic based on how the client or server is expected to behave.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". The paper \"Insertion, Evasion, and Denial of Service: Eluding Network Intrusion Detection\" [REF-428] shows that OSes varied widely in how they manage unusual packets, which made it difficult or impossible for intrusion detection systems to properly detect certain attacker manipulations that took advantage of these OS differences.. Null characters have different interpretations in Perl and C, which have security consequences when Perl invokes C functions. Similar problems have been reported in ASP [REF-429] and PHP.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "435", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "73", "Name": "External Control of File Name or Path", "Description": "Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Extended_Description": "This could allow an attacker to access or modify system files or other files that are critical to the application.Path manipulation errors occur when the following two conditions are met:For example, the program may give the attacker the ability to overwrite the specified file or run with a configuration controlled by the attacker.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Read Files or DirectoriesModify Files or Directories. Note: The application can operate on unexpected files. Confidentiality is violated when the targeted filename is not directly readable by the attacker.Scopes: IntegrityConfidentialityAvailability. Impacts: Modify Files or DirectoriesExecute Unauthorized Code or Commands. Note: The application can operate on unexpected files. This may violate integrity if the filename is written to, or if the filename is for a program or other form of executable code.Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (Other). Note: The application can operate on unexpected files. Availability can be violated if the attacker specifies an unexpected file that the application modifies. Availability can also be affected if the attacker specifies a filename for a large file, or points to a special device or a file that does not have the format that the application expects.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: The external control or influence of filenames can often be detected using automated static analysis that models data flow within the product.Automated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or require any code changes.", "Potential_Mitigations": "Architecture and Design : When the set of filenames is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames, and reject all other inputs. For example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\". Features such as the ESAPI AccessReferenceMap provide this capability.Architecture and Design : Run your code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict all access to files within a particular directory.\n                  Examples include the Unix chroot jail and AppArmor. In general, managed code may provide some protection.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of your application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Use a built-in path canonicalization function (such as realpath() in C) that produces the canonical version of the pathname, which effectively removes \"..\" sequences and symbolic links (CWE-23, CWE-59).Installation : Use OS-level permissions and run as a low-privileged user to limit the scope of any successful attack.Operation : If you are using PHP, configure your application so that it does not use register_globals. During implementation, develop your application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.Testing : Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Demonstrative_Examples": ". The following code uses input from an HTTP request to create a file name. The programmer has not considered the possibility that an attacker could provide a file name such as \"../../tomcat/conf/server.xml\", which causes the application to delete one of its own configuration files (CWE-22).. The following code uses input from a configuration file to determine which file to open and echo back to the user. If the program runs with privileges and malicious users can change the configuration file, they can use the program to read any file on the system that ends with the extension .txt.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "642", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "22", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "41", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "98", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "434", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "59", "View_ID": "1000", "Ordinal": null}]}, {"ID": "114", "Name": "Process Control", "Description": "Libraries that are loaded should be well understood and come from a trusted source. The application can execute code contained in the native libraries, which often contain calls that are susceptible to other security problems, such as buffer overflows or command injection. All native libraries should be validated to determine if the application requires the use of the library. It is very difficult to determine what these native libraries actually do, and the potential for malicious code is high. In addition, the potential for an inadvertent mistake in these native libraries is also high, as many are written in C or C++ and may be susceptible to buffer overflow or race condition problems. To help prevent buffer overflow attacks, validate all input to native calls for content and length. If the native library does not come from a trusted source, review the source code of the library. The library should be built from the reviewed source before using it.", "Extended_Description": "Process control vulnerabilities of the first type occur when either data enters the application from an untrusted source and the data is used as part of a string representing a command that is executed by the application. By executing the command, the application gives an attacker a privilege or capability that the attacker would not otherwise have.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Libraries that are loaded should be well understood and come from a trusted source. The application can execute code contained in the native libraries, which often contain calls that are susceptible to other security problems, such as buffer overflows or command injection. All native libraries should be validated to determine if the application requires the use of the library. It is very difficult to determine what these native libraries actually do, and the potential for malicious code is high. In addition, the potential for an inadvertent mistake in these native libraries is also high, as many are written in C or C++ and may be susceptible to buffer overflow or race condition problems. To help prevent buffer overflow attacks, validate all input to native calls for content and length. If the native library does not come from a trusted source, review the source code of the library. The library should be built from the reviewed source before using it.", "Demonstrative_Examples": "The following code uses System.loadLibrary() to load code from a native library named library.dll, which is normally found in a standard system directory.. The problem here is that System.loadLibrary() accepts a library name, not a path, for the library to be loaded. From the Java 1.4.2 API documentation this function behaves as follows [1]: A file containing native code is loaded from the local file system from a place where library files are conventionally obtained. The details of this process are implementation-dependent. The mapping from a library name to a specific filename is done in a system-specific manner. If an attacker is able to place a malicious copy of library.dll higher in the search order than file the application intends to load, then the application will load the malicious copy instead of the intended file. Because of the nature of the application, it runs with elevated privileges, which means the contents of the attacker's library.dll will now be run with elevated privileges, possibly giving them complete control of the system.The following code from a privileged application uses a registry entry to determine the directory in which it is installed and loads a library file based on a relative path from the specified directory.. The code in this example allows an attacker to load an arbitrary library, from which code will be executed with the elevated privilege of the application, by modifying a registry key to specify a different path containing a malicious version of INITLIB. Because the program does not validate the value read from the environment, if an attacker can control the value of APPHOME, they can fool the application into running malicious code.The following code is from a web-based administration utility that allows users access to an interface through which they can update their profile on the system. The utility makes use of a library named liberty.dll, which is normally found in a standard system directory.. The problem is that the program does not specify an absolute path for liberty.dll. If an attacker is able to place a malicious library named liberty.dll higher in the search order than file the application intends to load, then the application will load the malicious copy instead of the intended file. Because of the nature of the application, it runs with elevated privileges, which means the contents of the attacker's liberty.dll will now be run with elevated privileges, possibly giving the attacker complete control of the system. The type of attack seen in this example is made possible because of the search order used by LoadLibrary() when an absolute path is not specified. If the current directory is searched before system directories, as was the case up until the most recent versions of Windows, then this type of attack becomes trivial if the attacker can execute the program locally. The search order is operating system version dependent, and is controlled on newer operating systems by the value of the registry key: HKLM\\System\\CurrentControlSet\\Control\\Session Manager\\SafeDllSearchMode", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "73", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "115", "Name": "Misinterpretation of Input", "Description": "Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "707", "Name": "Improper Neutralization", "Description": "The product does not ensure or incorrectly ensures that structured messages or data are well-formed and that certain security properties are met before being read from an upstream component or sent to a downstream component.", "Extended_Description": "If a message is malformed, it may cause the message to be incorrectly interpreted.Neutralization is an abstract term for any technique that ensures that input (and output) conforms with expectations and is \"safe.\"  This can be done by:This weakness typically applies in cases where the product prepares a control message that another process must act on, such as a command or query, and malicious input that was intended as data, can enter the control plane instead. However, this weakness also applies to more general cases where there are not always control implications.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": []}, {"ID": "116", "Name": "Improper Encoding or Escaping of Output", "Description": "When exchanging data between components, ensure that both components are using the same character encoding. Ensure that the proper encoding is applied at each interface. Explicitly set the encoding you are using whenever the protocol allows you to do so.", "Extended_Description": "Improper encoding or escaping can allow attackers to change the commands that are sent to another component, inserting malicious commands instead.Most products follow a certain protocol that uses structured messages for communication between components, such as queries or commands. These structured messages can contain raw data interspersed with metadata or control information. For example, \"GET /index.html HTTP/1.1\" is a structured message containing a command (\"GET\") with a single argument (\"/index.html\") and metadata about which protocol version is being used (\"HTTP/1.1\").If an application uses attacker-supplied inputs to construct a structured message without properly encoding or escaping, then the attacker could insert special characters that will cause the data to be interpreted as control information or metadata. Consequently, the component that receives the output will perform the wrong operations, or otherwise interpret the data incorrectly.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: The communications between components can be modified in unexpected ways. Unexpected commands can be executed, bypassing other security mechanisms. Incoming data can be misinterpreted.Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or Commands. Note: The communications between components can be modified in unexpected ways. Unexpected commands can be executed, bypassing other security mechanisms. Incoming data can be misinterpreted.Scopes: Confidentiality. Impacts: Bypass Protection Mechanism. Note: The communications between components can be modified in unexpected ways. Unexpected commands can be executed, bypassing other security mechanisms. Incoming data can be misinterpreted.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.", "Potential_Mitigations": "Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using the ESAPI Encoding control [REF-45] or a similar tool, library, or framework. These will help the programmer encode outputs in a manner less prone to error.\n                  Alternately, use built-in functions, but consider using wrappers in case those functions are discovered to have a vulnerability.Architecture and Design : If available, use structured mechanisms that automatically enforce the separation between data and code. These mechanisms may be able to provide the relevant quoting, encoding, and validation automatically, instead of relying on the developer to provide this capability at every point where output is generated.\n                  For example, stored procedures can enforce database query structure and reduce the likelihood of SQL injection.Architecture and Design : Understand the context in which your data will be used and the encoding that will be expected. This is especially important when transmitting data between different components, or when generating outputs that can contain multiple encodings at the same time, such as web pages or multi-part mail messages. Study all expected communication protocols and data representations to determine the required encoding strategies.Architecture and Design : In some cases, input validation may be an important strategy when output encoding is not a complete solution. For example, you may be providing the same output that will be processed by multiple consumers that use different encodings or representations. In other cases, you may be required to allow user-supplied input to contain control information, such as limited HTML tags that support formatting in a wiki or bulletin board. When this type of requirement must be met, use an extremely strict allowlist to limit which control sequences can be used. Verify that the resulting syntactic structure is what you expect. Use your normal encoding methods for the remainder of the input.Architecture and Design : Use input validation as a defense-in-depth measure to reduce the likelihood of output encoding errors (see CWE-20).Requirements : Fully specify which encodings are required by components that will be communicating with each other.Implementation : When exchanging data between components, ensure that both components are using the same character encoding. Ensure that the proper encoding is applied at each interface. Explicitly set the encoding you are using whenever the protocol allows you to do so.", "Demonstrative_Examples": "This code displays an email address that was submitted as part of a form.. The value read from the form parameter is reflected back to the client browser without having been encoded prior to output, allowing various XSS attacks (CWE-79).Consider a chat application in which a front-end web application communicates with a back-end server. The back-end is legacy code that does not perform authentication or authorization, so the front-end must implement it. The chat protocol supports two commands, SAY and BAN, although only administrators can use the BAN command. Each argument must be separated by a single space. The raw inputs are URL-encoded. The messaging protocol allows multiple commands to be specified on the same line if they are separated by a \"|\" character.. First let's look at the back end command processor codeThis example takes user input, passes it through an encoding scheme and then creates a directory specified by the user.. The programmer attempts to encode dangerous characters, however the denylist for encoding is incomplete (CWE-184) and an attacker can still pass a semicolon, resulting in a chain with command injection (CWE-77).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "74", "View_ID": "1000", "Ordinal": null}]}, {"ID": "117", "Name": "Improper Output Neutralization for Logs", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This can allow an attacker to forge log entries or inject malicious content into logs.Log forging vulnerabilities occur when:", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityNon-Repudiation. Impacts: Modify Application DataHide ActivitiesExecute Unauthorized Code or Commands. Note: Interpretation of the log files may be hindered or misdirected if an attacker can supply data to the application that is subsequently logged verbatim. In the most benign case, an attacker may be able to insert false entries into the log file by providing the application with input that includes appropriate characters. Forged or otherwise corrupted log files can be used to cover an attacker's tracks, possibly by skewing statistics, or even to implicate another party in the commission of a malicious act. If the log file is processed automatically, the attacker can render the file unusable by corrupting the format of the file or injecting unexpected characters. An attacker may inject code or other commands into the log file and take advantage of a vulnerability in the log processing utility.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "The following web application code attempts to read an integer value from a request object. If the parseInt call fails, then the input is logged with an error message indicating what happened.. If a user submits the string \"twenty-one\" for val, the following entry is logged:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "116", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "1174", "Name": "ASP.NET Misconfiguration: Improper Model Validation", "Description": "The ASP.NET application does not use, or incorrectly uses, the model validation framework.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Unexpected State. Note: Unchecked input leads to cross-site scripting, process control, and SQL injection vulnerabilities, among others.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1173", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1177", "Name": "Use of Prohibited Code", "Description": "The product uses a function, library, or third party component\n\t     that has been explicitly prohibited, whether by the developer or\n\t     the customer.", "Extended_Description": "The developer - or customers - may wish to restrict or eliminate use of a function, library, or third party component for any number of reasons, including real or suspected vulnerabilities; difficulty to use securely; export controls or license requirements; obsolete or poorly-maintained code; internal code being scheduled for deprecation; etc.To reduce risk of vulnerabilities, the developer might maintain a list of \"banned\" functions that programmers must avoid using because the functions are difficult or impossible to use securely.  This issue can also make the product more costly and difficult to maintain.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "664", "Name": "Improper Control of a Resource Through its Lifetime", "Description": "Use Static analysis tools to check for unreleased resources.", "Extended_Description": "Resources often have explicit instructions on how to be created, used and destroyed. When code does not follow these instructions, it can lead to unexpected behaviors and potentially exploitable states.Even without explicit instructions, various principles are expected to be adhered to, such as \"Do not use an object until after its creation is complete,\" or \"do not use an object after it has been slated for destruction.\"", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Use Static analysis tools to check for unreleased resources.", "Demonstrative_Examples": "", "Related_Weaknesses": []}, {"ID": "118", "Name": "Incorrect Access of Indexable Resource ('Range Error')", "Description": "The product does not restrict or incorrectly restricts operations within the boundaries of a resource that is accessed using an index or pointer, such as memory or files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1188", "Name": "Insecure Default Initialization of Resource", "Description": "The product initializes or sets a resource with a default that is intended to be changed by the administrator, but the default is not secure.", "Extended_Description": "Developers often choose default values that leave the product as open and easy to use as possible out-of-the-box, under the assumption that the administrator can (or should) change the default value.  However, this ease-of-use comes at a cost when the default is insecure and the administrator does not change it.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "653", "Name": "Improper Isolation or Compartmentalization", "Description": "Break up privileges between different modules, objects, or entities. Minimize the interfaces between modules and require strong access control between them.", "Extended_Description": "When a weakness occurs in functionality that is accessible by lower-privileged users, then without strong boundaries, an attack might extend the scope of the damage to higher-privileged users.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume IdentityBypass Protection Mechanism. Note: The exploitation of a weakness in low-privileged areas of the software can be leveraged to reach higher-privileged areas without having to overcome any additional obstacles.", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Break up privileges between different modules, objects, or entities. Minimize the interfaces between modules and require strong access control between them.", "Demonstrative_Examples": ". Single sign-on technology is intended to make it easier for users to access multiple resources or domains without having to authenticate each time. While this is highly convenient for the user and attempts to address problems with psychological acceptability, it also means that a compromise of a user's credentials can provide immediate access to all other resources or domains.. The traditional UNIX privilege model provides root with arbitrary access to all resources, but root is frequently the only user that has privileges. As a result, administrative tasks require root privileges, even if those tasks are limited to a small area, such as updating user manpages. Some UNIX flavors have a \"bin\" user that is the owner of system executables, but since root relies on executables owned by bin, a compromise of the bin account can be leveraged for root privileges by modifying a bin-owned executable, such as CVE-2007-4238.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1189", "Name": "Improper Isolation of Shared Resources on System-on-a-Chip (SoC)", "Description": "When sharing resources, avoid mixing agents of varying trust levels.\n                 Untrusted agents should not share resources with trusted agents.", "Extended_Description": "A System-On-a-Chip (SoC) has a lot of functionality, but it may have a limited number of pins or pads. A pin can only perform one function at a time. However, it can be configured to perform multiple different functions. This technique is called pin multiplexing. Similarly, several resources on the chip may be shared to multiplex and support different features or functions. When such resources are shared between trusted and untrusted agents, untrusted agents may be able to access the assets intended to be accessed only by the trusted agents.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If resources being used by a trusted user are shared with an untrusted user, the untrusted user may be able to modify the functionality of the shared resource of the trusted user.Scopes: Integrity. Impacts: Quality Degradation. Note: The functionality of the shared resource may be intentionally degraded.", "Detection_Methods": "Method Name: Automated Dynamic Analysis. Description: Pre-silicon / post-silicon: Test access to shared systems resources (memory ranges, control registers, etc.) from untrusted software to verify that the assets are not incorrectly exposed to untrusted agents. Note that access to shared resources can be dynamically allowed or revoked based on system flows. Security testing should cover such dynamic shared resource allocation and access control modification flows.", "Potential_Mitigations": "Architecture and Design : When sharing resources, avoid mixing agents of varying trust levels.\n                 Untrusted agents should not share resources with trusted agents.", "Demonstrative_Examples": "Consider the following SoC\n\t      design. The Hardware Root of Trust (HRoT) local SRAM is memory mapped in the core{0-N}\n\t      address space. The HRoT allows or disallows access to private memory ranges, thus\n\t      allowing the sram to function as a mailbox for communication between untrusted and\n\t      trusted HRoT partitions.. We assume that the threat is from malicious software in\n\t      the untrusted domain. We assume this software has access\n\t      to the core{0-N} memory map and can be running at any\n\t      privilege level on the untrusted cores. The capability\n\t      of this threat in this example is communication to and\n\t      from the mailbox region of SRAM modulated by the\n\t      hrot_iface. To address this threat, information must not\n\t      enter or exit the shared region of SRAM through\n\t      hrot_iface when in secure or privileged mode.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "653", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "1331", "View_ID": "1000", "Ordinal": null}]}, {"ID": "668", "Name": "Exposure of Resource to Wrong Sphere", "Description": "The product exposes a resource to the wrong control sphere, providing unintended actors with inappropriate access to the resource.", "Extended_Description": "Resources such as files and directories may be inadvertently exposed through mechanisms such as insecure permissions, or when a program accidentally operates on the wrong object. For example, a program may intend that private files can only be provided to a specific user. This effectively defines a control sphere that is intended to prevent attackers from accessing these private files. If the file permissions are insecure, then parties other than the user will be able to access those files.A separate control sphere might effectively require that the user can only access the private files, but not any other files on the system. If the program does not ensure that the user is only requesting private files, then the user might be able to access other files on the system.In either case, the end result is that a resource has been exposed to the wrong party.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "119", "Name": "Improper Restriction of Operations within the Bounds of a Memory Buffer", "Description": "Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.", "Extended_Description": "Certain languages allow direct addressing of memory locations and do not automatically ensure that these locations are valid for the memory buffer that is being referenced. This can cause read or write operations to be performed on memory locations that may be associated with other variables, data structures, or internal program data.As a result, an attacker may be able to execute arbitrary code, alter the intended control flow, read sensitive information, or cause the system to crash.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or CommandsModify Memory. Note: If the memory accessible by the attacker can be effectively controlled, it may be possible to execute arbitrary code, as with a standard buffer overflow. If the attacker can overwrite a pointer's worth of memory (usually 32 or 64 bits), they can redirect a function pointer to their own malicious code. Even when the attacker can only modify a single byte arbitrary code execution can be possible. Sometimes this is because the same problem can be exploited repeatedly to the same effect. Other times it is because the attacker can overwrite security-critical application-specific data -- such as a flag indicating whether the user is an administrator.Scopes: AvailabilityConfidentiality. Impacts: Read MemoryDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.Scopes: Confidentiality. Impacts: Read Memory. Note: In the case of an out-of-bounds read, the attacker may have access to sensitive information. If the sensitive information contains system details, such as the current buffers position in memory, this knowledge can be used to craft further attacks, possibly with more severe consequences.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.Automated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, many languages that perform their own memory management, such as Java and Perl, are not subject to buffer overflows. Other languages, such as Ada and C#, typically provide overflow protection, but the protection can be disabled by the programmer.\n                  Be wary that a language's interface to native code may still be subject to overflows, even if the language itself is theoretically safe.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Examples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57], and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer versions of overflow-prone string-handling functions.Operation : Use automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking.  \n\t\t D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail.Implementation : Consider adhering to the following rules when allocating and managing an application's memory:\n                     \n                        Double check that the buffer is as large as specified.\n                        When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string.\n                        Check buffer boundaries if accessing the buffer in a loop and make sure there is no danger of writing past the allocated space.\n                        If necessary, truncate all input strings to a reasonable length before passing them to the copy and concatenation functions.Operation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t\t  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].Operation : Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment.   \n\t          For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336].Implementation : Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.", "Demonstrative_Examples": "This example takes an IP address from a user, verifies that it is well formed and then looks up the hostname and copies it into a buffer.. This function allocates a buffer of 64 bytes to store the hostname, however there is no guarantee that the hostname will not be larger than 64 bytes. If an attacker specifies an address which resolves to a very large hostname, then the function may overwrite sensitive data or even relinquish control flow to the attacker.This example applies an encoding procedure to an input string and stores it into a buffer.. The programmer attempts to encode the ampersand character in the user-controlled string, however the length of the string is validated before the encoding procedure is applied. Furthermore, the programmer assumes encoding expansion will only expand a given character by a factor of 4, while the encoding of the ampersand expands by 5. As a result, when the encoding procedure expands the string it is possible to overflow the destination buffer if the attacker provides a string of many ampersands.The following example asks a user for an offset into an array to select an item.. The programmer allows the user to specify which element in the list to select, however an attacker can provide an out-of-bounds offset, resulting in a buffer over-read (CWE-126).In the following code, the method retrieves a value from an array at a specific array index location that is given as an input parameter to the method. However, this method only verifies that the given array index is less than the maximum length of the array but does not check for the minimum value (CWE-839). This will allow a negative value to be accepted as the input array index, which will result in a out of bounds read (CWE-125) and may allow access to sensitive memory. The input array index should be checked to verify that is within the maximum and minimum range required for the array (CWE-129). In this example the if statement should be modified to include a minimum range check, as shown below.. Windows provides the _mbs family of functions to perform various operations on multibyte strings. When these functions are passed a malformed multibyte string, such as a string containing a valid leading byte followed by a single null byte, they can read or write past the end of the string buffer causing a buffer overflow. The following functions all pose a risk of buffer overflow: _mbsinc _mbsdec _mbsncat _mbsncpy _mbsnextc _mbsnset _mbsrev _mbsset _mbsstr _mbstok _mbccpy _mbslen", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "118", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "696", "Name": "Incorrect Behavior Order", "Description": "The product performs multiple related behaviors, but the behaviors are performed in the wrong order in ways which may produce resultant weaknesses.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1190", "Name": "DMA Device Enabled Too Early in Boot Phase", "Description": "Utilize an IOMMU to orchestrate IO access from\n                 the start of the boot process.", "Extended_Description": "DMA is included in a number of devices because it allows\n              data transfer between the computer and the connected device, using\n              direct hardware access to read or write directly to main memory\n              without any OS interaction. An attacker could exploit this to\n              access secrets. Several virtualization-based mitigations have been introduced to thwart DMA attacks. These are usually\n              configured/setup during boot time. However, certain IPs that are\n              powered up before boot is complete (known as early boot IPs) may\n              be DMA capable. Such IPs, if not trusted, could launch DMA\n              attacks and gain access to assets that should otherwise be\n              protected.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismModify Memory. Note: DMA devices have direct write access to main memory and\n                 due to time of attack will be able to bypass OS or Bootloader\n                 access control.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Utilize an IOMMU to orchestrate IO access from\n                 the start of the boot process.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "696", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "284", "Name": "Improper Access Control", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "Access control involves the use of several protection mechanisms such as:When any mechanism is not applied or otherwise fails, attackers can compromise the security of the product by gaining privileges, reading sensitive information, executing commands, evading detection, etc.There are two distinct behaviors that can introduce access control weaknesses:", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": "", "Related_Weaknesses": []}, {"ID": "1191", "Name": "On-Chip Debug and Test Interface With Improper Access Control", "Description": "If feasible, the manufacturer should disable the JTAG interface or implement authentication and authorization for the JTAG interface. If authentication logic is added, it should be resistant to timing attacks. Security-sensitive data stored in registers, such as keys, etc. should be cleared when entering debug mode.", "Extended_Description": "A device's internal information may be accessed through a scan chain of interconnected internal registers, usually through a JTAG interface. The JTAG interface provides access to these registers in a serial fashion in the form of a scan chain for the purposes of debugging programs running on a device. Since almost all information contained within a device may be accessed over this interface, device manufacturers typically insert some form of authentication and authorization to prevent unintended use of this sensitive information. This mechanism is implemented in addition to on-chip protections that are already present.If authorization, authentication, or some other form of access control is not implemented or not implemented correctly, a user may be able to bypass on-chip protection mechanisms through the debug interface.Sometimes, designers choose not to expose the debug pins on the motherboard. Instead, they choose to hide these pins in the intermediate layers of the board. This is primarily done to work around the lack of debug authorization inside the chip. In such a scenario (without debug authorization), when the debug interface is exposed, chip internals are accessible to an attacker.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Dynamic Analysis with Manual Results Interpretation. Description: Authentication and authorization of debug and test interfaces should be part of the architecture and design review process. Withholding of private register documentation from the debug and test interface public specification (\"Security by obscurity\") should not be considered as sufficient security. Method Name: Dynamic Analysis with Manual Results Interpretation. Description: Dynamic tests should be done in the pre-silicon and post-silicon stages to verify that the debug and test interfaces are not open by default. Method Name: Fuzzing. Description: Tests that fuzz Debug and Test Interfaces should ensure that no access without appropriate authentication and authorization is possible.", "Potential_Mitigations": "Architecture and Design : If feasible, the manufacturer should disable the JTAG interface or implement authentication and authorization for the JTAG interface. If authentication logic is added, it should be resistant to timing attacks. Security-sensitive data stored in registers, such as keys, etc. should be cleared when entering debug mode.", "Demonstrative_Examples": "A home, WiFi-router device implements a login prompt which prevents an unauthorized user from issuing any commands on the device until appropriate credentials are provided. The credentials are protected on the device and are checked for strength against attack.. JTAG is useful to chip and device manufacturers during design, testing, and production and is included in nearly every product. Without proper authentication and authorization, the interface may allow tampering with a product.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "657", "Name": "Violation of Secure Design Principles", "Description": "The product violates well-established principles for secure design.", "Extended_Description": "This can introduce resultant weaknesses or make it easier for developers to introduce related weaknesses during implementation. Because code is centered around design, it can be resource-intensive to fix design problems.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1192", "Name": "System-on-Chip (SoC) Using Components without Unique, Immutable Identifiers", "Description": "Every identity generated in the SoC should be unique and\n                    immutable in hardware. The actions that an IP is trusted or\n                    not trusted should be clearly defined, implemented,\n                    configured, and tested. If the definition is implemented via a\n                    policy, then the policy should be immutable or protected with\n                    clear authentication and authorization.", "Extended_Description": "A System-on-Chip (SoC) comprises several components (IP) with varied\n           trust requirements. It is required that each IP is identified\n           uniquely and should distinguish itself from other entities in\n           the SoC without any ambiguity. The unique secured identity is\n           required for various purposes. Most of the time the identity is used\n           to route a transaction or perform certain actions, including \n           resetting, retrieving a sensitive information, and acting upon or on\n           behalf of something else.There are several variants of this weakness:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Every identity generated in the SoC should be unique and\n                    immutable in hardware. The actions that an IP is trusted or\n                    not trusted should be clearly defined, implemented,\n                    configured, and tested. If the definition is implemented via a\n                    policy, then the policy should be immutable or protected with\n                    clear authentication and authorization.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1193", "Name": "Power-On of Untrusted Execution Core Before Enabling Fabric Access Control", "Description": "The boot sequence should enable fabric access controls and memory protections before enabling third-party hardware IPs and peripheral microcontrollers that use untrusted firmware.", "Extended_Description": "After initial reset, System-on-Chip (SoC) fabric access controls and other\n           security features need to be programmed by trusted firmware as part\n           of the boot sequence. If untrusted IPs or peripheral microcontrollers\n\t   are enabled first, then the untrusted component can master\n           transactions on the hardware bus and target memory or other assets to\n           compromise the SoC boot firmware.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: An untrusted component can master transactions on the HW bus and target memory or other assets to compromise the SoC boot firmware.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : The boot sequence should enable fabric access controls and memory protections before enabling third-party hardware IPs and peripheral microcontrollers that use untrusted firmware.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "696", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "756", "Name": "Missing Custom Error Page", "Description": "The product does not return custom error pages to the user, possibly exposing sensitive information.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Attackers can leverage the additional information provided by a default error page to mount attacks targeted on the framework, database, or other resources used by the application.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". In the snippet below, an unchecked runtime exception thrown from within the try block may cause the container to display its default error page (which may contain a full stack trace, among other things).The mode attribute of the <customErrors> tag in the Web.config file defines whether custom or default error pages are used.. In the following insecure ASP.NET application setting, custom error message mode is turned off. An ASP.NET error message with detailed stack trace and platform versions will be returned.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "209", "View_ID": "1000", "Ordinal": null}]}, {"ID": "12", "Name": "ASP.NET Misconfiguration: Missing Custom Error Page", "Description": "Verify return values are correct and do not supply sensitive information about the system.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Default error pages gives detailed information about the error that occurred, and should not be used in production environments. Attackers can leverage the additional information provided by a default error page to mount attacks targeted on the framework, database, or other resources used by the application.", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : Handle exceptions appropriately in source code. ASP .NET applications should be configured to use custom error pages instead of the framework default page.Architecture and Design : Do not attempt to process an error or attempt to mask it.Implementation : Verify return values are correct and do not supply sensitive information about the system.", "Demonstrative_Examples": "The mode attribute of the <customErrors> tag in the Web.config file defines whether custom or default error pages are used.. In the following insecure ASP.NET application setting, custom error message mode is turned off. An ASP.NET error message with detailed stack trace and platform versions will be returned.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "756", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "120", "Name": "Buffer Copy without Checking Size of Input ('Classic Buffer Overflow')", "Description": "Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Extended_Description": "A buffer overflow condition exists when a product attempts to put more data in a buffer than it can hold, or when it attempts to put data in a memory area outside of the boundaries of a buffer. The simplest type of error, and the most common cause of buffer overflows, is the \"classic\" case in which the product copies the buffer without restricting how much is copied. Other variants exist, but the existence of a classic overflow strongly suggests that the programmer is not considering even the most basic of security protections.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Modify MemoryExecute Unauthorized Code or Commands. Note: Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of the product's implicit security policy. This can often be used to subvert any other security service.Scopes: Availability. Impacts: Modify MemoryDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU). Note: Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the product into an infinite loop.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.Automated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Analysis. Description: Manual analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. This becomes difficult for weaknesses that must be considered for all inputs, since the attack surface can be too large. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, many languages that perform their own memory management, such as Java and Perl, are not subject to buffer overflows. Other languages, such as Ada and C#, typically provide overflow protection, but the protection can be disabled by the programmer.\n                  Be wary that a language's interface to native code may still be subject to overflows, even if the language itself is theoretically safe.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Examples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57], and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer versions of overflow-prone string-handling functions.Operation : Use automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking.  \n\t\t D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail.Implementation : Consider adhering to the following rules when allocating and managing an application's memory:\n                     \n                        Double check that your buffer is as large as you specify.\n                        When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string.\n                        Check buffer boundaries if accessing the buffer in a loop and make sure there is no danger of writing past the allocated space.\n                        If necessary, truncate all input strings to a reasonable length before passing them to the copy and concatenation functions.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Operation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t\t  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].Operation : Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment.   \n\t          For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336].Build and Compilation : Most mitigating technologies at the compiler or OS level to date address only a subset of buffer overflow problems and rarely provide complete protection against even that subset. It is good practice to implement strategies to increase the workload of an attacker, such as leaving the attacker to guess an unknown value that changes every program execution.Implementation : Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Demonstrative_Examples": "The following code asks the user to enter their last name and then attempts to store the value entered in the last_name array.. The problem with the code above is that it does not restrict or limit the size of the name entered by the user. If the user enters \"Very_very_long_last_name\" which is 24 characters long, then a buffer overflow will occur since the array can only hold 20 characters total.The following code attempts to create a local copy of a buffer to perform some manipulations to the data.. However, the programmer does not ensure that the size of the data pointed to by string will fit in the local buffer and copies the data with the potentially dangerous strcpy() function. This may result in a buffer overflow condition if an attacker can influence the contents of the string parameter.The code below calls the gets() function to read in data from the command line.. However, gets() is inherently unsafe, because it copies all input from STDIN to the buffer without checking size. This allows the user to provide a string that is larger than the buffer size, resulting in an overflow condition.In the following example, a server accepts connections from a client and processes the client request. After accepting a client connection, the program will obtain client information using the gethostbyaddr method, copy the hostname of the client that connected to a local variable and output the hostname of the client to a log file.. However, the hostname of the client that connected may be longer than the allocated size for the local hostname variable. This will result in a buffer overflow when copying the client hostname to the local variable using the strcpy method.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "123", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "330", "Name": "Use of Insufficiently Random Values", "Description": "Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Extended_Description": "When product generates predictable values in a context requiring unpredictability, it may be possible for an attacker to guess the next value that will be generated, and use this guess to impersonate another user or access sensitive information.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityOther. Impacts: Other. Note: When a protection mechanism relies on random values to restrict access to a sensitive resource, such as a session ID or a seed for generating a cryptographic key, then the resource being protected could be accessed by guessing the ID or key.Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: If product relies on unique, unguessable IDs to identify a resource, an attacker might be able to guess an ID for a resource that is owned by another user. The attacker could then read the resource, or pre-create a resource with the same ID to prevent the legitimate program from properly sending the resource to the intended user. For example, a product might maintain session information in a file whose name is based on a username. An attacker could pre-create this file for a victim user, then set the permissions so that the application cannot generate the session for the victim, preventing the victim from using the application.Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: When an authorization or authentication mechanism relies on random values to restrict access to restricted functionality, such as a session ID or a seed for generating a cryptographic key, then an attacker may access the restricted functionality by guessing the ID or key.", "Detection_Methods": "Method Name: Black Box. Description: Use monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.Attach the monitor to the process and look for library functions that indicate when randomness is being used. Run the process multiple times to see if the seed changes. Look for accesses of devices or equivalent resources that are commonly used for strong (or weak) randomness, such as /dev/urandom on Linux. Look for library or system calls that access predictable information such as process IDs and system time. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Use a well-vetted algorithm that is currently considered to be strong by experts in the field, and select well-tested implementations with adequate length seeds.\n                  In general, if a pseudo-random number generator is not advertised as being cryptographically secure, then it is probably a statistical PRNG and should not be used in security-sensitive contexts.\n                  Pseudo-random number generators can produce predictable numbers if the generator is known and the seed can be guessed. A 256-bit seed is a good starting point for producing a \"random enough\" number.Implementation : Consider a PRNG that re-seeds itself as needed from high quality pseudo-random output sources, such as hardware devices.Testing : Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").Testing : Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Demonstrative_Examples": "This code attempts to generate a unique random identifier for a user's session.. Because the seed for the PRNG is always the user's ID, the session ID will always be the same. An attacker could thus predict any user's session ID and potentially hijack the session.The following code uses a statistical PRNG to create a URL for a receipt that remains active for some period of time after a purchase.. This code uses the Random.nextInt() function to generate \"unique\" identifiers for the receipt pages it generates. Because Random.nextInt() is a statistical PRNG, it is easy for an attacker to guess the strings it generates. Although the underlying design of the receipt system is also faulty, it would be more secure if it used a random number generator that did not produce predictable receipt identifiers, such as a cryptographic PRNG.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "804", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1204", "Name": "Generation of Weak Initialization Vector (IV)", "Description": "Different cipher\n\t\t\t    modes have different requirements for\n\t\t\t    their IVs. When choosing and implementing\n\t\t\t    a mode, it is important to understand\n\t\t\t    those requirements in order to keep\n\t\t\t    security guarantees intact. Generally, it\n\t\t\t    is safest to generate a random IV, since\n\t\t\t    it will be both unpredictable and have a\n\t\t\t    very low chance of being non-unique. IVs\n\t\t\t    do not have to be kept secret, so if\n\t\t\t    generating duplicate IVs is a concern, a\n\t\t\t    list of already-used IVs can be kept and\n\t\t\t    checked against.\n\t\t\t    \n\t\t\t    \n\t\t\t      NIST offers recommendations on generation of IVs for modes of which they have approved. These include options for when random IVs are not practical. For CBC, CFB, and OFB, see [REF-1175]; for GCM, see [REF-1178].", "Extended_Description": "By design, some cryptographic primitives\n\t\t\t  (such as block ciphers) require that IVs\n\t\t\t  must have certain properties for the\n\t\t\t  uniqueness and/or unpredictability of an\n\t\t\t  IV. Primitives may vary in how important\n\t\t\t  these properties are. If these properties\n\t\t\t  are not maintained, e.g. by a bug in the\n\t\t\t  code, then the cryptography may be weakened\n\t\t\t  or broken by attacking the IVs themselves.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: If the IV is not properly initialized, data that is encrypted can be compromised and information about the data can be leaked. See [REF-1179].", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Different cipher\n\t\t\t    modes have different requirements for\n\t\t\t    their IVs. When choosing and implementing\n\t\t\t    a mode, it is important to understand\n\t\t\t    those requirements in order to keep\n\t\t\t    security guarantees intact. Generally, it\n\t\t\t    is safest to generate a random IV, since\n\t\t\t    it will be both unpredictable and have a\n\t\t\t    very low chance of being non-unique. IVs\n\t\t\t    do not have to be kept secret, so if\n\t\t\t    generating duplicate IVs is a concern, a\n\t\t\t    list of already-used IVs can be kept and\n\t\t\t    checked against.\n\t\t\t    \n\t\t\t    \n\t\t\t      NIST offers recommendations on generation of IVs for modes of which they have approved. These include options for when random IVs are not practical. For CBC, CFB, and OFB, see [REF-1175]; for GCM, see [REF-1178].", "Demonstrative_Examples": "In the following examples, CBC mode is used when encrypting data:. In both of these examples, the initialization vector (IV) is always a block of zeros. This makes the resulting cipher text much more predictable and susceptible to a dictionary attack.. The Wired Equivalent Privacy (WEP) protocol used in the 802.11\n\t\t\t    wireless standard only supported 40-bit keys, and the IVs were only 24\n\t\t\t    bits, increasing the chances that the same IV would be reused for\n\t\t\t    multiple messages. The IV was included in plaintext as part of the packet, making\n\t\t\t    it directly observable to attackers. Only 5000 messages are needed\n\t\t\t    before a collision occurs due to the \"birthday paradox\" [REF-1176]. Some\n\t\t\t    implementations would reuse the same IV for each packet. This IV reuse\n\t\t\t    made it much easier for attackers to recover plaintext from\n\t\t\t    two packets with the same IV, using well-understood attacks,\n\t\t\t    especially if the plaintext was known for one of the packets [REF-1175].", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1209", "Name": "Failure to Disable Reserved Bits", "Description": "Any writes to these reserve bits are blocked (e.g., ignored, access-protected, etc.), or an exception can be asserted.", "Extended_Description": "Reserved bits are labeled as such so they can be allocated for a later purpose. They are not to do anything in the current design.  However, designers might want to use these bits to debug or control/configure a future capability to help minimize time to market (TTM). If the logic being controlled by these bits is still enabled in production, an adversary could use the logic to induce unwanted/unsupported behavior in the hardware.", "Modes_Of_Introduction": "Architecture and Design: The Designer and Implementer have to make a conscious choice to do thisImplementation: The Designer and Implementer have to make a conscious choice to do thisDocumentation: If documentation labels anything \"for future use\", \"reserved\", or the like, such labeling could indicate to an attacker a potential attack point", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess ControlAccountabilityAuthenticationAuthorizationNon-Repudiation. Impacts: Varies by Context. Note: This type of weakness all depends on the capabilities of the logic being controlled or configured by the reserved bits", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Include a feature to disable reserved bits.Integration : Any writes to these reserve bits are blocked (e.g., ignored, access-protected, etc.), or an exception can be asserted.", "Demonstrative_Examples": "Assume a hardware Intellectual Property (IP) has address space 0x0-0x0F for its configuration registers, with the last one labeled reserved (i.e. 0x0F).  Therefore inside the Finite State Machine (FSM), the code is as follows:. An adversary may perform writes to reserved address space in hopes of changing the behavior of the hardware. In the code above, the GPIO pin should remain low for normal operation.  However, it can be asserted by accessing the reserved address space (0x0F).  This may be a concern if the GPIO state is being used as an indicator of health (e.g. if asserted the hardware may respond by shutting down or resetting the system, which may not be the correct action the system should perform).In the code below, the condition \"register_address = 0X0F\" is commented out, and a default is provided that will catch any values of register_address not explicitly accounted for and take no action with regards to gpio_out. This means that an attacker who is able to write 0X0F to register_address will not enable any undocumented \"features\" in the process.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "788", "Name": "Access of Memory Location After End of Buffer", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "This typically occurs when a pointer or its index is incremented to a position after the buffer; or when pointer arithmetic results in a position after the buffer.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Memory. Note: For an out-of-bounds read, the attacker may have access to sensitive information. If the sensitive information contains system details, such as the current buffers position in memory, this knowledge can be used to craft further attacks, possibly with more severe consequences.Scopes: IntegrityAvailability. Impacts: Modify MemoryDoS: Crash, Exit, or Restart. Note: Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.Scopes: Integrity. Impacts: Modify MemoryExecute Unauthorized Code or Commands. Note: If the memory accessible by the attacker can be effectively controlled, it may be possible to execute arbitrary code, as with a standard buffer overflow. If the attacker can overwrite a pointer's worth of memory (usually 32 or 64 bits), they can redirect a function pointer to their own malicious code. Even when the attacker can only modify a single byte arbitrary code execution can be possible. Sometimes this is because the same problem can be exploited repeatedly to the same effect. Other times it is because the attacker can overwrite security-critical application-specific data -- such as a flag indicating whether the user is an administrator.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "This example takes an IP address from a user, verifies that it is well formed and then looks up the hostname and copies it into a buffer.. This function allocates a buffer of 64 bytes to store the hostname, however there is no guarantee that the hostname will not be larger than 64 bytes. If an attacker specifies an address which resolves to a very large hostname, then the function may overwrite sensitive data or even relinquish control flow to the attacker.In the following example, it is possible to request that memcpy move a much larger segment of memory than assumed:. If returnChunkSize() happens to encounter an error it will return -1. Notice that the return value is not checked before the memcpy operation (CWE-252), so -1 can be passed as the size argument to memcpy() (CWE-805). Because memcpy() assumes that the value is unsigned, it will be interpreted as MAXINT-1 (CWE-195), and therefore will copy far more memory than is likely available to the destination buffer (CWE-787, CWE-788).This example applies an encoding procedure to an input string and stores it into a buffer.. The programmer attempts to encode the ampersand character in the user-controlled string, however the length of the string is validated before the encoding procedure is applied. Furthermore, the programmer assumes encoding expansion will only expand a given character by a factor of 4, while the encoding of the ampersand expands by 5. As a result, when the encoding procedure expands the string it is possible to overflow the destination buffer if the attacker provides a string of many ampersands.In the following C/C++ example the method processMessageFromSocket() will get a message from a socket, placed into a buffer, and will parse the contents of the buffer into a structure that contains the message length and the message body. A for loop is used to copy the message body into a local character string which will be passed to another method for processing.. However, the message length variable from the structure is used as the condition for ending the for loop without validating that the message length variable accurately reflects the length of the message body (CWE-606). This can result in a buffer over-read (CWE-125) by reading from memory beyond the bounds of the buffer if the message length variable indicates a length that is longer than the size of a message body (CWE-130).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "121", "Name": "Stack-based Buffer Overflow", "Description": "Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t        For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: Modify MemoryDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Modify MemoryExecute Unauthorized Code or CommandsBypass Protection Mechanism. Note: Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy.Scopes: IntegrityConfidentialityAvailabilityAccess ControlOther. Impacts: Modify MemoryExecute Unauthorized Code or CommandsBypass Protection MechanismOther. Note: When the consequence is arbitrary code execution, this can often be used to subvert any other security service.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Operation : Use automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking.  \n\t\t D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail.Architecture and Design : Use an abstraction library to abstract away risky APIs. Not a complete solution.Implementation : Implement and perform bounds checking on input.Implementation : Do not use dangerous functions such as gets. Use safer, equivalent functions which check for boundary errors.Operation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t        For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].", "Demonstrative_Examples": "While buffer overflow examples can be rather complex, it is possible to have very simple, yet still exploitable, stack-based buffer overflows:. The buffer size is fixed, but there is no guarantee the string in argv[1] will not exceed this size and cause an overflow.This example takes an IP address from a user, verifies that it is well formed and then looks up the hostname and copies it into a buffer.. This function allocates a buffer of 64 bytes to store the hostname, however there is no guarantee that the hostname will not be larger than 64 bytes. If an attacker specifies an address which resolves to a very large hostname, then the function may overwrite sensitive data or even relinquish control flow to the attacker.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "788", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "787", "View_ID": "1000", "Ordinal": null}]}, {"ID": "787", "Name": "Out-of-bounds Write", "Description": "Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.", "Extended_Description": "Typically, this can result in corruption of data, a crash, or code execution.  The product may modify an index or perform pointer arithmetic that references a memory location that is outside of the boundaries of the buffer.  A subsequent write operation then produces undefined or unexpected results.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.Automated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, many languages that perform their own memory management, such as Java and Perl, are not subject to buffer overflows. Other languages, such as Ada and C#, typically provide overflow protection, but the protection can be disabled by the programmer.\n                  Be wary that a language's interface to native code may still be subject to overflows, even if the language itself is theoretically safe.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Examples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57], and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer versions of overflow-prone string-handling functions.Operation : Use automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking.  \n\t\t D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail.Implementation : Consider adhering to the following rules when allocating and managing an application's memory:\n                     \n                        Double check that the buffer is as large as specified.\n                        When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string.\n                        Check buffer boundaries if accessing the buffer in a loop and make sure there is no danger of writing past the allocated space.\n                        If necessary, truncate all input strings to a reasonable length before passing them to the copy and concatenation functions.Operation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t\t  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].Operation : Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment.   \n\t          For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336].Implementation : Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.", "Demonstrative_Examples": "The following code attempts to save four different identification numbers into an array.. Since the array is only allocated to hold three elements, the valid indices are 0 to 2; so, the assignment to id_sequence[3] is out of bounds.In the following code, it is possible to request that memcpy move a much larger segment of memory than assumed:. If returnChunkSize() happens to encounter an error it will return -1. Notice that the return value is not checked before the memcpy operation (CWE-252), so -1 can be passed as the size argument to memcpy() (CWE-805). Because memcpy() assumes that the value is unsigned, it will be interpreted as MAXINT-1 (CWE-195), and therefore will copy far more memory than is likely available to the destination buffer (CWE-787, CWE-788).This code takes an IP address from the user and verifies that it is well formed. It then looks up the hostname and copies it into a buffer.. This function allocates a buffer of 64 bytes to store the hostname. However, there is no guarantee that the hostname will not be larger than 64 bytes. If an attacker specifies an address which resolves to a very large hostname, then the function may overwrite sensitive data or even relinquish control flow to the attacker.This code applies an encoding procedure to an input string and stores it into a buffer.. The programmer attempts to encode the ampersand character in the user-controlled string. However, the length of the string is validated before the encoding procedure is applied. Furthermore, the programmer assumes encoding expansion will only expand a given character by a factor of 4, while the encoding of the ampersand expands by 5. As a result, when the encoding procedure expands the string it is possible to overflow the destination buffer if the attacker provides a string of many ampersands.In the following C/C++ code, a utility function is used to trim trailing whitespace from a character string. The function copies the input string to a local character string and uses a while statement to remove the trailing whitespace by moving backward through the string and overwriting whitespace with a NUL character.. However, this function can cause a buffer underwrite if the input character string contains all whitespace. On some systems the while statement will move backwards past the beginning of a character string and will call the isspace() function on an address outside of the bounds of the local buffer.The following code allocates memory for a maximum number of widgets. It then gets a user-specified number of widgets, making sure that the user does not request too many. It then initializes the elements of the array using InitializeWidget(). Because the number of widgets can vary for each request, the code inserts a NULL pointer to signify the location of the last widget.. However, this code contains an off-by-one calculation error (CWE-193). It allocates exactly enough space to contain the specified number of widgets, but it does not include the space for the NULL pointer. As a result, the allocated buffer is smaller than it is supposed to be (CWE-131). So if the user ever requests MAX_NUM_WIDGETS, there is an out-of-bounds write (CWE-787) when the NULL is assigned. Depending on the environment and compilation settings, this could cause memory corruption.The following code may result in a buffer underwrite, if find() returns a negative value to indicate that ch is not found in srcBuf:. If the index to srcBuf is somehow under user control, this is an arbitrary write-what-where condition.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "122", "Name": "Heap-based Buffer Overflow", "Description": "Use OS-level preventative functionality. This is not a complete solution, but it provides some defense in depth.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsBypass Protection MechanismModify Memory. Note: Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy. Besides important user data, heap-based overflows can be used to overwrite function pointers that may be living in memory, pointing it to the attacker's code. Even in applications that do not explicitly use function pointers, the run-time will usually leave many in memory. For example, object methods in C++ are generally implemented using function pointers. Even in C programs, there is often a global offset table used by the underlying runtime.Scopes: IntegrityConfidentialityAvailabilityAccess ControlOther. Impacts: Execute Unauthorized Code or CommandsBypass Protection MechanismOther. Note: When the consequence is arbitrary code execution, this can often be used to subvert any other security service.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "N/A : Pre-design: Use a language or compiler that performs automatic bounds checking.Architecture and Design : Use an abstraction library to abstract away risky APIs. Not a complete solution.Operation : Use automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking.  \n\t\t D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail.Operation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t\t  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].Implementation : Implement and perform bounds checking on input.Implementation : Do not use dangerous functions such as gets. Look for their safe equivalent, which checks for the boundary.Operation : Use OS-level preventative functionality. This is not a complete solution, but it provides some defense in depth.", "Demonstrative_Examples": "While buffer overflow examples can be rather complex, it is possible to have very simple, yet still exploitable, heap-based buffer overflows:. The buffer is allocated heap memory with a fixed size, but there is no guarantee the string in argv[1] will not exceed this size and cause an overflow.This example applies an encoding procedure to an input string and stores it into a buffer.. The programmer attempts to encode the ampersand character in the user-controlled string, however the length of the string is validated before the encoding procedure is applied. Furthermore, the programmer assumes encoding expansion will only expand a given character by a factor of 4, while the encoding of the ampersand expands by 5. As a result, when the encoding procedure expands the string it is possible to overflow the destination buffer if the attacker provides a string of many ampersands.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "788", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "787", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1220", "Name": "Insufficient Granularity of Access Control", "Description": "Access-control-policy protections must be reviewed for design inconsistency and common weaknesses.\n                            Access-control-policy definition and programming flow must be tested in pre-silicon, post-silicon testing.", "Extended_Description": "Integrated circuits and hardware engines can expose accesses to assets (device configuration, keys, etc.) to trusted firmware or a software module (commonly set by BIOS/bootloader). This access is typically access-controlled. Upon a power reset, the hardware or system usually starts with default values in registers, and the trusted firmware (Boot firmware) configures the necessary access-control protection.A common weakness that can exist in such protection schemes is that access controls or policies are not granular enough. This condition allows agents beyond trusted agents to access assets and could lead to a loss of functionality or the ability to set up the device securely. This further results in security risks from leaked, sensitive, key material to modification of device configuration.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during hardware implementation and identified later during Testing or System Configuration phases.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Access-control-policy protections must be reviewed for design inconsistency and common weaknesses.\n                            Access-control-policy definition and programming flow must be tested in pre-silicon, post-silicon testing.", "Demonstrative_Examples": "Consider a system with a register for storing AES key for encryption or decryption. The key is 128 bits, implemented as a set of four 32-bit registers. The key registers are assets and registers, AES_KEY_READ_POLICY and AES_KEY_WRITE_POLICY, and are defined to provide necessary access controls.The read-policy register defines which agents can read the AES-key registers, and write-policy register defines which agents can program or write to those registers. Each register is a 32-bit register, and it can support access control for a maximum of 32 agents. The number of the bit when set (i.e., \"1\") allows respective action from an agent whose identity matches the number of the bit and, if \"0\" (i.e., Clear), disallows the respective action to that corresponding agent.. In the above example, there is only one policy register that controls access to both read and write accesses to the AES-key registers, and thus the design is not granular enough to separate read and writes access for different agents. Here, agent with identities \"1\" and \"2\" can both read and write.Consider the following SoC\n\t      design. The sram in HRoT has an address range that is readable and writable by unprivileged\n\t      software and it has an area that is only readable by unprivileged software. The tbus\n\t      interconnect enforces access control for slaves on the bus but uses only one bit to control\n\t      both read and write access. Address 0xA0000000 - 0xA000FFFF is readable and writable\n\t      by the untrusted cores core{0-N} and address 0xA0010000 - 0xA001FFFF is only\n\t      readable by the untrusted cores core{0-N}.. The security policy access control is not granular enough, as it uses one bit to enable both\n\t      read and write access. This gives write access to an area that should only be readable\n\t      by unprivileged agents.Access control logic should differentiate between read and write access and to have\n\t      sufficient address granularity.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1221", "Name": "Incorrect Register Defaults or Module Parameters", "Description": "Testing phase should use automated tools to test that values are configured per design specifications.", "Extended_Description": "Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to defined default values that are hard coded in the hardware description language (HDL) code of the hardware unit. Hardware descriptive languages also support definition of parameter variables, which can be defined in code during instantiation of the hardware IP module. Such parameters are generally used to configure a specific instance of a hardware IP in the design.The system security settings of a hardware design can be affected by incorrectly defined default values or IP parameters. The hardware IP would be in an insecure state at power reset, and this can be exposed or exploited by untrusted software running on the system. Both register defaults and parameters are hardcoded values, which cannot be changed using software or firmware patches but must be changed in hardware silicon. Thus, such security issues are considerably more difficult to address later in the lifecycle. Hardware designs can have a large number of such parameters and register defaults settings, and it is important to have design tool support to check these settings in an automated way and be able to identify which settings are security sensitive.", "Modes_Of_Introduction": "Implementation: Such issues could be introduced during implementation of hardware design, since IP parameters and defaults are defined in HDL code and identified later during Testing or System Configuration phases.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess Control. Impacts: Varies by Context. Note: Degradation of system functionality, or loss of access control enforcement can occur.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : During hardware design, all the system parameters and register defaults must be reviewed to identify security sensitive settings.Implementation : The default values of these security sensitive settings need to be defined as part of the design review phase.Testing : Testing phase should use automated tools to test that values are configured per design specifications.", "Demonstrative_Examples": "Consider example design module system verilog code shown below.register_example module is an example parameterized module that defines two parameters, REGISTER_WIDTH and REGISTER_DEFAULT. Register_example module defines a Secure_mode setting, which when set makes the register content read-only and not modifiable by software writes. register_top module instantiates two registers, Insecure_Device_ID_1 and Insecure_Device_ID_2. Generally, registers containing device identifier values are required to be read only to prevent any possibility of software modifying these values.. These example instantiations show how, in a hardware design, it would be possible to instantiate the register module with insecure defaults and parameters.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1222", "Name": "Insufficient Granularity of Address Regions Protected by Register Locks", "Description": "The defining of protected locked registers should be reviewed or tested early in the design phase with software teams to ensure software flows are not blocked by the security locks.\n                        As an alternative to using register lock control bits and fixed access control regions, the hardware design could use programmable security access control configuration so that device trusted firmware can configure and change the protected regions based on software usage and security models.", "Extended_Description": "Integrated circuits and hardware IPs can expose the device configuration controls that need to be programmed after device power reset by a trusted firmware or software module (commonly set by BIOS/bootloader) and then locked from any further modification. In hardware design, this is commonly implemented using a programmable lock bit which enables/disables writing to a protected set of registers or address regions. When the programmable lock bit is set, the relevant address region can be implemented as a hardcoded value in hardware logic that cannot be changed later.A problem can arise wherein the protected region definition is not granular enough. After the programmable lock bit has been set, then this new functionality cannot be implemented without change to the hardware design.", "Modes_Of_Introduction": "Architecture and Design: Such issues are introduced during hardware architecture and design since software controls and configuration are defined during these phases and identified later during Testing or System Configuration phases.", "Common_Consequences": "Scopes: Access Control. Impacts: Other. Note: System security configuration cannot be defined in a way that does not conflict with functional requirements of device.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : The defining of protected locked registers should be reviewed or tested early in the design phase with software teams to ensure software flows are not blocked by the security locks.\n                        As an alternative to using register lock control bits and fixed access control regions, the hardware design could use programmable security access control configuration so that device trusted firmware can configure and change the protected regions based on software usage and security models.", "Demonstrative_Examples": "For example, consider a hardware unit with a 32 kilobyte configuration address space where the first 8 kilobyte address contains security sensitive controls that must only be writable by device bootloader. One way to protect the security configuration could be to define a 32 bit system configuration locking register (SYS_LOCK) where each bit lock locks the corresponding 1 kilobyte region.. If a register exists within the first kilobyte address range (e.g. SW_MODE, address 0x310) and needs to be software writable at runtime, then this register cannot be written in a securely configured system since SYS_LOCK register lock bit 0 must be set to protect other security settings (e.g. SECURITY_FEATURE_ENABLE, address 0x0004). The only fix would be to change the hardware logic or not set the security lock bit.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1220", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "362", "Name": "Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition')", "Description": "Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.", "Extended_Description": "This can have security implications when the expected synchronization is in security-critical code, such as recording whether a user is authenticated or modifying important state information that should not be influenced by an outsider.A race condition occurs within concurrent environments, and is effectively a property of a code sequence. Depending on the context, a code sequence may be in the form of a function call, a small number of instructions, a series of program invocations, etc.A race condition violates these properties, which are closely related:A race condition exists when an \"interfering code sequence\" can still access the shared resource, violating exclusivity. Programmers may assume that certain code sequences execute too quickly to be affected by an interfering code sequence; when they are not, this violates atomicity. For example, the single \"x++\" statement may appear atomic at the code layer, but it is actually non-atomic at the instruction layer, since it involves a read (the original value of x), followed by a computation (x+1), followed by a write (save the result to x).The interfering code sequence could be \"trusted\" or \"untrusted.\" A trusted interfering code sequence occurs within the product; it cannot be modified by the attacker, and it can only be invoked indirectly. An untrusted interfering code sequence can be authored directly by the attacker, and typically it is external to the vulnerable product.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Resource Consumption (Other). Note: When a race condition makes it possible to bypass a resource cleanup routine or trigger multiple initialization routines, it may lead to resource exhaustion (CWE-400).Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Instability. Note: When a race condition allows multiple control flows to access a resource simultaneously, it might lead the product(s) into unexpected states, possibly resulting in a crash.Scopes: ConfidentialityIntegrity. Impacts: Read Files or DirectoriesRead Application Data. Note: When a race condition is combined with predictable resource names and loose permissions, it may be possible for an attacker to overwrite or access confidential data (CWE-59).", "Detection_Methods": "Method Name: Black Box. Description: Black box methods may be able to identify evidence of race conditions via methods such as multiple simultaneous connections, which may cause the software to become instable or crash. However, race conditions with very narrow timing windows would not be detectable. Method Name: White Box. Description: Common idioms are detectable in white box analysis, such as time-of-check-time-of-use (TOCTOU) file operations (CWE-367), or double-checked locking (CWE-609). Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.Race conditions may be detected with a stress-test by calling the software simultaneously from a large number of threads or processes, and look for evidence of any unexpected behavior.Insert breakpoints or delays in between relevant code statements to artificially expand the race window so that it will be easier to detect. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : In languages that support it, use synchronization primitives. Only wrap these around critical code to minimize the impact on performance.Architecture and Design : Use thread-safe capabilities such as the data access abstraction in Spring.Architecture and Design : Minimize the usage of shared resources in order to remove as much complexity as possible from the control flow and to reduce the likelihood of unexpected conditions occurring.\n                  Additionally, this will minimize the amount of synchronization necessary and may even help to reduce the likelihood of a denial of service where an attacker may be able to repeatedly trigger a critical section (CWE-400).Implementation : When using multithreading and operating on shared variables, only use thread-safe functions.Implementation : Use atomic operations on shared variables. Be wary of innocent-looking constructs such as \"x++\". This may appear atomic at the code layer, but it is actually non-atomic at the instruction layer, since it involves a read, followed by a computation, followed by a write.Implementation : Use a mutex if available, but be sure to avoid related weaknesses such as CWE-412.Implementation : Avoid double-checked locking (CWE-609) and other implementation errors that arise when trying to avoid the overhead of synchronization.Implementation : Disable interrupts or signals over critical parts of the code, but also make sure that the code does not go into a large or infinite loop.Implementation : Use the volatile type modifier for critical variables to avoid unexpected compiler optimization or reordering. This does not necessarily solve the synchronization problem, but it can help.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.", "Demonstrative_Examples": "This code could be used in an e-commerce application that supports transfers between accounts. It takes the total amount of the transfer, sends it to the new account, and deducts the amount from the original account.. A race condition could occur between the calls to GetBalanceFromDatabase() and SendNewBalanceToDatabase().The following function attempts to acquire a lock in order to perform operations on a shared resource.. However, the code does not check the value returned by pthread_mutex_lock() for errors. If pthread_mutex_lock() cannot acquire the mutex for any reason, the function may introduce a race condition into the program and result in undefined behavior.Suppose a processor's Memory Management Unit (MMU) has 5 other shadow MMUs to distribute its workload for its various cores. Each MMU has the start address and end address of \"accessible\" memory. Any time this accessible range changes (as per the processor's boot status), the main MMU sends an update message to all the shadow MMUs.. Suppose the interconnect fabric does not prioritize such \"update\" packets over other general traffic packets. This introduces a race condition. If an attacker can flood the target with enough messages so that some of those attack packets reach the target before the new access ranges gets updated, then the attacker can leverage this scenario.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1223", "Name": "Race Condition for Write-Once Attributes", "Description": "The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.", "Extended_Description": "Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to defined default values that are hard coded in the hardware description language (HDL) code of the hardware unit. A common security protection method used to protect register settings from modification by software is to make them write-once. This means the hardware implementation only allows writing to such registers once, and they become read-only after having been written once by software. This is useful to allow initial boot software to configure systems settings to secure values while blocking runtime software from modifying such hardware settings.Implementation issues in hardware design of such controls can expose such registers to a race condition security flaw. For example, consider a hardware design that has two different software/firmware modules executing in parallel. One module is trusted (module A) and another is untrusted (module B). In this design it could be possible for Module B to send write cycles to the write-once register before Module A. Since the field is write-once the programmed value from Module A will be ignored and the pre-empted value programmed by Module B will be used by hardware.", "Modes_Of_Introduction": "Architecture and Design: This weakness can appear in designs that use register write-once attributes with two or more software/firmware modules with varying levels of trust executing in parallel.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: System configuration cannot be programmed in a secure way.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : During hardware design all register write-once or sticky fields must be evaluated for proper configuration.Testing : The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.", "Demonstrative_Examples": "consider the example design module system verilog code shown below. register_write_once_example module is an example of register that has a write-once field defined. Bit 0 field captures the write_once_status value.. The first system component that sends a write cycle to this register can program the value. This could result in a race condition security issue in the SoC design, if an untrusted agent is running in the system in parallel with the trusted component that is expected to program the register.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1224", "Name": "Improper Restriction of Write-Once Bit Fields", "Description": "The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.", "Extended_Description": "Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to define default values that are hard coded in the hardware description language (HDL) code of the hardware unit. A common security protection method used to protect register settings from modification by software is to make the settings write-once or \"sticky.\" This allows writing to such registers only once, whereupon they become read-only. This is useful to allow initial boot software to configure systems settings to secure values while blocking runtime software from modifying such hardware settings.Failure to implement write-once restrictions in hardware design can expose such registers to being re-programmed by software and written multiple times. For example, write-once fields could be implemented to only be write-protected if they have been set to value \"1\", wherein they would work as \"write-1-once\" and not \"write-once\".", "Modes_Of_Introduction": "Implementation: Such issues could be introduced during implementation of hardware design, since IP parameters and defaults are defined in HDL code and identified later during Testing or System Configuration phases.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess Control. Impacts: Varies by Context. Note: System configuration cannot be programmed in a secure way.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : During hardware design all register write-once or sticky fields must be evaluated for proper configuration.Testing : The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.", "Demonstrative_Examples": "Consider the example design module system verilog code shown below. register_write_once_example module is an example of register that has a write-once field defined. Bit 0 field captures the write_once_status value. This implementation can be for a register that is defined by specification to be a write-once register, since the write_once_status field gets written by input data bit 0 on first write.. The above example only locks further writes if write_once_status bit is written to one. So it acts as write_1-Once instead of the write-once attribute.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1229", "Name": "Creation of Emergent Resource", "Description": "The product manages resources or behaves in a way that indirectly creates a new, distinct resource that can be used by attackers in violation of the intended policy.", "Extended_Description": "A product is only expected to behave in a way that was specifically intended by the developer.  Resource allocation and management is expected to be performed explicitly by the associated code.  However, in systems with complex behavior, the product might indirectly produce new kinds of resources that were never intended in the original design.  For example, a covert channel is a resource that was never explicitly intended by the developer, but it is useful to attackers.  \"Parasitic computing,\" while not necessarily malicious in nature, effectively tricks a product into performing unintended computations on behalf of another party.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "123", "Name": "Write-what-where Condition", "Description": "Use OS-level preventative functionality integrated after the fact. Not a complete solution.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Modify MemoryExecute Unauthorized Code or CommandsGain Privileges or Assume IdentityDoS: Crash, Exit, or RestartBypass Protection Mechanism. Note: Clearly, write-what-where conditions can be used to write data to areas of memory outside the scope of a policy. Also, they almost invariably can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy. If the attacker can overwrite a pointer's worth of memory (usually 32 or 64 bits), they can redirect a function pointer to their own malicious code. Even when the attacker can only modify a single byte arbitrary code execution can be possible. Sometimes this is because the same problem can be exploited repeatedly to the same effect. Other times it is because the attacker can overwrite security-critical application-specific data -- such as a flag indicating whether the user is an administrator.Scopes: IntegrityAvailability. Impacts: DoS: Crash, Exit, or RestartModify Memory. Note: Many memory accesses can lead to program termination, such as when writing to addresses that are invalid for the current process.Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: When the consequence is arbitrary code execution, this can often be used to subvert any other security service.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use a language that provides appropriate memory abstractions.Operation : Use OS-level preventative functionality integrated after the fact. Not a complete solution.", "Demonstrative_Examples": "The classic example of a write-what-where condition occurs when the accounting information for memory allocations is overwritten in a particular fashion. Here is an example of potentially vulnerable code:. Vulnerability in this case is dependent on memory layout. The call to strcpy() can be used to write past the end of buf1, and, with a typical layout, can overwrite the accounting information that the system keeps for buf2 when it is allocated. Note that if the allocation header for buf2 can be overwritten, buf2 itself can be overwritten as well.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "787", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "285", "Name": "Improper Authorization", "Description": "Use the access control capabilities of your operating system and server environment and define your access control lists accordingly. Use a \"default deny\" policy when defining these ACLs.", "Extended_Description": "Assuming a user with a given identity, authorization is the process of determining whether that user can access a given resource, based on the user's privileges and any permissions or other access-control specifications that apply to the resource.When access control checks are not applied consistently - or not at all - users are able to access data or perform actions that they should not be allowed to perform. This can lead to a wide range of problems, including information exposures, denial of service, and arbitrary code execution.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.A developer may introduce authorization weaknesses because of a lack of understanding about the underlying technologies. For example, a developer may assume that attackers cannot modify certain inputs such as headers or cookies.Architecture and Design: Authorization weaknesses may arise when a single-user application is ported to a multi-user environment.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Files or Directories. Note: An attacker could read sensitive data, either by reading the data directly from a data store that is not properly restricted, or by accessing insufficiently-protected, privileged functionality to read the data.Scopes: Integrity. Impacts: Modify Application DataModify Files or Directories. Note: An attacker could modify sensitive data, either by writing the data directly to a data store that is not properly restricted, or by accessing insufficiently-protected, privileged functionality to write the data.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker could gain privileges by modifying or reading critical data directly, or by accessing insufficiently-protected, privileged functionality.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis is useful for detecting commonly-used idioms for authorization. A tool may be able to analyze related configuration files, such as .htaccess in Apache web servers, or detect the usage of commonly-used authorization libraries.Generally, automated static analysis tools have difficulty detecting custom authorization schemes. In addition, the software's design may include some functionality that is accessible to any user and does not require an authorization check; an automated technique that detects the absence of authorization may report false positives. Method Name: Automated Dynamic Analysis. Description: Automated dynamic analysis may find many or all possible interfaces that do not require authorization, but manual analysis is required to determine if the lack of authorization violates business logic Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual static analysis is useful for evaluating the correctness of custom authorization mechanisms. Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Divide the product into anonymous, normal, privileged, and administrative areas. Reduce the attack surface by carefully mapping roles with data and functionality. Use role-based access control (RBAC) to enforce the roles at the appropriate boundaries.\n                  Note that this approach may not protect against horizontal authorization, i.e., it will not protect a user from attacking others with the same role.Architecture and Design : Ensure that you perform access control checks related to your business logic. These checks may be different than the access control checks that you apply to more generic resources such as files, connections, processes, memory, and database records. For example, a database may restrict access for medical records to a specific database user, but each record might only be intended to be accessible to the patient and the patient's doctor.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using authorization frameworks such as the JAAS Authorization Framework [REF-233] and the OWASP ESAPI Access Control feature [REF-45].Architecture and Design : For web applications, make sure that the access control mechanism is enforced correctly at the server side on every page. Users should not be able to access any unauthorized functionality or information by simply requesting direct access to that page.\n                  One way to do this is to ensure that all pages containing sensitive information are not cached, and that all such pages restrict access to requests that are accompanied by an active and authenticated session token associated with a user who has the required permissions to access that page.System Configuration : Use the access control capabilities of your operating system and server environment and define your access control lists accordingly. Use a \"default deny\" policy when defining these ACLs.", "Demonstrative_Examples": "This function runs an arbitrary SQL query on a given database, returning the result of the query.. While this code is careful to avoid SQL Injection, the function does not confirm the user sending the query is authorized to do so. An attacker may be able to obtain sensitive employee information from the database.The following program could be part of a bulletin board system that allows users to send private messages to each other. This program intends to authenticate the user before deciding whether a private message should be displayed. Assume that LookupMessageObject() ensures that the $id argument is numeric, constructs a filename based on that id, and reads the message details from that file. Also assume that the program stores all private messages for all users in the same directory.. While the program properly exits if authentication fails, it does not ensure that the message is addressed to the user. As a result, an authenticated attacker could provide any arbitrary identifier and read private messages that were intended for other users.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1230", "Name": "Exposure of Sensitive Information Through Metadata", "Description": "The product prevents direct access to a resource containing sensitive information, but it does not sufficiently limit access to metadata that is derived from the original, sensitive information.", "Extended_Description": "Developers might correctly prevent unauthorized access to a database or other resource containing sensitive information, but they might not consider that portions of the original information might also be recorded in metadata, search indices, statistical reports, or other resources.  If these resources are not also restricted, then attackers might be able to extract some or all of the original information, or otherwise infer some details.  For example, an attacker could specify search terms that are known to be unique to a particular person, or view metadata such as activity or creation dates in order to identify usage patterns.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1231", "Name": "Improper Prevention of Lock Bit Modification", "Description": "Security lock bit protections must be reviewed for design inconsistency and common weaknesses.\n                            Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.", "Extended_Description": "In integrated circuits and hardware\n\t\t\t  intellectual property (IP) cores, device configuration\n\t\t\t  controls are commonly programmed after a device power\n\t\t\t  reset by a trusted firmware or software module (e.g.,\n\t\t\t  BIOS/bootloader) and then locked from any further\n\t\t\t  modification.This behavior is commonly implemented using a trusted lock bit. \n\t\t\t  When set, the lock bit disables writes to a protected set of\n\t\t\t  registers or address regions. Design or coding errors in\n\t\t\t  the implementation of the lock bit protection feature\n\t\t\t  may allow the lock bit to be modified or cleared by\n\t\t\t  software after it has been set. Attackers might be able to unlock the system and\n\t\t\t  features that the bit is intended to protect.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.", "Common_Consequences": "Scopes: Access Control. Impacts: Modify Memory. Note: Registers protected by lock bit can be modified even when lock is set.", "Detection_Methods": "Method Name: Manual Analysis. Description: Set the lock bit. Power cycle the\n\t     device. Attempt to clear the lock bit.  If the\n\t     information is changed, implement a design\n\t     fix. Retest. Also, attempt to indirectly clear the lock\n\t     bit or bypass it.", "Potential_Mitigations": "Architecture and Design : Security lock bit protections must be reviewed for design inconsistency and common weaknesses.\n                            Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.", "Demonstrative_Examples": "Consider the example design below for a digital thermal sensor that detects overheating of the silicon and triggers system shutdown. The system critical temperature limit (CRITICAL_TEMP_LIMIT) and thermal sensor calibration (TEMP_SENSOR_CALIB) data have to be programmed by firmware, and then the register needs to be locked (TEMP_SENSOR_LOCK).. In this example, note that if the system heats to critical temperature, the response of the system is controlled by the TEMP_HW_SHUTDOWN bit [1], which is not lockable. Thus, the intended security property of the critical temperature sensor cannot be fully protected, since software can misconfigure the TEMP_HW_SHUTDOWN register even after the lock bit is set to disable the shutdown response.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "667", "Name": "Improper Locking", "Description": "Use industry standard APIs to implement locking mechanism.", "Extended_Description": "Locking is a type of synchronization behavior that ensures that multiple independently-operating processes or threads do not interfere with each other when accessing the same resource. All processes/threads are expected to follow the same steps for locking. If these steps are not followed precisely - or if no locking is done at all - then another process/thread could modify the shared resource in a way that is not visible or predictable to the original process.  This can lead to data or memory corruption, denial of service, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU). Note: Inconsistent locking discipline can lead to deadlock.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Use industry standard APIs to implement locking mechanism.", "Demonstrative_Examples": ". In the following Java snippet, methods are defined to get and set a long field in an instance of a class that is shared across multiple threads. Because operations on double and long are nonatomic in Java, concurrent access may cause unexpected behavior. Thus, all operations on long and double fields should be synchronized.This code tries to obtain a lock for a file, then writes to it.. PHP by default will wait indefinitely until a file lock is released. If an attacker is able to obtain the file lock, this code will pause execution, possibly leading to denial of service for other users. Note that in this case, if an attacker can perform an flock() on the file, they may already have privileges to destroy the log file. However, this still impacts the execution of other programs that depend on flock().The following function attempts to acquire a lock in order to perform operations on a shared resource.. However, the code does not check the value returned by pthread_mutex_lock() for errors. If pthread_mutex_lock() cannot acquire the mutex for any reason, the function may introduce a race condition into the program and result in undefined behavior.It may seem that the following bit of code achieves thread safety while avoiding unnecessary synchronization.... The programmer wants to guarantee that only one Helper() object is ever allocated, but does not want to pay the cost of synchronization every time this code is called.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1232", "Name": "Improper Lock Behavior After Power State Transition", "Description": "Security Lock bit protections should be reviewed for behavior across supported power state transitions.\n              Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing including testing across power transitions.", "Extended_Description": "Devices may allow device configuration controls which need to be programmed after device power reset via a trusted firmware or software module (commonly set by BIOS/bootloader) and then locked from any further modification. This action is commonly implemented using a programmable lock bit, which, when set, disables writes to a protected set of registers or address regions.After a power state transition, the lock bit is set to unlocked. Some common weaknesses that can exist in such a protection scheme are that the lock gets cleared, the values of the protected registers get reset, or the lock become programmable.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Security Lock bit protections should be reviewed for behavior across supported power state transitions.\n              Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing including testing across power transitions.", "Demonstrative_Examples": "Consider the memory configuration settings of a system that uses DDR3 DRAM memory. Protecting the DRAM memory configuration from modification by software is required to ensure that system memory access control protections cannot be bypassed. This can be done by using lock bit protection that locks all of the memory configuration registers. The memory configuration lock can be set by the BIOS during the boot process.If such a system also supports a rapid power on mode like hibernate, the DRAM data must be saved to a disk before power is removed and restored back to the DRAM once the system powers back up and before the OS resumes operation after returning from hibernate.. To support the hibernate transition back to the operating state, the DRAM memory configuration must be reprogrammed even though it was locked previously. As the hibernate resume does a partial reboot, the memory configuration could be altered before the memory lock is set. Functionally the hibernate resume flow requires a bypass of the lock-based protection. The memory configuration must be securely stored and restored by trusted system firmware. Lock settings and system configuration must be restored to the same state it was in before the device entered into the hibernate mode.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1233", "Name": "Security-Sensitive Hardware Controls with Missing Lock Bit Protection", "Description": "Security lock bit protections must be reviewed for design inconsistency and common weaknesses.\n\t\t\t    Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.", "Extended_Description": "Integrated circuits and hardware intellectual properties (IPs) might provide device configuration controls that need to be programmed after device power reset by a trusted firmware or software module, commonly set by BIOS/bootloader. After reset, there can be an expectation that the controls cannot be used to perform any further modification. This behavior is commonly implemented using a trusted lock bit, which can be set to disable writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration).However, if the lock bit does not effectively write-protect all system registers or controls that could modify the protected system configuration, then an adversary may be able to use software to access the registers/controls and modify the protected hardware configuration.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.", "Common_Consequences": "Scopes: Access Control. Impacts: Modify Memory. Note: System Configuration protected by the lock bit can be modified even when the lock is set.", "Detection_Methods": "Method Name: Manual Analysis. Description: Set the lock bit. Attempt to modify the\n\t     information protected by the lock bit. If the information\n\t     is changed, implement a design fix. Retest. Also, attempt\n\t     to indirectly clear the lock bit or bypass\n\t     it.", "Potential_Mitigations": "Architecture and Design : Security lock bit protections must be reviewed for design inconsistency and common weaknesses.\n\t\t\t    Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.", "Demonstrative_Examples": "Consider the example design below for a digital thermal sensor that detects overheating of the silicon and triggers system shutdown. The system critical temperature limit (CRITICAL_TEMP_LIMIT) and thermal sensor calibration (TEMP_SENSOR_CALIB) data have to be programmed by the firmware.. In this example note that only the CRITICAL_TEMP_LIMIT register is protected by the TEMP_SENSOR_LOCK bit, while the security design intent is to protect any modification of the critical temperature detection and response.The response of the system, if the system heats to a critical temperature, is controlled by TEMP_HW_SHUTDOWN bit [1], which is not lockable. Also, the TEMP_SENSOR_CALIB register is not protected by the lock bit.By modifying the temperature sensor calibration, the conversion of the sensor data to a degree centigrade can be changed, such that the current temperature will never be detected to exceed critical temperature value programmed by the protected lock.Similarly, by modifying the TEMP_HW_SHUTDOWN.Enable bit, the system response detection of the current temperature exceeding critical temperature can be disabled.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1234", "Name": "Hardware Internal or Debug Modes Allow Override of Locks", "Description": "Security Lock bit protections should be reviewed for any bypass/override modes supported.\n          Any supported override modes either should be removed or protected using authenticated debug modes.\n          Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing.", "Extended_Description": "Device configuration controls are commonly programmed after a device power reset by a trusted firmware or software module (e.g., BIOS/bootloader) and then locked from any further modification. This is commonly implemented using a trusted lock bit, which when set, disables writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration). If debug features supported by hardware or internal modes/system states are supported in the hardware design, modification of the lock protection may be allowed allowing access and modification of configuration information.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: Bypass of lock bit allows access and modification of system configuration even when the lock bit is set.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Security Lock bit protections should be reviewed for any bypass/override modes supported.\n          Any supported override modes either should be removed or protected using authenticated debug modes.\n          Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing.", "Demonstrative_Examples": "For example, consider the example Locked_override_register example. This register module supports a lock mode that blocks any writes after lock is set to 1.. If either the scan_mode or the debug_unlocked modes can be triggered by software, then the lock protection may be bypassed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "400", "Name": "Uncontrolled Resource Consumption", "Description": "Ensure that all failures in resource allocation place the system into a safe posture.", "Extended_Description": "Limited resources include memory, file system storage, database connection pool entries, and CPU. If an attacker can trigger the allocation of these limited resources, but the number or size of the resources is not controlled, then the attacker could cause a denial of service that consumes all available resources. This would prevent valid users from accessing the product, and it could potentially have an impact on the surrounding environment. For example, a memory exhaustion attack against an application could slow down the application as well as its host operating system.There are at least three distinct scenarios which can commonly lead to resource exhaustion:Resource exhaustion problems are often result due to an incorrect implementation of the following situations:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Resource Consumption (Other). Note: The most common result of resource exhaustion is denial of service. The product may slow down, crash due to unhandled errors, or lock out legitimate users.Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: In some cases it may be possible to force the product to \"fail open\" in the event of resource exhaustion. The state of the product -- and possibly the security functionality - may then be compromised.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis typically has limited utility in recognizing resource exhaustion problems, except for program-independent system resources such as files, sockets, and processes. For system resources, automated static analysis may be able to detect circumstances in which resources are not released after they have expired. Automated analysis of configuration files may be able to detect settings that do not specify a maximum value.Automated static analysis tools will not be appropriate for detecting exhaustion of custom resources, such as an intended security policy in which a bulletin board user is only allowed to make a limited number of posts per day. Method Name: Automated Dynamic Analysis. Description: Certain automated dynamic analysis techniques may be effective in spotting resource exhaustion problems, especially with resources such as processes, memory, and connections. The technique may involve generating a large number of requests to the product within a short time frame. Method Name: Fuzzing. Description: While fuzzing is typically geared toward finding low-level implementation bugs, it can inadvertently find resource exhaustion problems. This can occur when the fuzzer generates a large number of test cases but does not restart the targeted product in between test cases. If an individual test case produces a crash, but it does not do so reliably, then an inability to handle resource exhaustion may be the cause.", "Potential_Mitigations": "Architecture and Design : Design throttling mechanisms into the system architecture. The best protection is to limit the amount of resources that an unauthorized user can cause to be expended. A strong authentication and access control model will help prevent such attacks from occurring in the first place. The login application should be protected against DoS attacks as much as possible. Limiting the database access, perhaps by caching result sets, can help minimize the resources expended. To further limit the potential for a DoS attack, consider tracking the rate of requests received from users and blocking requests that exceed a defined rate threshold.Architecture and Design : Mitigation of resource exhaustion attacks requires that the target system either:\n                     \n                        recognizes the attack and denies that user further access for a given amount of time, or\n                        uniformly throttles all requests in order to make it more difficult to consume resources more quickly than they can again be freed.\n                     \n                  The first of these solutions is an issue in itself though, since it may allow attackers to prevent the use of the system by a particular valid user. If the attacker impersonates the valid user, they may be able to prevent the user from accessing the server in question.\n                  The second solution is simply difficult to effectively institute -- and even when properly done, it does not provide a full solution. It simply makes the attack require more resources on the part of the attacker.Architecture and Design : Ensure that protocols have specific limits of scale placed on them.Implementation : Ensure that all failures in resource allocation place the system into a safe posture.", "Demonstrative_Examples": "The following example demonstrates the weakness.. There are no limits to runnables. Potentially an attacker could cause resource problems very quickly.This code allocates a socket and forks each time it receives a new connection.. The program does not track how many connections have been made, and it does not limit the number of connections. Because forking is a relatively expensive operation, an attacker would be able to cause the system to run out of CPU, processes, or memory by making a large number of connections. Alternatively, an attacker could consume all available connections, preventing others from accessing the system remotely.In the following example a server socket connection is used to accept a request to store data on the local file system using a specified filename. The method openSocketConnection establishes a server socket to accept requests from a client. When a client establishes a connection to this service the getNextMessage method is first used to retrieve from the socket the name of the file to store the data, the openFileToWrite method will validate the filename and open a file to write to on the local file system. The getNextMessage is then used within a while loop to continuously read data from the socket and output the data to the file until there is no longer any data from the socket.. This example creates a situation where data can be dumped to a file on the local file system without any limits on the size of the file. This could potentially exhaust file or disk resources and/or limit other clients' ability to access the service.In the following example, the processMessage method receives a two dimensional character array containing the message to be processed. The two-dimensional character array contains the length of the message in the first character array and the message body in the second character array. The getMessageLength method retrieves the integer value of the length from the first character array. After validating that the message length is greater than zero, the body character array pointer points to the start of the second character array of the two-dimensional character array and memory is allocated for the new body character array.. This example creates a situation where the length of the body character array can be very large and will consume excessive memory, exhausting system resources. This can be avoided by restricting the length of the second character array with a maximum length checkIn the following example, a server object creates a server socket and accepts client connections to the socket. For every client connection to the socket a separate thread object is generated using the ClientSocketThread class that handles request made by the client through the socket.. In this example there is no limit to the number of client connections and client threads that are created. Allowing an unlimited number of client connections and threads could potentially overwhelm the system and system resources.In the following example, the serve function receives an http request and an http response writer. It reads the entire request body.. Because ReadAll is defined to read from src until EOF, it does not treat an EOF from Read as an error to be reported. This example creates a situation where the length of the body supplied can be very large and will consume excessive memory, exhausting system resources. This can be avoided by ensuring the body does not exceed a predetermined length of bytes.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1235", "Name": "Incorrect Use of Autoboxing and Unboxing for Performance Critical Operations", "Description": "Use of boxed primitives should be limited to certain situations such as when calling methods with typed parameters.  Examine the use of boxed primitives prior to use. Use SparseArrays or ArrayMap instead of HashMap to avoid performance overhead.", "Extended_Description": "Languages such as Java and C# support automatic conversion through their respective compilers from primitive types into objects of the corresponding wrapper classes, and vice versa. For example, a compiler might convert an int to Integer (called autoboxing) or an Integer to int (called unboxing). This eliminates forcing the programmer to perform these conversions manually, which makes the code cleaner.However, this feature comes at a cost of performance and can lead to resource exhaustion and impact availability when used with generic collections. Therefore, they should not be used for scientific computing or other performance critical operations. They are only suited to support \"impedance mismatch\" between reference types and primitives.", "Modes_Of_Introduction": "Implementation: The programmer may use boxed primitives when not strictly necessary.", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Resource Consumption (Other)Reduce Performance. Note: Incorrect autoboxing/unboxing would result in reduced performance, which sometimes can lead to resource consumption issues.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use of boxed primitives should be limited to certain situations such as when calling methods with typed parameters.  Examine the use of boxed primitives prior to use. Use SparseArrays or ArrayMap instead of HashMap to avoid performance overhead.", "Demonstrative_Examples": "Java has a boxed primitive for each primitive type. A long can be represented with the boxed primitive Long. Issues arise where boxed primitives are used when not strictly necessary.. In the above loop, we see that the count variable is declared as a boxed primitive. This causes autoboxing on the line that increments. This causes execution to be magnitudes less performant (time and possibly space) than if the \"long\" primitive was used to declare the count variable, which can impact availability of a resource.. This code uses primitive long which fixes the issue.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "74", "Name": "Improper Neutralization of Special Elements in Output Used by a Downstream Component ('Injection')", "Description": "Utilize an appropriate mix of allowlist and denylist parsing to filter control-plane syntax from all input.", "Extended_Description": "Software or other automated logic has certain assumptions about what constitutes data and control respectively. It is the lack of verification of these assumptions for user-controlled input that leads to injection problems. Injection problems encompass a wide variety of issues -- all mitigated in very different ways and usually attempted in order to alter the control flow of the process. For this reason, the most effective way to discuss these weaknesses is to note the distinct features that classify them as injection weaknesses. The most important issue to note is that all injection problems share one thing in common -- i.e., they allow for the injection of control plane data into the user-controlled data plane. This means that the execution of the process may be altered by sending code in through legitimate data channels, using no other mechanism. While buffer overflows, and many other flaws, involve the use of some further issue to gain execution, injection problems need only for the data to be parsed.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Many injection attacks involve the disclosure of important information -- in terms of both data sensitivity and usefulness in further exploitation.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: In some cases, injectable code controls authentication; this may lead to a remote vulnerability.Scopes: Other. Impacts: Alter Execution Logic. Note: Injection attacks are characterized by the ability to significantly change the flow of a given process, and in some cases, to the execution of arbitrary code.Scopes: IntegrityOther. Impacts: Other. Note: Data injection attacks lead to loss of data integrity in nearly all cases as the control-plane data injected is always incidental to data recall or writing.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: Often the actions performed by injected control code are unlogged.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : Programming languages and supporting technologies might be chosen which are not subject to these issues.Implementation : Utilize an appropriate mix of allowlist and denylist parsing to filter control-plane syntax from all input.", "Demonstrative_Examples": "This example code intends to take the name of a user and list the contents of that user's home directory. It is subject to the first variant of OS command injection.. The $userName variable is not checked for malicious input. An attacker could set the $userName variable to an arbitrary OS command such as:Consider the following program. It intends to perform an \"ls -l\" on an input filename. The validate_name() subroutine performs validation on the input to make sure that only alphanumeric and \"-\" characters are allowed, which avoids path traversal (CWE-22) and OS command injection (CWE-78) weaknesses. Only filenames like \"abc\" or \"d-e-f\" are intended to be allowed.. However, validate_name() alows\n               filenames that begin with a \"-\". An adversary could\n               supply a filename like \"-aR\", producing the \"ls -l -aR\"\n               command (CWE-88), thereby getting a full recursive\n               listing of the entire directory and all of its\n               sub-directories.There are a couple possible mitigations for this\n\t\t\t   weakness. One would be to refactor the code to avoid\n\t\t\t   using system() altogether, instead relying on internal\n\t\t\t   functions.Another option could be to add a \"--\" argument\n\t\t\t   to the ls command, such as \"ls -l --\", so that any\n\t\t\t   remaining arguments are treated as filenames, causing\n\t\t\t   any leading \"-\" to be treated as part of a filename\n\t\t\t   instead of another option.Another fix might be to change the regular expression used in validate_name to force the first character of the filename to be a letter or number, such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1236", "Name": "Improper Neutralization of Formula Elements in a CSV File", "Description": "Certain implementations of spreadsheet software might disallow formulas from executing if the file is untrusted, or if the file is not authored by the current user.", "Extended_Description": "User-provided data is often saved to traditional databases.  This data can be exported to a CSV file, which allows users to read the data using spreadsheet software such as Excel, Numbers, or Calc.  This software interprets entries beginning with '=' as formulas, which are then executed by the spreadsheet software.  The software's formula language often allows methods to access hyperlinks or the local command line, and frequently allows enough characters to invoke an entire script. Attackers can populate data fields which, when saved to a CSV file, may attempt information exfiltration or other malicious activity when automatically executed by the spreadsheet software.", "Modes_Of_Introduction": "Implementation: The weakness is in the implementation of a software's CSV export feature, in particular how it formats formula entries as the output gets flattened into a text file.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataExecute Unauthorized Code or Commands. Note: Current versions of Excel warn users of untrusted content.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : When generating CSV output, ensure that formula-sensitive metacharacters are effectively escaped or removed from all data before storage in the resultant CSV.  Risky characters include '=' (equal), '+' (plus), '-' (minus), and '@' (at).Implementation : If a field starts with a formula character, prepend it with a ' (single apostrophe), which prevents Excel from executing the formula.Architecture and Design : Certain implementations of spreadsheet software might disallow formulas from executing if the file is untrusted, or if the file is not authored by the current user.", "Demonstrative_Examples": "Hyperlinks or other commands can be executed when a cell begins with the formula identifier, '='. Stripping the leading equals sign, or simply not executing formulas from untrusted sources, impedes malicious activity.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "226", "Name": "Sensitive Information in Resource Not Removed Before Reuse", "Description": "When releasing, de-allocating, or deleting a resource, overwrite its data and relevant metadata with fixed patterns or random data. Be cautious about complex resource types whose underlying representation might be non-contiguous or change at a low level, such as how a file might be split into different chunks on a file system, even though \"logical\" file positions are contiguous at the application layer. Such resource types might require invocation of special modes or APIs to tell the underlying operating system to perform the necessary clearing, such as SDelete (Secure Delete) on Windows, although the appropriate functionality might not be available at the application layer.", "Extended_Description": "When resources are released, they can be made available for reuse. For example, after memory is de-allocated, an operating system may make the memory available to another process, or disk space may be reallocated when a file is deleted. As removing information requires time and additional resources, operating systems do not usually clear the previously written information.Even when the resource is reused by the same process, this weakness can arise when new data is not as large as the old data, which leaves portions of the old data still available. Equivalent errors can occur in other situations where the length of data is variable but the associated data structure is not. If memory is not cleared after use, the information may be read by less trustworthy parties when the memory is reallocated.This weakness can apply in hardware, such as when a device or system switches between power, sleep, or debug states during normal operation, or when execution changes to different users or privilege levels.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Analysis. Description: Write a known pattern into each sensitive location. Trigger the release of the resource or cause the desired state transition to occur. Read data back from the sensitive locations. If the reads are successful, and the data is the same as the pattern that was originally written, the test fails and the product needs to be fixed. Note that this test can likely be automated. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : During critical state transitions, information not needed in the next state should be removed or overwritten with fixed patterns (such as all 0's) or random data, before the transition to the next state.Architecture and Design : When releasing, de-allocating, or deleting a resource, overwrite its data and relevant metadata with fixed patterns or random data. Be cautious about complex resource types whose underlying representation might be non-contiguous or change at a low level, such as how a file might be split into different chunks on a file system, even though \"logical\" file positions are contiguous at the application layer. Such resource types might require invocation of special modes or APIs to tell the underlying operating system to perform the necessary clearing, such as SDelete (Secure Delete) on Windows, although the appropriate functionality might not be available at the application layer.", "Demonstrative_Examples": "This example shows how an attacker can take advantage of an incorrect state transition.. Suppose a device is transitioning from state A to state B. During state A, it can read certain private keys from the hidden fuses that are only accessible in state A but not in state B. The device reads the keys, performs operations using those keys, then transitions to state B, where those private keys should no longer be accessible.After the transition to state B, even though the private keys are no longer accessible directly from the fuses in state B, they can be accessed indirectly by reading the memory that contains the private keys.The following code calls realloc() on a buffer containing sensitive data:. There is an attempt to scrub the sensitive data from memory, but realloc() is used, so it could return a pointer to a different part of memory. The memory that was originally allocated for cleartext_buffer could still contain an uncleared copy of the data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "459", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "212", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "201", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1239", "Name": "Improper Zeroization of Hardware Register", "Description": "Every register potentially containing sensitive information must have a policy specifying how and when information is cleared, in addition to clarifying if it is the responsibility of the hardware logic or IP user to initiate the zeroization procedure at the appropriate time.", "Extended_Description": "Hardware logic operates on data stored in registers local to the hardware block. Most hardware IPs, including cryptographic accelerators, rely on registers to buffer I/O, store intermediate values, and interface with software. The result of this is that sensitive information, such as passwords or encryption keys, can exist in locations not transparent to the user of the hardware logic. When a different entity obtains access to the IP due to a change in operating mode or conditions, the new entity can extract information belonging to the previous user if no mechanisms are in place to clear register contents. It is important to clear information stored in the hardware if a physical attack on the product is detected, or if the user of the hardware block changes. The process of clearing register contents in a hardware IP is referred to as zeroization in standards for cryptographic hardware modules such as FIPS-140-2 [REF-267].", "Modes_Of_Introduction": "Architecture and Design: Lack of hardware mechanisms to zeroize or clear registers in the design or specification.Implementation: Mechanisms to zeroize and clear registers are in the design but implemented incorrectly.Operation: Hardware-provided zeroization mechanisms are not used appropriately by the IP user (ex. firmware), or data remanence issues are not taken into account.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Varies by Context. Note: The consequences will depend on the information disclosed due to the vulnerability.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Every register potentially containing sensitive information must have a policy specifying how and when information is cleared, in addition to clarifying if it is the responsibility of the hardware logic or IP user to initiate the zeroization procedure at the appropriate time.", "Demonstrative_Examples": ". Suppose a hardware IP for implementing an encryption routine works as expected, but it leaves the intermediate results in some registers that can be accessed. Exactly why this access happens is immaterial - it might be unintentional or intentional, where the designer wanted a \"quick fix\" for something.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "226", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "226", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "786", "Name": "Access of Memory Location Before Start of Buffer", "Description": "Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Extended_Description": "This typically occurs when a pointer or its index is decremented to a position before the buffer, when pointer arithmetic results in a position before the beginning of the valid memory location, or when a negative index is used.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Memory. Note: For an out-of-bounds read, the attacker may have access to sensitive information. If the sensitive information contains system details, such as the current buffers position in memory, this knowledge can be used to craft further attacks, possibly with more severe consequences.Scopes: IntegrityAvailability. Impacts: Modify MemoryDoS: Crash, Exit, or Restart. Note: Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash.Scopes: Integrity. Impacts: Modify MemoryExecute Unauthorized Code or Commands. Note: If the corrupted memory can be effectively controlled, it may be possible to execute arbitrary code. If the corrupted memory is data rather than instructions, the system will continue to function with improper changes, possibly in violation of an implicit or explicit policy.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "", "Demonstrative_Examples": "In the following C/C++ example, a utility function is used to trim trailing whitespace from a character string. The function copies the input string to a local character string and uses a while statement to remove the trailing whitespace by moving backward through the string and overwriting whitespace with a NUL character.. However, this function can cause a buffer underwrite if the input character string contains all whitespace. On some systems the while statement will move backwards past the beginning of a character string and will call the isspace() function on an address outside of the bounds of the local buffer.The following example asks a user for an offset into an array to select an item.. The programmer allows the user to specify which element in the list to select, however an attacker can provide an out-of-bounds offset, resulting in a buffer over-read (CWE-126).The following is an example of code that may result in a buffer underwrite, if find() returns a negative value to indicate that ch is not found in srcBuf:. If the index to srcBuf is somehow under user control, this is an arbitrary write-what-where condition.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "124", "Name": "Buffer Underwrite ('Buffer Underflow')", "Description": "All calculated values that are used as index or for pointer arithmetic should be validated to ensure that they are within an expected range.", "Extended_Description": "This typically occurs when a pointer or its index is decremented to a position before the buffer, when pointer arithmetic results in a position before the beginning of the valid memory location, or when a negative index is used.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityAvailability. Impacts: Modify MemoryDoS: Crash, Exit, or Restart. Note: Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash.Scopes: IntegrityConfidentialityAvailabilityAccess ControlOther. Impacts: Execute Unauthorized Code or CommandsModify MemoryBypass Protection MechanismOther. Note: If the corrupted memory can be effectively controlled, it may be possible to execute arbitrary code. If the corrupted memory is data rather than instructions, the system will continue to function with improper changes, possibly in violation of an implicit or explicit policy. The consequences would only be limited by how the affected data is used, such as an adjacent memory location that is used to specify whether the user has special privileges.Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: When the consequence is arbitrary code execution, this can often be used to subvert any other security service.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Choose a language that is not susceptible to these issues.Implementation : All calculated values that are used as index or for pointer arithmetic should be validated to ensure that they are within an expected range.", "Demonstrative_Examples": "In the following C/C++ example, a utility function is used to trim trailing whitespace from a character string. The function copies the input string to a local character string and uses a while statement to remove the trailing whitespace by moving backward through the string and overwriting whitespace with a NUL character.. However, this function can cause a buffer underwrite if the input character string contains all whitespace. On some systems the while statement will move backwards past the beginning of a character string and will call the isspace() function on an address outside of the bounds of the local buffer.The following is an example of code that may result in a buffer underwrite, if find() returns a negative value to indicate that ch is not found in srcBuf:. If the index to srcBuf is somehow under user control, this is an arbitrary write-what-where condition.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "786", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "787", "View_ID": "1000", "Ordinal": null}]}, {"ID": "327", "Name": "Use of a Broken or Risky Cryptographic Algorithm", "Description": "When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.", "Extended_Description": "Cryptographic algorithms are the methods by which data is scrambled to prevent observation or influence by unauthorized actors. Insecure cryptography can be exploited to expose sensitive information, modify data in unexpected ways, spoof identities of other users or devices, or other impacts.It is very difficult to produce a secure algorithm, and even high-profile algorithms by accomplished cryptographic experts have been broken. Well-known techniques exist to break or weaken various kinds of cryptography. Accordingly, there are a small number of well-understood and heavily studied algorithms that should be used by most products. Using a non-standard or known-insecure algorithm is dangerous because a determined adversary may be able to break the algorithm and compromise whatever data has been protected.Since the state of cryptography advances so rapidly, it is common for an algorithm to be considered \"unsafe\" even if it was once thought to be strong. This can happen when new attacks are discovered, or if computing power increases so much that the cryptographic algorithm no longer provides the amount of protection that was originally thought.For a number of reasons, this weakness is even more challenging to manage with hardware deployment of cryptographic algorithms as opposed to software implementation. First, if a flaw is discovered with hardware-implemented cryptography, the flaw cannot be fixed in most cases without a recall of the product, because hardware is not easily replaceable like software. Second, because the hardware product is expected to work for years, the adversary's computing power will only increase over time.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.Implementation: With hardware, the Architecture or Design Phase might start with compliant cryptography, but it is replaced with a non-compliant crypto during the later Implementation phase due to implementation constraints (e.g., not enough entropy to make it function properly, or not enough silicon real estate available to implement). Or, in rare cases (especially for long projects that span over years), the Architecture specifications might start with cryptography that was originally compliant at the time the Architectural specs were written, but over the time it became non-compliant due to progress made in attacking the crypto.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: The confidentiality of sensitive data may be compromised by the use of a broken or risky cryptographic algorithm.Scopes: Integrity. Impacts: Modify Application Data. Note: The integrity of sensitive data may be compromised by the use of a broken or risky cryptographic algorithm.Scopes: AccountabilityNon-Repudiation. Impacts: Hide Activities. Note: If the cryptographic algorithm is used to ensure the identity of the source of the data (such as digital signatures), then a broken algorithm will compromise this scheme and the source of the data cannot be proven.", "Detection_Methods": "Method Name: Automated Analysis. Description: Automated methods may be useful for recognizing commonly-used libraries or features that have become obsolete. Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : When there is a need to store or transmit sensitive data, use strong, up-to-date cryptographic algorithms to encrypt that data. Select a well-vetted algorithm that is currently considered to be strong by experts in the field, and use well-tested implementations. As with all cryptographic mechanisms, the source code should be available for analysis.\n                  For example, US government systems require FIPS 140-2 certification [REF-1192].\n                  Do not develop custom or private cryptographic algorithms. They will likely be exposed to attacks that are well-understood by cryptographers. Reverse engineering techniques are mature. If the algorithm can be compromised if attackers find out how it works, then it is especially weak.\n                  Periodically ensure that the cryptography has not become obsolete. Some older algorithms, once thought to require a billion years of computing time, can now be broken in days or hours. This includes MD4, MD5, SHA1, DES, and other algorithms that were once regarded as strong. [REF-267]Architecture and Design : Ensure that the design allows one cryptographic algorithm to be replaced with another in the next generation or version. Where possible, use wrappers to make the interfaces uniform. This will make it easier to upgrade to stronger algorithms. With hardware, design the product at the Intellectual Property (IP) level so that one cryptographic algorithm can be replaced with another in the next generation of the hardware product.Architecture and Design : Carefully manage and protect cryptographic keys (see CWE-320). If the keys can be guessed or stolen, then the strength of the cryptography itself is irrelevant.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Industry-standard implementations will save development time and may be more likely to avoid errors that can occur during implementation of cryptographic algorithms. Consider the ESAPI Encryption feature.Implementation : When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.", "Demonstrative_Examples": "These code examples use the Data Encryption Standard (DES).. Once considered a strong algorithm, DES now regarded as insufficient for many applications. It has been replaced by Advanced Encryption Standard (AES).Suppose a chip manufacturer decides to implement a hashing scheme for verifying integrity property of certain bitstream, and it chooses to implement a SHA1 hardware accelerator for to implement the scheme.. However, SHA1 was theoretically broken in 2005 and practically broken in 2017 at a cost of $110K. This means an attacker with access to cloud-rented computing power will now be able to provide a malicious bitstream with the same hash value, thereby defeating the purpose for which the hash was used.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple OT products used weak cryptography.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "311", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1240", "Name": "Use of a Cryptographic Primitive with a Risky Implementation", "Description": "Do not store keys in areas accessible to untrusted agents. Carefully manage and protect the cryptographic keys (see CWE-320). If the keys can be guessed or stolen, then the strength of the cryptography algorithm is irrelevant.", "Extended_Description": "Cryptographic protocols and systems depend on cryptographic primitives (and associated algorithms) as their basic building blocks. Some common examples of primitives are digital signatures, one-way hash functions, ciphers, and public key cryptography; however, the notion of \"primitive\" can vary depending on point of view. See \"Terminology Notes\" for further explanation of some concepts.Cryptographic primitives are defined to accomplish one very specific task in a precisely defined and mathematically reliable fashion. For example, suppose that for a specific cryptographic primitive (such as an encryption routine), the consensus is that the primitive can only be broken after trying out N different inputs (where the larger the value of N, the stronger the cryptography). For an encryption scheme like AES-256, one would expect N to be so large as to be infeasible to execute in a reasonable amount of time.If a vulnerability is ever found that shows that one can break a cryptographic primitive in significantly less than the expected number of attempts, then that primitive is considered weakened (or sometimes in extreme cases, colloquially it is \"broken\"). As a result, anything using this cryptographic primitive would now be considered insecure or risky. Thus, even breaking or weakening a seemingly small cryptographic primitive has the potential to render the whole system vulnerable, due to its reliance on the primitive. A historical example can be found in TLS when using DES. One would colloquially call DES the cryptographic primitive for transport encryption in this version of TLS. In the past, DES was considered strong, because no weaknesses were found in it; importantly, DES has a key length of 56 bits. Trying N=2^56 keys was considered impractical for most actors. Unfortunately, attacking a system with 56-bit keys is now practical via brute force, which makes defeating DES encryption practical. It is now practical for an adversary to read any information sent under this version of TLS and use this information to attack the system. As a result, it can be claimed that this use of TLS is weak, and that any system depending on TLS with DES could potentially render the entire system vulnerable to attack.Cryptographic primitives and associated algorithms are only considered safe after extensive research and review from experienced cryptographers from academia, industry, and government entities looking for any possible flaws. Furthermore, cryptographic primitives and associated algorithms are frequently reevaluated for safety when new mathematical and attack techniques are discovered.  As a result and over time, even well-known cryptographic primitives can lose their compliance status with the discovery of novel attacks that might either defeat the algorithm or reduce its robustness significantly.If ad-hoc cryptographic primitives are implemented, it is almost certain that the implementation will be vulnerable to attacks that are well understood by cryptographers, resulting in the exposure of sensitive information and other consequences.This weakness is even more difficult to manage for hardware-implemented deployment of cryptographic algorithms. First, because hardware is not patchable as easily as software, any flaw discovered after release and production typically cannot be fixed without a recall of the product. Secondly, the hardware product is often expected to work for years, during which time computation power available to the attacker only increases. Therefore, for hardware implementations of cryptographic primitives, it is absolutely essential that only strong, proven cryptographic primitives are used.", "Modes_Of_Introduction": "Architecture and Design: This weakness is primarily introduced during the architecture and design phase as risky primitives are included.Implementation: Even in cases where the Architectural phase properly specifies a cryptographically secure design, the design may be changed during implementation due to unforeseen constraints.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Incorrect usage of crypto primitives could render the supposedly encrypted data as unencrypted plaintext in the worst case.", "Detection_Methods": "Method Name: Architecture or Design Review. Description: Review requirements, documentation, and product design to ensure that primitives are consistent with the strongest-available recommendations from trusted parties. If the product appears to be using custom or proprietary implementations that have not had sufficient public review and approval, then this is a significant concern. Method Name: Manual Analysis. Description: Analyze the product to ensure that implementations for each primitive do not contain any known vulnerabilities and are not using any known-weak algorithms, including MD4, MD5, SHA1, DES, etc. Method Name: Dynamic Analysis with Manual Results Interpretation. Description: For hardware, during the implementation (pre-Silicon / post-Silicon) phase, dynamic tests should be done to ensure that outputs from cryptographic routines are indeed working properly, such as test vectors provided by NIST [REF-1236]. Method Name: Dynamic Analysis with Manual Results Interpretation. Description: It needs to be determined if the output of a cryptographic primitive is lacking entropy, which is one clear sign that something went wrong with the crypto implementation. There exist many methods of measuring the entropy of a bytestream, from sophisticated ones (like calculating Shannon's entropy of a sequence of characters) to crude ones (by compressing it and comparing the size of the original bytestream vs. the compressed - a truly random byte stream should not be compressible and hence the uncompressed and compressed bytestreams should be nearly identical in size).", "Potential_Mitigations": "Requirements : Require compliance with the strongest-available recommendations from trusted parties, and require that compliance must be kept up-to-date, since recommendations evolve over time. For example, US government systems require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].Architecture and Design : Ensure that the architecture/design uses the strongest-available primitives and algorithms from trusted parties. For example, US government systems require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].Architecture and Design : Do not develop custom or private cryptographic algorithms. They will likely be exposed to attacks that are well-understood by cryptographers. As with all cryptographic mechanisms, the source code should be available for analysis. If the algorithm may be compromised when attackers find out how it works, then it is especially weak.Architecture and Design : Try not to use cryptographic algorithms in novel ways or with new modes of operation even when you \"know\" it is secure. For example, using SHA-2 chaining to create a 1-time pad for encryption might sound like a good idea, but one should not do this.Architecture and Design : Ensure that the design can replace one cryptographic primitive or algorithm with another in the next generation (\"cryptographic agility\"). Where possible, use wrappers to make the interfaces uniform. This will make it easier to upgrade to stronger algorithms. This is especially important for hardware, which can be more difficult to upgrade quickly than software; design the hardware at a replaceable block level.Architecture and Design : Do not use outdated or non-compliant cryptography algorithms. Some older algorithms, once thought to require a billion years of computing time, can now be broken in days or hours. This includes MD4, MD5, SHA1, DES, and other algorithms that were once regarded as strong [REF-267].Architecture and Design : Do not use a linear-feedback shift register (LFSR) or other legacy methods as a substitute for an accepted and standard Random Number Generator.Architecture and Design : Do not use a checksum as a substitute for a cryptographically generated hash.Architecture and Design : Use a vetted cryptographic library or framework. Industry-standard implementations will save development time and are more likely to avoid errors that can occur during implementation of cryptographic algorithms. However, the library/framework could be used incorrectly during implementation.Architecture and Design : When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for the prevention of common attacks.Architecture and Design : Do not store keys in areas accessible to untrusted agents. Carefully manage and protect the cryptographic keys (see CWE-320). If the keys can be guessed or stolen, then the strength of the cryptography algorithm is irrelevant.", "Demonstrative_Examples": "Re-using random values may compromise security.. While an LFSR may provide pseudo-random number generation service, the entropy (measure of randomness) of the resulting output may be less than that of an accepted DRNG (like that used in dev/urandom). Thus, using an LFSR weakens the strength of the cryptographic system, because it may be possible for an attacker to guess the LFSR output and subsequently the encryption key.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "327", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1241", "Name": "Use of Predictable Algorithm in Random Number Generator", "Description": "A true random number generator should be implemented for cryptographic algorithms.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: In many cases, the design originally defines a cryptographically secure random number generator, but is then changed during implementation due to unforeseen constraints.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : A true random number generator should be specified for cryptographic algorithms.Implementation : A true random number generator should be implemented for cryptographic algorithms.", "Demonstrative_Examples": "Suppose a cryptographic function expects random value to be supplied for the crypto algorithm.. During the implementation phase, due to space constraint, a cryptographically secure random-number-generator could not be used, and instead  of using a TRNG (True Random Number Generator), a LFSR (Linear Feedback Shift Register) is used to generate a random value. While an LFSR will provide a pseudo-random number, its entropy (measure of randomness) is insufficient for a cryptographic algorithm.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1242", "Name": "Inclusion of Undocumented Features or Chicken Bits", "Description": "The implementation of chicken bits in a released product is highly discouraged. If implemented at all, ensure that they are disabled in production devices. All interfaces to a device should be documented.", "Extended_Description": "A common design practice is to use undocumented bits on a device that can be used to disable certain functional security features. These bits are commonly referred to as \"chicken bits\". They can facilitate quick identification and isolation of faulty components, features that negatively affect performance, or features that do not provide the required controllability for debug and test. Another way to achieve this is through implementation of undocumented features. An attacker might exploit these interfaces for unauthorized access.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : The implementation of chicken bits in a released product is highly discouraged. If implemented at all, ensure that they are disabled in production devices. All interfaces to a device should be documented.", "Demonstrative_Examples": "Consider a device that comes with various security measures, such as secure boot. The secure-boot process performs firmware-integrity verification at boot time, and this code is stored in a separate SPI-flash device. However, this code contains undocumented \"special access features\" intended to be used only for performing failure analysis and intended to only be unlocked by the device designer.. Remove all chicken bits and hidden features that are exposed to attackers. Add authorization schemes that rely on cryptographic primitives to access any features that the manufacturer does not want to expose. Clearly document all interfaces.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1263", "Name": "Improper Physical Access Control", "Description": "Ensure that all protection mechanisms are fully activated at the time of manufacturing and distribution.", "Extended_Description": "Sections of a product intended to have restricted access may be inadvertently or intentionally rendered accessible when the implemented physical protections are insufficient. The specific requirements around how robust the design of the physical protection mechanism needs to be depends on the type of product being protected. Selecting the correct physical protection mechanism and properly enforcing it through implementation and manufacturing are critical to the overall physical security of the product.", "Modes_Of_Introduction": "Architecture and Design: This weakness can arise if design decisions are made that do not align with the intended physical protection of the productManufacturing: While the architecture and design phase of the product may have accurately met the intended robustness for product physical protections, this phase may introduce the weakness through errors in physically manufacturing the product.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Specific protection requirements depend strongly on contextual factors including the level of acceptable risk associated with compromise to the product's protection mechanism. Designers could incorporate anti-tampering measures that protect against or detect when the product has been tampered with.Testing : The testing phase of the lifecycle should establish a method for determining whether the protection mechanism is sufficient to prevent unauthorized access.Manufacturing : Ensure that all protection mechanisms are fully activated at the time of manufacturing and distribution.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1191", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1243", "Name": "Sensitive Non-Volatile Information Not Protected During Debug", "Description": "Disable access to security-sensitive information stored in fuses directly and also reflected from  temporary storage locations when in debug mode.", "Extended_Description": "Several security-sensitive values are programmed into fuses to be used during early-boot flows or later at runtime. Examples of these security-sensitive values include root keys, encryption keys, manufacturing-specific information, chip-manufacturer-specific information, and original-equipment-manufacturer (OEM) data. After the chip is powered on, these values are sensed from fuses and stored in temporary locations such as registers and local memories. These locations are typically access-control protected from untrusted agents capable of accessing them. Even to trusted agents, only read-access is provided. However, these locations are not blocked during debug operations, allowing a user to access this sensitive information.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Disable access to security-sensitive information stored in fuses directly and also reflected from  temporary storage locations when in debug mode.", "Demonstrative_Examples": ". Sensitive manufacturing data (such as die information) are stored in fuses. When the chip powers on, these values are read from the fuses and stored in microarchitectural registers. These registers are only given read access to trusted software running on the core. Untrusted software running on the core is not allowed to access these registers.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1263", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "863", "Name": "Incorrect Authorization", "Description": "Use the access control capabilities of your operating system and server environment and define your access control lists accordingly. Use a \"default deny\" policy when defining these ACLs.", "Extended_Description": "Assuming a user with a given identity, authorization is the process of determining whether that user can access a given resource, based on the user's privileges and any permissions or other access-control specifications that apply to the resource.When access control checks are incorrectly applied, users are able to access data or perform actions that they should not be allowed to perform. This can lead to a wide range of problems, including information exposures, denial of service, and arbitrary code execution.", "Modes_Of_Introduction": "Architecture and Design: Authorization weaknesses may arise when a single-user application is ported to a multi-user environment.Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.A developer may introduce authorization weaknesses because of a lack of understanding about the underlying technologies. For example, a developer may assume that attackers cannot modify certain inputs such as headers or cookies.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Files or Directories. Note: An attacker could read sensitive data, either by reading the data directly from a data store that is not correctly restricted, or by accessing insufficiently-protected, privileged functionality to read the data.Scopes: Integrity. Impacts: Modify Application DataModify Files or Directories. Note: An attacker could modify sensitive data, either by writing the data directly to a data store that is not correctly restricted, or by accessing insufficiently-protected, privileged functionality to write the data.Scopes: Access Control. Impacts: Gain Privileges or Assume IdentityBypass Protection Mechanism. Note: An attacker could gain privileges by modifying or reading critical data directly, or by accessing privileged functionality.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis is useful for detecting commonly-used idioms for authorization. A tool may be able to analyze related configuration files, such as .htaccess in Apache web servers, or detect the usage of commonly-used authorization libraries.Generally, automated static analysis tools have difficulty detecting custom authorization schemes. Even if they can be customized to recognize these schemes, they might not be able to tell whether the scheme correctly performs the authorization in a way that cannot be bypassed or subverted by an attacker. Method Name: Automated Dynamic Analysis. Description: Automated dynamic analysis may not be able to find interfaces that are protected by authorization checks, even if those checks contain weaknesses. Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual static analysis is useful for evaluating the correctness of custom authorization mechanisms. Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Divide the product into anonymous, normal, privileged, and administrative areas. Reduce the attack surface by carefully mapping roles with data and functionality. Use role-based access control (RBAC) [REF-229] to enforce the roles at the appropriate boundaries.\n                  Note that this approach may not protect against horizontal authorization, i.e., it will not protect a user from attacking others with the same role.Architecture and Design : Ensure that access control checks are performed related to the business logic. These checks may be different than the access control checks that are applied to more generic resources such as files, connections, processes, memory, and database records. For example, a database may restrict access for medical records to a specific database user, but each record might only be intended to be accessible to the patient and the patient's doctor [REF-7].Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using authorization frameworks such as the JAAS Authorization Framework [REF-233] and the OWASP ESAPI Access Control feature [REF-45].Architecture and Design : For web applications, make sure that the access control mechanism is enforced correctly at the server side on every page. Users should not be able to access any unauthorized functionality or information by simply requesting direct access to that page.\n                  One way to do this is to ensure that all pages containing sensitive information are not cached, and that all such pages restrict access to requests that are accompanied by an active and authenticated session token associated with a user who has the required permissions to access that page.System Configuration : Use the access control capabilities of your operating system and server environment and define your access control lists accordingly. Use a \"default deny\" policy when defining these ACLs.", "Demonstrative_Examples": "The following code could be for a medical records application. It displays a record to already authenticated users, confirming the user's authorization using a value stored in a cookie.. The programmer expects that the cookie will only be set when getRole() succeeds. The programmer even diligently specifies a 2-hour expiration for the cookie. However, the attacker can easily set the \"role\" cookie to the value \"Reader\". As a result, the $role variable is \"Reader\", and getRole() is never invoked. The attacker has bypassed the authorization system.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1244", "Name": "Internal Asset Exposed to Unsafe Debug Access Level or State", "Description": "Add shielding or tamper-resistant protections to the device, which increases the difficulty and cost for accessing debug/test interfaces.", "Extended_Description": "Debug authorization can have multiple levels of\n\t  access, defined such that different system internal assets\n\t  are accessible based on the current authorized debug\n\t  level. Other than debugger authentication (e.g., using\n\t  passwords or challenges), the authorization can also be\n\t  based on the system state or boot stage. For example, full\n\t  system debug access might only be allowed early in boot\n\t  after a system reset to ensure that previous session data is\n\t  not accessible to the authenticated debugger.If this protection mechanism does not ensure that\n          internal assets have the correct debug access level during\n          each boot stage or change in system state, an attacker could\n          obtain sensitive information from the internal asset using a\n          debugger.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Analysis. Description: Check 2 devices for their passcode to authenticate access to JTAG/debugging ports. If the passcodes are missing or the same, update the design to fix and retest. Check communications over JTAG/debugging ports for encryption. If the communications are not encrypted, fix the design and retest.", "Potential_Mitigations": "Architecture and Design : For security-sensitive assets accessible over debug/test interfaces, only allow trusted agents.Architecture and Design : Apply blinding [REF-1219] or masking techniques in strategic areas.Implementation : Add shielding or tamper-resistant protections to the device, which increases the difficulty and cost for accessing debug/test interfaces.", "Demonstrative_Examples": "The JTAG interface is used to perform debugging and provide CPU core access for developers. JTAG-access protection is implemented as part of the JTAG_SHIELD bit in the hw_digctl_ctrl register. This register has no default value at power up and is set only after the system boots from ROM and control is transferred to the user software.. This means that since the end user has access to JTAG at system reset and during ROM code execution before control is transferred to user software, a JTAG user can modify the boot flow and subsequently disclose all CPU information, including data-encryption keys.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "863", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "684", "Name": "Incorrect Provision of Specified Functionality", "Description": "Ensure that your code strictly conforms to specifications.", "Extended_Description": "When providing functionality to an external party, it is important that the product behaves in accordance with the details specified. When requirements of nuances are not documented, the functionality may produce unintended behaviors for the caller, possibly leading to an exploitable state.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Ensure that your code strictly conforms to specifications.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1245", "Name": "Improper Finite State Machines (FSMs) in Hardware Logic", "Description": "Define all possible states and handle all unused states through default statements. Ensure that system defaults to a secure state.", "Extended_Description": "The functionality and security of the system heavily depend on the implementation of FSMs. FSMs can be used to indicate the current security state of the system. Lots of secure data operations and data transfers rely on the state reported by the FSM. Faulty FSM designs that do not account for all states, either through undefined states (left as don't cares) or through incorrect implementation, might lead an attacker to drive the system into an unstable state from which the system cannot recover without a reset, thus causing a DoS. Depending on what the FSM is used for, an attacker might also gain additional privileges to launch further attacks and compromise the security guarantees.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Define all possible states and handle all unused states through default statements. Ensure that system defaults to a secure state.", "Demonstrative_Examples": "The Finite State Machine (FSM) shown in the \"bad\" code snippet below assigns the output (\"out\") based on the value of state, which is determined based on the user provided input (\"user_input\").. The case statement does not include a default to handle the scenario when the user provides inputs of 3'h6 and 3'h7.  Those inputs push the system to an undefined state and might cause a crash (denial of service) or any other unanticipated outcome.Adding a default statement to handle undefined inputs mitigates this issue.  This is shown in the \"Good\" code snippet below.  The default statement is in bold.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "684", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1246", "Name": "Improper Write Handling in Limited-write Non-Volatile Memories", "Description": "Include secure wear leveling algorithms and ensure they may not be bypassed.", "Extended_Description": "Non-volatile memories such as NAND Flash, EEPROM, etc. have individually erasable segments, each of which can be put through a limited number of program/erase or write cycles. For example, the device can only endure a limited number of writes, after which the device becomes unreliable. In order to wear out the cells in a uniform manner, non-volatile memory and storage products based on the above-mentioned technologies implement a technique called wear leveling. Once a set threshold is reached, wear leveling maps writes of a logical block to a different physical block. This prevents a single physical block from prematurely failing due to a high concentration of writes. If wear leveling is improperly implemented, attackers may be able to programmatically cause the storage to become unreliable within a much shorter time than would normally be expected.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Include secure wear leveling algorithms and ensure they may not be bypassed.", "Demonstrative_Examples": "An attacker can render a memory line unusable by repeatedly causing a write to the memory line.. Below is example code from [REF-1058] that the user can execute repeatedly to cause line failure. W is the maximum associativity of any cache in the system; S is the size of the largest cache in the system.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1384", "Name": "Improper Handling of Physical or Environmental Conditions", "Description": "Where possible, use shielding or other materials that can increase the adversary's workload and reduce the likelihood of being able to successfully trigger a security-related failure.", "Extended_Description": "Hardware products are typically only guaranteed to behave correctly within certain physical limits or environmental conditions. Such products cannot necessarily control the physical or external conditions to which they are subjected. However, the inability to handle such conditions can undermine a product's security. For example, an unexpected physical or environmental condition may cause the flipping of a bit that is used for an authentication decision. This unexpected condition could occur naturally or be induced artificially by an adversary.Physical or environmental conditions of concern are:", "Modes_Of_Introduction": "Architecture and Design: The product's design might not consider checking and handling extreme conditions.Manufacturing: For hardware manufacturing, sub-par components might be chosen that are not able to handle the expected environmental conditions.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Varies by ContextUnexpected State. Note: Consequences of this weakness are highly dependent on the role of affected components within the larger product.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : In requirements, be specific about expectations for how the product will perform when it exceeds physical and environmental boundary conditions, e.g., by shutting down.Architecture and Design : Where possible, include independent components that can detect excess environmental conditions and have the capability to shut down the product.Architecture and Design : Where possible, use shielding or other materials that can increase the adversary's workload and reduce the likelihood of being able to successfully trigger a security-related failure.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1247", "Name": "Improper Protection Against Voltage and Clock Glitches", "Description": "At the circuit-level, using Tunable Replica Circuits (TRCs) or special flip-flops such as Razor flip-flops helps mitigate glitch attacks. Working at the SoC or platform base, level sensors may be implemented to detect glitches. Implementing redundancy in security-sensitive code (e.g., where checks are performed)also can help with mitigation of glitch attacks.", "Extended_Description": "A device might support features such as secure boot which are supplemented with hardware and firmware support. This involves establishing a chain of trust, starting with an immutable root of trust by checking the signature of the next stage (culminating with the OS and runtime software) against a golden value before transferring control. The intermediate stages typically set up the system in a secure state by configuring several access control settings. Similarly, security logic for exercising a debug or testing interface may be implemented in hardware, firmware, or both. A device needs to guard against fault attacks such as voltage glitches and clock glitches that an attacker may employ in an attempt to compromise the system.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Analysis. Description: Put the processor in an infinite\n\t\t\tloop, which is then followed by instructions\n\t\t\tthat should not ever be executed, since the\n\t\t\tloop is not expected to exit.  After the loop,\n\t\t\ttoggle an I/O bit (for oscilloscope monitoring\n\t\t\tpurposes), print a console message, and\n\t\t\treenter the loop.  Note that to ensure that\n\t\t\tthe loop exit is actually captured, many NOP\n\t\t\tinstructions should be coded after the loop\n\t\t\tbranch instruction and before the I/O bit\n\t\t\ttoggle and the print statement.Margining the clock consists of varying the clock\n\t\t\tfrequency until an anomaly occurs. This could be a\n\t\t\tcontinuous frequency change or it could be a single\n\t\t\tcycle. The single cycle method is described here. For\n\t\t\tevery 1000th clock pulse, the clock cycle is shortened by\n\t\t\t10 percent. If no effect is observed, the width is\n\t\t\tshortened by 20%. This process is continued in 10%\n\t\t\tincrements up to and including 50%. Note that the cycle\n\t\t\ttime may be increased as well, down to seconds per\n\t\t\tcycle.Separately, the voltage is margined. Note that\n\t\t\tthe voltage could be increased or decreased. Increasing\n\t\t\tthe voltage has limits, as the circuitry may not be able\n\t\t\tto withstand a drastically increased voltage. This process\n\t\t\tstarts with a 5% reduction of the DC supply to the CPU\n\t\t\tchip for 5 millisecond repeated at 1KHz. If this has no\n\t\t\teffect, the process is repeated, but a 10% reduction is\n\t\t\tused. This process is repeated at 10% increments down to a\n\t\t\t50% reduction. If no effects are observed at 5\n\t\t\tmillisecond, the whole process is repeated using a 10\n\t\t\tmillisecond pulse. If no effects are observed, the process\n\t\t\tis repeated in 10 millisecond increments out to 100\n\t\t\tmillisecond pulses.While these are suggested starting points for\n\t\t\ttesting circuitry for weaknesses, the limits may need to\n\t\t\tbe pushed further at the risk of device damage. See\n\t\t\t[REF-1217] for descriptions of Smart Card attacks against\n\t\t\ta clock (section 14.6.2) and using a voltage glitch\n\t\t\t(section 15.5.3). Method Name: Dynamic Analysis with Manual Results Interpretation. Description: During the implementation phase where actual hardware is available, specialized hardware tools and apparatus such as ChipWhisperer may be used to check if the platform is indeed susceptible to voltage and clock glitching attacks. Method Name: Architecture or Design Review. Description: Review if the protections against glitching merely transfer the attack target. For example, suppose a critical authentication routine that an attacker would want to bypass is given the protection of modifying certain artifacts from within that specific routine (so that if the routine is bypassed, one can examine the artifacts and figure out that an attack must have happened). However, if the attacker has the ability to bypass the critical authentication routine, they might also have the ability to bypass the other protection routine that checks the artifacts. Basically, depending on these kind of protections is akin to resorting to \"Security by Obscurity\". Method Name: Architecture or Design Review. Description: Many SoCs come equipped with a built-in Dynamic Voltage and Frequency Scaling (DVFS) that can control the voltage and clocks via software alone. However, there have been demonstrated attacks (like Plundervolt and CLKSCREW) that target this DVFS [REF-1081] [REF-1082]. During the design and implementation phases, one needs to check if the interface to this power management feature is available from unprivileged SW (CWE-1256), which would make the attack very easy.", "Potential_Mitigations": "Architecture and Design : At the circuit-level, using Tunable Replica Circuits (TRCs) or special flip-flops such as Razor flip-flops helps mitigate glitch attacks. Working at the SoC or platform base, level sensors may be implemented to detect glitches. Implementing redundancy in security-sensitive code (e.g., where checks are performed)also can help with mitigation of glitch attacks.", "Demonstrative_Examples": "Below is a representative snippet of C code that is part of the secure-boot flow. A signature of the runtime-firmware image is calculated and compared against a golden value. If the signatures match, the bootloader loads runtime firmware. If there is no match, an error halt occurs. If the underlying hardware executing this code does not contain any circuitry or sensors to detect voltage or clock glitches, an attacker might launch a fault-injection attack right when the signature check is happening (at the location marked with the comment), causing a bypass of the signature-checking process.. After bypassing secure boot, an attacker can gain access to system assets to which the attacker should not have access.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1384", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1248", "Name": "Semiconductor Defects in Hardware Logic with Security-Sensitive Implications", "Description": "Operating the hardware outside device specification, such as at extremely high temperatures, voltage, etc., accelerates semiconductor degradation and results in defects.  When these defects manifest as faults in security-critical, hardware modules, it results in compromise of security guarantees. Thus, operating the device within the specification is important.", "Extended_Description": "A semiconductor device can fail for various reasons. While some are manufacturing and packaging defects, the rest are due to prolonged use or usage under extreme conditions. Some mechanisms that lead to semiconductor defects include encapsulation failure, die-attach failure, wire-bond failure, bulk-silicon defects, oxide-layer faults, aluminum-metal faults (including electromigration, corrosion of aluminum, etc.), and thermal/electrical stress. These defects manifest as faults on chip-internal signals or registers, have the effect of inputs, outputs, or intermediate signals being always 0 or always 1, and do not switch as expected. If such faults occur in security-sensitive hardware modules, the security objectives of the hardware module may be compromised.", "Modes_Of_Introduction": "Manufacturing: May be introduced due to issues in the manufacturing environment or improper handling of components, for example.Operation: May be introduced by improper handling or usage outside of rated operating environments (temperature, humidity, etc.)", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : While semiconductor-manufacturing companies implement several mechanisms to continuously improve the semiconductor manufacturing process to ensure reduction of defects, some defects can only be fixed after manufacturing. Post-manufacturing testing of silicon die is critical. Fault models such as stuck-at-0 or stuck-at-1 must be used to develop post-manufacturing test cases and achieve good coverage. Once the silicon packaging is done, extensive post-silicon testing must be performed to ensure that hardware logic implementing security functionalities is defect-free.Operation : Operating the hardware outside device specification, such as at extremely high temperatures, voltage, etc., accelerates semiconductor degradation and results in defects.  When these defects manifest as faults in security-critical, hardware modules, it results in compromise of security guarantees. Thus, operating the device within the specification is important.", "Demonstrative_Examples": "The network-on-chip implements a firewall for access control to peripherals from all IP cores capable of mastering transactions.. Post-manufacture testing must be performed to ensure that hardware logic implementing security functionalities is defect-free.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1250", "Name": "Improper Preservation of Consistency Between Independent Representations of Shared State", "Description": "The product has or supports multiple distributed components or sub-systems that are each required to keep their own local copy of shared data - such as state or cache - but the product does not ensure that all local copies remain consistent with each other.", "Extended_Description": "In highly distributed environments, or on systems with distinct physical components that operate independently, there is often a need for each component to store and update its own local copy of key data such as state or cache, so that all components have the same \"view\" of the overall system and operate in a coordinated fashion.  For example, users of a social media service or a massively multiplayer online game might be using their own personal computers while also interacting with different physical hosts in a globally distributed service, but all participants must be able to have the same \"view\" of the world.  Alternately, a processor's Memory Management Unit (MMU) might have \"shadow\" MMUs to distribute its workload, and all shadow MMUs are expected to have the same accessible ranges of memory.In such environments, it becomes critical for\n\t\tthe product to ensure that this \"shared state\" is\n\t\tconsistently modified across all distributed systems.\n\t\tIf state is not consistently maintained across all\n\t\tsystems, then critical transactions might take place\n\t\tout of order, or some users might not get the same\n\t\tdata as other users.  When this inconsistency affects\n\t\tcorrectness of operations, it can introduce\n\t\tvulnerabilities in mechanisms that depend on\n\t\tconsistent state.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "Suppose a processor's Memory Management Unit (MMU) has 5 other shadow MMUs to distribute its workload for its various cores. Each MMU has the start address and end address of \"accessible\" memory. Any time this accessible range changes (as per the processor's boot status), the main MMU sends an update message to all the shadow MMUs.. Suppose the interconnect fabric does not prioritize such \"update\" packets over other general traffic packets. This introduces a race condition. If an attacker can flood the target with enough messages so that some of those attack packets reach the target before the new access ranges gets updated, then the attacker can leverage this scenario.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1249", "Name": "Application-Level Admin Tool with Inconsistent View of Underlying Operating System", "Description": "Ensure that the admin tool refreshes its model of the underlying OS on a regular basis, and note any inconsistencies with configuration files or other data sources that are expected to have the same data.", "Extended_Description": "Many products provide web-based applications or other interfaces for managing the underlying operating system. This is common with cloud, network access devices, home networking, and other systems.  When the management tool does not accurately represent what is in the OS - such as user accounts - then the administrator might not see suspicious activities that would be noticed otherwise.For example, numerous systems utilize a web\n\t\t\t\tfront-end for administrative control. They also offer\n\t\t\t\tthe ability to add, alter, and drop users with various\n\t\t\t\tprivileges as it relates to the functionality of the\n\t\t\t\tsystem.  A potential architectural weakness may exist\n\t\t\t\twhere the user information reflected in the web\n\t\t\t\tinterface does not mirror the users in the underlying\n\t\t\t\toperating system.  Many web UI or REST APIs use the\n\t\t\t\tunderlying operating system for authentication; the\n\t\t\t\tsystem's logic may also track an additional set of\n\t\t\t\tuser capabilities within configuration files\n\t\t\t\tand datasets for authorization capabilities. When\n\t\t\t\tthere is a discrepancy between the user information in\n\t\t\t\tthe UI or REST API's interface system and the\n\t\t\t\tunderlying operating system's user listing, this may\n\t\t\t\tintroduce a weakness into the system.  For example, if an\n\t\t\t\tattacker compromises the OS and adds a new user\n\t\t\t\taccount - a \"ghost\" account - then the attacker could escape detection if\n\t\t\t\tthe management tool does not list the newly-added\n\t\t\t\taccount.This discrepancy could be exploited in several ways:Many of these attacker scenarios can be\n\t\t\t\trealized by leveraging separate vulnerabilities\n\t\t\t\trelated to XSS, command injection, authentication\n\t\t\t\tbypass, or logic flaws on the various systems.", "Modes_Of_Introduction": "Architecture and Design: The design might assume that the underlying OS does not change.Implementation: Assumptions about the underlying OS might be hard-coded into the application or otherwise in external data stores in a way that is not updated when the OS's state changes.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Ensure that the admin tool refreshes its model of the underlying OS on a regular basis, and note any inconsistencies with configuration files or other data sources that are expected to have the same data.", "Demonstrative_Examples": "Suppose that an attacker successfully gains root privileges on a Linux system and adds a new 'user2' account:. This new user2 account would not be noticed on the web interface, if the interface does not refresh its data of available users.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1250", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "125", "Name": "Out-of-bounds Read", "Description": "Use a language that provides appropriate memory abstractions.", "Extended_Description": "Typically, this can allow attackers to read sensitive information from other memory locations or cause a crash.  A crash can occur when the code reads a variable amount of data and assumes that a sentinel exists to stop the read operation, such as a NUL in a string.  The expected sentinel might not be located in the out-of-bounds memory, causing excessive data to be read, leading to a segmentation fault or a buffer overflow.  The product may modify an index or perform pointer arithmetic that references a memory location that is outside of the boundaries of the buffer.  A subsequent read operation then produces undefined or unexpected results.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Bypass Protection Mechanism. Note: By reading out-of-bounds memory, an attacker might be able to get secret values, such as memory addresses, which can be bypass protection mechanisms such as ASLR in order to improve the reliability and likelihood of exploiting a separate weakness to achieve code execution instead of just denial of service.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  To reduce the likelihood of introducing an out-of-bounds read, ensure that you validate and ensure correct calculations for any length argument, buffer size calculation, or offset. Be especially careful of relying on a sentinel (i.e. special character such as NUL) in untrusted inputs.Architecture and Design : Use a language that provides appropriate memory abstractions.", "Demonstrative_Examples": "In the following code, the method retrieves a value from an array at a specific array index location that is given as an input parameter to the method. However, this method only verifies that the given array index is less than the maximum length of the array but does not check for the minimum value (CWE-839). This will allow a negative value to be accepted as the input array index, which will result in a out of bounds read (CWE-125) and may allow access to sensitive memory. The input array index should be checked to verify that is within the maximum and minimum range required for the array (CWE-129). In this example the if statement should be modified to include a minimum range check, as shown below.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1251", "Name": "Mirrored Regions with Different Values", "Description": "Whenever there are multiple, physically different copies of the same value that might change and the process to update them is not instantaneous and atomic, it is impossible to assert that the original and shadow copies will always be in sync - there will always be a time period when they are out of sync. To mitigate the consequential risk, the recommendations essentially are:\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tMake this out-of-sync time period as small as possible, and\n\t\t\t\t\t\t\t\t\tMake the update process as robust as possible.", "Extended_Description": "Having mirrored regions with different values might result in the exposure of sensitive information or possibly system compromise.In the interest of increased performance, one might need to duplicate a resource. A cache memory is a common example of this concept, which keeps a \"local\" copy of a data element in the high speed cache memory. Unfortunately, this speed improvement comes with a downside, since the product needs to ensure that the local copy always mirrors the original copy truthfully. If they get out of sync, the computational result is no longer true.During hardware design, memory is not the only item which gets mirrored. There are many other entities that get mirrored, as well: registers, memory regions, and, in some cases, even whole computational units. For example, within a multi-core processor, if all memory accesses for each and every core goes through a single Memory-Management Unit (MMU) then the MMU will become a performance bottleneck. In such cases, duplicating local MMUs that will serve only a subset of the cores rather than all of them may resolve the performance issue. These local copies are also called \"shadow copies\" or \"mirrored copies.\"If the original resource never changed, local duplicate copies getting out of sync would never be an issue. However, the values of the original copy will sometimes change. When the original copy changes, the mirrored copies must also change, and change fast.This situation of shadow-copy-possibly-out-of-sync-with-original-copy might occur as a result of multiple scenarios, including the following:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Whenever there are multiple, physically different copies of the same value that might change and the process to update them is not instantaneous and atomic, it is impossible to assert that the original and shadow copies will always be in sync - there will always be a time period when they are out of sync. To mitigate the consequential risk, the recommendations essentially are:\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tMake this out-of-sync time period as small as possible, and\n\t\t\t\t\t\t\t\t\tMake the update process as robust as possible.", "Demonstrative_Examples": "Suppose a processor's Memory Management Unit (MMU) has 5 other shadow MMUs to distribute its workload for its various cores. Each MMU has the start address and end address of \"accessible\" memory. Any time this accessible range changes (as per the processor's boot status), the main MMU sends an update message to all the shadow MMUs.. Suppose the interconnect fabric does not prioritize such \"update\" packets over other general traffic packets. This introduces a race condition. If an attacker can flood the target with enough messages so that some of those attack packets reach the target before the new access ranges gets updated, then the attacker can leverage this scenario.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1250", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1252", "Name": "CPU Hardware Not Configured to Support Exclusivity of Write and Execute Operations", "Description": "If MMU/MPU are not available, then the firewalls need to be implemented in the SoC interconnect to mimic the write-exclusivity operation.", "Extended_Description": "CPUs provide a special bit that supports exclusivity of write and execute operations. This bit is used to segregate areas of memory to either mark them as code (instructions, which can be executed) or data (which should not be executed). In this way, if a user can write to a region of memory, the user cannot execute from that region and vice versa. This exclusivity provided by special hardware bit is leveraged by the operating system to protect executable space. While this bit is available in most modern processors by default, in some CPUs the exclusivity is implemented via a memory-protection unit (MPU) and memory-management unit (MMU) in which memory regions can be carved out with exact read, write, and execute permissions. However, if the CPU does not have an MMU/MPU, then there is no write exclusivity. Without configuring exclusivity of operations via segregated areas of memory, an attacker may be able to inject malicious code onto memory and later execute it.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Implement a dedicated bit that can be leveraged by the Operating System to mark data areas as non-executable. If such a bit is not available in the CPU, implement MMU/MPU (memory management unit / memory protection unit).Integration : If MMU/MPU are not available, then the firewalls need to be implemented in the SoC interconnect to mimic the write-exclusivity operation.", "Demonstrative_Examples": "MCS51 Microcontroller (based on 8051) does not have a special bit to support write exclusivity. It also does not have an MMU/MPU support. The Cortex-M CPU has an optional MPU that supports up to 8 regions.. If the MPU is not configured, then an attacker will be able to inject malicious data into memory and execute it.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1253", "Name": "Incorrect Selection of Fuse Values", "Description": "Logic should be designed in a way that blown fuses do not put the product into an insecure state that can be leveraged by an attacker.", "Extended_Description": "Fuses are often used to store secret data, including security configuration data. When not blown, a fuse is considered to store a logic 0, and, when blown, it indicates a logic 1. Fuses are generally considered to be one-directional, i.e., once blown to logic 1, it cannot be reset to logic 0. However, if the logic used to determine system-security state (by leveraging the values sensed from the fuses) uses negative logic, an attacker might blow the fuse and drive the system to an insecure state.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Logic should be designed in a way that blown fuses do not put the product into an insecure state that can be leveraged by an attacker.", "Demonstrative_Examples": ". A chip implements a secure boot and uses the sensed value of a fuse \n         \"do_secure_boot\" to determine whether to perform a secure boot or not. If this fuse \n         value is \"0\", the system performs secure boot. Otherwise, it does not perform secure \n         boot.An attacker blows the \"do_secure_boot\" fuse to \"1\". After reset, the attacker loads a custom \n         bootloader, and, since the fuse value is now \"1\", the system does not perform secure boot, \n         and the attacker can execute their custom firmware image.Since by default, a fuse-configuration value is a \"0\", an attacker can blow it to a \"1\" with \n         inexpensive hardware.If the logic is reversed, an attacker cannot easily reset the fuse. Note that, with \n         specialized and expensive equipment, an attacker with full physical access might be able to \"unblow\" the fuse \n         value to a \"0\".", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "208", "Name": "Observable Timing Discrepancy", "Description": "Two separate operations in a product require different amounts of time to complete, in a way that is observable to an actor and reveals security-relevant information about the state of the product, such as whether a particular operation was successful or not.", "Extended_Description": "In security-relevant contexts, even small variations in timing can be exploited by attackers to indirectly infer certain details about the product's internal operations.  For example, in some cryptographic algorithms, attackers can use timing differences to infer certain properties about a private key, making the key easier to guess.  Timing discrepancies effectively form a timing side channel.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "203", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "385", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "327", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1254", "Name": "Incorrect Comparison Logic Granularity", "Description": "The hardware designer should ensure that comparison logic is implemented so as to compare in one operation instead in smaller chunks.", "Extended_Description": "Comparison logic is used to compare a variety of objects including passwords, Message \n         Authentication Codes (MACs), and responses to verification challenges. When comparison logic is \n         implemented at a finer granularity (e.g., byte-by-byte comparison) and breaks in the case of a \n         comparison failure, an attacker can exploit this implementation to identify when exactly \n         the failure occurred. With multiple attempts, the attacker may be able to guesses the correct \n         password/response to challenge and elevate their privileges.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : The hardware designer should ensure that comparison logic is implemented so as to compare in one operation instead in smaller chunks.", "Demonstrative_Examples": "Consider an example hardware module that checks a user-provided password to grant access to a user. The user-provided password is compared against a golden value in a byte-by-byte manner.. Since the code breaks on an incorrect entry of password, an attacker can guess the correct password for that byte-check iteration with few repeat attempts.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "208", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1300", "Name": "Improper Protection of Physical Side Channels", "Description": "Add shielding or tamper-resistant protections to the device to increase the difficulty of obtaining measurements of the side-channel.", "Extended_Description": "An adversary could monitor and measure physical\n\t  phenomena to detect patterns and make inferences, even if it\n\t  is not possible to extract the information in the digital\n\t  domain.Physical side channels have been well-studied for\n\t  decades in the context of breaking implementations of\n\t  cryptographic algorithms or other attacks against security\n\t  features. These side channels may be easily observed by an\n\t  adversary with physical access to the device, or using a\n\t  tool that is in close proximity.  If the adversary can\n\t  monitor hardware operation and correlate its data processing\n\t  with power, EME, and acoustic measurements, the adversary\n\t  might be able to recover of secret keys and data.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Analysis. Description: Perform a set of leakage detection tests such as the procedure outlined in the Test Vector Leakage Assessment (TVLA) test requirements for AES [REF-1230].  TVLA is the basis for the ISO standard 17825 [REF-1229]. A separate methodology is provided by [REF-1228]. Note that sole reliance on this method might not yield expected results [REF-1239] [REF-1240]. Method Name: Manual Analysis. Description: Post-silicon, perform full side-channel attacks (penetration testing) covering as many known leakage models as possible against test code. Method Name: Manual Analysis. Description: Pre-silicon - while the aforementioned TVLA methods can be performed post-silicon, models of device power consumption or other physical emanations can be built from information present at various stages of the hardware design process before fabrication. TVLA or known side-channel attacks can be applied to these simulated traces and countermeasures applied before tape-out.  Academic research in this field includes [REF-1231] [REF-1232] [REF-1233].", "Potential_Mitigations": "Architecture and Design : Apply blinding or masking techniques to implementations of cryptographic algorithms.Implementation : Add shielding or tamper-resistant protections to the device to increase the difficulty of obtaining measurements of the side-channel.", "Demonstrative_Examples": "Consider a device that checks a\n\t\t    passcode to unlock the screen.. PIN numbers used to unlock a cell phone\n\t\t    should not exhibit any characteristics about\n\t\t    themselves. This creates a side channel. An\n\t\t    attacker could monitor the pulses using an\n\t\t    oscilloscope or other method. Once the first\n\t\t    character is correctly guessed (based on the\n\t\t    oscilloscope readings), they can then move to the\n\t\t    next character, which is much more efficient than\n\t\t    the brute force method of guessing every possible\n\t\t    sequence of characters.. Consider the device vulnerability CVE-2021-3011, which affects certain microcontrollers [REF-1221]. The Google Titan Security Key is used for two-factor authentication using cryptographic algorithms. The device uses an internal secret key for this purpose and exchanges information based on this key for the authentication. If this internal secret key and the encryption algorithm were known to an adversary, the key function could be duplicated, allowing the adversary to masquerade as the legitimate user.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "203", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "203", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "1255", "Name": "Comparison Logic is Vulnerable to Power Side-Channel Attacks", "Description": "During integration, avoid use of a single secret for an extended period (e.g. frequent key updates). This limits the amount of data compromised but at the cost of complexity of use.", "Extended_Description": "The power consumed by a device may be instrumented and monitored in real time. If the algorithm for evaluating security tokens is not sufficiently robust, the power consumption may vary by token entry comparison against the reference value. Further, if retries are unlimited, the power difference between a \"good\" entry and a \"bad\" entry may be observed and used to determine whether each entry itself is correct thereby allowing unauthorized parties to calculate the reference value.", "Modes_Of_Introduction": "Architecture and Design: The design of the algorithm itself may intrinsically allow the power side channel attack to be effectiveImplementation: This weakness may be introduced during implementation despite a robust design that otherwise prevents exploitation", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess ControlAccountabilityAuthenticationAuthorizationNon-Repudiation. Impacts: Modify MemoryRead MemoryRead Files or DirectoriesModify Files or DirectoriesExecute Unauthorized Code or CommandsGain Privileges or Assume IdentityBypass Protection MechanismRead Application DataModify Application DataHide Activities. Note: As compromising a security token may result in complete system control, the impacts are relatively universal", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : The design phase must consider each check of a security token against a standard and the amount of power consumed during the check of a good token versus a bad token. The alternative is an all at once check where a retry counter is incremented PRIOR to the check.Architecture and Design : Another potential mitigation is to parallelize shifting of secret data (see example 2 below). Note that the wider the bus the more effective the result.Architecture and Design : An additional potential mitigation is to add random data to each crypto operation then subtract it out afterwards. This is highly effective but costly in performance, area, and power consumption. It also requires a random number generator.Implementation : If the architecture is unable to prevent the attack, using filtering components may reduce the ability to implement an attack, however, consideration must be given to the physical removal of the filter elements.Integration : During integration, avoid use of a single secret for an extended period (e.g. frequent key updates). This limits the amount of data compromised but at the cost of complexity of use.", "Demonstrative_Examples": "Consider an example hardware module that checks a user-provided password (or PIN) to grant access to a user. The user-provided password is compared against a stored value byte-by-byte.. Since the algorithm uses a different number of 1's and 0's for password validation, a different amount of power is consumed for the good byte versus the bad byte comparison. Using this information, an attacker may be able to guess the correct password for that byte-by-byte iteration with several repeated attempts by stopping the password evaluation before it completes.This code demonstrates the transfer of a secret key using Serial-In/Serial-Out shift. It's easy to extract the secret using simple power analysis as each shift gives data on a single bit of the key.. This code demonstrates the transfer of a secret key using a Parallel-In/Parallel-Out shift. In a parallel shift, data confounded by multiple bits of the key, not just one.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1300", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1259", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "1256", "Name": "Improper Restriction of Software Interfaces to Hardware Features", "Description": "Ensure proper access control mechanisms protect software-controllable features altering physical operating conditions such as clock frequency and voltage.", "Extended_Description": "It is frequently assumed that physical attacks\n              such as fault injection and side-channel analysis\n              require an attacker to have physical access to the\n              target device.  This assumption may be false if the\n              device has improperly secured power management features,\n              or similar features.  For mobile devices, minimizing\n              power consumption is critical, but these devices run a\n              wide variety of applications with different performance\n              requirements. Software-controllable mechanisms to\n              dynamically scale device voltage and frequency and\n              monitor power consumption are common features in today's\n              chipsets, but they also enable attackers to mount fault\n              injection and side-channel attacks without having\n              physical access to the device.Fault injection attacks involve strategic\n              manipulation of bits in a device to achieve a desired\n              effect such as skipping an authentication step,\n              elevating privileges, or altering the output of a\n              cryptographic operation.  Manipulation of the device\n              clock and voltage supply is a well-known technique to\n              inject faults and is cheap to implement with physical\n              device access.  Poorly protected power management\n              features allow these attacks to be performed from\n              software.  Other features, such as the ability to write\n              repeatedly to DRAM at a rapid rate from unprivileged\n              software, can result in bit flips in other memory\n              locations (Rowhammer, [REF-1083]).Side channel analysis requires gathering\n\t\t\t  measurement traces of physical quantities such as power\n\t\t\t  consumption.  Modern processors often include power\n\t\t\t  metering capabilities in the hardware itself (e.g.,\n\t\t\t  Intel RAPL) which if not adequately protected enable\n\t\t\t  attackers to gather measurements necessary for\n\t\t\t  performing side-channel attacks from software.", "Modes_Of_Introduction": "Architecture and Design: An architect may initiate introduction of\n\t\t\t\t\tthis weakness via exacting requirements for\n\t\t\t\t\tsoftware accessible power/clock management\n\t\t\t\t\trequirementsImplementation: An implementer may introduce this weakness\n\t\t\t\t\tby assuming there are no consequences to unbounded\n\t\t\t\t\tpower and clock management for secure components\n\t\t\t\t\tfrom untrusted ones.", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Analysis. Description: Perform a security evaluation of system-level\n\t\tarchitecture and design with software-aided physical attacks\n\t\tin scope. Method Name: Automated Dynamic Analysis. Description: Use custom software to change registers that control clock settings or power settings to try to bypass security locks, or repeatedly write DRAM to try to change adjacent locations. This can be effective in extracting or changing data. The drawback is that it cannot be run before manufacturing, and it may require specialized software.", "Potential_Mitigations": "Architecture and Design : Ensure proper access control mechanisms protect software-controllable features altering physical operating conditions such as clock frequency and voltage.", "Demonstrative_Examples": "This example considers the Rowhammer problem [REF-1083]. The Rowhammer issue was caused by a program in a tight loop writing repeatedly to a location to which the program was allowed to write but causing an adjacent memory location value to change.. Preventing the loop required to defeat the Rowhammer exploit is not always possible:. Suppose a hardware design implements a set of software-accessible registers for scaling clock frequency and voltage but does not control access to these registers. Attackers may cause register and memory changes and race conditions by changing the clock or voltage of the device under their control.Consider the following SoC\n\t      design. Security-critical settings for scaling clock\n\t      frequency and voltage are available in a range of\n\t      registers bounded by [PRIV_END_ADDR : PRIV_START_ADDR]\n\t      in the tmcu.csr module in the HW Root of Trust. These\n\t      values are writable based on the lock_bit register in\n\t      the same module. The lock_bit is only writable by\n\t      privileged software running on the tmcu.. We assume that untrusted software running on any of the\n\t      Core{0-N} processors has access to the input and output\n\t      ports of the hrot_iface. If untrusted software can clear\n\t      the lock_bit or write the clock frequency and voltage\n\t      registers due to inadequate protection, a fault\n\t      injection attack could be performed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1257", "Name": "Improper Access Control Applied to Mirrored or Aliased Memory Regions", "Description": "The controls that allow enabling memory aliases or changing the size of mapped memory regions should only be programmable by trusted software components.", "Extended_Description": "Hardware product designs often need to implement memory protection features that enable privileged software to define isolated memory regions and access control (read/write) policies. Isolated memory regions can be defined on different memory spaces in a design (e.g. system physical address, virtual address, memory mapped IO).Each memory cell should be mapped and assigned a system address that the core software can use to read/write to that memory. It is possible to map the same memory cell to multiple system addresses such that read/write to any of the aliased system addresses would be decoded to the same memory cell.This is commonly done in hardware designs for redundancy and simplifying address decoding logic. If one of the memory regions is corrupted or faulty, then that hardware can switch to using the data in the mirrored memory region. Memory aliases can also be created in the system address map if the address decoder unit ignores higher order address bits when mapping a smaller address region into the full system address.A common security weakness that can exist in such memory mapping is that aliased memory regions could have different read/write access protections enforced by the hardware such that an untrusted agent is blocked from accessing a memory address but is not blocked from accessing the corresponding aliased memory address. Such inconsistency can then be used to bypass the access protection of the primary memory block and read or modify the protected memory.An untrusted agent could also possibly create memory aliases in the system address map for malicious purposes if it is able to change the mapping of an address region or modify memory region sizes.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : The checks should be applied for consistency access rights between primary memory regions and any mirrored or aliased memory regions. If different memory protection units (MPU) are protecting the aliased regions, their protected range definitions and policies should be synchronized.Architecture and Design : The controls that allow enabling memory aliases or changing the size of mapped memory regions should only be programmable by trusted software components.", "Demonstrative_Examples": ". In a System-on-a-Chip (SoC) design the system fabric uses 16 bit addresses. An IP unit (Unit_A) has 4 kilobyte of internal memory which is mapped into a 16 kilobyte address range in the system fabric address map.To protect the register controls in Unit_A unprivileged software is blocked from accessing addresses between 0x0000 - 0x0FFF.The address decoder of Unit_A masks off the higher order address bits and decodes only the lower 12 bits for computing the offset into the 4 kilobyte internal memory space.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}]}, {"ID": "212", "Name": "Improper Removal of Sensitive Information Before Storage or Transfer", "Description": "Avoid errors related to improper resource shutdown or release (CWE-404), which may leave the sensitive data within the resource if it is in an incomplete state.", "Extended_Description": "Resources that may contain sensitive data include documents, packets, messages, databases, etc. While this data may be useful to an individual user or small set of users who share the resource, it may need to be removed before the resource can be shared outside of the trusted group. The process of removal is sometimes called cleansing or scrubbing.For example, a product for editing documents might not remove sensitive data such as reviewer comments or the local pathname where the document is stored. Or, a proxy might not remove an internal IP address from headers before making an outgoing request to an Internet site.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or DirectoriesRead Application Data. Note: Sensitive data may be exposed to an unauthorized actor in another control sphere. This may have a wide range of secondary consequences which will depend on what data is exposed. One possibility is the exposure of system data allowing an attacker to craft a specific, more effective attack.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Clearly specify which information should be regarded as private or sensitive, and require that the product offers functionality that allows the user to cleanse the sensitive information from the resource before it is published or exported to other parties.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.Implementation : Use naming conventions and strong types to make it easier to spot when sensitive data is being used. When creating structures, objects, or other complex entities, separate the sensitive and non-sensitive data as much as possible.Implementation : Avoid errors related to improper resource shutdown or release (CWE-404), which may leave the sensitive data within the resource if it is in an incomplete state.", "Demonstrative_Examples": "This code either generates a public HTML user information page or a JSON response containing the same user information.. The programmer is careful to not display the user's e-mail address when displaying the public HTML page. However, the e-mail address is not removed from the JSON response, exposing the user's e-mail address.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "201", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1258", "Name": "Exposure of Sensitive System Information Due to Uncleared Debug Information", "Description": "Whenever debug mode is enabled, all registers containing sensitive assets must be cleared.", "Extended_Description": "Security sensitive values, keys, intermediate steps of cryptographic operations, etc. are stored in temporary registers in the hardware. If these values are not cleared when debug mode is entered they may be accessed by a debugger allowing sensitive information to be accessible by untrusted parties.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Whenever debug mode is enabled, all registers containing sensitive assets must be cleared.", "Demonstrative_Examples": ". A cryptographic core in a System-On-a-Chip (SoC) is used for cryptographic acceleration and implements several cryptographic operations (e.g., computation of AES encryption and decryption, SHA-256, HMAC, etc.). The keys for these operations or the intermediate values are stored in registers internal to the cryptographic core. These internal registers are in the Memory Mapped Input Output (MMIO) space and are blocked from access by software and other untrusted agents on the SoC. These registers are accessible through the debug and test interface.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "212", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": null}]}, {"ID": "200", "Name": "Exposure of Sensitive Information to an Unauthorized Actor", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "There are many different kinds of mistakes that introduce information exposures. The severity of the error can range widely, depending on the context in which the product operates, the type of sensitive information that is revealed, and the benefits it may provide to an attacker.  Some kinds of sensitive information include:Information might be sensitive to different parties, each of which may have their own expectations for whether the information should be protected.  These parties include:Information exposures can occur in different ways:It is common practice to describe any loss of confidentiality as an \"information exposure,\" but this can lead to overuse of CWE-200 in CWE mapping. From the CWE perspective, loss of confidentiality is a technical impact that can arise from dozens of different weaknesses, such as insecure file permissions or out-of-bounds read.  CWE-200 and its lower-level descendants are intended to cover the mistakes that occur in behaviors that explicitly manage, store, transfer, or cleanse sensitive information.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": "The following code checks validity of the supplied username and password and notifies the user of a successful or failed login.. In the above code, there are different messages for when an incorrect username is supplied, versus when the username is correct but the password is wrong. This difference enables a potential attacker to understand the state of the login function, and could allow an attacker to discover a valid username by trying different values until the incorrect password message is returned. In essence, this makes it easier for an attacker to obtain half of the necessary authentication credentials.This code tries to open a database connection, and prints any exceptions that occur.. If an exception occurs, the printed message exposes the location of the configuration file the script is using. An attacker can use this information to target the configuration file (perhaps exploiting a Path Traversal weakness). If the file can be read, the attacker could gain credentials for accessing the database. The attacker may also be able to replace the file with a malicious one, causing the application to use an arbitrary database.In the example below, the method getUserBankAccount retrieves a bank account object from a database using the supplied username and account number to query the database. If an SQLException is raised when querying the database, an error message is created and output to a log file.. The error message that is created includes information about the database query that may contain sensitive information about the database or query logic. In this case, the error message will expose the table name and column names used in the database. This data could be used to simplify other attacks, such as SQL injection (CWE-89) to directly access the database.This code stores location information about the current user:. When the application encounters an exception it will write the user object to the log. Because the user object contains location information, the user's location is also written to the log.The following is an actual MySQL error statement:. The error clearly exposes the database credentials.This code displays some information on a web page.. The code displays a user's credit card and social security numbers, even though they aren't absolutely necessary.The following program changes its behavior based on a debug flag.. The code writes sensitive debug information to the client browser if the \"debugEnabled\" flag is set to true .This code uses location to determine the user's current US State location.. First the application must declare that it requires the ACCESS_FINE_LOCATION permission in the application's manifest.xml:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1259", "Name": "Improper Restriction of Security Token Assignment", "Description": "Security Token assignment review checks for design inconsistency and common weaknesses.\n\t\t\t\t\t\t\tSecurity-Token definition and programming flow is tested in both pre-silicon and post-silicon testing.", "Extended_Description": "Systems-On-A-Chip (Integrated circuits and hardware engines) implement Security Tokens to differentiate and identify which actions originated from which agent. These actions may be one of the directives: 'read', 'write', 'program', 'reset', 'fetch', 'compute', etc. Security Tokens are assigned to every agent in the System that is capable of generating an action or receiving an action from another agent. Multiple Security Tokens may be assigned to an agent and may be unique based on the agent's trust level or allowed privileges. Since the Security Tokens are integral for the maintenance of security in an SoC, they need to be protected properly. A common weakness afflicting Security Tokens is improperly restricting the assignment to trusted components. Consequently, an improperly protected Security Token may be able to be programmed by a malicious agent (i.e., the Security Token is mutable) to spoof the action as if it originated from a trusted agent.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Security Token assignment review checks for design inconsistency and common weaknesses.\n\t\t\t\t\t\t\tSecurity-Token definition and programming flow is tested in both pre-silicon and post-silicon testing.", "Demonstrative_Examples": "For example, consider a system with a register for storing an AES key for encryption and decryption. The key is of 128 bits implemented as a set of four 32-bit registers. The key register assets have an associated control register, AES_KEY_ACCESS_POLICY, which provides the necessary access controls. This access-policy register defines which agents may engage in a transaction, and the type of transaction, with the AES-key registers. Each bit in this 32-bit register defines a security Token. There could be a maximum of 32 security Tokens that are allowed access to the AES-key registers. The number of the bit when set (i.e., \"1\") allows respective action from an agent whose identity matches the number of the bit and, if \"0\" (i.e., Clear), disallows the respective action to that corresponding agent.. Let's assume the system has two agents: a Main-controller and an Aux-controller. The respective Security Tokens are \"1\" and \"2\".", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1294", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "1294", "Name": "Insecure Security Identifier Mechanism", "Description": "Access and programming flows must be tested in pre-silicon and post-silicon testing.", "Extended_Description": "Systems-On-Chip (Integrated circuits and hardware\n                    engines) implement Security Identifiers to\n                    differentiate/identify actions originated from various\n                    agents. These actions could be 'read', 'write', 'program',\n                    'reset', 'fetch', 'compute', etc. Security identifiers are\n                    generated and assigned to every agent in the System (SoC)\n                    that is either capable of generating an action or receiving\n                    an action from another agent. Every agent could be assigned\n                    a unique, Security Identifier based on its trust level or\n                    privileges.A broad class of flaws can exist in the Security\n                    Identifier process, including but not limited to missing\n                    security identifiers, improper conversion of security\n                    identifiers, incorrect generation of security identifiers,\n                    etc.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design, then identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during hardware implementation, then identified later during Testing or System Configuration phases.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Security Identifier Decoders must be reviewed for design inconsistency and common weaknesses.Implementation : Access and programming flows must be tested in pre-silicon and post-silicon testing.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "126", "Name": "Buffer Over-read", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "This typically occurs when the pointer or its index is incremented to a position beyond the bounds of the buffer or when pointer arithmetic results in a position outside of the valid memory location to name a few. This may result in exposure of sensitive information or possibly a crash.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Bypass Protection Mechanism. Note: By reading out-of-bounds memory, an attacker might be able to get secret values, such as memory addresses, which can be bypass protection mechanisms such as ASLR in order to improve the reliability and likelihood of exploiting a separate weakness to achieve code execution instead of just denial of service.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "In the following C/C++ example the method processMessageFromSocket() will get a message from a socket, placed into a buffer, and will parse the contents of the buffer into a structure that contains the message length and the message body. A for loop is used to copy the message body into a local character string which will be passed to another method for processing.. However, the message length variable from the structure is used as the condition for ending the for loop without validating that the message length variable accurately reflects the length of the message body (CWE-606). This can result in a buffer over-read (CWE-125) by reading from memory beyond the bounds of the buffer if the message length variable indicates a length that is longer than the size of a message body (CWE-130).The following C/C++ example demonstrates a buffer over-read due to a missing NULL terminator. The main method of a pattern matching utility that looks for a specific pattern within a specific file uses the string strncopy() method to copy the command line user input file name and pattern to the Filename and Pattern character arrays respectively.. However, the code do not take into account that strncpy() will not add a NULL terminator when the source buffer is equal in length of longer than that provide size attribute. Therefore if a user enters a filename or pattern that are the same size as (or larger than) their respective character arrays, a NULL terminator will not be added (CWE-170) which leads to the printf() read beyond the expected end of the Filename and Pattern buffers.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "125", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "788", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1260", "Name": "Improper Handling of Overlap Between Protected Memory Ranges", "Description": "For all of the programmable memory protection regions, the memory protection unit (MPU) design can define a priority scheme.\n                 For example: if three memory regions can be programmed (Region_0, Region_1, and Region_2), the design can enforce a priority scheme, such that, if a system address is within multiple regions, then the region with the lowest ID takes priority and the access-control policy of that region will be applied.  In some MPU designs, the priority scheme can also be programmed by trusted software.\n                 Hardware logic or trusted firmware can also check for region definitions and block programming of memory regions with overlapping addresses. \n                 The memory-access-control-check filter can also be designed to apply a policy filter to all of the overlapping ranges, i.e., if an address is within Region_0 and Region_1, then access to this address is only granted if both Region_0 and Region_1 policies allow the access.", "Extended_Description": "Isolated memory regions and access control (read/write) policies are used by hardware to protect privileged software. Software components are often allowed to change or remap memory region definitions in order to enable flexible and dynamically changeable memory management by system software.If a software component running at lower privilege can program a memory address region to overlap with other memory regions used by software running at higher privilege, privilege escalation may be available to attackers. The memory protection unit (MPU) logic can incorrectly handle such an address overlap and allow the lower-privilege software to read or write into the protected memory region, resulting in privilege escalation attack. An address overlap weakness can also be used to launch a denial of service attack on the higher-privilege software memory regions.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design or implementation and identified later during the Testing phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Analysis. Description: Create a high privilege memory block of any arbitrary size. Attempt to create a lower privilege memory block with an overlap of the high privilege memory block. If the creation attempt works, fix the hardware. Repeat the test.", "Potential_Mitigations": "Architecture and Design : Ensure that memory regions are isolated as intended and that access control (read/write) policies are used by hardware to protect privileged software.Implementation : For all of the programmable memory protection regions, the memory protection unit (MPU) design can define a priority scheme.\n                 For example: if three memory regions can be programmed (Region_0, Region_1, and Region_2), the design can enforce a priority scheme, such that, if a system address is within multiple regions, then the region with the lowest ID takes priority and the access-control policy of that region will be applied.  In some MPU designs, the priority scheme can also be programmed by trusted software.\n                 Hardware logic or trusted firmware can also check for region definitions and block programming of memory regions with overlapping addresses. \n                 The memory-access-control-check filter can also be designed to apply a policy filter to all of the overlapping ranges, i.e., if an address is within Region_0 and Region_1, then access to this address is only granted if both Region_0 and Region_1 policies allow the access.", "Demonstrative_Examples": "For example, consider a design with a 16-bit address that has two software privilege levels: Privileged_SW and Non_privileged_SW. To isolate the system memory regions accessible by these two privilege levels, the design supports three memory regions: Region_0, Region_1, and Region_2.Each region is defined by two 32 bit registers: its range and its access policy.Certain bits of the access policy are defined symbolically as follows:For any requests from software, an address-protection filter checks the address range and access policies for each of the three regions, and only allows software access if all three filters allow access.Consider the following goals for access control as intended by the designer:The intention is that Non_privileged_SW cannot modify memory region and policies defined by Privileged_SW in Region_0 and Region_1. Thus, it cannot read or write the memory regions that Privileged_SW is using.. This design could be improved in several ways.The example code below is taken from the IOMMU controller module of the HACK@DAC'19 buggy CVA6 SoC [REF-1338]. The static memory map is composed of a set of Memory-Mapped Input/Output (MMIO) regions covering different IP agents within the SoC. Each region is defined by two 64-bit variables representing the base address and size of the memory region (XXXBase and XXXLength).. In this example, we have 12 IP agents, and only 4 of them are called out for illustration purposes in the code snippets. Access to the AES IP MMIO region is considered privileged as it provides access to AES secret key, internal states, or decrypted data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1261", "Name": "Improper Handling of Single Event Upsets", "Description": "SEUs mostly affect SRAMs.  For SRAMs storing security-critical data, implement Error-Correcting-Codes (ECC) and Address Interleaving.", "Extended_Description": "Technology trends such as CMOS-transistor down-sizing, use of \n            new materials, and system-on-chip architectures continue to increase the \n            sensitivity of systems to soft errors. These errors are random, and \n            their causes might be internal (e.g., interconnect coupling) or external \n            (e.g., cosmic radiation). These soft errors are not permanent in nature \n            and cause temporary bit flips known as single-event upsets (SEUs). \n            SEUs are induced errors in circuits caused when charged particles lose \n            energy by ionizing the medium through which they pass, leaving behind a \n            wake of electron-hole pairs that cause temporary failures. If these \n            failures occur in security-sensitive modules in a chip, it might \n            compromise the security guarantees of the chip. For instance, these \n            temporary failures could be bit flips that change the privilege of\n\t    a regular user to root.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Implement triple-modular redundancy around security-sensitive modules.Architecture and Design : SEUs mostly affect SRAMs.  For SRAMs storing security-critical data, implement Error-Correcting-Codes (ECC) and Address Interleaving.", "Demonstrative_Examples": "This is an example from [REF-1089].  See the reference for full details of this issue.. Parity is error detecting but not error correcting.. In 2016, a security researcher, who was also a patient using a pacemaker, was on an airplane when a bit flip occurred in the pacemaker, likely due to the higher prevalence of cosmic radiation at such heights. The pacemaker was designed to account for bit flips and went into a default safe mode, which still forced the patient to go to a hospital to get it reset. The bit flip also inadvertently enabled the researcher to access the crash file, perform reverse engineering, and detect a hard-coded key. [REF-1101]", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1384", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1254", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1262", "Name": "Improper Access Control for Register Interface", "Description": "Ensure that access control policies for register access are implemented in accordance with the specified design.", "Extended_Description": "Software commonly accesses peripherals in a System-on-Chip (SoC) or other device through a memory-mapped register interface. Malicious software could tamper with any security-critical hardware data that is accessible directly or indirectly through the register interface, which could lead to a loss of confidentiality and integrity.", "Modes_Of_Introduction": "Architecture and Design: This weakness may be exploited if the register interface design does not adequately protect hardware assets from software.Implementation: Mis-implementation of access control policies may inadvertently allow access to hardware assets through the register interface.", "Common_Consequences": "Scopes: ConfidentialityIntegrity. Impacts: Read MemoryRead Application DataModify MemoryModify Application DataGain Privileges or Assume IdentityBypass Protection MechanismUnexpected StateAlter Execution Logic. Note: Confidentiality of hardware assets may be violated if the protected information can be read out by software through the register interface. Registers storing security state, settings, other security-critical data may be corruptible by software without correctly implemented protections.", "Detection_Methods": "Method Name: Manual Analysis. Description: This is applicable in the Architecture phase before implementation started. Make sure access policy is specified for the entire memory map. Manual analysis may not ensure the implementation is correct. Method Name: Manual Analysis. Description: Registers controlling hardware should have access control implemented. This access control may be checked manually for correct implementation. Items to check consist of how are trusted parties set, how are trusted parties verified, how are accesses verified, etc. Effectiveness of a manual analysis will vary depending upon how complicated the interface is constructed. Method Name: Simulation / Emulation. Description: Functional simulation is applicable during the Implementation Phase. Testcases must be created and executed for memory mapped registers to verify adherence to the access control policy. This method can be effective, since functional verification needs to be performed on the design, and verification for this weakness will be included. There can be difficulty covering the entire memory space during the test. Method Name: Formal Verification. Description: Formal verification is applicable during the Implementation phase. Assertions need to be created in order to capture illegal register access scenarios and prove that they cannot occur. Formal methods are exhaustive and can be very effective, but creating the cases for large designs may be complex and difficult. Method Name: Automated Analysis. Description: Information flow tracking can be applicable during the Implementation phase. Security sensitive data (assets) - for example, as stored in registers - is automatically tracked over time through the design to verify the data doesn't reach illegal destinations that violate the access policies for the memory map. This method can be very effective when used together with simulation and emulation, since detecting violations doesn't rely on specific scenarios or data values. This method does rely on simulation and emulation, so testcases must exist in order to use this method. Method Name: Architecture or Design Review. Description: Manual documentation review of the system memory map, register specification, and permissions associated with accessing security-relevant functionality exposed via memory-mapped registers. Method Name: Fuzzing. Description: Perform penetration testing (either manual or semi-automated with fuzzing) to verify that access control mechanisms such as the memory protection units or on-chip bus firewall settings adequately protect critical hardware registers from software access.", "Potential_Mitigations": "Architecture and Design : Design proper policies for hardware register access from software.Implementation : Ensure that access control policies for register access are implemented in accordance with the specified design.", "Demonstrative_Examples": ". The register interface provides software access to hardware functionality. This functionality is an attack surface. This attack surface may be used to run untrusted code on the system through the register interface. As an example, cryptographic accelerators require a mechanism for software to select modes of operation and to provide plaintext or ciphertext data to be encrypted or decrypted as well as other functions. This functionality is commonly provided through registers.The example code is taken from the Control/Status Register (CSR) module inside the processor core of the HACK@DAC'19 buggy CVA6 SoC [REF-1340]. In RISC-V ISA [REF-1341], the CSR file contains different sets of registers with different privilege levels, e.g., user mode (U), supervisor mode (S), hypervisor mode (H), machine mode (M), and debug mode (D), with different read-write policies, read-only (RO) and read-write (RW). For example, machine mode, which is the highest privilege mode in a RISC-V system, registers should not be accessible in user, supervisor, or hypervisor modes.. The vulnerable example code allows the machine exception program counter (MEPC) register to be accessed from a user mode program by excluding the MEPC from the access control check. MEPC as per the RISC-V specification can be only written or read by machine mode code. Thus, the attacker in the user mode can run code in machine mode privilege (privilege escalation).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1264", "Name": "Hardware Logic with Insecure De-Synchronization between Control and Data Channels", "Description": "Thoroughly verify the data routing logic to ensure that any error handling or security checks effectively block illegal dataflows.", "Extended_Description": "Many high-performance on-chip bus protocols and processor data-paths employ separate channels for control and data to increase parallelism and maximize throughput. Bugs in the hardware logic that handle errors and security checks can make it possible for data to be forwarded before the completion of the security checks. If the data can propagate to a location in the hardware observable to an attacker, loss of data confidentiality can occur. 'Meltdown' is a concrete example of how de-synchronization between data and permissions checking logic can violate confidentiality requirements. Data loaded from a page marked as privileged was returned to the cpu regardless of current privilege level for performance reasons. The assumption was that the cpu could later remove all traces of this data during the handling of the illegal memory access exception, but this assumption was proven false as traces of the secret data were not removed from the microarchitectural state.", "Modes_Of_Introduction": "Architecture and Design: The weakness can be introduced in the data transfer or bus protocol itself or in the implementation.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Thoroughly verify the data routing logic to ensure that any error handling or security checks effectively block illegal dataflows.", "Demonstrative_Examples": ". There are several standard on-chip bus protocols used in modern SoCs to allow communication between components. There are a wide variety of commercially available hardware IP implementing the interconnect logic for these protocols. A bus connects components which initiate/request communications such as processors and DMA controllers (bus masters) with peripherals which respond to requests. In a typical system, the privilege level or security designation of the bus master along with the intended functionality of each peripheral determine the security policy specifying which specific bus masters can access specific peripherals.  This security policy (commonly referred to as a bus firewall) can be enforced using separate IP/logic from the actual interconnect responsible for the data routing.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "821", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1037", "View_ID": "1000", "Ordinal": null}]}, {"ID": "691", "Name": "Insufficient Control Flow Management", "Description": "The code does not sufficiently manage its control flow during execution, creating conditions in which the control flow can be modified in unexpected ways.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": []}, {"ID": "1265", "Name": "Unintended Reentrant Invocation of Non-reentrant Code Via Nested Calls", "Description": "Make sure the code (e.g., function or class) in question is reentrant by not leveraging non-local data, not modifying its own code, and not calling other non-reentrant code.", "Extended_Description": "In a complex product, a single function call may lead to many different possible code paths, some of which may involve deeply nested calls. It may be difficult to foresee all possible code paths that could emanate from a given function call. In some systems, an external actor can manipulate inputs to the system and thereby achieve a wide range of possible control flows. This is frequently a concern in products that execute scripts from untrusted sources. Examples of such products are web browsers and PDF readers. A weakness is present when one of the possible code paths resulting from a function call alters program state that the original caller assumes to be unchanged during the call.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Unexpected State. Note: Exploitation of this weakness can leave the application in an unexpected state and cause variables to be reassigned before the first invocation has completed. This may eventually result in memory corruption or unexpected code execution.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : When architecting a system that will execute untrusted code in response to events, consider executing the untrusted event handlers asynchronously (asynchronous message passing) as opposed to executing them synchronously at the time each event fires. The untrusted code should execute at the start of the next iteration of the thread's message loop. In this way, calls into non-reentrant code are strictly serialized, so that each operation completes fully before the next operation begins. Special attention must be paid to all places where type coercion may result in script execution. Performing all needed coercions at the very beginning of an operation can help reduce the chance of operations executing at unexpected junctures.Implementation : Make sure the code (e.g., function or class) in question is reentrant by not leveraging non-local data, not modifying its own code, and not calling other non-reentrant code.", "Demonstrative_Examples": "The implementation of the Widget class in the following C++ code is an example of code that is not designed to be reentrant. If an invocation of a method of Widget inadvertently produces a second nested invocation of a method of Widget, then data member backgroundImage may unexpectedly change during execution of the outer call.. Looking closer at this example, Widget::click() calls backgroundImage->click(), which in turn calls scriptEngine->fireOnImageClick(). The code within fireOnImageClick() invokes the appropriate script handler routine as defined by the document being rendered. In this scenario this script routine is supplied by an adversary and this malicious script makes a call to Widget::changeBackgroundImage(), deleting the Image object pointed to by backgroundImage. When control returns to Image::click, the function's backgroundImage \"this\" pointer (which is the former value of backgroundImage) is a dangling pointer. The root of this weakness is that while one operation on Widget (click) is in the midst of executing, a second operation on the Widget object may be invoked (in this case, the second invocation is a call to different method, namely changeBackgroundImage) that modifies the non-local variable.This is another example of C++ code that is not designed to be reentrant.. The expected order of operations is a call to Request::setup(), followed by a call to Request::send(). Request::send() calls scriptEngine->coerceToString(_data) to coerce a script-provided parameter into a string. This operation may produce script execution. For example, if the script language is ECMAScript, arbitrary script execution may result if _data is an adversary-supplied ECMAScript object having a custom toString method. If the adversary's script makes a new call to Request::setup, then when control returns to Request::send, the field uri and the local variable credentials will no longer be consistent with one another. As a result, credentials for one resource will be shared improperly with a different resource. The root of this weakness is that while one operation on Request (send) is in the midst of executing, a second operation may be invoked (setup).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "663", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "416", "View_ID": "1000", "Ordinal": null}]}, {"ID": "404", "Name": "Improper Resource Shutdown or Release", "Description": "When releasing a complex object or structure, ensure that you properly dispose of all of its member components, not just the object itself.", "Extended_Description": "When a resource is created or allocated, the developer is responsible for properly releasing the resource as well as accounting for all potential paths of expiration or invalidation, such as a set period of time or revocation.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityOther. Impacts: DoS: Resource Consumption (Other)Varies by Context. Note: Most unreleased resource issues result in general software reliability problems, but if an attacker can intentionally trigger a resource leak, the attacker might be able to launch a denial of service attack by depleting the resource pool.Scopes: Confidentiality. Impacts: Read Application Data. Note: When a resource containing sensitive information is not correctly shutdown, it may expose the sensitive data in a subsequent allocation.", "Detection_Methods": "Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.Resource clean up errors might be detected with a stress-test by calling the software simultaneously from a large number of threads or processes, and look for evidence of any unexpected behavior. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Dynamic Analysis. Description: Identify error conditions that are not likely to occur during normal usage and trigger them. For example, run the product under low memory conditions, run with insufficient privileges or permissions, interrupt a transaction before it is completed, or disable connectivity to basic network services such as DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled exception or similar error that was discovered and handled by the application's environment, it may still indicate unexpected conditions that were not handled by the application itself. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, languages such as Java, Ruby, and Lisp perform automatic garbage collection that releases memory for objects that have been deallocated.Implementation : It is good practice to be responsible for freeing all resources you allocate and to be consistent with how and where you free memory in a function. If you allocate memory that you intend to free upon completion of the function, you must be sure to free the memory at all exit points for that function including error conditions.Implementation : Memory should be allocated/freed using matching functions such as malloc/free, new/delete, and new[]/delete[].Implementation : When releasing a complex object or structure, ensure that you properly dispose of all of its member components, not just the object itself.", "Demonstrative_Examples": "The following method never closes the new file handle. Given enough time, the Finalize() method for BufferReader should eventually call Close(), but there is no guarantee as to how long this action will take. In fact, there is no guarantee that Finalize() will ever be invoked. In a busy environment, the Operating System could use up all of the available file handles before the Close() function is called.. The good code example simply adds an explicit call to the Close() function when the system is done using the file. Within a simple example such as this the problem is easy to see and fix. In a real system, the problem may be considerably more obscure.This code attempts to open a connection to a database and catches any exceptions that may occur.. If an exception occurs after establishing the database connection and before the same connection closes, the pool of database connections may become exhausted. If the number of available connections is exceeded, other users cannot access this resource, effectively denying access to the application.. Under normal conditions the following C# code executes a database query, processes the results returned by the database, and closes the allocated SqlConnection object. But if an exception occurs while executing the SQL or processing the results, the SqlConnection object is not closed. If this happens often enough, the database will run out of available cursors and not be able to execute any more SQL queries.. The following C function does not close the file handle it opens if an error occurs. If the process is long-lived, the process can run out of file handles.. In this example, the program does not use matching functions such as malloc/free, new/delete, and new[]/delete[] to allocate/deallocate the resource.. In this example, the program calls the delete[] function on non-heap memory.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "619", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1266", "Name": "Improper Scrubbing of Sensitive Data from Decommissioned Device", "Description": "If the capability to wipe sensitive data isn't built-in, the manufacturer may need to provide a utility to scrub sensitive data from storage if that data is located in a place which is non-accessible by the administrator. One example of this could be when sensitive data is stored on an EEPROM for which there is no user/admin interface provided by the system.", "Extended_Description": "When a product is decommissioned - i.e., taken out of service - best practices or regulatory requirements may require the administrator to remove or overwrite sensitive data first, i.e. \"scrubbing.\"  Improper scrubbing of sensitive data from a decommissioned device leaves that data vulnerable to acquisition by a malicious actor. Sensitive data may include, but is not limited to, device/manufacturer proprietary information, user/device credentials, network configurations, and other forms of sensitive data.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Functionality to completely scrub data from a product at the conclusion of its lifecycle should be part of the design phase. Trying to add this function on top of an existing architecture could lead to incomplete removal of sensitive information/data.Policy : The manufacturer should describe the location(s) where sensitive data is stored and the policies and procedures for its removal. This information may be conveyed, for example, in an Administrators Guide or a Statement of Volatility.Implementation : If the capability to wipe sensitive data isn't built-in, the manufacturer may need to provide a utility to scrub sensitive data from storage if that data is located in a place which is non-accessible by the administrator. One example of this could be when sensitive data is stored on an EEPROM for which there is no user/admin interface provided by the system.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1267", "Name": "Policy Uses Obsolete Encoding", "Description": "Security Token Decoders should be reviewed for design inconsistency and common weaknesses.\n      Access and programming flows should be tested in both pre-silicon and post-silicon testing.", "Extended_Description": "Within a System-On-a-Chip (SoC), various circuits and hardware engines generate transactions for the purpose of accessing (read/write) assets or performing various actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (identifying the originator of the transaction) and a destination identity (routing the transaction to the respective entity). Sometimes the transactions are qualified with a Security Token. This Security Token helps the destination agent decide on the set of allowed actions (e.g., access to an asset for reads and writes). A policy encoder is used to map the bus transactions to Security Tokens that in turn are used as access-controls/protection mechanisms. A common weakness involves using an encoding which is no longer trusted, i.e., an obsolete encoding.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Security Token Decoders should be reviewed for design inconsistency and common weaknesses.\n      Access and programming flows should be tested in both pre-silicon and post-silicon testing.", "Demonstrative_Examples": "For example, consider a system that has four bus masters. The table below provides bus masters, their Security Tokens, and trust assumptions.The policy encoding is to be defined such that Security Token will be used in implemented access-controls. The bits in the bus transaction that contain Security-Token information are Bus_transaction [15:11]. The assets are the AES-Key registers for encryption or decryption. The key of 128 bits is implemented as a set of four, 32-bit registers.Below is an example of a policy encoding scheme inherited from a previous project where all \"ODD\" numbered Security Tokens are trusted.. The inherited policy encoding is obsolete and does not work for the new system where an untrusted bus master with an odd Security Token exists in the system, i.e., Master_3 whose Security Token is \"11\". Based on the old policy, the untrusted bus master (Master_3) has access to the AES-Key registers. To resolve this, a register AES_KEY_ACCESS_POLICY can be defined to provide necessary, access controls:New Policy:The AES_KEY_ACCESS_POLICY register defines which agents with a Security Token in the transaction can access the AES-key registers. Each bit in this 32-bit register defines a Security Token. There could be a maximum of 32 security Tokens that are allowed access to the AES-key registers. The number of the bit when set (i.e., \"1\") allows respective action from an agent whose identity matches the number of the bit and, if \"0\" (i.e., Clear), disallows the respective action to that corresponding agent. Thus, any bus master with Security Token \"01\" is allowed access to the AES-Key registers. Below is the Pseudo Code for policy encoding:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1268", "Name": "Policy Privileges are not Assigned Consistently Between Control and Data Agents", "Description": "Access-control-policy definition and programming flow must be sufficiently tested in pre-silicon and post-silicon testing.", "Extended_Description": "Integrated circuits and hardware engines may provide access to resources (device-configuration, encryption keys, etc.) belonging to trusted firmware or software modules (commonly set by a BIOS or a bootloader). These accesses are typically controlled and limited by the hardware. Hardware design access control is sometimes implemented using a policy. A policy defines which entity or agent may or may not be allowed to perform an action. When a system implements multiple levels of policies, a control policy may allow direct access to a resource as well as changes to the policies themselves.Resources that include agents in their control policy but not in their write policy could unintentionally allow an untrusted agent to insert itself in the write policy register. Inclusion in the write policy register could allow a malicious or misbehaving agent write access to resources. This action could result in security compromises including leaked information, leaked encryption keys, or modification of device configuration.", "Modes_Of_Introduction": "Architecture and Design: This weakness may be introduced during the design of a device when the architect does not comprehensively specify all of the policies required by an agent.Implementation: This weakness may be introduced during implementation if device policy restrictions do not sufficiently constrain less-privileged clients.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Access-control-policy definition and programming flow must be sufficiently tested in pre-silicon and post-silicon testing.", "Demonstrative_Examples": "Consider a system of seven registers for storing and configuring an AES key for encryption or decryption.Four 32-bit registers are used to store a 128-bit AES key. The names of those registers are AES_ENC_DEC_KEY_0, AES_ENC_DEC_KEY_1, AES_ENC_DEC_KEY_2, and AES_ENC_DEC_KEY_3. Collectively these are referred to as the AES Key registers.Three 32-bit registers are used to define access control for the AES-key registers. The names of those registers are AES_KEY_CONTROL_POLICY, AES_KEY_READ_POLICY, and AES_KEY_WRITE_POLICY. Collectively these registers are referred to as the Policy registers, and their functions are explained next.The preceding three policy registers encode access control at the bit level. Therefore a maximum of 32 agents can be defined (1 bit per agent). The value of the bit when set (i.e., \"1\") allows the respective action from an agent whose identity corresponds to the number of the bit. If clear (i.e., \"0\"), it disallows the respective action to that corresponding agent. For example, if bit 0 is set to \"1\" in the AES_KEY_READ_POLICY register, then agent 0 has permission to read the AES-key registers.Consider that there are 4 agents named Agent 1, Agent 2, Agent 3, and Agent 4. For access control purposes Agent 1 is assigned to bit 1, Agent 2 to bit 2, Agent 3 to bit 3, and Agent 4 to bit 4. All agents are trusted except for Agent 3 who is untrusted. Also consider the register values in the below table.. IThe AES_KEY_CONTROL_POLICY register value is 0x00000018. In binary, the lower 8 bits will be 0001 1000, meaning that:The AES_KEY_READ_POLICY register value is 0x00000002. In binary, the lower 8 bits will be 0000 0010, meaning that:The AES_KEY_WRITE_POLICY register value is 0x00000004. In binary, the lower 8 bits will be 0000 0100, meaning that:The configured access control policy for Agents 1,2,3,4 is summarized in table below.At this point Agents 3 and 4 can only configure which agents can read AES keys and which agents can write AES keys. Agents 3 and 4 cannot read or write AES keys - just configure access control.Now, recall Agent 3 is untrusted. As explained above, the value of the AES_KEY_CONTROL_POLICY register gives agent 3 access to write to the AES_KEY_WRITE_POLICY register. Agent 3 can use this write access to add themselves to the AES_KEY_WRITE_POLICY register. This is accomplished by Agent 3 writing the value 0x00000006. In binary, the lower 8 bits are 0000 0110, meaning that bit 3 will be set. Thus, giving Agent 3 having the ability to write to the AES Key registers.If the AES_KEY_CONTROL_POLICY register value is 0x00000010, the lower 8 bits will be 0001 0000. This will give Agent 4, a trusted agent, write access to AES_KEY_WRITE_POLICY, but Agent 3, who is untrusted, will not have write access. The Policy register values should therefore be as follows:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1269", "Name": "Product Released in Non-Release Configuration", "Description": "Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).", "Extended_Description": "Products in the pre-production or manufacturing stages are configured to have many debug hooks and debug capabilities, including but not limited to:The above is by no means an exhaustive list, but it alludes to the greater capability and the greater state of vulnerability of a product during it's preproduction or manufacturing state.Complexity increases when multiple parties are involved in executing the tests before the final production version. For example, a chipmaker might fabricate a chip and run its own preproduction tests, following which the chip would be delivered to the Original Equipment Manufacturer (OEM), who would now run a second set of different preproduction tests on the same chip. Only after both of these sets of activities are complete, can the overall manufacturing phase be called \"complete\" and have the \"Manufacturing Complete\" fuse blown. However, if the OEM forgets to blow the Manufacturing Complete fuse, then the system remains in the manufacturing stage, rendering the system both exposed and vulnerable.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).Integration : Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).Manufacturing : Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).", "Demonstrative_Examples": "This example shows what happens when a preproduction system is made available for production.. An attacker will now be able to scan all the internal memory (containing chipmaker-level secrets).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "127", "Name": "Buffer Under-read", "Description": "The product reads from a buffer using buffer access mechanisms such as indexes or pointers that reference memory locations prior to the targeted buffer.", "Extended_Description": "This typically occurs when the pointer or its index is decremented to a position before the buffer, when pointer arithmetic results in a position before the beginning of the valid memory location, or when a negative index is used. This may result in exposure of sensitive information or possibly a crash.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Bypass Protection Mechanism. Note: By reading out-of-bounds memory, an attacker might be able to get secret values, such as memory addresses, which can be bypass protection mechanisms such as ASLR in order to improve the reliability and likelihood of exploiting a separate weakness to achieve code execution instead of just denial of service.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "125", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "786", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1270", "Name": "Generation of Incorrect Security Tokens", "Description": "Generation of Security Tokens should be reviewed for design inconsistency and common weaknesses.\n\t\t\t\t\t\t\tSecurity-Token definition and programming flow should be tested in pre-silicon and post-silicon testing.", "Extended_Description": "Systems-On-a-Chip (SoC) (Integrated circuits and hardware engines) implement Security Tokens to differentiate and identify actions originated from various agents. These actions could be \"read\", \"write\", \"program\", \"reset\", \"fetch\", \"compute\", etc. Security Tokens are generated and assigned to every agent on the SoC that is either capable of generating an action or receiving an action from another agent. Every agent could be assigned a unique, Security Token based on its trust level or privileges. Incorrectly generated Security Tokens could result in the same token used for multiple agents or multiple tokens being used for the same agent. This condition could result in a Denial-of-Service (DoS) or the execution of an action that in turn could result in privilege escalation or unintended access.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Generation of Security Tokens should be reviewed for design inconsistency and common weaknesses.\n\t\t\t\t\t\t\tSecurity-Token definition and programming flow should be tested in pre-silicon and post-silicon testing.", "Demonstrative_Examples": "Consider a system with a register for storing an AES key for encryption or decryption. The key is 128 bits long implemented as a set of four 32-bit registers. The key registers are assets, and register, AES_KEY_ACCESS_POLICY, is defined to provide necessary access controls. The access-policy register defines which agents, using a Security Token, may access the AES-key registers. Each bit in this 32-bit register is used to define a Security Token. There could be a maximum of 32 Security Tokens that are allowed access to the AES-key registers. When set (bit = \"1\") bit number allows action from an agent whose identity matches that bit number. If Clear (bit = \"0\") the action is disallowed for the corresponding agent.. Assume the system has two agents: a Main-controller and an Aux-controller. The respective Security Tokens are \"1\" and \"2\".", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1294", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "909", "Name": "Missing Initialization of Resource", "Description": "Run or compile your product with settings that generate warnings about uninitialized variables or data.", "Extended_Description": "Many resources require initialization before they can be properly used. If a resource is not initialized, it could contain unpredictable or expired data, or it could be initialized to defaults that are invalid. This can have security implications when the resource is expected to have certain properties or values.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read MemoryRead Application Data. Note: When reusing a resource such as memory or a program variable, the original contents of that resource may not be cleared before it is sent to an untrusted party.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: The uninitialized resource may contain values that cause program flow to change in ways that the programmer did not intend.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Explicitly initialize the resource before use. If this is performed through an API function or standard procedure, follow all specified steps.Implementation : Pay close attention to complex conditionals that affect initialization, since some branches might not perform the initialization.Implementation : Avoid race conditions (CWE-362) during initialization routines.Build and Compilation : Run or compile your product with settings that generate warnings about uninitialized variables or data.", "Demonstrative_Examples": ". Here, a boolean initiailized field is consulted to ensure that initialization tasks are only completed once. However, the field is mistakenly set to true during static initialization, so the initialization code is never reached.The following code intends to limit certain operations to the administrator only.. If the application is unable to extract the state information - say, due to a database timeout - then the $uid variable will not be explicitly set by the programmer. This will cause $uid to be regarded as equivalent to \"0\" in the conditional, allowing the original user to perform administrator actions. Even if the attacker cannot directly influence the state data, unexpected errors could cause incorrect privileges to be assigned to a user just by accident.The following code intends to concatenate a string to a variable and print the string.. This might seem innocent enough, but str was not initialized, so it contains random memory. As a result, str[0] might not contain the null terminator, so the copy might start at an offset other than 0. The consequences can vary, depending on the underlying memory.This example will leave test_string in an\n\t\t\t  unknown condition when i is the same value as err_val,\n\t\t\t  because test_string is not initialized\n\t\t\t  (CWE-456). Depending on where this code segment appears\n\t\t\t  (e.g. within a function body), test_string might be\n\t\t\t  random if it is stored on the heap or stack. If the\n\t\t\t  variable is declared in static memory, it might be zero\n\t\t\t  or NULL. Compiler optimization might contribute to the\n\t\t\t  unpredictability of this address.. When the printf() is reached,\n              test_string might be an unexpected address, so the\n              printf might print junk strings (CWE-457).To fix this code, there are a couple approaches to\n\t\t\t  making sure that test_string has been properly set once\n\t\t\t  it reaches the printf().One solution would be to set test_string to an\n\t\t\t  acceptable default before the conditional:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "908", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1271", "Name": "Uninitialized Value on Reset for Registers Holding Security Settings", "Description": "All registers holding security-critical information should be set to a specific value on reset.", "Extended_Description": "When the device is first brought out of reset, the state of registers will be indeterminate if they have not been initialized by the logic. Before the registers are initialized, there will be a window during which the device is in an insecure state and may be vulnerable to attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Design checks should be performed to identify any uninitialized flip-flops used for security-critical functions.Architecture and Design : All registers holding security-critical information should be set to a specific value on reset.", "Demonstrative_Examples": "Shown below is a positive clock edge triggered flip-flop used to implement a lock bit for test and debug interface. When the circuit is first brought out of reset, the state of the flip-flop will be unknown until the enable input and D-input signals update the flip-flop state. In this example, an attacker can reset the device until the test and debug interface is unlocked and access the test interface until the lock signal is driven to a known state by the logic.. The flip-flop can be set to a known value (0 or 1) on reset, but requires that the logic explicitly update the output of the flip-flop if the reset signal is active.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "909", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1272", "Name": "Sensitive Information Uncleared Before Debug/Power State Transition", "Description": "During state transitions, information not needed in the next state should be removed before the transition to the next state.", "Extended_Description": "A device or system frequently employs many power and sleep states during its normal operation (e.g., normal power, additional power, low power, hibernate, deep sleep, etc.). A device also may be operating within a debug condition. State transitions can happen from one power or debug state to another. If there is information available in the previous state which should not be available in the next state and is not properly removed before the transition into the next state, sensitive information may leak from the system.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess ControlAccountabilityAuthenticationAuthorizationNon-Repudiation. Impacts: Read MemoryRead Application Data. Note: Sensitive information may be used to unlock additional capabilities of the device and take advantage of hidden functionalities which could be used to compromise device security.", "Detection_Methods": "Method Name: Manual Analysis. Description: Write a known pattern into each sensitive location. Enter the power/debug state in question. Read data back from the sensitive locations. If the reads are successful, and the data is the same as the pattern that was originally written, the test fails and the device needs to be fixed. Note that this test can likely be automated.", "Potential_Mitigations": "Architecture and Design : During state transitions, information not needed in the next state should be removed before the transition to the next state.", "Demonstrative_Examples": "This example shows how an attacker can take advantage of an incorrect state transition.. Suppose a device is transitioning from state A to state B. During state A, it can read certain private keys from the hidden fuses that are only accessible in state A but not in state B. The device reads the keys, performs operations using those keys, then transitions to state B, where those private keys should no longer be accessible.After the transition to state B, even though the private keys are no longer accessible directly from the fuses in state B, they can be accessed indirectly by reading the memory that contains the private keys.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "226", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1273", "Name": "Device Unlock Credential Sharing", "Description": "Ensure the unlock credentials are shared with the minimum number of parties and with utmost secrecy. To limit the risk associated with compromised credentials, where possible, the credentials should be part-specific.", "Extended_Description": "\"Unlocking a device\" often means activating certain unadvertised debug and manufacturer-specific capabilities of a device using sensitive credentials. Unlocking a device might be necessary for the purpose of troubleshooting device problems. For example, suppose a device contains the ability to dump the content of the full system memory by disabling the memory-protection mechanisms. Since this is a highly security-sensitive capability, this capability is \"locked\" in the production part. Unless the device gets unlocked by supplying the proper credentials, the debug capabilities are not available. For cases where the chip designer, chip manufacturer (fabricator), and manufacturing and assembly testers are all employed by the same company, the risk of compromise of the credentials is greatly reduced. However, the risk is greater when the chip designer is employed by one company, the chip manufacturer is employed by another company (a foundry), and the assemblers and testers are employed by yet a third company. Since these different companies will need to perform various tests on the device to verify correct device function, they all need to share the unlock key. Unfortunately, the level of secrecy and policy might be quite different at each company, greatly increasing the risk of sensitive credentials being compromised.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess ControlAccountabilityAuthenticationAuthorizationNon-Repudiation. Impacts: Modify MemoryRead MemoryModify Files or DirectoriesRead Files or DirectoriesModify Application DataExecute Unauthorized Code or CommandsGain Privileges or Assume IdentityBypass Protection Mechanism. Note: Once unlock credentials are compromised, an attacker can use the credentials to unlock the device and gain unauthorized access to the hidden functionalities protected by those credentials.", "Detection_Methods": "", "Potential_Mitigations": "Integration : Ensure the unlock credentials are shared with the minimum number of parties and with utmost secrecy. To limit the risk associated with compromised credentials, where possible, the credentials should be part-specific.Manufacturing : Ensure the unlock credentials are shared with the minimum number of parties and with utmost secrecy. To limit the risk associated with compromised credentials, where possible, the credentials should be part-specific.", "Demonstrative_Examples": "This example shows how an attacker can take advantage of compromised credentials.. When the credentials of multiple organizations are stored together, exposure to third parties occurs frequently.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1274", "Name": "Improper Access Control for Volatile Memory Containing Boot Code", "Description": "Test the volatile-memory protections to ensure they are safe from modification or untrusted code.", "Extended_Description": "Adversaries could bypass the secure-boot process and execute their own untrusted, malicious boot code.As a part of a secure-boot process, the read-only-memory (ROM) code for a System-on-Chip (SoC) or other system fetches bootloader code from Non-Volatile Memory (NVM) and stores the code in Volatile Memory (VM), such as dynamic, random-access memory (DRAM) or static, random-access memory (SRAM). The NVM is usually external to the SoC, while the VM is internal to the SoC. As the code is transferred from NVM to VM, it is authenticated by the SoC's ROM code.If the volatile-memory-region protections or access controls are insufficient to prevent modifications from an adversary or untrusted agent, the secure boot may be bypassed or replaced with the execution of an adversary's code.", "Modes_Of_Introduction": "Architecture and Design: This weakness can be introduced during hardware architecture or design but can be identified later during testing.", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Analysis. Description: Ensure the volatile memory is lockable or has locks. Ensure the volatile memory is locked for writes from untrusted agents or adversaries. Try modifying the volatile memory from an untrusted agent, and ensure these writes are dropped. Method Name: Manual Analysis. Description: Analyze the device using the following steps:Only trusted masters should be allowed to write to the memory regions. For example, pluggable device peripherals should not have write access to program load memory regions.", "Potential_Mitigations": "Architecture and Design : Ensure that the design of volatile-memory protections is enough to prevent modification from an adversary or untrusted code.Testing : Test the volatile-memory protections to ensure they are safe from modification or untrusted code.", "Demonstrative_Examples": "A typical SoC secure boot's flow includes fetching the next piece of code (i.e., the boot loader) from NVM (e.g., serial, peripheral interface (SPI) flash), and transferring it to DRAM/SRAM volatile, internal memory, which is more efficient.. The memory from where the boot loader executes can be modified by an adversary.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "923", "Name": "Improper Restriction of Communication Channel to Intended Endpoints", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "Attackers might be able to spoof the intended endpoint from a different system or process, thus gaining the same level of access as the intended endpoint.While this issue frequently involves authentication between network-based clients and servers, other types of communication channels and endpoints can have this weakness.", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Gain Privileges or Assume Identity. Note: If an attacker can spoof the endpoint, the attacker gains all the privileges that were intended for the original endpoint.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1275", "Name": "Sensitive Cookie with Improper SameSite Attribute", "Description": "Set the SameSite attribute of a sensitive cookie to 'Lax' or 'Strict'. This instructs the browser to apply this cookie only to same-domain requests, which provides a good Defense in Depth against CSRF attacks. When the 'Lax' value is in use, cookies are also sent for top-level cross-domain navigation via HTTP GET, HEAD, OPTIONS, and TRACE methods, but not for other HTTP methods that are more like to cause side-effects of state mutation.", "Extended_Description": "The SameSite attribute controls how cookies are sent for cross-domain requests. This attribute may have three values: 'Lax', 'Strict', or 'None'. If the 'None' value is used, a website may create a cross-domain POST HTTP request to another website, and the browser automatically adds cookies to this request. This may lead to Cross-Site-Request-Forgery (CSRF) attacks if there are no additional protections in place (such as Anti-CSRF tokens).", "Modes_Of_Introduction": "Implementation: This weakness occurs during implementation when the coder does not properly set the SameSite attribute.", "Common_Consequences": "Scopes: ConfidentialityIntegrityNon-RepudiationAccess Control. Impacts: Modify Application Data. Note: If the website does not impose additional defense against CSRF attacks, failing to use the 'Lax' or 'Strict' values could increase the risk of exposure to CSRF attacks. The likelihood of the integrity breach is Low because a successful attack does not only depend on an insecure SameSite attribute. In order to perform a CSRF attack there are many conditions that must be met, such as the lack of CSRF tokens, no confirmations for sensitive actions on the website, a \"simple\" \"Content-Type\" header in the HTTP request and many more.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Set the SameSite attribute of a sensitive cookie to 'Lax' or 'Strict'. This instructs the browser to apply this cookie only to same-domain requests, which provides a good Defense in Depth against CSRF attacks. When the 'Lax' value is in use, cookies are also sent for top-level cross-domain navigation via HTTP GET, HEAD, OPTIONS, and TRACE methods, but not for other HTTP methods that are more like to cause side-effects of state mutation.", "Demonstrative_Examples": "In this example, a cookie is used to store a session ID for a client's interaction with a website. The snippet of code below establishes a new cookie to hold the sessionID.. Since the sameSite attribute is not specified, the cookie will be sent to the website with each request made by the client. An attacker can potentially perform CSRF attack by using the following malicious page:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "352", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1276", "Name": "Hardware Child Block Incorrectly Connected to Parent System", "Description": "System-level verification may be used to ensure that components are correctly connected and that design security requirements are not violated due to interactions between various IP blocks.", "Extended_Description": "Individual hardware IP must communicate with the parent system in order for the product to function correctly and as intended. If implemented incorrectly, while not causing any apparent functional issues, may cause security issues. For example, if the IP should only be reset by a system-wide hard reset, but instead the reset input is connected to a software-triggered debug mode reset (which is also asserted during a hard reset), integrity of data inside the IP can be violated.", "Modes_Of_Introduction": "Implementation: This weakness is introduced when integrating IP into a parent design.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : System-level verification may be used to ensure that components are correctly connected and that design security requirements are not violated due to interactions between various IP blocks.", "Demonstrative_Examples": "Many SoCs use hardware to partition system resources between trusted and un-trusted entities. One example of this concept is the Arm TrustZone, in which the processor and all security-aware IP attempt to isolate resources based on the status of a privilege bit. This privilege bit is part of the input interface in all TrustZone-aware IP. If this privilege bit is accidentally grounded or left unconnected when the IP is instantiated, privilege escalation of all input data may occur.. In the Verilog code below, the security level input to the TrustZone aware peripheral is correctly driven by an appropriate signal instead of being grounded.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1329", "Name": "Reliance on Component That is Not Updateable", "Description": "Implement the necessary functionality to allow each component to be updated.", "Extended_Description": "If the component is discovered to contain a vulnerability or critical bug, but the issue cannot be fixed using an update or patch, then the product's owner will not be able to protect against the issue.  The only option might be replacement of the product, which could be too financially or operationally expensive for the product owner.  As a result, the inability to patch or update can leave the product open to attacker exploitation or critical operation failures. This weakness can be especially difficult to manage when using ROM, firmware, or similar components that traditionally have had limited or no update capabilities.In industries such as healthcare, \"legacy\"\n\t\t\t    devices can be operated for decades.  As a\n\t\t\t    US task force report [REF-1197] notes, \"the inability\n\t\t\t    to update or replace equipment has both\n\t\t\t    large and small health care delivery\n\t\t\t    organizations struggle with numerous\n\t\t\t    unsupported legacy systems that cannot\n\t\t\t    easily be replaced (hardware, software, and\n\t\t\t    operating systems) with large numbers of\n\t\t\t    vulnerabilities and few modern\n\t\t\t    countermeasures.\"While hardware can be prone to this weakness, software systems can also be affected, such as when a third-party driver or library is no longer actively maintained or supported but is still critical for the required functionality.", "Modes_Of_Introduction": "Requirements: Requirements development might not consider the importance of updates over the lifetime of the product or might intentionally exclude this capability due to concerns such as expense or speed to market.Architecture and Design: Lack of planning during architecture development and design, or external pressures such as speed to market, could ignore the capability to update.Architecture and Design: Designers might omit capabilities for updating a component due to time pressures to release the product or assumptions about the stability of the component.Implementation: The weakness can appear through oversight during implementation.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAccess ControlAuthenticationAuthorizationOther. Impacts: Gain Privileges or Assume IdentityBypass Protection MechanismExecute Unauthorized Code or CommandsDoS: Crash, Exit, or RestartQuality DegradationReduce Maintainability. Note: If an attacker can identify an exploitable vulnerability in one product that has no means of patching, the attack may be used against all affected versions of that product.", "Detection_Methods": "Method Name: Architecture or Design Review. Description: Check the consumer or maintainer documentation, the architecture/design documentation, or the original requirements to ensure that the documentation includes details for how to update the firmware.", "Potential_Mitigations": "Requirements : Specify requirements that each component should be updateable, including ROM, firmware, etc.Architecture and Design : Design the product to allow for updating of its components. Include the external infrastructure that might be necessary to support updates, such as distribution servers.Architecture and Design : With hardware, support patches that can be programmed in-field or during manufacturing through hardware fuses. This feature can be used for limited patching of devices after shipping, or for the next batch of silicon devices manufactured, without changing the full device ROM.Implementation : Implement the necessary functionality to allow each component to be updated.", "Demonstrative_Examples": ". A refrigerator has an Internet interface for the official purpose of alerting the manufacturer when that refrigerator detects a fault. Because the device is attached to the Internet, the refrigerator is a target for hackers who may wish to use the device other potentially more nefarious purposes.A System-on-Chip (SOC) implements a Root-of-Trust (RoT) in ROM to boot secure code. However, at times this ROM code might have security vulnerabilities and need to be patched. Since ROM is immutable, it can be impossible to patch.. ROM does not have built-in application-programming interfaces (APIs) to patch if the code is vulnerable. Implement mechanisms to patch the vulnerable ROM code.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1357", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1277", "Name": "Firmware Not Updateable", "Description": "Implement the necessary functionality to allow the firmware to be updated.", "Extended_Description": "Without the ability to\n\t\t\tpatch or update firmware, consumers will be\n\t\t\tleft vulnerable to exploitation of any known\n\t\t\tvulnerabilities, or any vulnerabilities that\n\t\t\tare discovered in the future. This can expose\n\t\t\tconsumers to permanent risk throughout the\n\t\t\tentire lifetime of the device, which could be\n\t\t\tyears or decades. Some external protective\n\t\t\tmeasures and mitigations might be employed to\n\t\t\taid in preventing or reducing the risk of\n\t\t\tmalicious attack, but the root weakness cannot\n\t\t\tbe corrected.", "Modes_Of_Introduction": "Requirements: Requirements development might not consider the importance of updates over the lifetime of the product, or might not choose the ability due to concerns such as expense or speed to market.Architecture and Design: Lack of planning during architecture development and design, or external pressures such as speed to market, could ignore the capability to update.Implementation: The weakness can appear through oversight during implementation.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAccess ControlAuthenticationAuthorization. Impacts: Gain Privileges or Assume IdentityBypass Protection MechanismExecute Unauthorized Code or CommandsDoS: Crash, Exit, or Restart. Note: If an attacker can identify an exploitable vulnerability in one device that has no means of patching, the attack may be used against an entire class of devices.", "Detection_Methods": "Method Name: Manual Analysis. Description: Create a new installable boot image of the current build with a minor version number change. Use the standard installation method to update the boot image. Verify that the minor version number has changed. Create a fake image. Verify that the boot updater will not install the fake image and generates an \"invalid image\" error message or equivalent. Method Name: Architecture or Design Review. Description: Check the consumer or maintainer documentation, the architecture/design documentation, or the original requirements to ensure that the documentation includes details for how to update the firmware. Method Name: Manual Dynamic Analysis. Description: Determine if there is a lack of a capability to update read-only memory (ROM) structure. This could manifest as a difference between the latest firmware version and the current version within the device.", "Potential_Mitigations": "Requirements : Specify requirements to include the ability to update the firmware. Include integrity checks and authentication to ensure that untrusted firmware cannot be installed.Architecture and Design : Design the device to allow for updating the firmware. Ensure that the design specifies how to distribute the updates and ensure their integrity and authentication.Implementation : Implement the necessary functionality to allow the firmware to be updated.", "Demonstrative_Examples": ". A refrigerator has an Internet interface for the official purpose of alerting the manufacturer when that refrigerator detects a fault. Because the device is attached to the Internet, the refrigerator is a target for hackers who may wish to use the device other potentially more nefarious purposes.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1329", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1278", "Name": "Missing Protection Against Hardware Reverse Engineering Using Integrated Circuit (IC) Imaging Techniques", "Description": "The cost of secret extraction via IC reverse engineering should outweigh the potential value of the secrets being extracted. Threat model and value of secrets should be used to choose the technology used to safeguard those secrets. Examples include IC camouflaging and obfuscation, tamper-proof packaging, active shielding, and physical tampering detection information erasure.", "Extended_Description": "The physical structure of a device, viewed at high enough magnification, can reveal the information stored inside. Typical steps in IC reverse engineering involve removing the chip packaging (decapsulation) then using various imaging techniques ranging from high resolution x-ray microscopy to invasive techniques involving removing IC layers and imaging each layer using a scanning electron microscope.The goal of such activities is to recover secret keys, unique device identifiers, and proprietary code and circuit designs embedded in hardware that the attacker has been unsuccessful at accessing through other means. These secrets may be stored in non-volatile memory or in the circuit netlist. Memory technologies such as masked ROM allow easier to extraction of secrets than One-time Programmable (OTP) memory.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Varies by Context. Note: A common goal of malicious actors who reverse engineer ICs is to produce and sell counterfeit versions of the IC.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : The cost of secret extraction via IC reverse engineering should outweigh the potential value of the secrets being extracted. Threat model and value of secrets should be used to choose the technology used to safeguard those secrets. Examples include IC camouflaging and obfuscation, tamper-proof packaging, active shielding, and physical tampering detection information erasure.", "Demonstrative_Examples": ". Consider an SoC design that embeds a secret key in read-only memory (ROM). The key is baked into the design logic and may not be modified after fabrication causing the key to be identical for all devices.  An attacker in possession of the IC can decapsulate and delayer the device. After imaging the layers, computer vision algorithms or manual inspection of the circuit features locate the ROM and reveal the value of the key bits as encoded in the visible circuit structure of the ROM.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1279", "Name": "Cryptographic Operations are run Before Supporting Units are Ready", "Description": "Continuously ensuring that cryptographic inputs are supplying valid information is necessary to ensure that the encrypted output is secure.", "Extended_Description": "Many cryptographic hardware units depend upon other hardware units to supply information to them to produce a securely encrypted result. For example, a cryptographic unit that depends on an external random-number-generator (RNG) unit for entropy must wait until the RNG unit is producing random numbers. If a cryptographic unit retrieves a private encryption key from a fuse unit, the fuse unit must be up and running before a key may be supplied.", "Modes_Of_Introduction": "Implementation: The decision to continue using a cryptographic unit even though the input units to it are not producing valid data will compromise the encrypted result.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Best practices should be used to design cryptographic systems.Implementation : Continuously ensuring that cryptographic inputs are supplying valid information is necessary to ensure that the encrypted output is secure.", "Demonstrative_Examples": "The following pseudocode illustrates the weak encryption resulting from the use of a pseudo-random-number generator output.. In the example above, first a check of RNG ready is performed. If the check fails, the RNG is ignored and a hard coded value is used instead. The hard coded value severely weakens the encrypted output.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "682", "Name": "Incorrect Calculation", "Description": "Use dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.", "Extended_Description": "When product performs a security-critical calculation incorrectly, it might lead to incorrect resource allocations, incorrect privilege assignments, or failed comparisons among other things. Many of the direct results of an incorrect calculation can lead to even larger problems such as failed protection mechanisms or even arbitrary code execution.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: If the incorrect calculation causes the program to move into an unexpected state, it may lead to a crash or impairment of service.Scopes: IntegrityConfidentialityAvailability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (Other)Execute Unauthorized Code or Commands. Note: If the incorrect calculation is used in the context of resource allocation, it could lead to an out-of-bounds operation (CWE-119) leading to a crash or even arbitrary code execution. Alternatively, it may result in an integer overflow (CWE-190) and / or a resource consumption problem (CWE-400).Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: In the context of privilege or permissions assignment, an incorrect calculation can provide an attacker with access to sensitive resources.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If the incorrect calculation leads to an insufficient comparison (CWE-697), it may compromise a protection mechanism such as a validation routine and allow an attacker to bypass the security-critical code.", "Detection_Methods": "Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual static analysis is useful for evaluating the correctness of allocation calculations. This can be useful for detecting overflow conditions (CWE-190) or similar weaknesses that might have serious security impacts on the program.", "Potential_Mitigations": "Implementation : Understand your programming language's underlying representation and how it interacts with numeric calculation. Pay close attention to byte size discrepancies, precision, signed/unsigned distinctions, truncation, conversion and casting between types, \"not-a-number\" calculations, and how your language handles numbers that are too large or too small for its underlying representation.Implementation : Perform input validation on any numeric input by ensuring that it is within the expected range. Enforce that the input meets both the minimum and maximum requirements for the expected range.Implementation : Use the appropriate type for the desired action. For example, in C/C++, only use unsigned types for values that could never be negative, such as height, width, or other numbers related to quantity.Architecture and Design : Use languages, libraries, or frameworks that make it easier to handle numbers without unexpected consequences.\n                  Examples include safe integer handling packages such as SafeInt (C++) or IntegerLib (C or C++).Architecture and Design : Use languages, libraries, or frameworks that make it easier to handle numbers without unexpected consequences.\n                  Examples include safe integer handling packages such as SafeInt (C++) or IntegerLib (C or C++).Implementation : Examine compiler warnings closely and eliminate problems with potential security implications, such as signed / unsigned mismatch in memory operations, or use of uninitialized variables. Even if the weakness is rarely exploitable, a single failure may lead to the compromise of the entire system.Testing : Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.Testing : Use dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.", "Demonstrative_Examples": "The following image processing code allocates a table for images.. This code intends to allocate a table of size num_imgs, however as num_imgs grows large, the calculation determining the size of the list will eventually overflow (CWE-190). This will result in a very small list to be allocated instead. If the subsequent code operates on the list as if it were num_imgs long, it may result in many types of out-of-bounds problems (CWE-119).This code attempts to calculate a football team's average number of yards gained per touchdown.. The code does not consider the event that the team they are querying has not scored a touchdown, but has gained yardage. In that case, we should expect an ArithmeticException to be thrown by the JVM. This could lead to a loss of availability if our error handling code is not set up correctly.This example attempts to calculate the position of the second byte of a pointer.. In this example, second_char is intended to point to the second byte of p. But, adding 1 to p actually adds sizeof(int) to p, giving a result that is incorrect (3 bytes off on 32-bit platforms). If the resulting memory address is read, this could potentially be an information leak. If it is a write, it could be a security-critical write to unauthorized memory-- whether or not it is a buffer overflow. Note that the above code may also be wrong in other ways, particularly in a little endian environment.", "Related_Weaknesses": [{"Nature": "CanPrecede", "CWE_ID": "170", "View_ID": "1000", "Ordinal": null}]}, {"ID": "128", "Name": "Wrap-around Error", "Description": "Perform validation on all incremented variables to ensure that they remain within reasonable bounds.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Instability. Note: This weakness will generally lead to undefined behavior and therefore crashes. In the case of overflows involving loop index variables, the likelihood of infinite loops is also high.Scopes: Integrity. Impacts: Modify Memory. Note: If the value in question is important to data (as opposed to flow), simple data corruption has occurred. Also, if the wrap around results in other conditions such as buffer overflows, further memory corruption may occur.Scopes: ConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsBypass Protection Mechanism. Note: This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.", "Detection_Methods": "", "Potential_Mitigations": "N/A : Requirements specification: The choice could be made to use a language that is not susceptible to these issues.Architecture and Design : Provide clear upper and lower bounds on the scale of any protocols designed.Implementation : Perform validation on all incremented variables to ensure that they remain within reasonable bounds.", "Demonstrative_Examples": "The following image processing code allocates a table for images.. This code intends to allocate a table of size num_imgs, however as num_imgs grows large, the calculation determining the size of the list will eventually overflow (CWE-190). This will result in a very small list to be allocated instead. If the subsequent code operates on the list as if it were num_imgs long, it may result in many types of out-of-bounds problems (CWE-119).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "190", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1280", "Name": "Access Control Check Implemented After Asset is Accessed", "Description": "Implement the access control check first. Access should only be given to asset if agent is authorized.", "Extended_Description": "The product implements a hardware-based access control check. The asset should be accessible only after the check is successful. If, however, this operation is not atomic and the asset is accessed before the check is complete, the security of the system may be compromised.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Implement the access control check first. Access should only be given to asset if agent is authorized.", "Demonstrative_Examples": "Assume that the module foo_bar implements a protected register. The register content is the asset. Only transactions made by user id (indicated by signal usr_id) 0x4 are allowed to modify the register contents. The signal grant_access is used to provide access.. This code uses Verilog blocking assignments for data_out and grant_access. Therefore, these assignments happen sequentially (i.e., data_out is updated to new value first, and grant_access is updated the next cycle) and not in parallel. Therefore, the asset data_out is allowed to be modified even before the access control check is complete and grant_access signal is set. Since grant_access does not have a reset value, it will be meta-stable and will randomly go to either 0 or 1.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "696", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1281", "Name": "Sequence of Processor Instructions Leads to Unexpected Behavior", "Description": "Patch operating system to avoid running Halt and Catch Fire type sequences or to mitigate the damage caused by unexpected behavior.  See [REF-1108].", "Extended_Description": "If the instruction set architecture (ISA) and processor logic are not designed carefully and tested thoroughly, certain combinations of instructions may lead to locking the processor or other unexpected and undesirable behavior.  Upon encountering unimplemented instruction opcodes or illegal instruction operands, the processor should throw an exception and carry on without negatively impacting security.  However, specific combinations of legal and illegal instructions may cause unexpected behavior with security implications such as allowing unprivileged programs to completely lock the CPU.", "Modes_Of_Introduction": "Architecture and Design: Unexpected behavior from certain instruction combinations can arise from bugs in the ISAImplementation: Unexpected behavior from certain instruction combinations can arise because of implementation details such as speculative execution, caching etc.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Implement a rigorous testing strategy that incorporates randomization to explore instruction sequences that are unlikely to appear in normal workloads in order to identify halt and catch fire instruction sequences.Patching and Maintenance : Patch operating system to avoid running Halt and Catch Fire type sequences or to mitigate the damage caused by unexpected behavior.  See [REF-1108].", "Demonstrative_Examples": ". The Pentium F00F bug is a real-world example of how a sequence of instructions can lock a processor. The \"cmpxchg8b\" instruction compares contents of registers with a memory location.  The operand is expected to be a memory location, but in the bad code snippet it is the eax register. Because the specified operand is illegal, an exception is generated, which is the correct behavior and not a security issue in itself. However, when prefixed with the \"lock\" instruction, the processor deadlocks because locked memory transactions require a read and write pair of transactions to occur before the lock on the memory bus is released. The exception causes a read to occur but there is no corresponding write, as there would have been if a legal operand had been supplied to the cmpxchg8b instruction. [REF-1331]. The Cyrix Coma bug was capable of trapping a Cyrix 6x86, 6x86L, or 6x86MX processor in an infinite loop. An infinite loop on a processor is not necessarily an issue on its own, as interrupts could stop the loop. However, on select Cyrix processors, the x86 Assembly 'xchg' instruction was designed to prevent interrupts. On these processors, if the loop was such that a new 'xchg' instruction entered the instruction pipeline before the previous one exited, the processor would become deadlocked. [REF-1323]. The Motorola MC6800 microprocessor contained the first documented instance of a Halt and Catch Fire instruction - an instruction that causes the normal function of a processor to stop. If the MC6800 was given the opcode 0x9D or 0xDD, the processor would begin to read all memory very quickly, in sequence, and without executing any other instructions. This will cause the processor to become unresponsive to anything but a hard reset. [REF-1324]The example code is taken from the commit stage inside the processor core of the HACK@DAC'19 buggy CVA6 SoC [REF-1342]. To ensure the correct execution of atomic instructions, the CPU must guarantee atomicity: no other device overwrites the memory location between the atomic read starts and the atomic write finishes. Another device may overwrite the memory location only before the read operation or after the write operation, but never between them, and finally, the content will still be consistent.. Atomicity is especially critical when the variable to be modified is a mutex, counting semaphore, or similar piece of data that controls access to shared resources. Failure to ensure atomicity may result in two processors accessing a shared resource simultaneously, permanent lock-up, or similar disastrous behavior", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1282", "Name": "Assumed-Immutable Data is Stored in Writable Memory", "Description": "All immutable code or data should be programmed into ROM or write-once memory.", "Extended_Description": "Security services such as secure boot, authentication of code and data, and device attestation all require assets such as the first stage bootloader, public keys, golden hash digests, etc. which are implicitly trusted. Storing these assets in read-only memory (ROM), fuses, or one-time programmable (OTP) memory provides strong integrity guarantees and provides a root of trust for securing the rest of the system. Security is lost if assets assumed to be immutable can be modified.", "Modes_Of_Introduction": "Implementation: Keys, code, configuration settings, and other data should be programmed in write-once or read-only memory instead of writable memory.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : All immutable code or data should be programmed into ROM or write-once memory.", "Demonstrative_Examples": ". Cryptographic hash functions are commonly used to create unique fixed-length digests used to ensure the integrity of code and keys. A golden digest is stored on the device and compared to the digest computed from the data to be verified. If the digests match, the data has not been maliciously modified. If an attacker can modify the golden digest they then have the ability to store arbitrary data that passes the verification check. Hash digests used to verify public keys and early stage boot code should be immutable, with the strongest protection offered by hardware immutability.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "471", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1283", "Name": "Mutable Attestation or Measurement Reporting Data", "Description": "Measurement data should be stored in registers that are read-only or otherwise have access controls that prevent modification by an untrusted agent.", "Extended_Description": "A System-on-Chip (SoC) implements secure boot or verified boot. During this boot flow, the SoC often measures the code that it authenticates. The measurement is usually done by calculating the one-way hash of the code binary and extending it to the previous hash. The hashing algorithm should be a Secure One-Way hash function. The final hash, i.e., the value obtained after the completion of the boot flow, serves as the measurement data used in reporting or in attestation. The calculated hash is often stored in registers that can later be read by the party of interest to determine tampering of the boot flow. A common weakness is that the contents in these registers are modifiable by an adversary, thus spoofing the measurement.", "Modes_Of_Introduction": "Architecture and Design: Such issues can be introduced during hardware architecture or design and can be identified later during Testing or System Configuration phases.Implementation: If the access-controls which protecting the reporting registers are misconfigured during implementation, this weakness can arise.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Measurement data should be stored in registers that are read-only or otherwise have access controls that prevent modification by an untrusted agent.", "Demonstrative_Examples": "The SoC extends the hash and stores the results in registers. Without protection, an adversary can write their chosen hash values to these registers. Thus, the attacker controls the reported results.. To prevent the above scenario, the registers should have one or more of the following properties:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1284", "Name": "Improper Validation of Specified Quantity in Input", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "Specified quantities include size, length, frequency, price, rate, number of operations, time, and others. Code may rely on specified quantities to allocate resources, perform calculations, control iteration, etc. When the quantity is not properly validated, then attackers can specify malicious quantities to cause excessive resource allocation, trigger unexpected failures, enable buffer overflows, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Varies by Context. Note: Since quantities are used so often to affect resource allocation or process financial data, they are often present in many places in the code.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": "This example demonstrates a shopping interaction in which the user is free to specify the quantity of items to be purchased and a total is calculated.. The user has no control over the price variable, however the code does not prevent a negative value from being specified for quantity. If an attacker were to provide a negative value, then the user would have their account credited instead of debited.This example asks the user for a height and width of an m X n game board with a maximum dimension of 100 squares.. While this code checks to make sure the user cannot specify large, positive integers and consume too much memory, it does not check for negative values supplied by the user. As a result, an attacker can perform a resource consumption (CWE-400) attack against this program by specifying two, large negative values that will not overflow, resulting in a very large memory allocation (CWE-789) and possibly a system crash. Alternatively, an attacker can provide very large negative values which will cause an integer overflow (CWE-190) and unexpected behavior will follow depending on how the values are treated in the remainder of the program.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "789", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1285", "Name": "Improper Validation of Specified Index, Position, or Offset in Input", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "Often, indexable resources such as memory buffers or files can be accessed using a specific position, index, or offset, such as an index for an array or a position for a file.  When untrusted input is not properly validated before it is used as an index, attackers could access (or attempt to access) unauthorized portions of these resources.  This could be used to cause buffer overflows, excessive resource allocation, or trigger unexpected failures.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": "The following example retrieves the sizes of messages for a pop3 mail server. The message sizes are retrieved from a socket that returns in a buffer the message number and the message size, the message number (num) and size (size) are extracted from the buffer and the message size is placed into an array using the message number for the array index.. In this example the message number retrieved from the buffer could be a value that is outside the allowable range of indices for the array and could possibly be a negative number. Without proper validation of the value to be used for the array index an array overflow could occur and could potentially lead to unauthorized access to memory addresses and system crashes. The value of the array index should be validated to ensure that it is within the allowable range of indices for the array as in the following code.In the following example the method displayProductSummary is called from a Web service servlet to retrieve product summary information for display to the user. The servlet obtains the integer value of the product number from the user and passes it to the displayProductSummary method. The displayProductSummary method passes the integer value of the product number to the getProductSummary method which obtains the product summary from the array object containing the project summaries using the integer value of the product number as the array index.. In this example the integer value used as the array index that is provided by the user may be outside the allowable range of indices for the array which may provide unexpected results or cause the application to fail. The integer value used for the array index should be validated to ensure that it is within the allowable range of indices for the array as in the following code.The following example asks a user for an offset into an array to select an item.. The programmer allows the user to specify which element in the list to select, however an attacker can provide an out-of-bounds offset, resulting in a buffer over-read (CWE-126).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1287", "Name": "Improper Validation of Specified Type of Input", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "When input does not comply with the expected type, attackers could trigger unexpected errors, cause incorrect actions to take place, or exploit latent vulnerabilities that would not be possible if the input conformed with the expected type.This weakness can appear in type-unsafe programming languages, or in programming languages that support casting or conversion of an input to another type.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "843", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1288", "Name": "Improper Validation of Consistency within Input", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "Some input data can be structured with multiple elements or fields that must be consistent with each other, e.g. a number-of-items field that is followed by the expected number of elements.  When such complex inputs are inconsistent, attackers could trigger unexpected errors, cause incorrect actions to take place, or exploit latent vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1289", "Name": "Improper Validation of Unsafe Equivalence in Input", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "Attackers can sometimes bypass input validation schemes by finding inputs that appear to be safe, but will be dangerous when processed at a lower layer or by a downstream component.  For example, a simple XSS protection mechanism might try to validate that an input has no \"<script>\" tags using case-sensitive matching, but since HTML is case-insensitive when processed by web browsers, an attacker could inject \"<ScrIpT>\" and trigger XSS.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "178", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "129", "Name": "Improper Validation of Array Index", "Description": "Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityAvailability. Impacts: DoS: Crash, Exit, or Restart. Note: Use of an index that is outside the bounds of an array will very likely result in the corruption of relevant memory and perhaps instructions, leading to a crash, if the values are outside of the valid memory area.Scopes: Integrity. Impacts: Modify Memory. Note: If the memory corrupted is data, rather than instructions, the system will continue to function with improper values.Scopes: ConfidentialityIntegrity. Impacts: Modify MemoryRead Memory. Note: Use of an index that is outside the bounds of an array can also trigger out-of-bounds read or write operations, or operations on the wrong objects; i.e., \"buffer overflows\" are not always the result. This may result in the exposure or modification of sensitive data.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: If the memory accessible by the attacker can be effectively controlled, it may be possible to execute arbitrary code, as with a standard buffer overflow and possibly without the use of large inputs if a precise index can be controlled.Scopes: IntegrityAvailabilityConfidentiality. Impacts: DoS: Crash, Exit, or RestartExecute Unauthorized Code or CommandsRead MemoryModify Memory. Note: A single fault could allow either an overflow (CWE-788) or underflow (CWE-786) of the array index. What happens next will depend on the type of operation being performed out of bounds, but can expose sensitive information, cause a system crash, or possibly lead to arbitrary code execution.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.Automated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report array index errors that originate from command line arguments in a program that is not expected to run with setuid or other special privileges. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Black Box. Description: Black box methods might not get the needed code coverage within limited time constraints, and a dynamic test might not produce any noticeable side effects even if it is successful.", "Potential_Mitigations": "Architecture and Design : Use an input validation framework such as Struts or the OWASP ESAPI Validation API. Note that using a framework does not automatically address all input validation problems; be mindful of weaknesses that could arise from misusing the framework itself (CWE-1173).Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n                  Even though client-side checks provide minimal benefits with respect to server-side security, they are still useful. First, they can support intrusion detection. If the server receives input that should have been rejected by the client, then it may be an indication of an attack. Second, client-side error-checking can provide helpful feedback to the user about the expectations for valid input. Third, there may be a reduction in server-side processing time for accidental input errors, although this is typically a small savings.Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, Ada allows the programmer to constrain the values of a variable and languages such as Java and Ruby will allow the programmer to handle exceptions when an out-of-bounds index is accessed.Operation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t        For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].Operation : Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment.   \n\t          For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336].Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When accessing a user-controlled array index, use a stringent range of values that are within the target array. Make sure that you do not allow negative values to be used. That is, verify the minimum as well as the maximum of the range of acceptable values.Implementation : Be especially careful to validate all input when invoking code that crosses language boundaries, such as from an interpreted language to native code. This could create an unexpected interaction between the language boundaries. Ensure that you are not violating any of the expectations of the language with which you are interfacing. For example, even though Java may not be susceptible to buffer overflows, providing a large argument in a call to native code might trigger an overflow.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Demonstrative_Examples": "In the code snippet below, an untrusted integer value is used to reference an object in an array.. If index is outside of the range of the array, this may result in an ArrayIndexOutOfBounds Exception being raised.The following example takes a user-supplied value to allocate an array of objects and then operates on the array.. This example attempts to build a list from a user-specified value, and even checks to ensure a non-negative value is supplied. If, however, a 0 value is provided, the code will build an array of size 0 and then try to store a new Widget in the first location, causing an exception to be thrown.In the following code, the method retrieves a value from an array at a specific array index location that is given as an input parameter to the method. However, this method only verifies that the given array index is less than the maximum length of the array but does not check for the minimum value (CWE-839). This will allow a negative value to be accepted as the input array index, which will result in a out of bounds read (CWE-125) and may allow access to sensitive memory. The input array index should be checked to verify that is within the maximum and minimum range required for the array (CWE-129). In this example the if statement should be modified to include a minimum range check, as shown below.The following example retrieves the sizes of messages for a pop3 mail server. The message sizes are retrieved from a socket that returns in a buffer the message number and the message size, the message number (num) and size (size) are extracted from the buffer and the message size is placed into an array using the message number for the array index.. In this example the message number retrieved from the buffer could be a value that is outside the allowable range of indices for the array and could possibly be a negative number. Without proper validation of the value to be used for the array index an array overflow could occur and could potentially lead to unauthorized access to memory addresses and system crashes. The value of the array index should be validated to ensure that it is within the allowable range of indices for the array as in the following code.In the following example the method displayProductSummary is called from a Web service servlet to retrieve product summary information for display to the user. The servlet obtains the integer value of the product number from the user and passes it to the displayProductSummary method. The displayProductSummary method passes the integer value of the product number to the getProductSummary method which obtains the product summary from the array object containing the project summaries using the integer value of the product number as the array index.. In this example the integer value used as the array index that is provided by the user may be outside the allowable range of indices for the array which may provide unexpected results or cause the application to fail. The integer value used for the array index should be validated to ensure that it is within the allowable range of indices for the array as in the following code.The following example asks a user for an offset into an array to select an item.. The programmer allows the user to specify which element in the list to select, however an attacker can provide an out-of-bounds offset, resulting in a buffer over-read (CWE-126).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1285", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "823", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "789", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1290", "Name": "Incorrect Decoding of Security Identifiers ", "Description": "Access and programming flows must be tested in pre-silicon and post-silicon testing in order to check for this weakness.", "Extended_Description": "In a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity). Sometimes the transactions are qualified with a security identifier. The security identifier helps the destination agent decide on the set of allowed actions (e.g., access an asset for read and writes). A decoder decodes the bus transactions to map security identifiers into necessary access-controls/protections.A common weakness that can exist in this scenario is incorrect decoding because an untrusted agent's security identifier is decoded into a trusted agent's security identifier. Thus, an untrusted agent previously without access to an asset can now gain access to the asset.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Security identifier decoders must be reviewed for design consistency and common weaknesses.Implementation : Access and programming flows must be tested in pre-silicon and post-silicon testing in order to check for this weakness.", "Demonstrative_Examples": "Consider a system that has four bus masters and a decoder. The decoder is supposed to decode every bus transaction and assign a corresponding security identifier. The security identifier is used to determine accesses to the assets. The bus transaction that contains the security information is Bus_transaction [15:14], and the bits 15 through 14 contain the security identifier information. The table below provides bus masters as well as their security identifiers and trust assumptions:The assets are the AES-Key registers for encryption or decryption. The key is 128 bits implemented as a set of four 32-bit registers. The AES_KEY_ACCESS_POLICY is used to define which agents with a security identifier in the transaction can access the AES-key registers. The size of the security identifier is 4 bits (i.e., bit 3 through 0). Each bit in these 4 bits defines a security identifier. There are only 4 security identifiers that are allowed accesses to the AES-key registers. The number of the bit when set (i.e., \"1\") allows respective action from an agent whose identity matches the number of the bit. If clear (i.e., \"0\"), disallows the respective action to that corresponding agent.. The following Pseudo code outlines the process of checking the value of the Security Identifier within the AES_KEY_ACCESS_POLICY register:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1294", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "1291", "Name": "Public Key Re-Use for Signing both Debug and Production Code", "Description": "Use different keys for Production and Debug", "Extended_Description": "A common usage of public-key cryptography is to verify the integrity and authenticity of another entity (for example a firmware binary). If a company wants to ensure that its firmware runs only on its own hardware, before the firmware runs, an encrypted hash of the firmware image will be decrypted with the public key and then verified against the now-computed hash of the firmware image. This means that the public key forms the root of trust, which necessitates that the public key itself must be protected and used properly.During the development phase, debug firmware enables many hardware debug hooks, debug modes, and debug messages for testing. Those debug facilities provide significant, additional views about the firmware's capability and, in some cases, additional capability into the chip or SoC. If compromised, these capabilities could be exploited by an attacker to take full control of the system.Once the product exits the manufacturing stage and enters production, it is good practice to use a different public key. Debug firmware images are known to leak. With the debug key being reused as the production key, the debug image will also work on the production image. Thus, it will open all the internal, debug capabilities to the attacker.If a different public key is used for the production image, even if the attacker gains access to the debug firmware image, they will not be able to run it on a production machine. Thus, damage will be limited to the intellectual property leakage resulting from the debug image.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Architecture or Design Review. Description: Compare the debug key with the production key to make sure that they are not the same. Method Name: Dynamic Analysis with Manual Results Interpretation. Description: Compare the debug key with the production key to make sure that they are not the same.", "Potential_Mitigations": "Implementation : Use different keys for Production and Debug", "Demonstrative_Examples": ". This example illustrates the danger of using the same public key for debug and production.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "321", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1292", "Name": "Incorrect Conversion of Security Identifiers", "Description": "Access and programming flows must be tested in pre-silicon and post-silicon testing.", "Extended_Description": "In a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity). Sometimes the transactions are qualified with a security identifier. This security identifier helps the destination agent decide on the set of allowed actions (e.g., access an asset for read and writes).A typical bus connects several leader and follower agents. Some follower agents implement bus protocols differently from leader agents. A protocol conversion happens at a bridge to seamlessly connect different protocols on the bus. One example is a system that implements a leader with the Advanced High-performance Bus (AHB) protocol and a follower with the Open-Core Protocol (OCP). A bridge AHB-to-OCP is needed to translate the transaction from one form to the other.A common weakness that can exist in this scenario is that this conversion between protocols is implemented incorrectly, whereupon an untrusted agent may gain unauthorized access to an asset.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design, then identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during hardware implementation, then identified later during Testing or System Configuration phases.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Security identifier decoders must be reviewed for design inconsistency and common weaknesses.Implementation : Access and programming flows must be tested in pre-silicon and post-silicon testing.", "Demonstrative_Examples": "Consider a system that supports AHB. Let us assume we have a follower agent that only understands OCP. To connect this follower to the leader, a bridge is introduced, i.e., AHB to OCP.The follower has assets to protect accesses from untrusted leaders, and it employs access controls based on policy, (e.g., AES-Key registers for encryption or decryption). The key is 128 bits implemented as a set of four 32-bit registers. The key registers are assets, and register AES_KEY_ACCESS_POLICY is defined to provide the necessary access controls.The AES_KEY_ACCESS_POLICY access-policy register defines which agents with a security identifier in the transaction can access the AES-key registers. The implemented AES_KEY_ACCESS_POLICY has 4 bits where each bit when \"Set\" allows access to the AES-Key registers to the corresponding agent that has the security identifier. The other bits from 31 through 4 are reserved and not used.During conversion of the AHB-to-OCP transaction, the security identifier information must be preserved and passed on to the follower correctly.. Because of the incorrect conversion, the security identifier information is either lost or could be modified in such a way that an untrusted leader can access the AES-Key registers.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1294", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "345", "Name": "Insufficient Verification of Data Authenticity", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors did not sign firmware images.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1293", "Name": "Missing Source Correlation of Multiple Independent Data", "Description": "Failure to use a Practical Byzantine fault method when requesting data. Lack of place to report potentially compromised information sources. Relying on non-independent information sources for integrity checking. Failure to report information sources that respond in the minority to incident response procedures.", "Extended_Description": "To operate successfully, a product sometimes has to implicitly trust the integrity of an information source. When information is implicitly signed, one can ensure that the data was not tampered in transit. This does not ensure that the information source was not compromised when responding to a request. By requesting information from multiple sources, one can check if all of the data is the same. If they are not, the system should report the information sources that respond with a different or minority value as potentially compromised. If there are not enough answers to provide a majority or plurality of responses, the system should report all of the sources as potentially compromised. As the seriousness of the impact of incorrect integrity increases, so should the number of independent information sources that would need to be queried.", "Modes_Of_Introduction": "Architecture and Design: This flaw could be introduced during the design of the application or misconfiguration at run time by only specifying a single point of validation.Implementation: Such issues could be introduced during hardware implementation, then identified later during Testing or System Configuration phases.Operation: This weakness could be introduced by intentionally failing all but one of the devices used to retrieve the data or by failing the devices that validate the data.", "Common_Consequences": "Scopes: ConfidentialityIntegrity. Impacts: Read Application DataModify Application DataGain Privileges or Assume Identity. Note: An attacker that may be able to execute a single Person-in-the-Middle attack can subvert a check of an external oracle (e.g. the ACME protocol check for a file on a website), and thus inject an arbitrary reply to the single perspective request to the external oracle.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Design system to use a Practical Byzantine fault method, to request information from multiple sources to verify the data and report on potentially compromised information sources.Implementation : Failure to use a Practical Byzantine fault method when requesting data. Lack of place to report potentially compromised information sources. Relying on non-independent information sources for integrity checking. Failure to report information sources that respond in the minority to incident response procedures.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "654", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1295", "Name": "Debug Messages Revealing Unnecessary Information", "Description": "Ensure that a debug message does not reveal any unnecessary information during the debug process for the intended response.", "Extended_Description": "Debug messages are messages that help troubleshoot an issue by revealing the internal state of the system. For example, debug data in design can be exposed through internal memory array dumps or boot logs through interfaces like UART via TAP commands, scan chain, etc. Thus, the more information contained in a debug message, the easier it is to debug. However, there is also the risk of revealing information that could help an attacker either decipher a vulnerability, and/or gain a better understanding of the system. Thus, this extra information could lower the \"security by obscurity\" factor. While \"security by obscurity\" alone is insufficient, it can help as a part of \"Defense-in-depth\".", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Ensure that a debug message does not reveal any unnecessary information during the debug process for the intended response.", "Demonstrative_Examples": "This example here shows how an attacker can take advantage of unnecessary information in debug messages.. Example 1: Suppose in response to a Test Access Port (TAP) chaining request the debug message also reveals the current TAP hierarchy (the full topology) in addition to the success/failure message.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "209", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1296", "Name": "Incorrect Chaining or Granularity of Debug Components", "Description": "Ensure that debug components are properly chained and their granularity is maintained at different authentication levels.", "Extended_Description": "For debugging and troubleshooting a chip, several hardware design elements are often implemented, including:Logic errors during design or synthesis could misconfigure the interconnection of the debug components, which could allow unintended access permissions.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAccess ControlAuthenticationAuthorizationAvailabilityAccountability. Impacts: Gain Privileges or Assume IdentityBypass Protection MechanismExecute Unauthorized Code or CommandsModify MemoryModify Files or Directories. Note: Depending on the access to debug component(s) erroneously granted, an attacker could use the debug component to gain additional understanding about the system to further an attack and/or execute other commands. This could compromise any security property, including the ones listed above.", "Detection_Methods": "Method Name: Architecture or Design Review. Description: Appropriate Post-Si tests should be carried out at various authorization levels to ensure that debug components are properly chained and accessible only to users with appropriate credentials. Method Name: Dynamic Analysis with Manual Results Interpretation. Description: Appropriate Post-Si tests should be carried out at various authorization levels to ensure that debug components are properly chained and accessible only to users with appropriate credentials.", "Potential_Mitigations": "Implementation : Ensure that debug components are properly chained and their granularity is maintained at different authentication levels.", "Demonstrative_Examples": "The following example shows how an attacker can take advantage of incorrect chaining or missing granularity of debug components.. In a System-on-Chip (SoC), the user might be able to access the SoC-level TAP with a certain level of authorization. However, this access should not also grant access to all of the internal TAPs (e.g., Core). Separately, if any of the internal TAPs is also stitched to the TAP chain when it should not be because of a logic error, then an attacker can access the internal TAPs as well and execute commands there.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1297", "Name": "Unprotected Confidential Information on Device is Accessible by OSAT Vendors", "Description": "Ensure that when an OSAT vendor is allowed to access test interfaces necessary for preproduction and returned parts, the vendor only pulls the minimal information necessary. Also, architect the product in such a way that, when an \"unlock device\" request comes, it only unlocks that specific part and not all the parts for that product line.\n\t\t\t\t\t  Ensure that the product's non-volatile memory (NVM) is scrubbed of all confidential information and secrets before handing it over to an OSAT.\n\t\t\t\t\t  Arrange to secure all communication between an OSAT facility and the chipmaker.", "Extended_Description": "In contrast to complete vertical integration of architecting, designing, manufacturing, assembling, and testing chips all within a single organization, an organization can choose to simply architect and design a chip before outsourcing the rest of the process to OSAT entities (e.g., external foundries and test houses). In the latter example, the device enters an OSAT facility in a much more vulnerable pre-production stage where many debug and test modes are accessible. Therefore, the chipmaker must place a certain level of trust with the OSAT. To counter this, the chipmaker often requires the OSAT partner to enter into restrictive non-disclosure agreements (NDAs). Nonetheless, OSAT vendors likely have many customers, which increases the risk of accidental sharing of information. There may also be a security vulnerability in the information technology (IT) system of the OSAT facility. Alternatively, a malicious insider at the OSAT facility may carry out an insider attack. Considering these factors, it behooves the chipmaker to minimize any confidential information in the device that may be accessible to the OSAT vendor.Logic errors during design or synthesis could misconfigure the interconnection of the debug components, which could provide improper authorization to sensitive information.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAccess ControlAuthenticationAuthorizationAvailabilityAccountabilityNon-Repudiation. Impacts: Gain Privileges or Assume IdentityBypass Protection MechanismExecute Unauthorized Code or CommandsModify MemoryModify Files or Directories. Note: The impact depends on the confidential information itself and who is inadvertently granted access. For example, if the confidential information is a key that can unlock all the parts of a generation, the impact could be severe.", "Detection_Methods": "Method Name: Architecture or Design Review. Description: Appropriate Post-Si tests should be carried out to ensure that residual confidential information is not left on parts leaving one facility for another facility. Method Name: Dynamic Analysis with Manual Results Interpretation. Description: Appropriate Post-Si tests should be carried out to ensure that residual confidential information is not left on parts leaving one facility for another facility.", "Potential_Mitigations": "Architecture and Design : Ensure that when an OSAT vendor is allowed to access test interfaces necessary for preproduction and returned parts, the vendor only pulls the minimal information necessary. Also, architect the product in such a way that, when an \"unlock device\" request comes, it only unlocks that specific part and not all the parts for that product line.\n\t\t\t\t\t  Ensure that the product's non-volatile memory (NVM) is scrubbed of all confidential information and secrets before handing it over to an OSAT.\n\t\t\t\t\t  Arrange to secure all communication between an OSAT facility and the chipmaker.", "Demonstrative_Examples": "The following example shows how an attacker can take advantage of a piece of confidential information that has not been protected from the OSAT.. Suppose the preproduction device contains NVM (a storage medium that by definition/design can retain its data without power), and this NVM contains a key that can unlock all the parts for that generation.  An OSAT facility accidentally leaks the key.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1298", "Name": "Hardware Logic Contains Race Conditions", "Description": "Logic redundancy can be implemented along security critical paths to prevent race conditions. To avoid metastability, it is a good practice in general to default to a secure state in which access is not given to untrusted agents.", "Extended_Description": "A race condition in logic circuits typically occurs when a logic gate gets inputs from signals that have traversed different paths while originating from the same source. Such inputs to the gate can change at slightly different times in response to a change in the source signal. This results in a timing error or a glitch (temporary or permanent) that causes the output to change to an unwanted state before settling back to the desired state. If such timing errors occur in access control logic or finite state machines that are implemented in security sensitive flows, an attacker might exploit them to circumvent existing protections.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Adopting design practices that encourage designers to recognize and eliminate race conditions, such as Karnaugh maps, could result in the decrease in occurrences of race conditions.Implementation : Logic redundancy can be implemented along security critical paths to prevent race conditions. To avoid metastability, it is a good practice in general to default to a secure state in which access is not given to untrusted agents.", "Demonstrative_Examples": "The code below shows a 2x1 multiplexor using logic gates. Though the code shown below results in the minimum gate solution, it is disjoint and causes glitches.. The buggy line of code, commented above, results in signal 'z' periodically changing to an unwanted state. Thus, any logic that references signal 'z' may access it at a time when it is in this unwanted state. This line should be replaced with the line shown below in the Good Code Snippet which results in signal 'z' remaining in a continuous, known, state. Reference for the above code, along with waveforms for simulation can be found in the references below.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "420", "Name": "Unprotected Alternate Channel", "Description": "Identify all alternate channels and use the same protection mechanisms that are used for the primary channels.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Identify all alternate channels and use the same protection mechanisms that are used for the primary channels.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1299", "Name": "Missing Protection Mechanism for Alternate Hardware Interface", "Description": "Protect assets from accesses against all potential interfaces and alternate paths.", "Extended_Description": "An asset inside a chip might have access-control\n                    protections through one interface. However, if all paths to\n                    the asset are not protected, an attacker might compromise\n                    the asset through alternate paths. These alternate paths\n                    could be through shadow or mirror registers inside the IP\n                    core, or could be paths from other external-facing\n                    interfaces to the IP core or SoC.Consider an SoC with various interfaces such as UART,\n                    SMBUS, PCIe, USB, etc. If access control is implemented for\n                    SoC internal registers only over the PCIe interface, then\n                    an attacker could still modify the SoC internal registers\n                    through alternate paths by coming through interfaces such\n                    as UART, SMBUS, USB, etc.Alternatively, attackers might be able to bypass\n                    existing protections by exploiting unprotected, shadow\n                    registers. Shadow registers and mirror registers typically\n                    refer to registers that can be accessed from multiple\n                    addresses. Writing to or reading from the aliased/mirrored\n                    address has the same effect as writing to the address of\n                    the main register. They are typically implemented within an\n                    IP core or SoC to temporarily hold certain data. These data\n                    will later be updated to the main register, and both\n                    registers will be in synch. If the shadow registers are not\n                    access-protected, attackers could simply initiate\n                    transactions to the shadow registers and compromise system\n                    security.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Protect assets from accesses against all potential interfaces and alternate paths.Architecture and Design : Protect assets from accesses against all potential interfaces and alternate paths.Implementation : Protect assets from accesses against all potential interfaces and alternate paths.", "Demonstrative_Examples": "Register SECURE_ME is located at address 0xF00. A\n                            mirror of this register called COPY_OF_SECURE_ME is\n                            at location 0x800F00. The register SECURE_ME is\n                            protected from malicious agents and only allows\n                            access to select, while COPY_OF_SECURE_ME is not.Access control is implemented using an allowlist (as\n                            indicated by acl_oh_allowlist). The identity of the\n                            initiator of the transaction is indicated by the\n                            one hot input, incoming_id. This is checked against\n                            the acl_oh_allowlist (which contains a list of\n                            initiators that are allowed to access the asset).Though this example is shown in Verilog, it will\n                            apply to VHDL as well.. The bugged line of code is repeated in the Bad\n                        example above. Weakness arises from the fact that the\n                        SECURE_ME register can be modified by writing to the\n                        shadow register COPY_OF_SECURE_ME, the address of\n                        COPY_OF_SECURE_ME should also be included in the check.\n                        That buggy line of code should instead be replaced as\n                        shown in the Good Code Snippet below.", "Related_Weaknesses": [{"Nature": "PeerOf", "CWE_ID": "1191", "View_ID": "1194", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "420", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "288", "View_ID": "1000", "Ordinal": null}]}, {"ID": "288", "Name": "Authentication Bypass Using an Alternate Path or Channel", "Description": "Funnel all access through a single choke point to simplify how users can access a resource. For every access, perform a check to determine if the user has permissions to access the resource.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.Architecture and Design: This is often seen in web applications that assume that access to a particular CGI program can only be obtained through a \"front\" screen, when the supporting programs are directly accessible. But this problem is not just in web apps.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Funnel all access through a single choke point to simplify how users can access a resource. For every access, perform a check to determine if the user has permissions to access the resource.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "306", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "420", "View_ID": "1000", "Ordinal": null}]}, {"ID": "260", "Name": "Password in Configuration File", "Description": "Consider storing cryptographic hashes of passwords as an alternative to storing in plaintext.", "Extended_Description": "This can result in compromise of the system for which the password is used. An attacker could gain access to this file and learn the stored password or worse yet, change the password to one of their choosing.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Avoid storing passwords in easily accessible locations.Architecture and Design : Consider storing cryptographic hashes of passwords as an alternative to storing in plaintext.", "Demonstrative_Examples": "Below is a snippet from a Java properties file.. Because the LDAP credentials are stored in plaintext, anyone with access to the file can gain access to the resource.The following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but they are stored in cleartext.. This Java example shows a properties file with a cleartext username / password pair.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "522", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "13", "Name": "ASP.NET Misconfiguration: Password in Configuration File", "Description": "Credentials stored in configuration files should be encrypted, Use standard APIs and industry accepted algorithms to encrypt the credentials stored in configuration files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Credentials stored in configuration files should be encrypted, Use standard APIs and industry accepted algorithms to encrypt the credentials stored in configuration files.", "Demonstrative_Examples": "The following example shows a portion of a configuration file for an ASP.Net application. This configuration file includes username and password information for a connection to a database, but the pair is stored in plaintext.. Username and password information should not be included in a configuration file or a properties file in plaintext as this will allow anyone who can read the file access to the resource. If possible, encrypt this information.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "260", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "240", "Name": "Improper Handling of Inconsistent Structural Elements", "Description": "The product does not handle or incorrectly handles when two or more structural elements should be consistent, but are not.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "237", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": null}]}, {"ID": "130", "Name": "Improper Handling of Length Parameter Inconsistency", "Description": "Validate that the length of the user-supplied data is consistent with the buffer size.", "Extended_Description": "If an attacker can manipulate the length parameter associated with an input such that it is inconsistent with the actual length of the input, this can be leveraged to cause the target application to behave in unexpected, and possibly, malicious ways. One of the possible motives for doing so is to pass in arbitrarily large input to the application. Another possible motivation is the modification of application state by including invalid data for subsequent properties of the application. Such weaknesses commonly lead to attacks such as buffer overflows and execution of arbitrary code.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : When processing structured incoming data containing a size field followed by raw data, ensure that you identify and resolve any inconsistencies between the size field and the actual size of the data.Implementation : Do not let the user control the size of the buffer.Implementation : Validate that the length of the user-supplied data is consistent with the buffer size.", "Demonstrative_Examples": "In the following C/C++ example the method processMessageFromSocket() will get a message from a socket, placed into a buffer, and will parse the contents of the buffer into a structure that contains the message length and the message body. A for loop is used to copy the message body into a local character string which will be passed to another method for processing.. However, the message length variable from the structure is used as the condition for ending the for loop without validating that the message length variable accurately reflects the length of the message body (CWE-606). This can result in a buffer over-read (CWE-125) by reading from memory beyond the bounds of the buffer if the message length variable indicates a length that is longer than the size of a message body (CWE-130).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "240", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "805", "View_ID": "1000", "Ordinal": null}]}, {"ID": "203", "Name": "Observable Discrepancy", "Description": "Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.", "Extended_Description": "Discrepancies can take many forms, and variations may be detectable in timing, control flow, communications such as replies or requests, or general behavior. These discrepancies can reveal information about the product's operation or internal state to an unauthorized actor. In some cases, discrepancies can be used by attackers to form a side channel.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityAccess Control. Impacts: Read Application DataBypass Protection Mechanism. Note: An attacker can gain access to sensitive information about the system, including authentication information that may allow an attacker to gain access to the system.Scopes: Confidentiality. Impacts: Read Application Data. Note: When cryptographic primitives are vulnerable to side-channel-attacks, this could be used to reveal unencrypted plaintext in the worst case.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.Implementation : Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.", "Demonstrative_Examples": "The following code checks validity of the supplied username and password and notifies the user of a successful or failed login.. In the above code, there are different messages for when an incorrect username is supplied, versus when the username is correct but the password is wrong. This difference enables a potential attacker to understand the state of the login function, and could allow an attacker to discover a valid username by trying different values until the incorrect password message is returned. In essence, this makes it easier for an attacker to obtain half of the necessary authentication credentials.Non-uniform processing time causes timing channel.. In the example above, an attacker may vary the inputs, then observe differences between processing times (since different plaintexts take different time). This could be used to infer information about the key.Suppose memory access patterns for an encryption routine are dependent on the secret key.. An attacker can recover the key by knowing if specific memory locations have been accessed or not.  The value stored at those memory locations is irrelevant.  The encryption routine's memory accesses will affect the state of the processor cache.  If cache resources are shared across contexts, after the encryption routine completes, an attacker in different execution context can discover which memory locations the routine accessed by measuring the time it takes for their own memory accesses to complete.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "1301", "Name": "Insufficient or Incomplete Data Removal within Hardware Component", "Description": "Alter the method of erasure, add protection of media, or destroy the media to protect the data.", "Extended_Description": "Physical properties of hardware devices, such as remanence of magnetic media, residual charge of ROMs/RAMs, or screen burn-in may still retain sensitive data after a data removal process has taken place and power is removed.Recovering data after erasure or overwriting is possible due to a phenomenon called data remanence. For example, if the same value is written repeatedly to a memory location, the corresponding memory cells can become physically altered to a degree such that even after the original data is erased that data can still be recovered through physical characterization of the memory cells.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Apply blinding or masking techniques to implementations of cryptographic algorithms.Implementation : Alter the method of erasure, add protection of media, or destroy the media to protect the data.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "226", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1302", "Name": "Missing Security Identifier", "Description": "Security identifier definition and programming flow must be tested in pre-silicon and post-silicon testing.", "Extended_Description": "In a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute). A typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity) in addition to much more information in the message. Sometimes the transactions are qualified with a Security Identifier.  This Security Identifier helps the destination agent decide on the set of allowed or disallowed actions.A common weakness that can exist in such transaction schemes is that the source agent fails to include the necessary, security identifier with the transaction.  Because of the missing security identifier, the destination agent might drop the message, thus resulting in Denial-of-Service (DoS), or get confused in its attempt to execute the given action, which confusion could result in privilege escalation or a gain of unintended access.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Transaction details must be reviewed for design inconsistency and common weaknesses.Implementation : Security identifier definition and programming flow must be tested in pre-silicon and post-silicon testing.", "Demonstrative_Examples": "Consider a system with a register for storing AES key for encryption or decryption. The key is of 128 bits implemented as a set of four 32-bit registers.  The key registers are assets, and the register AES_KEY_ACCESS_POLICY is defined to provide the necessary access controls.The access-policy register defines which agents with a security identifier in the transaction can access the AES-key registers. Each bit in this 32-bit register defines a security identifier. There could be a maximum of 32 security identifiers that are allowed accesses to the AES-key registers. The number of the bit when set (i.e., \"1\") allows for a respective action from an agent whose identity matches the number of the bit; if set to \"0\" (i.e., Clear), it disallows the respective action to that corresponding agent.. The originator sends a transaction with no security identifier, i.e., meaning the value is \"0\" or NULL. The AES-Key-access register does not allow the necessary action and drops the transaction because the originator failed to include the required security identifier.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1294", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1303", "Name": "Non-Transparent Sharing of Microarchitectural Resources", "Description": "Microarchitectural covert channels can be addressed using a mixture of hardware and software mitigation techniques. These include partitioned caches, new barrier and flush instructions, and disabling high resolution performance counters and timers.", "Extended_Description": "Modern processors use techniques such as out-of-order execution, speculation, prefetching, data forwarding, and caching to increase performance. Details about the implementation of these techniques are hidden from the programmer's view. This is problematic when the hardware implementation of these techniques results in resources being shared across supposedly isolated contexts. Contention for shared resources between different contexts opens covert channels that allow malicious programs executing in one context to recover information from another context.Some examples of shared micro-architectural resources that have been used to leak information between contexts are caches, branch prediction logic, and load or store buffers. Speculative and out-of-order execution provides an attacker with increased control over which data is leaked through the covert channel.If the extent of resource sharing between contexts in the design microarchitecture is undocumented, it is extremely difficult to ensure system assets are protected against disclosure.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Memory. Note: Microarchitectural side-channels have been used to leak specific information such as cryptographic keys, and Address Space Layout Randomization (ALSR) offsets as well as arbitrary memory.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Microarchitectural covert channels can be addressed using a mixture of hardware and software mitigation techniques. These include partitioned caches, new barrier and flush instructions, and disabling high resolution performance counters and timers.Requirements : Microarchitectural covert channels can be addressed using a mixture of hardware and software mitigation techniques. These include partitioned caches, new barrier and flush instructions, and disabling high resolution performance counters and timers.", "Demonstrative_Examples": ". On some processors the hardware indirect branch predictor is shared between execution contexts, for example, between sibling SMT threads. When SMT thread A executes an indirect branch to a target address X, this target may be temporarily stored by the indirect branch predictor. A subsequent indirect branch mis-prediction for SMT thread B could speculatively execute instructions at X (or at a location in B's address space that partially aliases X). Even though the processor rolls back the architectural effects of the mis-predicted indirect branch, the memory accesses alter data cache state, which is not rolled back after the indirect branch is resolved.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1189", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "203", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1304", "Name": "Improperly Preserved Integrity of Hardware Configuration State During a Power Save/Restore Operation", "Description": "Outside the IP, incorporate a protected\n                        environment that prevents undetected modification of\n                        the configuration state by untrusted agents. Before\n                        powering down, a trusted agent saves the IP's\n                        configuration state in this protected location that\n                        only it is privileged to. Upon restore, the trusted\n                        agent loads the saved state into the IP.", "Extended_Description": "Before powering down, the Intellectual\n                Property (IP) saves current state (S) to persistent\n                storage such as flash or always-on memory in order to\n                optimize the restore operation.  During this process,\n                an attacker with access to the persistent storage may\n                alter (S) to a configuration that could potentially\n                modify privileges, disable protections, and/or cause\n                damage to the hardware. If the IP does not validate\n                the configuration state stored in persistent memory,\n                upon regaining power or becoming operational again,\n                the IP could be compromised through the activation of\n                an unwanted/harmful configuration.", "Modes_Of_Introduction": "Architecture and Design: Weakness introduced via missing internal integrity guarantees during power save/restoreIntegration: Weakness introduced via missing external integrity verification during power save/restore", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Inside the IP, incorporate integrity checking\n                        on the configuration state via a cryptographic\n                        hash. The hash can be protected inside the IP such as\n                        by storing it in internal registers which never lose\n                        power. Before powering down, the IP performs a hash of\n                        the configuration and saves it in these persistent\n                        registers. Upon restore, the IP performs a hash of the\n                        saved configuration and compares it with the\n                        saved hash. If they do not match, then the IP should\n                        not trust the configuration.Integration : Outside the IP, incorporate integrity checking\n                        of the configuration state via a trusted agent. Before\n                        powering down, the trusted agent performs a hash of the\n                        configuration and saves the hash in persistent storage.\n                        Upon restore, the IP requests the trusted agent\n                        validate its current configuration. If the\n                        configuration hash is invalid, then the IP should not\n                        trust the configuration.Integration : Outside the IP, incorporate a protected\n                        environment that prevents undetected modification of\n                        the configuration state by untrusted agents. Before\n                        powering down, a trusted agent saves the IP's\n                        configuration state in this protected location that\n                        only it is privileged to. Upon restore, the trusted\n                        agent loads the saved state into the IP.", "Demonstrative_Examples": "The following pseudo code demonstrates the\n                        power save/restore workflow which may lead to weakness\n                        through a lack of validation of the config state after\n                        restore.. The following pseudo-code is the proper workflow for the integrity checking mitigation:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "1271", "View_ID": "1194", "Ordinal": null}]}, {"ID": "131", "Name": "Incorrect Calculation of Buffer Size", "Description": "Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityAvailabilityConfidentiality. Impacts: DoS: Crash, Exit, or RestartExecute Unauthorized Code or CommandsRead MemoryModify Memory. Note: If the incorrect calculation is used in the context of memory allocation, then the software may create a buffer that is smaller or larger than expected. If the allocated buffer is smaller than expected, this could lead to an out-of-bounds read or write (CWE-119), possibly causing a crash, allowing arbitrary code execution, or exposing sensitive data.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.Automated static analysis generally does not account for environmental considerations when reporting potential errors in buffer calculations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Analysis. Description: Manual analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. This becomes difficult for weaknesses that must be considered for all inputs, since the attack surface can be too large. Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual static analysis is useful for evaluating the correctness of allocation calculations. This can be useful for detecting overflow conditions (CWE-190) or similar weaknesses that might have serious security impacts on the program. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Implementation : When allocating a buffer for the purpose of transforming, converting, or encoding an input, allocate enough memory to handle the largest possible encoding. For example, in a routine that converts \"&\" characters to \"&amp;\" for HTML entity encoding, the output buffer needs to be at least 5 times as large as the input buffer.Implementation : Understand the programming language's underlying representation and how it interacts with numeric calculation (CWE-681). Pay close attention to byte size discrepancies, precision, signed/unsigned distinctions, truncation, conversion and casting between types, \"not-a-number\" calculations, and how the language handles numbers that are too large or too small for its underlying representation. [REF-7]\n                  Also be careful to account for 32-bit, 64-bit, and other potential differences that may affect the numeric representation.Implementation : Perform input validation on any numeric input by ensuring that it is within the expected range. Enforce that the input meets both the minimum and maximum requirements for the expected range.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Implementation : When processing structured incoming data containing a size field followed by raw data, identify and resolve any inconsistencies between the size field and the actual size of the data (CWE-130).Implementation : When allocating memory that uses sentinels to mark the end of a data structure - such as NUL bytes in strings - make sure you also include the sentinel in your calculation of the total amount of memory that must be allocated.Implementation : Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.Implementation : Use sizeof() on the appropriate data type to avoid CWE-467.Implementation : Use the appropriate type for the desired action. For example, in C/C++, only use unsigned types for values that could never be negative, such as height, width, or other numbers related to quantity. This will simplify validation and will reduce surprises related to unexpected casting.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Use libraries or frameworks that make it easier to handle numbers without unexpected consequences, or buffer allocation routines that automatically track buffer size.\n                  Examples include safe integer handling packages such as SafeInt (C++) or IntegerLib (C or C++). [REF-106]Operation : Use automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking.  \n\t\t D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail.Operation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t\t  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].Operation : Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment.   \n\t          For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336].Implementation : Examine compiler warnings closely and eliminate problems with potential security implications, such as signed / unsigned mismatch in memory operations, or use of uninitialized variables. Even if the weakness is rarely exploitable, a single failure may lead to the compromise of the entire system.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Demonstrative_Examples": "The following code allocates memory for a maximum number of widgets. It then gets a user-specified number of widgets, making sure that the user does not request too many. It then initializes the elements of the array using InitializeWidget(). Because the number of widgets can vary for each request, the code inserts a NULL pointer to signify the location of the last widget.. However, this code contains an off-by-one calculation error (CWE-193). It allocates exactly enough space to contain the specified number of widgets, but it does not include the space for the NULL pointer. As a result, the allocated buffer is smaller than it is supposed to be (CWE-131). So if the user ever requests MAX_NUM_WIDGETS, there is an out-of-bounds write (CWE-787) when the NULL is assigned. Depending on the environment and compilation settings, this could cause memory corruption.The following image processing code allocates a table for images.. This code intends to allocate a table of size num_imgs, however as num_imgs grows large, the calculation determining the size of the list will eventually overflow (CWE-190). This will result in a very small list to be allocated instead. If the subsequent code operates on the list as if it were num_imgs long, it may result in many types of out-of-bounds problems (CWE-119).This example applies an encoding procedure to an input string and stores it into a buffer.. The programmer attempts to encode the ampersand character in the user-controlled string, however the length of the string is validated before the encoding procedure is applied. Furthermore, the programmer assumes encoding expansion will only expand a given character by a factor of 4, while the encoding of the ampersand expands by 5. As a result, when the encoding procedure expands the string it is possible to overflow the destination buffer if the attacker provides a string of many ampersands.The following code is intended to read an incoming packet from a socket and extract one or more headers.. The code performs a check to make sure that the packet does not contain too many headers. However, numHeaders is defined as a signed int, so it could be negative. If the incoming packet specifies a value such as -3, then the malloc calculation will generate a negative number (say, -300 if each header can be a maximum of 100 bytes). When this result is provided to malloc(), it is first converted to a size_t type. This conversion then produces a large value such as 4294966996, which may cause malloc() to fail or to allocate an extremely large amount of memory (CWE-195). With the appropriate negative numbers, an attacker could trick malloc() into using a very small positive number, which then allocates a buffer that is much smaller than expected, potentially leading to a buffer overflow.The following code attempts to save three different identification numbers into an array. The array is allocated from memory using a call to malloc().. The problem with the code above is the value of the size parameter used during the malloc() call. It uses a value of '3' which by definition results in a buffer of three bytes to be created. However the intention was to create a buffer that holds three ints, and in C, each int requires 4 bytes worth of memory, so an array of 12 bytes is needed, 4 bytes for each int. Executing the above code could result in a buffer overflow as 12 bytes of data is being saved into 3 bytes worth of allocated space. The overflow would occur during the assignment of id_sequence[0] and would continue with the assignment of id_sequence[1] and id_sequence[2].", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1310", "Name": "Missing Ability to Patch ROM Code", "Description": "Support patches that can be programmed in-field or during manufacturing through hardware fuses. This feature can be used for limited patching of devices after shipping, or for the next batch of silicon devices manufactured, without changing the full device ROM.", "Extended_Description": "A System or System-on-Chip (SoC) that implements a boot process utilizing security mechanisms such as Root-of-Trust (RoT) typically starts by executing code from a Read-only-Memory (ROM) component. The code in ROM is immutable, hence any security vulnerabilities discovered in the ROM code can never be fixed for the systems that are already in use.A common weakness is that the ROM does not have the ability to patch if security vulnerabilities are uncovered after the system gets shipped.  This leaves the system in a vulnerable state where an adversary can compromise the SoC.", "Modes_Of_Introduction": "Architecture and Design: This issue could be introduced during hardware architecture and design and can be identified later during Testing.Implementation: This issue could be introduced during implementation and can be identified later during Testing.Integration: This issue could be introduced during integration and can be identified later during Testing.Manufacturing: This issue could be introduced during manufacturing and can be identified later during Testing.", "Common_Consequences": "Scopes: Other. Impacts: Varies by ContextReduce Maintainability. Note: When the system is unable to be patched, it can be left in a vulnerable state.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Secure patch support to allow ROM code to be patched on the next boot.Architecture and Design : Support patches that can be programmed in-field or during manufacturing through hardware fuses. This feature can be used for limited patching of devices after shipping, or for the next batch of silicon devices manufactured, without changing the full device ROM.", "Demonstrative_Examples": "A System-on-Chip (SOC) implements a Root-of-Trust (RoT) in ROM to boot secure code. However, at times this ROM code might have security vulnerabilities and need to be patched. Since ROM is immutable, it can be impossible to patch.. ROM does not have built-in application-programming interfaces (APIs) to patch if the code is vulnerable. Implement mechanisms to patch the vulnerable ROM code.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1329", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1311", "Name": "Improper Translation of Security Attributes by Fabric Bridge", "Description": "Ensure that the translation maps signals in such a way that untrusted agents cannot map to trusted agents or vice-versa.", "Extended_Description": "A bridge allows IP blocks supporting different fabric protocols to be integrated into the system.  Fabric end-points or interfaces usually have dedicated signals to transport security attributes. For example, HPROT signals in AHB, AxPROT signals in AXI, and MReqInfo and SRespInfo signals in OCP.The values on these signals are used to indicate the security attributes of the transaction. These include the immutable hardware identity of the controller initiating the transaction, privilege level, and type of transaction (e.g., read/write, cacheable/non-cacheable, posted/non-posted).A weakness can arise if the bridge IP block, which translates the signals from the protocol used in the IP block endpoint to the protocol used by the central bus, does not properly translate the security attributes. As a result, the identity of the initiator could be translated from untrusted to trusted or vice-versa. This could result in access-control bypass, privilege escalation, or denial of service.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : The translation must map signals in such a way that untrusted agents cannot map to trusted agents or vice-versa.Implementation : Ensure that the translation maps signals in such a way that untrusted agents cannot map to trusted agents or vice-versa.", "Demonstrative_Examples": "The bridge interfaces between OCP and AHB end points. OCP uses MReqInfo signal to indicate security attributes, whereas AHB uses HPROT signal to indicate the security attributes. The width of MReqInfo can be customized as needed. In this example, MReqInfo is 5-bits wide and carries the privilege level of the OCP controller.The values 5'h11, 5'h10, 5'h0F, 5'h0D, 5'h0C, 5'h0B, 5'h09, 5'h08, 5'h04, and 5'h02 in MReqInfo indicate that the request is coming from a privileged state of the OCP bus controller. Values 5'h1F, 5'h0E, and 5'h00 indicate untrusted, privilege state.Though HPROT is a 5-bit signal, we only consider the lower, two bits in this example. HPROT values 2'b00 and 2'b10 are considered trusted, and 2'b01 and 2'b11 are considered untrusted.The OCP2AHB bridge is expected to translate trusted identities on the controller side to trusted identities on the responder side.  Similarly, it is expected to translate untrusted identities on the controller side to untrusted identities on the responder side.. Logic in the case statement only checks for MReqInfo bits 4:2, i.e., hardware-identity bits 3:1. When ocp_mreqinfo is 5'h1F or 5'h0E, p0_mreqinfo_o_temp[2] will be 1. As a result, untrusted IDs from OCP 5'h1F and 5'h0E get translated to trusted ahb_hprot values 2'b00.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1312", "Name": "Missing Protection for Mirrored Regions in On-Chip Fabric Firewall", "Description": "The fabric firewall should apply the same protections as the original region to the mirrored regions.", "Extended_Description": "Few fabrics mirror memory and address ranges, where mirrored regions contain copies of the original data. This redundancy is used to achieve fault tolerance. Whatever protections the fabric firewall implements for the original region should also apply to the mirrored regions. If not, an attacker could bypass existing read/write protections by reading from/writing to the mirrored regions to leak or corrupt the original data.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Dynamic Analysis. Description: Using an external debugger, send write transactions to mirrored regions to test if original, write-protected regions are modified. Similarly, send read transactions to mirrored regions to test if the original, read-protected signals can be read.", "Potential_Mitigations": "Architecture and Design : The fabric firewall should apply the same protections as the original region to the mirrored regions.Implementation : The fabric firewall should apply the same protections as the original region to the mirrored regions.", "Demonstrative_Examples": "A memory-controller IP block is connected to the on-chip fabric in a System on Chip (SoC).  The memory controller is configured to divide the memory into four parts: one original and three mirrored regions inside the memory. The upper two bits of the address indicate which region is being addressed. 00 indicates the original region and 01, 10, and 11 are used to address the mirrored regions. All four regions operate in a lock-step manner and are always synchronized. The firewall in the on-chip fabric is programmed to protect the assets in the memory.. The firewall only protects the original range but not the mirrored regions.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1251", "View_ID": "1194", "Ordinal": null}]}, {"ID": "1313", "Name": "Hardware Allows Activation of Test or Debug Logic at Runtime", "Description": "Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.", "Extended_Description": "An adversary can take advantage of test or debug logic that is made accessible through the hardware during normal operation to modify the intended behavior of the system. For example, an accessible Test/debug mode may allow read/write access to any system data. Using error injection (a common test/debug feature) during a transmit/receive operation on a bus, data may be modified to produce an unintended message. Similarly, confidentiality could be compromised by such features allowing access to secrets.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.Integration: Such issues could be introduced during integration and identified later during Testing or System configuration phases.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.Implementation : Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.Integration : Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "862", "Name": "Missing Authorization", "Description": "Use the access control capabilities of your operating system and server environment and define your access control lists accordingly. Use a \"default deny\" policy when defining these ACLs.", "Extended_Description": "Assuming a user with a given identity, authorization is the process of determining whether that user can access a given resource, based on the user's privileges and any permissions or other access-control specifications that apply to the resource.When access control checks are not applied, users are able to access data or perform actions that they should not be allowed to perform. This can lead to a wide range of problems, including information exposures, denial of service, and arbitrary code execution.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.Authorization weaknesses may arise when a single-user application is ported to a multi-user environment.Implementation: A developer may introduce authorization weaknesses because of a lack of understanding about the underlying technologies. For example, a developer may assume that attackers cannot modify certain inputs such as headers or cookies.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Files or Directories. Note: An attacker could read sensitive data, either by reading the data directly from a data store that is not restricted, or by accessing insufficiently-protected, privileged functionality to read the data.Scopes: Integrity. Impacts: Modify Application DataModify Files or Directories. Note: An attacker could modify sensitive data, either by writing the data directly to a data store that is not restricted, or by accessing insufficiently-protected, privileged functionality to write the data.Scopes: Access Control. Impacts: Gain Privileges or Assume IdentityBypass Protection Mechanism. Note: An attacker could gain privileges by modifying or reading critical data directly, or by accessing privileged functionality.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis is useful for detecting commonly-used idioms for authorization. A tool may be able to analyze related configuration files, such as .htaccess in Apache web servers, or detect the usage of commonly-used authorization libraries.Generally, automated static analysis tools have difficulty detecting custom authorization schemes. In addition, the software's design may include some functionality that is accessible to any user and does not require an authorization check; an automated technique that detects the absence of authorization may report false positives. Method Name: Automated Dynamic Analysis. Description: Automated dynamic analysis may find many or all possible interfaces that do not require authorization, but manual analysis is required to determine if the lack of authorization violates business logic. Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual static analysis is useful for evaluating the correctness of custom authorization mechanisms. Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Divide the product into anonymous, normal, privileged, and administrative areas. Reduce the attack surface by carefully mapping roles with data and functionality. Use role-based access control (RBAC) [REF-229] to enforce the roles at the appropriate boundaries.\n                  Note that this approach may not protect against horizontal authorization, i.e., it will not protect a user from attacking others with the same role.Architecture and Design : Ensure that access control checks are performed related to the business logic. These checks may be different than the access control checks that are applied to more generic resources such as files, connections, processes, memory, and database records. For example, a database may restrict access for medical records to a specific database user, but each record might only be intended to be accessible to the patient and the patient's doctor [REF-7].Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using authorization frameworks such as the JAAS Authorization Framework [REF-233] and the OWASP ESAPI Access Control feature [REF-45].Architecture and Design : For web applications, make sure that the access control mechanism is enforced correctly at the server side on every page. Users should not be able to access any unauthorized functionality or information by simply requesting direct access to that page.\n                  One way to do this is to ensure that all pages containing sensitive information are not cached, and that all such pages restrict access to requests that are accompanied by an active and authenticated session token associated with a user who has the required permissions to access that page.System Configuration : Use the access control capabilities of your operating system and server environment and define your access control lists accordingly. Use a \"default deny\" policy when defining these ACLs.", "Demonstrative_Examples": "This function runs an arbitrary SQL query on a given database, returning the result of the query.. While this code is careful to avoid SQL Injection, the function does not confirm the user sending the query is authorized to do so. An attacker may be able to obtain sensitive employee information from the database.The following program could be part of a bulletin board system that allows users to send private messages to each other. This program intends to authenticate the user before deciding whether a private message should be displayed. Assume that LookupMessageObject() ensures that the $id argument is numeric, constructs a filename based on that id, and reads the message details from that file. Also assume that the program stores all private messages for all users in the same directory.. While the program properly exits if authentication fails, it does not ensure that the message is addressed to the user. As a result, an authenticated attacker could provide any arbitrary identifier and read private messages that were intended for other users.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1314", "Name": "Missing Write Protection for Parametric Data Values", "Description": "Access controls for sensor blocks should ensure that only trusted software is allowed to change threshold limits and sensor parametric data.", "Extended_Description": "Various sensors are used by hardware to detect any devices operating outside of the design limits. The threshold limit values are set by hardware fuses or trusted software such as the BIOS. These limits may be related to thermal, power, voltage, current, and frequency. Hardware mechanisms may be used to protect against alteration of the threshold limit values by untrusted software.The limit values are generally programmed in standard units for the type of value being read. However, the hardware-sensor blocks may report the settings in different units depending upon sensor design and operation. The raw sensor output value is converted to the desired units using a scale conversion based on the parametric data programmed into the sensor. The final converted value is then compared with the previously programmed limits.While the limit values are usually protected, the sensor parametric data values may not be. By changing the parametric data, safe operational limits may be bypassed.", "Modes_Of_Introduction": "Architecture and Design: The lack of a requirement to protect parametric values may contribute to this weakness.Implementation: The lack of parametric value protection may be a cause of this weakness.", "Common_Consequences": "Scopes: Availability. Impacts: Quality DegradationDoS: Resource Consumption (Other). Note: Sensor value manipulation, particularly thermal or power, may allow physical damage to occur or disabling of the device by a false fault shutdown causing a Denial-Of-Service.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Access controls for sensor blocks should ensure that only trusted software is allowed to change threshold limits and sensor parametric data.", "Demonstrative_Examples": "Malicious software executes instructions to increase power consumption to the highest possible level while causing the clock frequency to increase to its maximum value.\n\t\t\t\t\t\t\tSuch a program executing for an extended period of time would likely overheat the device, possibly resulting in permanent damage to the device.A ring, oscillator-based temperature sensor will generally report the sensed value as\n\t\t\t\t\t\t\toscillator frequency rather than degrees centigrade.  The temperature sensor will have\n\t\t\t\t\t\t\tcalibration values that are used to convert the detected frequency into the corresponding temperature in degrees centigrade.Consider a SoC design where the critical maximum temperature limit is set in fuse values to 100C and\n\t\t\t\t\t\t\tis not modifiable by software.  If the scaled thermal sensor output equals or exceeds this limit, the system is commanded to shut itself down.The thermal sensor calibration values are programmable through registers that are exposed to system software.\n\t\t\t\t\t\tThese registers allow software to affect the converted temperature output such that the output will never exceed the maximum temperature limit.. This weakness may be addressed by preventing access to a and b.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "862", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1299", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "1315", "Name": "Improper Setting of Bus Controlling Capability in Fabric End-point", "Description": "For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.", "Extended_Description": "To support reusability, certain fabric interfaces and end points provide a configurable register bit that allows IP blocks connected to the controller to access other peripherals connected to the fabric. This allows the end point to be used with devices that function as a controller or responder. If this bit is set by default in hardware, or if firmware incorrectly sets it later, a device intended to be a responder on a fabric is now capable of controlling transactions to other devices and might compromise system security.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.Implementation : For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.System Configuration : For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.", "Demonstrative_Examples": "A typical, phone platform consists of the main, compute core or CPU, a DRAM-memory chip, an audio codec, a baseband modem, a power-management-integrated circuit (\"PMIC\"), a connectivity (WiFi and Bluetooth) modem, and several other analog/RF components. The main CPU is the only component that can control transactions, and all the other components are responder-only devices. All the components implement a PCIe end-point to interface with the rest of the platform. The responder devices should have the bus-control-enable bit in the PCIe-end-point register set to 0 in hardware to prevent the devices from controlling transactions to the CPU or other peripherals.. The audio-codec chip does not have the bus-controller-enable-register bit hardcoded to 0.  There is no platform-firmware flow to verify that the bus-controller-enable bit is set to 0 in all responders.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1316", "Name": "Fabric-Address Map Allows Programming of Unwarranted Overlaps of Protected and Unprotected Ranges", "Description": "Validate mitigation actions with robust testing.", "Extended_Description": "Various ranges can be defined in the system-address map, either in the memory or in Memory-Mapped-IO (MMIO) space. These ranges are usually defined using special range registers that contain information, such as base address and size. Address decoding is the process of determining for which range the incoming transaction is destined. To ensure isolation, ranges containing secret data are access-control protected.Occasionally, these ranges could overlap. The overlap could either be intentional (e.g. due to a limited number of range registers or limited choice in choosing size of the range) or unintentional (e.g. introduced by errors). Some hardware designs allow dynamic remapping of address ranges assigned to peripheral MMIO ranges. In such designs, intentional address overlaps can be created through misconfiguration by malicious software. When protected and unprotected ranges overlap, an attacker could send a transaction and potentially compromise the protections in place, violating the principle of least privilege.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Dynamic Analysis. Description: Review address map in specification to see if there are any overlapping ranges. Method Name: Manual Static Analysis. Description: Negative testing of access control on overlapped ranges.", "Potential_Mitigations": "Architecture and Design : When architecting the address map of the chip, ensure that protected and unprotected ranges are isolated and do not overlap. When designing, ensure that ranges hardcoded in Register-Transfer Level (RTL) do not overlap.Implementation : Ranges configured by firmware should not overlap. If overlaps are mandatory because of constraints such as a limited number of registers, then ensure that no assets are present in the overlapped portion.Testing : Validate mitigation actions with robust testing.", "Demonstrative_Examples": "An on-chip fabric supports a 64KB address space that is memory-mapped. The fabric has two range registers that support creation of two protected ranges with specific size constraints--4KB, 8KB, 16KB or 32KB. Assets that belong to user A require 4KB, and those of user B require 20KB.  Registers and other assets that are not security-sensitive require 40KB.  One range register is configured to program 4KB to protect user A's assets. Since a 20KB range cannot be created with the given size constraints, the range register for user B's assets is configured as 32KB. The rest of the address space is left as open. As a result, some part of untrusted and open-address space overlaps with user B range.. The fabric does not support least privilege, and an attacker can send a transaction to the overlapping region to tamper with user B data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1317", "Name": "Improper Access Control in Fabric Bridge", "Description": "Implement access-control checks in the bridge for both upstream and downstream transactions.", "Extended_Description": "In hardware designs, different IP blocks are connected through interconnect-bus fabrics (e.g. AHB and OCP). Within a System on Chip (SoC), the IP block subsystems could be using different bus protocols. In such a case, the IP blocks are then linked to the central bus (and to other IP blocks) through a fabric bridge. Bridges are used as bus-interconnect-routing modules that link different protocols or separate, different segments of the overall SoC interconnect.For overall system security, it is important that the access-control privileges associated with any fabric transaction are consistently maintained and applied, even when they are routed or translated by a fabric bridge. A bridge that is connected to a fabric without security features forwards transactions to the slave without checking the privilege level of the master and results in a weakness in SoC access-control security. The same weakness occurs if a bridge does not check the hardware identity of the transaction received from the slave interface of the bridge.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Simulation / Emulation. Description: RTL simulation to ensure that bridge-access controls are implemented properly. Method Name: Formal Verification. Description: Formal verification of bridge RTL to ensure that access control cannot be bypassed.", "Potential_Mitigations": "Architecture and Design : Ensure that the design includes provisions for access-control checks in the bridge for both upstream and downstream transactions.Implementation : Implement access-control checks in the bridge for both upstream and downstream transactions.", "Demonstrative_Examples": "This example is from CVE-2019-6260 [REF-1138]. The iLPC2AHB bridge connects a CPU (with multiple, privilege levels, such as user, super user, debug, etc.) over AHB interface to an LPC bus. Several peripherals are connected to the LPC bus. The bridge is expected to check the privilege level of the transactions initiated in the core before forwarding them to the peripherals on the LPC bus.. The bridge does not implement the checks and allows reads and writes from all privilege levels.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1318", "Name": "Missing Support for Security Features in On-chip Fabrics or Buses", "Description": "If fabric does not support security features, implement security checks in a bridge or any component that is between the master and the fabric.  Alternatively, connect all fabric slaves that do not have any security assets under one such fabric and connect peripherals with security assets to a different fabric that supports security features.", "Extended_Description": "Certain on-chip fabrics and buses, especially simple and low-power buses, do not support security features.  Apart from data transfer and addressing ports, some fabrics and buses do not have any interfaces to transfer privilege, immutable identity, or any other security attribute coming from the bus master.  Similarly, they do not have dedicated signals to transport security-sensitive data from slave to master, such as completions for certain types of transactions.  Few other on-chip fabrics and buses support security features and define specific interfaces/signals for transporting security attributes from master to slave or vice-versa.  However, including these signals is not mandatory and could be left unconfigured when generating the register-transfer-level (RTL) description for the fabric.  Such fabrics or buses should not be used to transport any security attribute coming from the bus master.  In general, peripherals with security assets should not be connected to such buses before the transaction from the bus master reaches the bus, unless some form of access control is performed at a fabric bridge or another intermediate module.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Architecture or Design Review. Description: Review the fabric specification and ensure that it contains signals to transfer security-sensitive signals. Method Name: Manual Static Analysis - Source Code. Description: Lack of security features can also be confirmed through manual RTL review of the fabric RTL.", "Potential_Mitigations": "Architecture and Design : If fabric does not support security features, implement security checks in a bridge or any component that is between the master and the fabric.  Alternatively, connect all fabric slaves that do not have any security assets under one such fabric and connect peripherals with security assets to a different fabric that supports security features.", "Demonstrative_Examples": "Several systems on chips (SoCs) use the Advanced-Microcontroller Bus Architecture (AMBA) Advanced-Peripheral Bus (APB) protocol.  APB is a simple, low-power bus and uses the PPROT[2:0] bits to indicate the security state of the bus masters ;PPROT[0] indicates privilege, PPROT[1] indicates secure/non-secure transaction, and PPROT[2] indicates instruction/data.  Assume that there is no fabric bridge in the SoC. One of the slaves, the power-management unit, contains registers that store the thermal-shutdown limits.. The APB bus is used to connect several bus masters, each with a unique and immutable hardware identity, to several slaves. For a CPU supporting 8 potential identities (each with varying privilege levels), 16 types of outgoing transactions can be made--8 read transactions with each supported privilege level and 8 write transactions with each supported privilege level.The Open-Core-Protocol (OCP) fabric supports two configurable, width-optional signals for transporting security attributes: MReqInfo and SRespInfo.  MReqInfo is used to transport security attributes from bus master to slave, and SRespInfo is used to transport security attributes from slave to bus master. An SoC uses OCP to connect several bus masters, each with a unique and immutable hardware identity, to several slaves.  One of the bus masters, the CPU, reports the privilege level (user or super user) in addition to the unique identity.  One of the slaves, the power-management unit, contains registers that store the thermal-shutdown limits.. Since MReqInfo and SRespInfo are not mandatory, these signals are not configured when autogenerating RTL for the OCP fabric.  Thus, the fabric cannot be used to transport security attributes from bus masters to slave.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1319", "Name": "Improper Protection against Electromagnetic Fault Injection (EM-FI)", "Description": "1. Redundancy - By replicating critical operations and comparing the two outputs can help indicate whether a fault has been injected.\n\t\t\t\t\t\t2. Error detection and correction codes - Gay, Mael, et al. proposed a new scheme that not only detects faults injected by a malicious adversary but also automatically corrects single nibble/byte errors introduced by low-multiplicity faults.\n\t\t\t\t\t\t3. Fail by default coding - When checking conditions (switch or if) check all possible cases and fail by default because the default case in a switch (or the else part of a cascaded if-else-if construct) is used for dealing with the last possible (and valid) value without checking. This is prone to fault injection because this alternative is easily selected as a result of potential data manipulation [REF-1141].\n\t\t\t\t\t\t4. Random Behavior - adding random delays before critical operations, so that timing is not predictable.\n\t\t\t\t\t\t5. Program Flow Integrity Protection - The program flow can be secured by integrating run-time checking aiming at detecting control flow inconsistencies. One such example is tagging the source code to indicate the points not to be bypassed [REF-1147].\n\t\t\t\t\t\t6. Sensors - Usage of sensors can detect variations in voltage and current.\n\t\t\t\t\t\t7. Shields - physical barriers to protect the chips from malicious manipulation.", "Extended_Description": "Electromagnetic fault injection may allow an attacker to locally and dynamically modify the signals (both internal and external) of an integrated circuit. EM-FI attacks consist of producing a local, transient magnetic field near the device, inducing current in the device wires. A typical EMFI setup is made up of a pulse injection circuit that generates a high current transient in an EMI coil, producing an abrupt magnetic pulse which couples to the target producing faults in the device, which can lead to:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : 1. Redundancy - By replicating critical operations and comparing the two outputs can help indicate whether a fault has been injected.\n\t\t\t\t\t\t2. Error detection and correction codes - Gay, Mael, et al. proposed a new scheme that not only detects faults injected by a malicious adversary but also automatically corrects single nibble/byte errors introduced by low-multiplicity faults.\n\t\t\t\t\t\t3. Fail by default coding - When checking conditions (switch or if) check all possible cases and fail by default because the default case in a switch (or the else part of a cascaded if-else-if construct) is used for dealing with the last possible (and valid) value without checking. This is prone to fault injection because this alternative is easily selected as a result of potential data manipulation [REF-1141].\n\t\t\t\t\t\t4. Random Behavior - adding random delays before critical operations, so that timing is not predictable.\n\t\t\t\t\t\t5. Program Flow Integrity Protection - The program flow can be secured by integrating run-time checking aiming at detecting control flow inconsistencies. One such example is tagging the source code to indicate the points not to be bypassed [REF-1147].\n\t\t\t\t\t\t6. Sensors - Usage of sensors can detect variations in voltage and current.\n\t\t\t\t\t\t7. Shields - physical barriers to protect the chips from malicious manipulation.", "Demonstrative_Examples": "In many devices, security related information is stored in fuses. These fuses are loaded into shadow registers at boot time. Disturbing this transfer phase with EM-FI can lead to the shadow registers storing erroneous values potentially resulting in reduced security.. Colin O'Flynn has demonstrated an attack scenario which uses electro-magnetic glitching during booting to bypass security and gain read access to flash, read and erase access to shadow memory area (where the private password is stored). Most devices in the MPC55xx and MPC56xx series that include the Boot Assist Module (BAM) (a serial or CAN bootloader mode) are susceptible to this attack. In this paper, a GM ECU was used as a real life target. While the success rate appears low (less than 2 percent), in practice a success can be found within 1-5 minutes once the EMFI tool is setup. In a practical scenario, the author showed that success can be achieved within 30-60 minutes from a cold start.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1320", "Name": "Improper Protection for Outbound Error Messages and Alert Signals", "Description": "Alert signals generated by critical events should be protected from access by untrusted agents. Only hardware or trusted firmware modules should be able to alter the alert configuration.", "Extended_Description": "Hardware sensors are used to detect whether a device is operating within design limits. The threshold values for these limits are set by hardware fuses or trusted software such as a BIOS.  \n\t\t\t\tModification of these limits may be protected by hardware mechanisms.When device sensors detect out of bound conditions, alert signals may be generated for remedial action, which may take the form of device shutdown or throttling.Warning signals that are not properly secured may be disabled or used to generate spurious alerts, causing degraded performance or denial-of-service (DoS).\n\t\t\t\tThese alerts may be masked by untrusted software. Examples of these alerts involve thermal and power sensor alerts.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Alert signals generated by critical events should be protected from access by untrusted agents. Only hardware or trusted firmware modules should be able to alter the alert configuration.", "Demonstrative_Examples": "Consider a platform design where a Digital-Thermal Sensor (DTS) is used to monitor temperature and compare that output against a threshold value.\n\t\t\t\t\t\t\tIf the temperature output equals or exceeds the threshold value, the DTS unit sends an alert signal to the processor.The processor, upon getting the alert, input triggers system shutdown. The alert signal is handled as a General-Purpose-I/O (GPIO) pin in input mode.. Reprogramming the state of the GPIO pin allows malicious software to trigger spurious alerts or to set the alert pin to a zero value so that thermal sensor alerts are not received by the processor.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "915", "Name": "Improperly Controlled Modification of Dynamically-Determined Object Attributes", "Description": "Refactor the code so that object attributes or fields do not need to be dynamically identified, and only expose getter/setter functionality for the intended attributes.", "Extended_Description": "If the object contains attributes that were only intended for internal use, then their unexpected modification could lead to a vulnerability.This weakness is sometimes known by the language-specific mechanisms that make it possible, such as mass assignment, autobinding, or object injection.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: An attacker could modify sensitive data or program variables.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : If available, use features of the language or framework that allow specification of allowlists of attributes or fields that are allowed to be modified. If possible, prefer allowlists over denylists.\n                  For applications written with Ruby on Rails, use the attr_accessible (allowlist) or attr_protected (denylist) macros in each class that may be used in mass assignment.Architecture and Design : If available, use the signing/sealing features of the programming language to assure that deserialized data has not been tainted. For example, a hash-based message authentication code (HMAC) could be used to ensure that data has not been modified.Implementation : For any externally-influenced input, check the input against an allowlist of internal object attributes or fields that are allowed to be modified.Implementation : Refactor the code so that object attributes or fields do not need to be dynamically identified, and only expose getter/setter functionality for the intended attributes.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "913", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "502", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1321", "Name": "Improperly Controlled Modification of Object Prototype Attributes ('Prototype Pollution')", "Description": "Map can be used instead of objects in most cases. If Map methods are used instead of object attributes, it is not possible to access the object prototype or modify it.", "Extended_Description": "By adding or modifying attributes of an object prototype, it is possible to create attributes that exist on every object, or replace critical attributes with malicious ones. This can be problematic if the product depends on existence or non-existence of certain attributes, or uses pre-defined attributes of object prototype (such as hasOwnProperty, toString or valueOf).This weakness is usually exploited by using a special attribute of objects called proto,  constructor or prototype. Such attributes give access to the object prototype. This weakness is often found in code that assigns object attributes based on user input, or merges or clones objects recursively.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: An attacker can inject attributes that are used in other components.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: An attacker can override existing attributes with ones that have incompatible type, which may lead to a crash.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : By freezing the object prototype first (for example, Object.freeze(Object.prototype)), modification of the prototype becomes impossible.Architecture and Design : By blocking modifications of attributes that resolve to object prototype, such as proto or prototype, this weakness can be mitigated.Implementation : When handling untrusted objects, validating using a schema can be used.Implementation : By using an object without prototypes (via Object.create(null) ), adding object prototype attributes by accessing the prototype via the special attributes becomes impossible, mitigating this weakness.Implementation : Map can be used instead of objects in most cases. If Map methods are used instead of object attributes, it is not possible to access the object prototype or modify it.", "Demonstrative_Examples": "This function sets object attributes based on a dot-separated path.. This function does not check if the attribute resolves to the object prototype. These codes can be used to add \"isAdmin: true\" to the object prototype.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "915", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "913", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "471", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "913", "Name": "Improper Control of Dynamically-Managed Code Resources", "Description": "Refactor the code so that it does not need to be dynamically managed.", "Extended_Description": "Many languages offer powerful features that allow the programmer to dynamically create or modify existing code, or resources used by code such as variables and objects. While these features can offer significant flexibility and reduce development time, they can be extremely dangerous if attackers can directly influence these code resources in unexpected ways.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "Implementation : For any externally-influenced input, check the input against an allowlist of acceptable values.Implementation : Refactor the code so that it does not need to be dynamically managed.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "834", "Name": "Excessive Iteration", "Description": "According to SOAR, the following detection techniques may be useful:", "Extended_Description": "If the iteration can be influenced by an attacker, this weakness could allow attackers to consume excessive resources such as CPU or memory. In many cases, a loop does not need to be infinite in order to cause enough resource consumption to adversely affect the product or its host system; it depends on the amount of resources consumed per iteration.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: AmplificationDoS: Crash, Exit, or Restart. Note: Excessive looping will cause unexpected consumption of resources, such as CPU cycles or memory. The product's operation may slow down, or cause a long time to respond. If limited resources such as memory are consumed for each iteration, the loop may eventually cause a crash or program exit due to exhaustion of resources, such as an out-of-memory error.", "Detection_Methods": "Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1322", "Name": "Use of Blocking Code in Single-threaded, Non-blocking Context", "Description": "For expensive computations, consider breaking them up into\n\t\t\t\t\tmultiple smaller computations. Refer to the documentation of the\n\t\t\t\t\tframework being used for guidance.", "Extended_Description": "When an attacker can directly invoke the blocking code, or the blocking code can be affected by environmental conditions that can be influenced by an attacker, then this can lead to a denial of service by causing unexpected hang or freeze of the code. Examples of blocking code might be an expensive computation or calling\n\t\t\t\tblocking library calls, such as those that perform exclusive file operations or require a successful network operation.Due to limitations in multi-thread models, single-threaded\n\t\t\t\tmodels are used to overcome the resource constraints that are caused by using\n\t\t\t\tmany threads. In such a model, all code should generally be\n\t\t\t\tnon-blocking. If blocking code is called, then the event loop will\n\t\t\t\teffectively be stopped, which can be undesirable or dangerous.  Such\n\t\t\t\tmodels are used in Python asyncio, Vert.x, and Node.js, or other\n\t\t\t\tcustom event loop code.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU). Note: An unexpected call to blocking code can trigger an infinite loop, or a large loop that causes the software to pause and wait indefinitely.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Generally speaking, blocking calls should be\n\t\t\t\t\treplaced with non-blocking alternatives that can be used asynchronously.\n\t\t\t\t\tExpensive computations should be passed off to worker threads, although\n\t\t\t\t\tthe correct approach depends on the framework being used.Implementation : For expensive computations, consider breaking them up into\n\t\t\t\t\tmultiple smaller computations. Refer to the documentation of the\n\t\t\t\t\tframework being used for guidance.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "834", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "835", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1323", "Name": "Improper Management of Sensitive Trace Data", "Description": "Tag traces to indicate owner and debugging privilege level (designer, OEM, or end user) needed to access that trace.", "Extended_Description": "To facilitate verification of complex System-on-Chip\n                    (SoC) designs, SoC integrators add specific IP blocks that\n                    trace the SoC's internal signals in real-time. This\n                    infrastructure enables observability of the SoC's internal\n                    behavior, validation of its functional design,\n                    and detection of hardware and software bugs. Such tracing\n                    IP blocks collect traces from several sources on the SoC\n                    including the CPU, crypto coprocessors, and on-chip fabrics. Traces collected from these sources are then\n                    aggregated inside trace IP block and forwarded to trace\n                    sinks, such as debug-trace ports that facilitate debugging by\n                    external hardware and software debuggers.Since\n                    these traces are collected from several security-sensitive\n                    sources, they must be protected against untrusted\n                    debuggers. If they are stored in unprotected memory, an\n                    untrusted software debugger can access these traces and\n                    extract secret information. Additionally, if\n                    security-sensitive traces are not tagged as secure, an\n                    untrusted hardware debugger might access them to extract\n                    confidential information.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Memory. Note: An adversary can read secret values if they are captured in debug traces and stored unsafely.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Tag traces to indicate owner and debugging privilege level (designer, OEM, or end user) needed to access that trace.", "Demonstrative_Examples": ". In a SoC, traces generated from sources\n                        include security-sensitive IP blocks such as CPU (with\n                        tracing information such as instructions executed and\n                        memory operands), on-chip fabric (e.g., memory-transfer\n                        signals, transaction type and destination, and\n                        on-chip-firewall-error signals), power-management\n                        IP blocks (e.g., clock- and power-gating signals), and\n                        cryptographic coprocessors (e.g., cryptographic keys and\n                        intermediate values of crypto operations), among\n                        other non-security-sensitive IP blocks including timers\n                        and other functional blocks. The collected traces are\n                        then forwarded to the debug and trace interface used by\n                        the external hardware debugger.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "770", "Name": "Allocation of Resources Without Limits or Throttling", "Description": "Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Extended_Description": "Code frequently has to work with limited resources, so programmers must be careful to ensure that resources are not consumed too quickly, or too easily.  Without use of quotas, resource limits, or other protection mechanisms, it can be easy for an attacker to consume many resources by rapidly making many requests, or causing larger resources to be used than is needed. When too many resources are allocated, or if a single resource is too large, then it can prevent the code from working correctly, possibly leading to a denial of service.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Resource Consumption (Other). Note: When allocating resources without limits, an attacker could prevent other systems, applications, or processes from accessing the same type of resource.", "Detection_Methods": "Method Name: Manual Static Analysis. Description: Manual static analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. If denial-of-service is not considered a significant risk, or if there is strong emphasis on consequences such as code execution, then manual analysis may not focus on this weakness at all. Method Name: Fuzzing. Description: While fuzzing is typically geared toward finding low-level implementation bugs, it can inadvertently find uncontrolled resource allocation problems. This can occur when the fuzzer generates a large number of test cases but does not restart the targeted product in between test cases. If an individual test case produces a crash, but it does not do so reliably, then an inability to limit resource allocation may be the cause.When the allocation is directly affected by numeric inputs, then fuzzing may produce indications of this weakness. Method Name: Automated Dynamic Analysis. Description: Certain automated dynamic analysis techniques may be effective in producing side effects of uncontrolled resource allocation problems, especially with resources such as processes, memory, and connections. The technique may involve generating a large number of requests to the product within a short time frame. Manual analysis is likely required to interpret the results. Method Name: Automated Static Analysis. Description: Specialized configuration or tuning may be required to train automated tools to recognize this weakness.Automated static analysis typically has limited utility in recognizing unlimited allocation problems, except for the missing release of program-independent system resources such as files, sockets, and processes, or unchecked arguments to memory. For system resources, automated static analysis may be able to detect circumstances in which resources are not released after they have expired, or if too much of a resource is requested at once, as can occur with memory. Automated analysis of configuration files may be able to detect settings that do not specify a maximum value.Automated static analysis tools will not be appropriate for detecting exhaustion of custom resources, such as an intended security policy in which a bulletin board user is only allowed to make a limited number of posts per day.", "Potential_Mitigations": "Requirements : Clearly specify the minimum and maximum expectations for capabilities, and dictate which behaviors are acceptable when resource allocation reaches limits.Architecture and Design : Limit the amount of resources that are accessible to unprivileged users. Set per-user limits for resources. Allow the system administrator to define these limits. Be careful to avoid CWE-410.Architecture and Design : Design throttling mechanisms into the system architecture. The best protection is to limit the amount of resources that an unauthorized user can cause to be expended. A strong authentication and access control model will help prevent such attacks from occurring in the first place, and it will help the administrator to identify who is committing the abuse. The login application should be protected against DoS attacks as much as possible. Limiting the database access, perhaps by caching result sets, can help minimize the resources expended. To further limit the potential for a DoS attack, consider tracking the rate of requests received from users and blocking requests that exceed a defined rate threshold.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Architecture and Design : Mitigation of resource exhaustion attacks requires that the target system either:\n                     \n                        recognizes the attack and denies that user further access for a given amount of time, typically by using increasing time delays\n                        uniformly throttles all requests in order to make it more difficult to consume resources more quickly than they can again be freed.\n                     \n                  The first of these solutions is an issue in itself though, since it may allow attackers to prevent the use of the system by a particular valid user. If the attacker impersonates the valid user, they may be able to prevent the user from accessing the server in question.\n                  The second solution can be difficult to effectively institute -- and even when properly done, it does not provide a full solution. It simply requires more resources on the part of the attacker.Architecture and Design : Ensure that protocols have specific limits of scale placed on them.Architecture and Design : If the program must fail, ensure that it fails gracefully (fails closed). There may be a temptation to simply let the program fail poorly in cases such as low memory conditions, but an attacker may be able to assert control before the software has fully exited. Alternately, an uncontrolled failure could cause cascading problems with other downstream components; for example, the program could send a signal to a downstream process so the process immediately knows that a problem has occurred and has a better chance of recovery.\n                  Ensure that all failures in resource allocation place the system into a safe posture.Operation : Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Demonstrative_Examples": "This code allocates a socket and forks each time it receives a new connection.. The program does not track how many connections have been made, and it does not limit the number of connections. Because forking is a relatively expensive operation, an attacker would be able to cause the system to run out of CPU, processes, or memory by making a large number of connections. Alternatively, an attacker could consume all available connections, preventing others from accessing the system remotely.In the following example a server socket connection is used to accept a request to store data on the local file system using a specified filename. The method openSocketConnection establishes a server socket to accept requests from a client. When a client establishes a connection to this service the getNextMessage method is first used to retrieve from the socket the name of the file to store the data, the openFileToWrite method will validate the filename and open a file to write to on the local file system. The getNextMessage is then used within a while loop to continuously read data from the socket and output the data to the file until there is no longer any data from the socket.. This example creates a situation where data can be dumped to a file on the local file system without any limits on the size of the file. This could potentially exhaust file or disk resources and/or limit other clients' ability to access the service.In the following example, the processMessage method receives a two dimensional character array containing the message to be processed. The two-dimensional character array contains the length of the message in the first character array and the message body in the second character array. The getMessageLength method retrieves the integer value of the length from the first character array. After validating that the message length is greater than zero, the body character array pointer points to the start of the second character array of the two-dimensional character array and memory is allocated for the new body character array.. This example creates a situation where the length of the body character array can be very large and will consume excessive memory, exhausting system resources. This can be avoided by restricting the length of the second character array with a maximum length checkIn the following example, a server object creates a server socket and accepts client connections to the socket. For every client connection to the socket a separate thread object is generated using the ClientSocketThread class that handles request made by the client through the socket.. In this example there is no limit to the number of client connections and client threads that are created. Allowing an unlimited number of client connections and threads could potentially overwhelm the system and system resources.. An unnamed web site allowed a user to purchase tickets for an event. A menu option allowed the user to purchase up to 10 tickets, but the back end did not restrict the actual number of tickets that could be purchased.. Here the problem is that every time a connection is made, more memory is allocated. So if one just opened up more and more connections, eventually the machine would run out of memory.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "1325", "Name": "Improperly Controlled Sequential Memory Allocation", "Description": "Run the program using system-provided resource limits for memory. This might still cause the program to crash or exit, but the impact to the rest of the system will be minimized.", "Extended_Description": "While the product might limit the amount of memory that is allocated in a single operation for a single object (such as a malloc of an array), if an attacker can cause multiple objects to be allocated in separate operations, then this might cause higher total memory consumption than the developer intended, leading to a denial of service.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Memory). Note: Not controlling memory allocation can result in a request for too much system memory, possibly leading to a crash of the application due to out-of-memory conditions, or the consumption of a large amount of memory on the system.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Ensure multiple allocations of the same kind of object are properly tracked - possibly across multiple sessions, requests, or messages. Define an appropriate strategy for handling requests that exceed the limit, and consider supporting a configuration option so that the administrator can extend the amount of memory to be used if necessary.Operation : Run the program using system-provided resource limits for memory. This might still cause the program to crash or exit, but the impact to the rest of the system will be minimized.", "Demonstrative_Examples": "This example contains a small allocation of stack memory. When the program was first constructed, the number of times this memory was allocated was probably inconsequential and presented no problem. Over time, as the number of objects in the database grow, the number of allocations will grow - eventually consuming the available stack, i.e. \"stack exhaustion.\" An attacker who is able to add elements to the database could cause stack exhaustion more rapidly than assumed by the developer.. Since this uses alloca(), it allocates memory directly on the stack.  If end_limit is large enough, then the stack can be entirely consumed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "770", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "789", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "476", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1326", "Name": "Missing Immutable Root of Trust in Hardware", "Description": "During implementation and test, the RoT memory location should be demonstrated to not allow further programming/writes.", "Extended_Description": "A System-on-Chip (SoC) implements secure boot by verifying or authenticating signed boot code. The signing of the code is achieved by an entity that the SoC trusts.  Before executing the boot code, the SoC verifies that the code or the public key with which the code has been signed has not been tampered with. The other data upon which the SoC depends are system-hardware settings in fuses such as whether \"Secure Boot is enabled\". These data play a crucial role in establishing a Root of Trust (RoT) to execute secure-boot flows.One of the many ways RoT is achieved is by storing the code and data in memory or fuses. This memory should be immutable, i.e., once the RoT is programmed/provisioned in memory, that memory should be locked and prevented from further programming or writes. If the memory contents (i.e., RoT) are mutable, then an adversary can modify the RoT to execute their choice of code, resulting in a compromised secure boot.Note that, for components like ROM, secure patching/update features should be supported to allow authenticated and authorized updates in the field.", "Modes_Of_Introduction": "Implementation: Such issues could be introduced during policy definition, hardware architecture, design, manufacturing, and/or provisioning. They can be identified later during testing or system configuration phases.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Dynamic Analysis. Description: Automated testing can verify that RoT components are immutable. Method Name: Architecture or Design Review. Description: Root of trust elements and memory should be part of architecture and design reviews.", "Potential_Mitigations": "Architecture and Design : When architecting the system, the RoT should be designated for storage in a memory that does not allow further programming/writes.Implementation : During implementation and test, the RoT memory location should be demonstrated to not allow further programming/writes.", "Demonstrative_Examples": "The RoT is stored in memory. This memory can be modified by an adversary. For example, if an SoC implements \"Secure Boot\" by storing the boot code in an off-chip/on-chip flash, the contents of the flash can be modified by using a flash programmer. Similarly, if the boot code is stored in ROM (Read-Only Memory) but the public key or the hash of the public key (used to enable \"Secure Boot\") is stored in Flash or a memory that is susceptible to modifications or writes, the implementation is vulnerable.. In general, if the boot code, key materials and data that enable \"Secure Boot\" are all mutable, the implementation is vulnerable.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1327", "Name": "Binding to an Unrestricted IP Address", "Description": "Unwanted connections to the configured server may be denied through a firewall or other packet filtering measures.", "Extended_Description": "When a server binds to the address 0.0.0.0, it allows connections from every IP address on the local machine, effectively exposing the server to every possible network. This might be much broader access than intended by the developer or administrator, who might only be expecting the server to be reachable from a single interface/network.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : Assign IP addresses that are not 0.0.0.0.System Configuration : Unwanted connections to the configured server may be denied through a firewall or other packet filtering measures.", "Demonstrative_Examples": "The following code snippet uses 0.0.0.0 in a Puppet script.. The Puppet code snippet is used to provision a signing server that will use 0.0.0.0 to accept traffic. However, as 0.0.0.0 is unrestricted, malicious users may use this IP address to launch frequent requests and cause denial of service attacks.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1328", "Name": "Security Version Number Mutable to Older Versions", "Description": "During implementation and test, security version data should be demonstrated to be read-only and access controls should be validated.", "Extended_Description": "A System-on-Chip (SoC) implements secure boot or verified boot. It might support a security version number, which prevents downgrading the current firmware to a vulnerable version. Once downgraded to a previous version, an adversary can launch exploits on the SoC and thus compromise the security of the SoC. These downgrade attacks are also referred to as roll-back attacks.The security version number must be stored securely and persistently across power-on resets. A common weakness is that the security version number is modifiable by an adversary, allowing roll-back or downgrade attacks or, under certain circumstances, preventing upgrades (i.e. Denial-of-Service on upgrades). In both cases, the SoC is in a vulnerable state.", "Modes_Of_Introduction": "Implementation: Such issues could be introduced during hardware architecture and design, and can be identified later during testing or system configuration phases.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAuthenticationAuthorization. Impacts: Other. Note: Impact includes roll-back or downgrade to a vulnerable version of the firmware or DoS (prevent upgrades).", "Detection_Methods": "Method Name: Automated Dynamic Analysis. Description: Mutability of stored security version numbers and programming with older firmware images should be part of automated testing. Method Name: Architecture or Design Review. Description: Anti-roll-back features should be reviewed as part of Architecture or Design review.", "Potential_Mitigations": "Architecture and Design : When architecting the system, security version data should be designated for storage in registers that are either read-only or have access controls that prevent modification by an untrusted agent.Implementation : During implementation and test, security version data should be demonstrated to be read-only and access controls should be validated.", "Demonstrative_Examples": "A new version of firmware is signed with a security version number higher than the previous version. During the firmware update process the SoC checks for the security version number and upgrades the SoC firmware with the latest version. This security version number is stored in persistent memory upon successful upgrade for use across power-on resets.. In general, if the security version number is mutable, the implementation is vulnerable. A mutable security version number allows an adversary to change the security version to a lower value to allow roll-back or to a higher value to prevent future upgrades.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "757", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1330", "Name": "Remanent Data Readable after Memory Erase", "Description": "Support for secure-erase commands that apply multiple cycles of overwriting memory with known patterns and of erasing actual content.\n\t\t\t\t\tSupport for cryptographic erase in self-encrypting, memory devices.\n\t\t\t\t\tExternal, physical tools to erase memory such as ultraviolet-rays-based erase of Electrically erasable, programmable, read-only memory (EEPROM).\n\t\t\t\t\tPhysical destruction of media device. This is done for repurposed or scrapped devices that are no longer in use.", "Extended_Description": "Data remanence occurs when stored, memory content is not fully lost after a memory-clear or -erase operation. Confidential memory contents can still be readable through data remanence in the hardware.Data remanence can occur because of performance optimization or memory organization during 'clear' or 'erase' operations, like a design that allows the memory-organization metadata (e.g., file pointers) to be erased without erasing the actual memory content. To protect against this weakness, memory devices will often support different commands for optimized memory erase and explicit secure erase.Data remanence can also happen because of the physical properties of memory circuits in use. For example, static, random-access-memory (SRAM) and dynamic, random-access-memory (DRAM) data retention is based on the charge retained in the memory cell, which depends on factors such as power supply, refresh rates, and temperature.Other than explicit erase commands, self-encrypting, secure-memory devices can also support secure erase through cryptographic erase commands. In such designs, only the decryption keys for encrypted data stored on the device are erased. That is, the stored data are always remnant in the media after a cryptographic erase. However, only the encrypted data can be extracted. Thus, protection against data recovery in such designs relies on the strength of the encryption algorithm.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Modify MemoryRead Memory. Note: Confidential data are readable to untrusted agent.", "Detection_Methods": "Method Name: Architecture or Design Review. Description:  Method Name: Dynamic Analysis with Manual Results Interpretation. Description:", "Potential_Mitigations": "Architecture and Design : Support for secure-erase commands that apply multiple cycles of overwriting memory with known patterns and of erasing actual content.\n\t\t\t\t\tSupport for cryptographic erase in self-encrypting, memory devices.\n\t\t\t\t\tExternal, physical tools to erase memory such as ultraviolet-rays-based erase of Electrically erasable, programmable, read-only memory (EEPROM).\n\t\t\t\t\tPhysical destruction of media device. This is done for repurposed or scrapped devices that are no longer in use.", "Demonstrative_Examples": "Consider a device that uses flash memory for non-volatile-data storage. To optimize flash-access performance or reliable-flash lifetime, the device might limit the number of flash writes/erases by maintaining some state in internal SRAM and only committing changes to flash memory periodically.. The device also supports user reset to factory defaults with the expectation that all personal information is erased from the device after this operation. On factory reset, user files are erased using explicit, erase commands supported by the flash device.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1301", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1301", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "1331", "Name": "Improper Isolation of Shared Resources in Network On Chip (NoC)", "Description": "Implement priority-based arbitration inside the NoC and have dedicated buffers or virtual channels for routing secret data from trusted agents.", "Extended_Description": "Typically, network on chips (NoC) have many internal resources that are shared between packets from different trust domains. These resources include internal buffers, crossbars and switches, individual ports, and channels. The sharing of resources causes contention and introduces interference between differently trusted domains, which poses a security threat via a timing channel, allowing attackers to infer data that belongs to a trusted agent. This may also result in introducing network interference, resulting in degraded throughput and latency.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityAvailability. Impacts: DoS: Resource Consumption (Other)Varies by ContextOther. Note: Attackers may infer data that belongs to a trusted agent. The methods used to perform this attack may result in noticeably increased resource consumption.", "Detection_Methods": "Method Name: Manual Analysis. Description: Providing marker flags to send through the interfaces coupled with examination of which users are able to read or manipulate the flags will help verify that the proper isolation has been achieved and is effective.", "Potential_Mitigations": "Architecture and Design : Implement priority-based arbitration inside the NoC and have dedicated buffers or virtual channels for routing secret data from trusted agents.", "Demonstrative_Examples": "Consider a NoC that implements a one-dimensional mesh network with four nodes. This supports two flows: Flow A from node 0 to node 3 (via node 1 and node 2) and Flow B from node 1 to node 2. Flows A and B share a common link between Node 1 and Node 2.  Only one flow can use the link in each cycle.. One of the masters to this NoC implements a cryptographic algorithm (RSA), and another master to the NoC is a core that can be exercised by an attacker. The RSA algorithm performs a modulo multiplication of two large numbers and depends on each bit of the secret key. The algorithm examines each bit in the secret key and only performs multiplication if the bit is 1. This algorithm is known to be prone to timing attacks. Whenever RSA performs multiplication, there is additional network traffic to the memory controller. One of the reasons for this is cache conflicts.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "653", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "1189", "View_ID": "1194", "Ordinal": null}]}, {"ID": "1332", "Name": "Improper Handling of Faults that Lead to Instruction Skips", "Description": "Ensure that fault mitigations are strong enough\n                        in practice. For example, a low power detection\n                        mechanism that takes 50 clock cycles to trigger at lower\n                        voltages may be an insufficient security mechanism if\n                        the instruction counter has already progressed with no\n                        other CPU activity occurring.", "Extended_Description": "The operating conditions of hardware may change\n              in ways that cause unexpected behavior to occur,\n              including the skipping of security-critical CPU\n              instructions. Generally, this can occur due to\n              electrical disturbances or when the device operates\n              outside of its expected conditions.In practice, application code may contain\n\t\t\t  conditional branches that are security-sensitive (e.g.,\n\t\t\t  accepting or rejecting a user-provided password). These\n\t\t\t  conditional branches are typically implemented by a\n\t\t\t  single conditional branch instruction in the program\n\t\t\t  binary which, if skipped, may lead to effectively\n\t\t\t  flipping the branch condition - i.e., causing the wrong\n\t\t\t  security-sensitive branch to be taken. This affects\n\t\t\t  processes such as firmware authentication, password\n\t\t\t  verification, and other security-sensitive decision\n\t\t\t  points.Attackers can use fault injection techniques to\n\t\t\t  alter the operating conditions of hardware so that\n\t\t\t  security-critical instructions are skipped more\n\t\t\t  frequently or more reliably than they would in a\n\t\t\t  \"natural\" setting.", "Modes_Of_Introduction": "Architecture and Design: Failure to design appropriate countermeasures to common fault injection techniques can manifest this weakness.Implementation: This weakness can arise if the hardware design incorrectly implements countermeasures to prevent fault injection.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAuthentication. Impacts: Bypass Protection MechanismAlter Execution LogicUnexpected State. Note: Depending on the context, instruction skipping can\n                        have a broad range of consequences related to the\n                        generic bypassing of security critical code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can be found using automated static analysis once a developer has indicated which code paths are critical to protect. Method Name: Simulation / Emulation. Description: This weakness can be found using automated dynamic analysis. Both emulation of a CPU with instruction skips, as well as RTL simulation of a CPU IP, can indicate parts of the code that are sensitive to faults due to instruction skips. Method Name: Manual Analysis. Description: This weakness can be found using manual (static) analysis. The analyst has security objectives that are matched against the high-level code. This method is less precise than emulation, especially if the analysis is done at the higher level language rather than at assembly level.", "Potential_Mitigations": "Architecture and Design : Design strategies for ensuring safe failure if\n                        inputs, such as Vcc, are modified out of acceptable\n                        ranges.Architecture and Design : Design strategies for ensuring safe behavior if\n                        instructions attempt to be skipped.Architecture and Design : Identify mission critical secrets that should\n                          be wiped if faulting is detected, and design a\n                          mechanism to do the deletion.Implementation : Add redundancy by performing an operation\n                          multiple times, either in space or time, and perform\n                          majority voting. Additionally, make conditional\n                          instruction timing unpredictable.Implementation : Use redundant operations or canaries to\n                          detect and respond to faults.Implementation : Ensure that fault mitigations are strong enough\n                        in practice. For example, a low power detection\n                        mechanism that takes 50 clock cycles to trigger at lower\n                        voltages may be an insufficient security mechanism if\n                        the instruction counter has already progressed with no\n                        other CPU activity occurring.", "Demonstrative_Examples": "A smart card contains authentication credentials that are used as authorization to enter a building. The credentials are only accessible when a correct PIN is presented to the card.. There are several ways this weakness could be fixed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1384", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1247", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "407", "Name": "Inefficient Algorithmic Complexity", "Description": "An algorithm in a product has an inefficient worst-case computational complexity that may be detrimental to system performance and can be triggered by an attacker, typically using crafted manipulations that ensure that the worst case is being reached.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Resource Consumption (Other). Note: The typical consequence is CPU consumption, but memory consumption and consumption of other resources can also occur.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This example attempts to check if an input string is a \"sentence\" [REF-1164].. The regular expression has a vulnerable backtracking clause inside (\\w+\\s?)*$ which can be triggered to cause a Denial of Service by processing particular phrases.To fix the backtracking problem, backtracking is removed with the ?= portion of the expression which changes it to a lookahead and the \\2 which prevents the backtracking. The modified example is:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1333", "Name": "Inefficient Regular Expression Complexity", "Description": "Limit the length of the input that the regular expression will process.", "Extended_Description": "Attackers can create crafted inputs that\n\t\t  intentionally cause the regular expression to use\n\t\t  excessive backtracking in a way that causes the CPU\n\t\t  consumption to spike.", "Modes_Of_Introduction": "Implementation: A RegEx can be easy to create and read using unbounded matching characters, but the programmer might not consider the risk of  excessive backtracking.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use regular expressions that do not support backtracking, e.g. by removing nested quantifiers.System Configuration : Set backtracking limits in the configuration of the regular expression implementation, such as PHP's pcre.backtrack_limit. Also consider limits on execution time for the process.Implementation : Do not use regular expressions with untrusted input. If regular expressions must be used, avoid using backtracking in the expression.Implementation : Limit the length of the input that the regular expression will process.", "Demonstrative_Examples": "This example attempts to check if an input string is a \"sentence\" [REF-1164].. The regular expression has a vulnerable backtracking clause inside (\\w+\\s?)*$ which can be triggered to cause a Denial of Service by processing particular phrases.To fix the backtracking problem, backtracking is removed with the ?= portion of the expression which changes it to a lookahead and the \\2 which prevents the backtracking. The modified example is:This example attempts to check if an input string is a \"sentence\" and is modified for Perl [REF-1164].. The regular expression has a vulnerable backtracking clause inside (\\w+\\s?)*$ which can be triggered to cause a Denial of Service by processing particular phrases.To fix the backtracking problem, backtracking is removed with the ?= portion of the expression which changes it to a lookahead and the \\2 which prevents the backtracking. The modified example is:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "407", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "407", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "1334", "Name": "Unauthorized Error Injection Can Degrade Hardware Redundancy", "Description": "Add an access control layer atop any unprotected interfaces for injecting errors.", "Extended_Description": "To ensure the performance and functional reliability of certain components, hardware designers can implement hardware blocks for redundancy in the case that others fail. This redundant block can be prevented from performing as intended if the design allows unauthorized agents to inject errors into it. In this way, a path with injected errors may become unavailable to serve as a redundant channel. This may put the system into a degraded mode of operation which could be exploited by a subsequent attack.", "Modes_Of_Introduction": "Architecture and Design: Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.Implementation: Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.Integration: Such issues could be introduced during integration and identified later during Testing or System Configuration phases.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Ensure the design does not allow error injection in modes intended for normal run-time operation. Provide access controls on interfaces for injecting errors.Implementation : Disallow error injection in modes which are expected to be used for normal run-time operation. Provide access controls on interfaces for injecting errors.Integration : Add an access control layer atop any unprotected interfaces for injecting errors.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1335", "Name": "Incorrect Bitwise Shift of Integer", "Description": "Implicitly or explicitly add checks and mitigation for negative or over-shift values.", "Extended_Description": "Specifying a value to be shifted by a negative amount is undefined in various languages. Various computer architectures implement this action in different ways. The compilers and interpreters when generating code to accomplish a shift generally do not do a check for this issue.Specifying an over-shift, a shift greater than or equal to the number of bits contained in a value to be shifted, produces a result which varies by architecture and compiler. In some languages, this action is specifically listed as producing an undefined result.", "Modes_Of_Introduction": "Implementation: Adding shifts without properly verifying the size and sign of the shift amount.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Implicitly or explicitly add checks and mitigation for negative or over-shift values.", "Demonstrative_Examples": "A negative shift amount for an x86 or x86_64 shift instruction will produce the number of bits to be shifted by taking a 2's-complement of the shift amount and effectively masking that amount to the lowest 6 bits for a 64 bit shift instruction.. The example above ends up with a shift amount of -5. The hexadecimal value is FFFFFFFFFFFFFFFD which, when bits above the  6th bit are masked off, the shift amount becomes a binary shift value of 111101 which is 61 decimal. A shift of 61 produces a very different result than -5. The previous example is a very simple version of the following code which is probably more realistic of what happens in a real system.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "94", "Name": "Improper Control of Generation of Code ('Code Injection')", "Description": "Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).", "Extended_Description": "When a product allows a user's input to contain code syntax, it might be possible for an attacker to craft the code in such a way that it will alter the intended control flow of the product. Such an alteration could lead to arbitrary code execution.Injection problems encompass a wide variety of issues -- all mitigated in very different ways. For this reason, the most effective way to discuss these weaknesses is to note the distinct features which classify them as injection weaknesses. The most important issue to note is that all injection problems share one thing in common -- i.e., they allow for the injection of control plane data into the user-controlled data plane. This means that the execution of the process may be altered by sending code in through legitimate data channels, using no other mechanism. While buffer overflows, and many other flaws, involve the use of some further issue to gain execution, injection problems need only for the data to be parsed. The most classic instantiations of this category of weakness are SQL injection and format string vulnerabilities.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: In some cases, injectable code controls authentication; this may lead to a remote vulnerability.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Injected code can access resources that the attacker is directly prevented from accessing.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: Code injection attacks can lead to loss of data integrity in nearly all cases as the control-plane data injected is always incidental to data recall or writing. Additionally, code injection can often result in the execution of arbitrary code.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: Often the actions performed by injected control code are unlogged.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Refactor your program so that you do not have to dynamically generate code.Architecture and Design : Run your code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which code can be executed by your product.\n                  Examples include the Unix chroot jail and AppArmor. In general, managed code may provide some protection.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of your application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  To reduce the likelihood of code injection, use stringent allowlists that limit which constructs are allowed. If you are dynamically constructing code that invokes a function, then verifying that the input is alphanumeric might be insufficient. An attacker might still be able to reference a dangerous function that you did not intend to allow, such as system(), exec(), or exit().Testing : Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.Testing : Use dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.Operation : Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).Operation : Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).", "Demonstrative_Examples": "This example attempts to write user messages to a message file and allow users to view them.. While the programmer intends for the MessageFile to only include data, an attacker can provide a message such as:edit-config.pl: This CGI script is used to modify settings in a configuration file.. The script intends to take the 'action' parameter and invoke one of a variety of functions based on the value of that parameter - config_file_add_key(), config_file_set_key(), or config_file_delete_key(). It could set up a conditional to invoke each function separately, but eval() is a powerful way of doing the same thing in fewer lines of code, especially when a large number of functions or variables are involved. Unfortunately, in this case, the attacker can provide other values in the action parameter, such as:This simple script asks a user to supply a list of numbers as input and adds them together.. The eval() function can take the user-supplied list and convert it into a Python list object, therefore allowing the programmer to use list comprehension methods to work with the data. However, if code is supplied to the eval() function, it will execute that code. For example, a malicious user could supply the following string:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "913", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1336", "Name": "Improper Neutralization of Special Elements Used in a Template Engine", "Description": "Use the template engine's sandbox or restricted mode, if available.", "Extended_Description": "Many web applications use template engines that allow developers to insert externally-influenced values into free text or messages in order to generate a full web page, document, message, etc. Such engines include Twig, Jinja2, Pug, Java Server Pages, FreeMarker, Velocity, ColdFusion, Smarty, and many others - including PHP itself. Some CMS (Content Management Systems) also use templates.Template engines often have their own custom command or expression language. If an attacker can influence input into a template before it is processed, then the attacker can invoke arbitrary expressions, i.e. perform injection attacks. For example, in some template languages, an attacker could inject the expression \"{{7*7}}\" and determine if the output returns \"49\" instead. The syntax varies depending on the language.In some cases, XSS-style attacks can work, which can obscure the root cause if the developer does not closely investigate the root cause of the error.Template engines can be used on the server or client, so both \"sides\" could be affected by injection. The mechanisms of attack or the affected technologies might be different, but the mistake is fundamentally the same.", "Modes_Of_Introduction": "Architecture and Design: The developer might choose a template engine that makes it easier for programmers to write vulnerable code.Implementation: The programmer might not use engine's built-in sandboxes or other capabilities to escape or otherwise prevent template injection from untrusted input.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Choose a template engine that offers a sandbox or restricted mode, or at least limits the power of any available expressions, function calls, or commands.Implementation : Use the template engine's sandbox or restricted mode, if available.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "94", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1338", "Name": "Improper Protections Against Hardware Overheating", "Description": "The platform should support cooling solutions such as fans that can be modulated based on device-operation needs to maintain a stable temperature.", "Extended_Description": "Hardware, electrical circuits, and semiconductor silicon have thermal side effects, such that some of the energy consumed by the device gets dissipated as heat and increases the temperature of the device. For example, in semiconductors, higher-operating frequency of silicon results in higher power dissipation and heat. The leakage current in CMOS circuits increases with temperature, and this creates positive feedback that can result in thermal runaway and damage the device permanently.Any device lacking protections such as thermal sensors, adequate platform cooling, or thermal insulation is susceptible to attacks by malicious software that might deliberately operate the device in modes that result in overheating. This can be used as an effective denial of service (DoS) or permanent denial of service (PDoS) attack.Depending on the type of hardware device and its expected usage, such thermal overheating can also cause safety hazards and reliability issues. Note that battery failures can also cause device overheating but the mitigations and examples included in this submission cannot reliably protect against a battery failure.There can be similar weaknesses with lack of protection from attacks based on overvoltage or overcurrent conditions. However, thermal heat is generated by hardware operation and the device should implement protection from overheating.", "Modes_Of_Introduction": "Implementation: Such issues could be introduced during hardware architecture, design or implementation.", "Common_Consequences": "", "Detection_Methods": "Method Name: Dynamic Analysis with Manual Results Interpretation. Description: Dynamic tests should be performed to stress-test temperature controls. Method Name: Architecture or Design Review. Description: Power management controls should be part of Architecture and Design reviews.", "Potential_Mitigations": "Architecture and Design : Temperature maximum and minimum limits should be enforced using thermal sensors both in silicon and at the platform level.Implementation : The platform should support cooling solutions such as fans that can be modulated based on device-operation needs to maintain a stable temperature.", "Demonstrative_Examples": "Malicious software running on a core can execute instructions that consume maximum power or increase core frequency. Such a power-virus program could execute on the platform for an extended time to overheat the device, resulting in permanent damage.. Execution core and platform do not support thermal sensors, performance throttling, or platform-cooling countermeasures to ensure that any software executing on the system cannot cause overheating past the maximum allowable temperature.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1339", "Name": "Insufficient Precision or Accuracy of a Real Number", "Description": "The developer or maintainer can move to a more accurate representation of real numbers.  In extreme cases, the programmer can move to representations such as ratios of BigInts which can represent real numbers to extremely fine precision. The programmer can also use the concept of an Unum real. The memory and CPU tradeoffs of this change must be examined. Since floating point reals are used in many products and many locations, they are implemented in hardware and most format changes will cause the calculations to be moved into software resulting in slower products.", "Extended_Description": "When a security decision or calculation requires highly precise, accurate numbers such as financial calculations or prices, then small variations in the number could be exploited by an attacker.There are multiple ways to store the fractional part of a real number in a computer. In all of these cases, there is a limit to the accuracy of recording a fraction. If the fraction can be represented in a fixed number of digits (binary or decimal), there might not be enough digits assigned to represent the number. In other cases the number cannot be represented in a fixed number of digits due to repeating in decimal or binary notation (e.g. 0.333333...) or due to a transcendental number such as \u03a0 or \u221a2. Rounding of numbers can lead to situations where the computer results do not adequately match the result of sufficiently accurate math.", "Modes_Of_Introduction": "Implementation: This weakness is introduced when the developer picks a method to represent a real number. The weakness may only be visible with very specific numeric inputs.", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: This weakness will generally lead to undefined results and therefore crashes. In some implementations the program will halt if the weakness causes an overflow during a calculation.Scopes: Integrity. Impacts: Execute Unauthorized Code or Commands. Note: The results of the math are not as expected. This could cause issues where a value would not be properly calculated and provide an incorrect answer.Scopes: ConfidentialityAvailabilityAccess Control. Impacts: Read Application DataModify Application Data. Note: This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a product's implicit security policy.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : The developer or maintainer can move to a more accurate representation of real numbers.  In extreme cases, the programmer can move to representations such as ratios of BigInts which can represent real numbers to extremely fine precision. The programmer can also use the concept of an Unum real. The memory and CPU tradeoffs of this change must be examined. Since floating point reals are used in many products and many locations, they are implemented in hardware and most format changes will cause the calculations to be moved into software resulting in slower products.", "Demonstrative_Examples": "Muller's Recurrence is a series that is supposed to converge to the number 5. When running this series with the following code, different implementations of real numbers fail at specific iterations:. The chart below shows values for different data structures in the rust language when Muller's recurrence is executed to 80 iterations. The data structure f64 is a 64 bit float. The data structures I<number>F<number> are fixed representations 128 bits in length that use the first number as the size of the integer and the second size as the size of the fraction (e.g. I16F112 uses 16 bits for the integer and 112 bits for the fraction). The data structure of Ratio comes in three different implementations: i32 uses a ratio of 32 bit signed  integers,  i64 uses a ratio of 64 bit signed integers and BigInt uses a ratio of signed integer with up to 2^32 digits of base 256.  Notice how even with 112 bits of fractions or ratios of 64bit unsigned integers, this math still does not converge to an expected value of 5.. On February 25, 1991, during the eve of the of an Iraqi invasion of Saudi Arabia, a Scud missile fired from Iraqi positions hit a US Army barracks in Dhahran, Saudi Arabia. It miscalculated time and killed 28 people [REF-1190].. Sleipner A, an offshore drilling platform in the North Sea, was incorrectly constructed with an underestimate of 50% of strength in a critical cluster of buoyancy cells needed for construction. This led to a leak in buoyancy cells during lowering, causing a seismic event of 3.0 on the Richter Scale and about $700M loss [REF-1281].", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "190", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "834", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}]}, {"ID": "134", "Name": "Use of Externally-Controlled Format String", "Description": "Run compilers and linkers with high warning levels, since they may detect incorrect usage.", "Extended_Description": "When an attacker can modify an externally-controlled format string, this can lead to buffer overflows, denial of service, or data representation problems.It should be noted that in some circumstances, such as internationalization, the set of format strings is externally controlled by design. If the source of these format strings is trusted (e.g. only contained in library files that are only modifiable by the system administrator), then the external control might not itself pose a vulnerability.", "Modes_Of_Introduction": "Implementation: The programmer rarely intends for a format string to be externally-controlled at all. This weakness is frequently introduced in code that constructs log messages, where a constant format string is omitted.Implementation: In cases such as localization and internationalization, the language-specific message repositories could be an avenue for exploitation, but the format string issue would be resultant, since attacker control of those repositories would also allow modification of message length, format, and content.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Memory. Note: Format string problems allow for information disclosure which can severely simplify exploitation of the program.Scopes: IntegrityConfidentialityAvailability. Impacts: Modify MemoryExecute Unauthorized Code or Commands. Note: Format string problems can result in the execution of arbitrary code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives. Method Name: Black Box. Description: Since format strings often occur in rarely-occurring erroneous conditions (e.g. for error message logging), they can be difficult to detect using black box methods. It is highly likely that many latent issues exist in executables that do not have associated source code (or equivalent source. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Requirements : Choose a language that is not subject to this flaw.Implementation : Ensure that all format string functions are passed a static string which cannot be controlled by the user, and that the proper number of arguments are always sent to that function as well. If at all possible, use functions that do not support the %n operator in format strings. [REF-116] [REF-117]Build and Compilation : Run compilers and linkers with high warning levels, since they may detect incorrect usage.", "Demonstrative_Examples": "The following program prints a string provided as an argument.. The example is exploitable, because of the call to printf() in the printWrapper() function. Note: The stack buffer was added to make exploitation more simple.The following code copies a command line argument into a buffer using snprintf().. This code allows an attacker to view the contents of the stack and write to the stack using a command line argument containing a sequence of formatting directives. The attacker can read from the stack by providing more formatting directives, such as %x, than the function takes as arguments to be formatted. (In this example, the function takes no arguments to be formatted.) By using the %n formatting directive, the attacker can write to the stack, causing snprintf() to write the number of bytes output thus far to the specified argument (rather than reading a value from the argument, which is the intended behavior). A sophisticated version of this attack will use four staggered writes to completely control the value of a pointer on the stack.Certain implementations make more advanced attacks even easier by providing format directives that control the location in memory to read from or write to. An example of these directives is shown in the following code, written for glibc:. This code produces the following output: 5 9 5 5 It is also possible to use half-writes (%hn) to accurately control arbitrary DWORDS in memory, which greatly reduces the complexity needed to execute an attack that would otherwise require four staggered writes, such as the one mentioned in the first example.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "123", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "675", "Name": "Multiple Operations on Resource in Single-Operation Context", "Description": "The product performs the same operation on a resource two or more times, when the operation should only be applied once.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "586", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "102", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1341", "Name": "Multiple Releases of Same Resource or Handle", "Description": "When closing a resource, set the resource's associated variable to NULL or equivalent value for the given language. Some APIs will ignore this null value without causing errors. For other APIs, this can lead to application crashes or exceptions, which may still be preferable to corrupting an unintended resource such as memory or data.", "Extended_Description": "Code typically requires \"opening\" handles or references to resources such as memory, files, devices, socket connections, services, etc. When the code is finished with using the resource, it is typically expected to \"close\" or \"release\" the resource, which indicates to the environment (such as the OS) that the resource can be re-assigned or reused by unrelated processes or actors - or in some cases, within the same process. API functions or other abstractions are often used to perform this release, such as free() or delete() within C/C++, or file-handle close() operations that are used in many languages.Unfortunately, the implementation or design of such APIs might expect the developer to be responsible for ensuring that such APIs are only called once per release of the resource. If the developer attempts to release the same resource/handle more than once, then the API's expectations are not met, resulting in undefined and/or insecure behavior. This could lead to consequences such as memory corruption, data corruption, execution path corruption, or other consequences.Note that while the implementation for most (if not all) resource reservation allocations involve a unique identifier/pointer/symbolic reference, then if this identifier is reused, checking the identifier for resource closure may result in a false state of openness and closing of the wrong resource. For this reason, reuse of identifiers is discouraged.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: For commonly-used APIs and resource types, automated tools often have signatures that can spot this issue. Method Name: Automated Dynamic Analysis. Description: Some compiler instrumentation tools such as AddressSanitizer (ASan) can indirectly detect some instances of this weakness.", "Potential_Mitigations": "Implementation : Change the code's logic so that the resource is only closed once. This might require simplifying or refactoring. This fix can be simple to do in small code blocks, but more difficult when multiple closes are buried within complex conditionals.Implementation : It can be effective to implement a flag that is (1) set when the resource is opened, (2) cleared when it is closed, and (3) checked before closing. This approach can be useful when there are disparate cases in which closes must be performed. However, flag-tracking can increase code complexity and requires diligent compliance by the programmer.Implementation : When closing a resource, set the resource's associated variable to NULL or equivalent value for the given language. Some APIs will ignore this null value without causing errors. For other APIs, this can lead to application crashes or exceptions, which may still be preferable to corrupting an unintended resource such as memory or data.", "Demonstrative_Examples": "This example attempts to close a file twice. In some cases, the C library fclose() function will catch the error and return an error code. In other implementations, a double-free (CWE-415) occurs, causing the program to fault. Note that the examples presented here are simplistic, and double fclose() calls will frequently be spread around a program, making them more difficult to find during code reviews.. There are multiple possible fixes. This fix only has one call to fclose(), which is typically the preferred handling of this problem - but this simplistic method is not always possible.The following code shows a simple example of a double free vulnerability.. Double free vulnerabilities have two common (and sometimes overlapping) causes:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "675", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "672", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1342", "Name": "Information Exposure through Microarchitectural State after Transient Execution", "Description": "Include instructions that explicitly remove traces of unneeded computations from software interactions with microarchitectural elements e.g. lfence, sfence, mfence, clflush.", "Extended_Description": "In many processor architectures an exception, mis-speculation, or microcode assist results in a flush operation to clear results that are no longer required. This action prevents these results from influencing architectural state that is intended to be visible from software. However, traces of this transient execution may remain in microarchitectural buffers, resulting in a change in microarchitectural state that can expose sensitive information to an attacker using side-channel analysis. For example, Load Value Injection (LVI) [REF-1202] can exploit direct injection of erroneous values into intermediate load and store buffers.Several conditions may need to be fulfilled for a successful attack:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Hardware ensures that no illegal data flows from faulting micro-ops exists at the microarchitectural level.Build and Compilation : Include instructions that explicitly remove traces of unneeded computations from software interactions with microarchitectural elements e.g. lfence, sfence, mfence, clflush.", "Demonstrative_Examples": "Faulting loads in a victim domain may trigger incorrect transient forwarding, which leaves secret-dependent traces in the microarchitectural state. Consider this example from [REF-1203].. A processor with this weakness will store the value of untrusted_arg (which may be provided by an attacker) to the stack, which is trusted memory. Additionally, this store operation will save this value in some microarchitectural buffer, e.g. the store queue.In this code gadget, \n\t\t\t\t\ttrusted_ptr is dereferenced while the attacker forces a page fault. The faulting load causes the processor to mis-speculate by forwarding untrusted_arg as the (speculative) load result. The processor then uses untrusted_arg for the pointer dereference. After the fault has been handled and the load has been re-issued with the correct argument, secret-dependent information stored at the address of trusted_ptr remains in microarchitectural state and can be extracted by an attacker using a code gadget.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "226", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "226", "View_ID": "1194", "Ordinal": "Primary"}]}, {"ID": "135", "Name": "Incorrect Calculation of Multi-Byte String Length", "Description": "Use length computing functions (e.g. strlen, wcslen, etc.) appropriately with their equivalent type (e.g.: byte, wchar_t, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: There are several ways in which improper string length checking may result in an exploitable condition. All of these, however, involve the introduction of buffer overflow conditions in order to reach an exploitable state.The first of these issues takes place when the output of a wide or multi-byte character string, string-length function is used as a size for the allocation of memory. While this will result in an output of the number of characters in the string, note that the characters are most likely not a single byte, as they are with standard character strings. So, using the size returned as the size sent to new or malloc and copying the string to this newly allocated memory will result in a buffer overflow.Another common way these strings are misused involves the mixing of standard string and wide or multi-byte string functions on a single string. Invariably, this mismatched information will result in the creation of a possibly exploitable buffer overflow condition.", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: This weakness may lead to a buffer overflow. Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy. This can often be used to subvert any other security service.Scopes: AvailabilityConfidentiality. Impacts: Read MemoryDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.Scopes: Confidentiality. Impacts: Read Memory. Note: In the case of an out-of-bounds read, the attacker may have access to sensitive information. If the sensitive information contains system details, such as the current buffers position in memory, this knowledge can be used to craft further attacks, possibly with more severe consequences.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Always verify the length of the string unit character.Implementation : Use length computing functions (e.g. strlen, wcslen, etc.) appropriately with their equivalent type (e.g.: byte, wchar_t, etc.)", "Demonstrative_Examples": "The following example would be exploitable if any of the commented incorrect malloc calls were used.. The output from the printf() statement would be:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1351", "Name": "Improper Handling of Hardware Behavior in Exceptionally Cold Environments", "Description": "The system should account for security primitive behavior when cooled outside standard temperatures.", "Extended_Description": "The hardware designer may improperly anticipate\n                    hardware behavior when exposed to exceptionally cold\n                    conditions. As a result they may introduce a weakness by not\n                    accounting for the modified behavior of critical components\n                    when in extreme environments.An example of a change in behavior is that power loss\n                    won't clear/reset any volatile state when cooled below\n                    standard operating temperatures. This may result in\n                    a weakness when the starting state of the volatile memory is\n                    being relied upon for a security decision. For example, a\n                    Physical Unclonable Function (PUF) may be supplied as a\n                    security primitive to improve confidentiality,\n                    authenticity, and integrity guarantees. However, when the\n                    PUF is paired with DRAM, SRAM, or another temperature\n                    sensitive entropy source, the system designer may introduce\n                    weakness by failing to account for the chosen entropy\n                    source's behavior at exceptionally low temperatures. In the\n                    case of DRAM and SRAM, when power is cycled at low\n                    temperatures, the device will not contain the bitwise\n                    biasing caused by inconsistencies in manufacturing and will\n                    instead contain the data from previous boot. Should the PUF\n                    primitive be used in a cryptographic construction which\n                    does not account for full adversary control of PUF seed\n                    data, weakness would arise.This weakness does not cover \"Cold Boot Attacks\"\n                    wherein RAM or other external storage is super cooled and\n                    read externally by an attacker.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityAuthentication. Impacts: Varies by ContextUnexpected State. Note: Consequences of this weakness are highly contextual.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : The system should account for security primitive behavior when cooled outside standard temperatures.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1384", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "138", "Name": "Improper Neutralization of Special Elements", "Description": "While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).", "Extended_Description": "Most languages and protocols have their own special elements such as characters and reserved words. These special elements can carry control implications. If product does not prevent external control or influence over the inclusion of such special elements, the control flow of the program may be altered from what was intended. For example, both Unix and Windows interpret the symbol < (\"less than\") as meaning \"read input from a file\".", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Developers should anticipate that special elements (e.g. delimiters, symbols) will be injected into input vectors of their product. One defense is to create an allowlist (e.g. a regular expression) that defines valid input according to the requirements specifications. Strictly filter any input that does not match against the allowlist. Properly encode your output, and quote any elements that have special meaning to the component with which you are communicating.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Use and specify an appropriate output encoding to ensure that the special elements are well-defined. A normal byte sequence in one encoding could be a special element in another.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "703", "Name": "Improper Check or Handling of Exceptional Conditions", "Description": "According to SOAR, the following detection techniques may be useful:", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": []}, {"ID": "346", "Name": "Origin Validation Error", "Description": "The product does not properly verify that the source of data or communication is valid.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlOther. Impacts: Gain Privileges or Assume IdentityVaries by Context. Note: An attacker can access any functionality that is inadvertently accessible to the source.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This Android application will remove a user account when it receives an intent to do so:. This application does not check the origin of the intent, thus allowing any malicious application to remove a user. Always check the origin of an intent, or create an allowlist of trusted applications using the manifest.xml file.These Android and iOS applications intercept URL loading within a WebView and perform special actions if a particular URL scheme is used, thus allowing the Javascript within the WebView to communicate with the application:. A call into native code can then be initiated by passing parameters within the URL:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": null}]}, {"ID": "1385", "Name": "Missing Origin Validation in WebSockets", "Description": "Treat data/input as untrusted in both directions and apply the same data/input sanitization as XSS, SQLi, etc.", "Extended_Description": "WebSockets provide a bi-directional low latency communication (near real-time) between a client and a server. WebSockets are different than HTTP in that the connections are long-lived, as the channel will remain open until the client or the server is ready to send the message, whereas in HTTP, once the response occurs (which typically happens immediately), the transaction completes.A WebSocket can leverage the existing HTTP protocol over ports 80 and 443, but it is not limited to HTTP. WebSockets can make cross-origin requests that are not restricted by browser-based protection mechanisms such as the Same Origin Policy (SOP) or Cross-Origin Resource Sharing (CORS). Without explicit origin validation, this makes CSRF attacks more powerful.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityNon-RepudiationAccess Control. Impacts: Varies by ContextGain Privileges or Assume IdentityBypass Protection MechanismRead Application DataModify Application DataDoS: Crash, Exit, or Restart. Note: The consequences will vary depending on the nature of the functionality that is vulnerable to CSRF. An attacker could effectively perform any operations as the victim. If the victim is an administrator or privileged user, the consequences may include obtaining complete control over the web application - deleting or stealing data, uninstalling the product, or using it to launch other attacks against all of the product's users. Because the attacker has the identity of the victim, the scope of the CSRF is limited only by the victim's privileges.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Enable CORS-like access restrictions by verifying the 'Origin' header during the WebSocket handshake.Implementation : Use a randomized CSRF token to verify requests.Implementation : Use TLS to securely communicate using 'wss' (WebSocket Secure) instead of 'ws'.Architecture and Design : Require user authentication prior to the WebSocket connection being established. For example, the WS library in Node has a 'verifyClient' function.Implementation : Leverage rate limiting to prevent against DoS. Use of the leaky bucket algorithm can help with this.Implementation : Use a library that provides restriction of the payload size. For example, WS library for Node includes 'maxPayloadoption' that can be set.Implementation : Treat data/input as untrusted in both directions and apply the same data/input sanitization as XSS, SQLi, etc.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "346", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "59", "Name": "Improper Link Resolution Before File Access ('Link Following')", "Description": "Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAccess Control. Impacts: Read Files or DirectoriesModify Files or DirectoriesBypass Protection Mechanism. Note: An attacker may be able to traverse the file system to unintended locations and read or overwrite the contents of unexpected files. If the files are used for a security mechanism then an attacker may be able to bypass the mechanism.Scopes: Other. Impacts: Execute Unauthorized Code or Commands. Note: Windows simple shortcuts, sometimes referred to as soft links, can be exploited remotely since a \".LNK\" file can be uploaded like a normal file. This can enable remote execution.", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "1386", "Name": "Insecure Operation on Windows Junction / Mount Point", "Description": "When designing software that will have different rights than the executer, the software should check that files that it is interacting with are not improper hard links or mount points.  One way to do this in Windows is to use the functionality embedded in the following command: \"dir /al /s /b\" or, in PowerShell, use LinkType as a filter. In addition, some software uses authentication via signing to ensure that the file is the correct one to use. Make checks atomic with the file action, otherwise a TOCTOU weakness (CWE-367) can be introduced.", "Extended_Description": "Depending on the intended action\n\t\t\t  being performed, this could allow an\n\t\t\t  attacker to cause the product to read,\n\t\t\t  write, delete, or otherwise operate on\n\t\t\t  unauthorized files.In Windows, NTFS5 allows for file\n\t\t\t  system objects called reparse points.\n\t\t\t  Applications can create a hard link from one\n\t\t\t  directory to another directory, called a\n\t\t\t  junction point. They can also create a\n\t\t\t  mapping from a directory to a drive letter,\n\t\t\t  called a mount point. If a file is used by a\n\t\t\t  privileged program, but it can be replaced\n\t\t\t  with a hard link to a sensitive file (e.g.,\n\t\t\t  AUTOEXEC.BAT), an attacker could excalate\n\t\t\t  privileges. When the process opens the file,\n\t\t\t  the attacker can assume the privileges of\n\t\t\t  that process, tricking the privileged\n\t\t\t  process to read, modify, or delete the\n\t\t\t  sensitive file, preventing the program from\n\t\t\t  accurately processing data. Note that one\n\t\t\t  can also point to registries and\n\t\t\t  semaphores.", "Modes_Of_Introduction": "Implementation: The developer might not consider that when a program in Windows operates with different permissions than the executing user, the use of links, mount points, and junctions might cause the program to access files or directories that are outside of the intended storage location.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or Directories. Note: Read arbitrary files by replacing a user-controlled folder with a mount point and additional hard links.Scopes: Integrity. Impacts: Modify Files or Directories. Note: Modify an arbitrary file by replacing the rollback files in installer directories, as they can have the installer execute those rollbacks.Scopes: Availability. Impacts: Modify Files or Directories. Note: Even if there is no control of contents, an arbitrary file delete or overwrite (when running as SYSTEM or admin) can be used for a permanent system denial-of-service, e.g. by deleting a startup configuration file that prevents the service from starting.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : When designing software that will have different rights than the executer, the software should check that files that it is interacting with are not improper hard links or mount points.  One way to do this in Windows is to use the functionality embedded in the following command: \"dir /al /s /b\" or, in PowerShell, use LinkType as a filter. In addition, some software uses authentication via signing to ensure that the file is the correct one to use. Make checks atomic with the file action, otherwise a TOCTOU weakness (CWE-367) can be introduced.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "59", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "704", "Name": "Incorrect Type Conversion or Cast", "Description": "Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1389", "Name": "Incorrect Parsing of Numbers with Different Radices", "Description": "If regular expressions are used to validate IP addresses, ensure that they are bounded using ^ and $ to prevent base-prepended IP addresses from being matched.", "Extended_Description": "Frequently, a numeric input that begins with \"0\" is treated as octal, or \"0x\" causes it to be treated as hexadecimal, e.g. by the inet_addr() function. For example, \"023\" (octal) is 35 decimal, or \"0x31\" is 49 decimal. Other bases may be used as well. If the developer assumes decimal-only inputs, the code could produce incorrect numbers when the inputs are parsed using a different base. This can result in unexpected and/or dangerous behavior. For example, a \"0127.0.0.1\" IP address is parsed as octal due to the leading \"0\", whose numeric value would be the same as 87.0.0.1 (decimal), where the developer likely expected to use 127.0.0.1.The consequences vary depending on the surrounding code in which this weakness occurs, but they can include bypassing network-based access control using unexpected IP addresses or netmasks, or causing apparently-symbolic identifiers to be processed as if they are numbers. In web applications, this can enable bypassing of SSRF restrictions.", "Modes_Of_Introduction": "Implementation: Input validation used may assume decimal bases during conditional checks, when it may not always be the case.Implementation: The application may rely on a service that supports different numerical bases.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: An attacker may use an unexpected numerical base to access private application resources.Scopes: Integrity. Impacts: Bypass Protection MechanismAlter Execution Logic. Note: An attacker may use an unexpected numerical base to bypass or manipulate access control mechanisms.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : If only decimal-based values are expected in the application, conditional checks should be created in a way that prevent octal or hexadecimal strings from being checked. This can be achieved by converting any numerical string to an explicit base-10 integer prior to the conditional check, to prevent octal or hex values from ever being checked against the condition.Implementation : If various numerical bases do need to be supported, check for leading values indicating the non-decimal base you wish to support (such as 0x for hex) and convert the numeric strings to integers of the respective base. Reject any other alternative-base string that is not intentionally supported by the application.Implementation : If regular expressions are used to validate IP addresses, ensure that they are bounded using ^ and $ to prevent base-prepended IP addresses from being matched.", "Demonstrative_Examples": "The below demonstrative example uses an IP validator that splits up an IP address by octet, tests to ensure each octet can be casted into an integer, and then returns the original IP address if no exceptions are raised. This validated IP address is then tested using the \"ping\" command.. If run_ping() were to be called with one or more zero-prepended octets, validate_ip() will succeed as zero-prepended numerical strings can be interpreted as decimal by a cast (\"012\" would cast to 12). However, as the original IP with the prepended zeroes is returned rather than the casted IP, it will be used in the call to the ping command. Ping DOES check and support octal-based IP octets, so the IP reached via ping may be different than the IP assumed by the validator. For example, ping would considered \"0127.0.0.1\" the same as \"87.0.0.1\".This code uses a regular expression to validate an IP string prior to using it in a call to the \"ping\" command.. Since the regular expression does not have anchors (CWE-777), i.e. is unbounded without ^ or $ characters, then prepending a 0 or 0x to the beginning of the IP address will still result in a matched regex pattern. Since the ping command supports octal and hex prepended IP addresses, it will use the unexpectedly valid IP address (CWE-1389). For example, \"0x63.63.63.63\" would be considered equivalent to \"99.63.63.63\". As a result, the attacker could potentially ping systems that the attacker cannot reach directly.Consider the following scenario, inspired by CWE team member Kelly Todd.Kelly wants to set up monitoring systems for his two cats, who pose very different threats. One cat, Night, tweets embarrassing or critical comments about his owner in ways that could cause reputational damage, so Night's blog needs to be monitored regularly. The other cat, Taki, likes to distract Kelly and his coworkers during business meetings with cute meows, so Kelly monitors Taki's location using a different web site.Suppose /etc/hosts provides the site info as follows:. The entry for night.example.com has a typo \"010\" in the first octet. When using ping to ensure the servers are up, the leading 0 causes the IP address to be converted using octal.  So when Kelly's script attempts to access night.example.com, it inadvertently scans 8.1.0.8 instead of 10.1.0.8 (since \"010\" in octal is 8 in decimal), and Night is free to send new Tweets without being immediately detected.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "704", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "287", "Name": "Improper Authentication", "Description": "Use an authentication framework or library such as the OWASP ESAPI Authentication feature.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Read Application DataGain Privileges or Assume IdentityExecute Unauthorized Code or Commands. Note: This weakness can lead to the exposure of resources or functionality to unintended actors, possibly providing attackers with sensitive information or even execute arbitrary code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis is useful for detecting certain types of authentication. A tool may be able to analyze related configuration files, such as .htaccess in Apache web servers, or detect the usage of commonly-used authentication libraries.Generally, automated static analysis tools have difficulty detecting custom authentication schemes. In addition, the software's design may include some functionality that is accessible to any user and does not require an established identity; an automated technique that detects the absence of authentication may report false positives. Method Name: Manual Static Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Manual static analysis is useful for evaluating the correctness of custom authentication mechanisms. Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Use an authentication framework or library such as the OWASP ESAPI Authentication feature.", "Demonstrative_Examples": "The following code intends to ensure that the user is already logged in. If not, the code performs authentication with the user-provided username and password. If successful, it sets the loggedin and user cookies to \"remember\" that the user has already logged in. Finally, the code performs administrator tasks if the logged-in user has the \"Administrator\" username, as recorded in the user cookie.. Unfortunately, this code can be bypassed. The attacker can set the cookies independently so that the code does not check the username and password. The attacker could do this with an HTTP request containing headers such as:. In January 2009, an attacker was able to gain administrator access to a Twitter server because the server did not restrict the number of login attempts [REF-236]. The attacker targeted a member of Twitter's support team and was able to successfully guess the member's password using a brute force attack by guessing a large number of common words. After gaining access as the member of the support staff, the attacker used the administrator panel to gain access to 33 accounts that belonged to celebrities and politicians. Ultimately, fake Twitter messages were sent that appeared to come from the compromised accounts.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors did not use any authentication or used client-side authentication for critical functionality in their OT products.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "1390", "Name": "Weak Authentication", "Description": "The product uses an authentication mechanism to restrict access to specific users or identities, but the mechanism does not sufficiently prove that the claimed identity is correct.", "Extended_Description": "Attackers may be able to bypass weak authentication faster and/or with less effort than expected.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Read Application DataGain Privileges or Assume IdentityExecute Unauthorized Code or Commands. Note: This weakness can lead to the exposure of resources or functionality to unintended actors, possibly providing attackers with sensitive information or even execute arbitrary code.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple OT products used weak authentication.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1391", "Name": "Use of Weak Credentials", "Description": "The product uses weak credentials (such as a default key or hard-coded password) that can be calculated, derived, reused, or guessed by an attacker.", "Extended_Description": "By design, authentication protocols try to ensure that attackers must perform brute force attacks if they do not know the credentials such as a key or password. However, when these credentials are easily predictable or even fixed (as with default or hard-coded passwords and keys), then the attacker can defeat the mechanism without relying on brute force.Credentials may be weak for different reasons, such as:Even if a new, unique credential is intended to be generated for each product installation, if the generation is predictable, then that may also simplify guessing attacks.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple OT products used weak credentials.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1392", "Name": "Use of Default Credentials", "Description": "The product administrator could change the defaults upon installation or during operation.", "Extended_Description": "It is common practice for products to be designed to use\n\tdefault keys, passwords, or other mechanisms for\n\tauthentication.  The rationale is to simplify the\n\tmanufacturing process or the system administrator's task of\n\tinstallation and deployment into an enterprise. However, if\n\tadmins do not change the defaults, it is easier for attackers\n\tto bypass authentication quickly across multiple\n\torganizations.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Prohibit use of default, hard-coded, or other values that do not vary for each installation of the product - especially for separate organizations.Architecture and Design : Force the administrator to change the credential upon installation.Installation : The product administrator could change the defaults upon installation or during operation.", "Demonstrative_Examples": "In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. At least one OT product used default credentials.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1391", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1393", "Name": "Use of Default Password", "Description": "The product administrator could change the defaults upon installation or during operation.", "Extended_Description": "It is common practice for products to be designed to use\n\tdefault passwords for authentication.  The rationale is to\n\tsimplify the manufacturing process or the system\n\tadministrator's task of installation and deployment into an\n\tenterprise. However, if admins do not change the defaults,\n\tthen it makes it easier for attackers to quickly bypass\n\tauthentication across multiple organizations. There are many\n\tlists of default passwords and default-password scanning tools\n\tthat are easily available from the World Wide Web.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Prohibit use of default, hard-coded, or other values that do not vary for each installation of the product - especially for separate organizations.Documentation : Ensure that product documentation clearly emphasizes the presence of default passwords and provides steps for the administrator to change them.Architecture and Design : Force the administrator to change the credential upon installation.Installation : The product administrator could change the defaults upon installation or during operation.", "Demonstrative_Examples": "In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple OT products used default credentials.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1392", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1394", "Name": "Use of Default Cryptographic Key", "Description": "The product administrator could change the defaults upon installation or during operation.", "Extended_Description": "It is common practice for products to be designed to use\n\tdefault keys.  The rationale is to simplify the manufacturing\n\tprocess or the system administrator's task of installation and\n\tdeployment into an enterprise. However, if admins do not\n\tchange the defaults, it is easier for attackers to bypass\n\tauthentication quickly across multiple organizations.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Prohibit use of default, hard-coded, or other values that do not vary for each installation of the product - especially for separate organizations.Architecture and Design : Force the administrator to change the credential upon installation.Installation : The product administrator could change the defaults upon installation or during operation.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1392", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "1395", "Name": "Dependency on Vulnerable Third-Party Component", "Description": "Continuously monitor changes in each of the product's components, especially when the changes indicate new vulnerabilities, end-of-life (EOL) plans, etc.", "Extended_Description": "Many products are large enough or complex enough that part of their functionality uses libraries, modules, or other intellectual property developed by third parties who are not the product creator. For example, even an entire operating system might be from a third-party supplier in some hardware products. Whether open or closed source, these components may contain publicly known vulnerabilities that could be exploited by adversaries to compromise the product.", "Modes_Of_Introduction": "Architecture and Design: The product architect or designer might choose a component that is already known to contain vulnerabilities or has a high likelihood of containing vulnerabilities in the future.Implementation: For reasons of compatibility or stability, developers might choose a third-party component, such as a library, that is already known to contain vulnerabilities.Patching and Maintenance: Since all products contain vulnerabilities, over time, a third-party component will be discovered to have a vulnerability.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Varies by Context. Note: The consequences vary widely, depending on the vulnerabilities that exist in the component; how those vulnerabilities can be \"reached\" by adversaries, as the exploitation paths and attack surface will vary depending on how the component is used; and the criticality of the privilege levels and features for which the product relies on the component.", "Detection_Methods": "Method Name: Automated Analysis. Description: For software, use Software Composition Analysis (SCA) tools, which automatically analyze products to identify third-party dependencies. Often, SCA tools can be used to link with known vulnerabilities in the dependencies that they detect. There are commercial and open-source alternatives, such as OWASP Dependency-Check [REF-1312]. Many languages or frameworks have package managers with similar capabilities, such as npm audit for JavaScript, pip-audit for Python, govulncheck for Go, and many others. Dynamic methods can detect loading of third-party components.", "Potential_Mitigations": "Requirements : In some industries such as healthcare [REF-1320] [REF-1322] or technologies such as the cloud [REF-1321], it might be unclear about who is responsible for applying patches for third-party vulnerabilities: the vendor, the operator/customer, or a separate service. Clarifying roles and responsibilities can be important to minimize confusion or unnecessary delay when third-party vulnerabilities are disclosed.Requirements : Require a Bill of Materials for all components and sub-components of the product. For software, require a Software Bill of Materials (SBOM) [REF-1247] [REF-1311].Architecture and Design : Maintain a Bill of Materials for all components and sub-components of the product. For software, maintain a Software Bill of Materials (SBOM). According to [REF-1247], \"An SBOM is a formal, machine-readable inventory of software components and dependencies, information about those components, and their hierarchical relationships.\"Operation : Actively monitor when a third-party component vendor announces vulnerability patches; fix the third-party component as soon as possible; and make it easy for operators/customers to obtain and apply the patch.Operation : Continuously monitor changes in each of the product's components, especially when the changes indicate new vulnerabilities, end-of-life (EOL) plans, etc.", "Demonstrative_Examples": ". The \"SweynTooth\" vulnerabilities in Bluetooth Low Energy (BLE) software development kits (SDK) were found to affect multiple Bluetooth System-on-Chip (SoC) manufacturers. These SoCs were used by many products such as medical devices, Smart Home devices, wearables, and other IoT devices. [REF-1314] [REF-1315]. log4j, a Java-based logging framework, is used in a large number of products, with estimates in the range of 3 billion affected devices [REF-1317]. When the \"log4shell\" (CVE-2021-44228) vulnerability was initially announced, it was actively exploited for remote code execution, requiring urgent mitigation in many organizations. However, it was unclear how many products were affected, as Log4j would sometimes be part of a long sequence of transitive dependencies. [REF-1316]", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "733", "Name": "Compiler Optimization Removal or Modification of Security-critical Code", "Description": "This weakness is only detectable using white box methods (see black box detection factor). Careful analysis is required to determine if the code is likely to be removed by the compiler.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Black Box. Description: This specific weakness is impossible to detect using black box methods. While an analyst could examine memory to see that it has not been scrubbed, an analysis of the executable would not be successful. This is because the compiler has already removed the relevant code. Only the source code shows whether the programmer intended to clear the memory or not, so this weakness is indistinguishable from others. Method Name: White Box. Description: This weakness is only detectable using white box methods (see black box detection factor). Careful analysis is required to determine if the code is likely to be removed by the compiler.", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1038", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "14", "Name": "Compiler Removal of Code to Clear Buffers", "Description": "Where possible, encrypt sensitive data that are used by a software system.", "Extended_Description": "This compiler optimization error occurs when:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityAccess Control. Impacts: Read MemoryBypass Protection Mechanism. Note: This weakness will allow data that has not been cleared from memory to be read. If this data contains sensitive password information, then an attacker can read the password and use the information to bypass protection mechanisms.", "Detection_Methods": "Method Name: Black Box. Description: This specific weakness is impossible to detect using black box methods. While an analyst could examine memory to see that it has not been scrubbed, an analysis of the executable would not be successful. This is because the compiler has already removed the relevant code. Only the source code shows whether the programmer intended to clear the memory or not, so this weakness is indistinguishable from others. Method Name: White Box. Description: This weakness is only detectable using white box methods (see black box detection factor). Careful analysis is required to determine if the code is likely to be removed by the compiler.", "Potential_Mitigations": "Implementation : Store the sensitive data in a \"volatile\" memory location if available.Build and Compilation : If possible, configure your compiler so that it does not remove dead stores.Architecture and Design : Where possible, encrypt sensitive data that are used by a software system.", "Demonstrative_Examples": "The following code reads a password from the user, uses the password to connect to a back-end mainframe and then attempts to scrub the password from memory using memset().. The code in the example will behave correctly if it is executed verbatim, but if the code is compiled using an optimizing compiler, such as Microsoft Visual C++ .NET or GCC 3.x, then the call to memset() will be removed as a dead store because the buffer pwd is not used after its value is overwritten [18]. Because the buffer pwd contains a sensitive value, the application may be vulnerable to attack if the data are left memory resident. If attackers are able to access the correct region of memory, they may use the recovered password to gain control of the system.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "733", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "140", "Name": "Improper Neutralization of Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Developers should anticipate that delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "141", "Name": "Improper Neutralization of Parameter/Argument Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that parameter/argument delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "140", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "142", "Name": "Improper Neutralization of Value Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that value delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "140", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "143", "Name": "Improper Neutralization of Record Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that record delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "140", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "144", "Name": "Improper Neutralization of Line Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that line delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "140", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "93", "View_ID": "1000", "Ordinal": null}]}, {"ID": "145", "Name": "Improper Neutralization of Section Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.One example of a section delimiter is the boundary string in a multipart MIME message. In many cases, doubled line delimiters can serve as a section delimiter.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that section delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "140", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "93", "View_ID": "1000", "Ordinal": null}]}, {"ID": "146", "Name": "Improper Neutralization of Expression/Command Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that inter-expression and inter-command delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "140", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "147", "Name": "Improper Neutralization of Input Terminators", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "For example, a \".\" in SMTP signifies the end of mail message data, whereas a null character can be used for the end of a string.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that terminators will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "148", "Name": "Improper Neutralization of Input Leaders", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that leading characters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "149", "Name": "Improper Neutralization of Quoting Syntax", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that quotes will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "642", "Name": "External Control of Critical State Data", "Description": "Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Extended_Description": "If an attacker can modify the state information without detection, then it could be used to perform unauthorized actions or access unexpected resources, since the application programmer does not expect that the state can be changed.State information can be stored in various locations such as a cookie, in a hidden web form field, input parameter or argument, an environment variable, a database record, within a settings file, etc. All of these locations have the potential to be modified by an attacker. When this state information is used to control security or determine resource usage, then it may create a vulnerability. For example, an application may perform authentication, then save the state in an \"authenticated=true\" cookie. An attacker may simply create this cookie in order to bypass the authentication.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: An attacker could potentially modify the state in malicious ways. If the state is related to the privileges or level of authentication that the user has, then state modification might allow the user to bypass authentication or elevate privileges.Scopes: Confidentiality. Impacts: Read Application Data. Note: The state variables may contain sensitive information that should not be known by the client.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: By modifying state variables, the attacker could violate the application's expectations for the contents of the state, leading to a denial of service due to an unexpected error condition.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Understand all the potential locations that are accessible to attackers. For example, some programmers assume that cookies and hidden form fields cannot be modified by an attacker, or they may not consider that environment variables can be modified before a privileged program is invoked.Architecture and Design : Store state information and sensitive data on the server side only.\n                  Ensure that the system definitively and unambiguously keeps track of its own state and user state and has rules defined for legitimate state transitions. Do not allow any application user to affect state directly in any way other than through legitimate actions leading to state transitions.\n                  If information must be stored on the client, do not do so without encryption and integrity checking, or otherwise having a mechanism on the server side to catch tampering. Use a message authentication code (MAC) algorithm, such as Hash Message Authentication Code (HMAC) [REF-529]. Apply this against the state or sensitive data that has to be exposed, which can guarantee the integrity of the data - i.e., that the data has not been modified. Ensure that a strong hash function is used (CWE-328).Architecture and Design : Store state information on the server side only. Ensure that the system definitively and unambiguously keeps track of its own state and user state and has rules defined for legitimate state transitions. Do not allow any application user to affect state directly in any way other than through legitimate actions leading to state transitions.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  With a stateless protocol such as HTTP, use some frameworks can maintain the state for you.\n                  Examples include ASP.NET View State and the OWASP ESAPI Session Management feature.\n                  Be careful of language features that provide state support, since these might be provided as a convenience to the programmer and may not be considering security.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Operation : When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.Testing : Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.Testing : Use dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.Testing : Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Demonstrative_Examples": ". In the following example, an authentication flag is read from a browser cookie, thus allowing for external control of user state data.. The following code uses input from an HTTP request to create a file name. The programmer has not considered the possibility that an attacker could provide a file name such as \"../../tomcat/conf/server.xml\", which causes the application to delete one of its own configuration files (CWE-22).. The following code uses input from a configuration file to determine which file to open and echo back to the user. If the program runs with privileges and malicious users can change the configuration file, they can use the program to read any file on the system that ends with the extension .txt.This program is intended to execute a command that lists the contents of a restricted directory, then performs other actions. Assume that it runs with setuid privileges in order to bypass the permissions check by the operating system.. This code may look harmless at first, since both the directory and the command are set to fixed values that the attacker can't control. The attacker can only see the contents for DIR, which is the intended program behavior. Finally, the programmer is also careful to limit the code that executes with raised privileges.The following code segment implements a basic server that uses the \"ls\" program to perform a directory listing of the directory that is listed in the \"HOMEDIR\" environment variable. The code intends to allow the user to specify an alternate \"LANG\" environment variable. This causes \"ls\" to customize its output based on a given language, which is an important capability when supporting internationalization.. The programmer takes care to call a specific \"ls\" program and sets the HOMEDIR to a fixed value. However, an attacker can use a command such as \"ENV HOMEDIR /secret/directory\" to specify an alternate directory, enabling a path traversal attack (CWE-22). At the same time, other attacks are enabled as well, such as OS command injection (CWE-78) by setting HOMEDIR to a value such as \"/tmp; rm -rf /\". In this case, the programmer never intends for HOMEDIR to be modified, so input validation for HOMEDIR is not the solution. A partial solution would be an allowlist that only allows the LANG variable to be specified in the ENV command. Alternately, assuming this is an authenticated user, the language could be stored in a local file so that no ENV command at all would be needed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "15", "Name": "External Control of System or Configuration Setting", "Description": "In general, do not allow user-provided or otherwise untrusted data to control sensitive values. The leverage that an attacker gains by controlling these values is not always immediately obvious, but do not underestimate the creativity of the attacker.", "Extended_Description": "Allowing external control of system settings can disrupt service or cause an application to behave in unexpected, and potentially malicious ways.", "Modes_Of_Introduction": "Implementation: Setting manipulation vulnerabilities occur when an attacker can control values that govern the behavior of the system, manage specific resources, or in some way affect the functionality of the application.Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.Implementation : Because setting manipulation covers a diverse set of functions, any attempt at illustrating it will inevitably be incomplete. Rather than searching for a tight-knit relationship between the functions addressed in the setting manipulation category, take a step back and consider the sorts of system values that an attacker should not be allowed to control.Implementation : In general, do not allow user-provided or otherwise untrusted data to control sensitive values. The leverage that an attacker gains by controlling these values is not always immediately obvious, but do not underestimate the creativity of the attacker.", "Demonstrative_Examples": "The following C code accepts a number as one of its command line parameters and sets it as the host ID of the current machine.. Although a process must be privileged to successfully invoke sethostid(), unprivileged users may be able to invoke the program. The code in this example allows user input to directly control the value of a system setting. If an attacker provides a malicious value for host ID, the attacker can misidentify the affected machine on the network or cause other unintended behavior.The following Java code snippet reads a string from an HttpServletRequest and sets it as the active catalog for a database Connection.. In this example, an attacker could cause an error by providing a nonexistent catalog name or connect to an unauthorized portion of the database.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "642", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "150", "Name": "Improper Neutralization of Escape, Meta, or Control Sequences", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that escape, meta and control characters/sequences will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "151", "Name": "Improper Neutralization of Comment Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that comments will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "152", "Name": "Improper Neutralization of Macro Symbols", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Developers should anticipate that macro symbols will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "153", "Name": "Improper Neutralization of Substitution Characters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that substitution characters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "154", "Name": "Improper Neutralization of Variable Name Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected delimiter may cause the process to take unexpected actions that result in an attack. Example: \"$\" for an environment variable.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that variable name delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "155", "Name": "Improper Neutralization of Wildcards or Matching Symbols", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected element may cause the process to take unexpected actions.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that wildcard or matching elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "156", "Name": "Improper Neutralization of Whitespace", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This can include space, tab, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that whitespace will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "157", "Name": "Failure to Sanitize Paired Delimiters", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "Paired delimiters might include:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that grouping elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "158", "Name": "Improper Neutralization of Null Byte or NUL Character", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, an injected NUL character or null byte may cause the product to believe the input is terminated earlier than it actually is, or otherwise cause the input to be misinterpreted. This could then be used to inject potentially dangerous input that occurs after the null byte or otherwise bypass validation routines and other protection mechanisms.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that null characters or null bytes will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "159", "Name": "Improper Handling of Invalid Use of Special Elements", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that special elements will be injected/removed/manipulated in the input vectors of their software system. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "160", "Name": "Improper Neutralization of Leading Special Elements", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, improperly handled leading special elements may cause the process to take unexpected actions that result in an attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that leading special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "161", "Name": "Improper Neutralization of Multiple Leading Special Elements", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, improperly handled multiple leading special elements may cause the process to take unexpected actions that result in an attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that multiple leading special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "160", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "162", "Name": "Improper Neutralization of Trailing Special Elements", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, improperly handled trailing special elements may cause the process to take unexpected actions that result in an attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that trailing special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "163", "Name": "Improper Neutralization of Multiple Trailing Special Elements", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, improperly handled multiple trailing special elements may cause the process to take unexpected actions that result in an attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that multiple trailing special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "162", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "164", "Name": "Improper Neutralization of Internal Special Elements", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, improperly handled internal special elements may cause the process to take unexpected actions that result in an attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that internal special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "165", "Name": "Improper Neutralization of Multiple Internal Special Elements", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "As data is parsed, improperly handled multiple internal special elements may cause the process to take unexpected actions that result in an attack.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that multiple internal special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "164", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "166", "Name": "Improper Handling of Missing Special Element", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that special elements will be removed in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "159", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": null}]}, {"ID": "167", "Name": "Improper Handling of Additional Special Element", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that extra special elements will be injected in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "159", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": null}]}, {"ID": "168", "Name": "Improper Handling of Inconsistent Special Elements", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "An example of this problem would be if paired characters appear in the wrong order, or if the special characters are not properly nested.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Developers should anticipate that inconsistent special elements will be injected/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "159", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": null}]}, {"ID": "170", "Name": "Improper Null Termination", "Description": "Add code that fills buffers with nulls (however, the length of buffers still needs to be inspected, to ensure that the non null-terminated string is not written at the physical end of the buffer).", "Extended_Description": "Null termination errors frequently occur in two different ways. An off-by-one error could cause a null to be written out of bounds, leading to an overflow. Or, a program could use a strncpy() function call incorrectly, which prevents a null terminator from being added at all. Other scenarios are possible.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Read MemoryExecute Unauthorized Code or Commands. Note: The case of an omitted null character is the most dangerous of the possible issues. This will almost certainly result in information disclosure, and possibly a buffer overflow condition, which may be exploited to execute arbitrary code.Scopes: ConfidentialityIntegrityAvailability. Impacts: DoS: Crash, Exit, or RestartRead MemoryDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: If a null character is omitted from a string, then most string-copying functions will read data until they locate a null character, even outside of the intended boundaries of the string. This could: cause a crash due to a segmentation fault cause sensitive adjacent memory to be copied and sent to an outsider trigger a buffer overflow when the copy is being written to a fixed-size buffer.Scopes: IntegrityAvailability. Impacts: Modify MemoryDoS: Crash, Exit, or Restart. Note: Misplaced null characters may result in any number of security problems. The biggest issue is a subset of buffer overflow, and write-what-where conditions, where data corruption occurs from the writing of a null character over valid data, or even instructions. A randomly placed null character may put the system into an undefined state, and therefore make it prone to crashing. A misplaced null character may corrupt other data in memory.Scopes: IntegrityConfidentialityAvailabilityAccess ControlOther. Impacts: Alter Execution LogicExecute Unauthorized Code or Commands. Note: Should the null character corrupt the process flow, or affect a flag controlling access, it may lead to logical errors which allow for the execution of arbitrary code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : Use a language that is not susceptible to these issues. However, be careful of null byte interaction errors (CWE-626) with lower-level constructs that may be written in a language that is susceptible.Implementation : Ensure that all string functions used are understood fully as to how they append null characters. Also, be wary of off-by-one errors when appending nulls to the end of strings.Implementation : If performance constraints permit, special code can be added that validates null-termination of string buffers, this is a rather naive and error-prone solution.Implementation : Switch to bounded string manipulation functions. Inspect buffer lengths involved in the buffer overrun trace reported with the defect.Implementation : Add code that fills buffers with nulls (however, the length of buffers still needs to be inspected, to ensure that the non null-terminated string is not written at the physical end of the buffer).", "Demonstrative_Examples": "The following code reads from cfgfile and copies the input into inputbuf using strcpy(). The code mistakenly assumes that inputbuf will always contain a NULL terminator.. The code above will behave correctly if the data read from cfgfile is null terminated on disk as expected. But if an attacker is able to modify this input so that it does not contain the expected NULL character, the call to strcpy() will continue copying from memory until it encounters an arbitrary NULL character. This will likely overflow the destination buffer and, if the attacker can control the contents of memory immediately following inputbuf, can leave the application susceptible to a buffer overflow attack.In the following code, readlink() expands the name of a symbolic link stored in pathname and puts the absolute path into buf. The length of the resulting value is then calculated using strlen().. The code above will not always behave correctly as readlink() does not append a NULL byte to buf. Readlink() will stop copying characters once the maximum size of buf has been reached to avoid overflowing the buffer, this will leave the value buf not NULL terminated. In this situation, strlen() will continue traversing memory until it encounters an arbitrary NULL character further on down the stack, resulting in a length value that is much larger than the size of string. Readlink() does return the number of bytes copied, but when this return value is the same as stated buf size (in this case MAXPATH), it is impossible to know whether the pathname is precisely that many bytes long, or whether readlink() has truncated the name to avoid overrunning the buffer. In testing, vulnerabilities like this one might not be caught because the unused contents of buf and the memory immediately following it may be NULL, thereby causing strlen() to appear as if it is behaving correctly.While the following example is not exploitable, it provides a good example of how nulls can be omitted or misplaced, even when \"safe\" functions are used:. The above code gives the following output: \"The last character in shortString is: n (6e)\". So, the shortString array does not end in a NULL character, even though the \"safe\" string function strncpy() was used. The reason is that strncpy() does not impliciitly add a NULL character at the end of the string when the source is equal in length or longer than the provided size.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "120", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "126", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "147", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "464", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "463", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "172", "Name": "Encoding Error", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "22", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "41", "View_ID": "1000", "Ordinal": null}]}, {"ID": "173", "Name": "Improper Handling of Alternate Encoding", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "172", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "289", "View_ID": "1000", "Ordinal": null}]}, {"ID": "174", "Name": "Double Decoding of the Same Data", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "172", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "675", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "175", "Name": "Improper Handling of Mixed Encoding", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "172", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "176", "Name": "Improper Handling of Unicode Encoding", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "Windows provides the MultiByteToWideChar(), WideCharToMultiByte(), UnicodeToBytes(), and BytesToUnicode() functions to convert between arbitrary multibyte (usually ANSI) character strings and Unicode (wide character) strings. The size arguments to these functions are specified in different units, (one in bytes, the other in characters) making their use prone to error.. In a multibyte character string, each character occupies a varying number of bytes, and therefore the size of such strings is most easily specified as a total number of bytes. In Unicode, however, characters are always a fixed size, and string lengths are typically given by the number of characters they contain. Mistakenly specifying the wrong units in a size argument can lead to a buffer overflow.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "172", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "177", "Name": "Improper Handling of URL Encoding (Hex Encoding)", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "172", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "706", "Name": "Use of Incorrectly-Resolved Name or Reference", "Description": "The product uses a name or reference to access a resource, but the name/reference resolves to a resource that is outside of the intended control sphere.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "99", "View_ID": "1000", "Ordinal": null}]}, {"ID": "178", "Name": "Improper Handling of Case Sensitivity", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "Improperly handled case sensitive data can lead to several possible consequences, including:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "In the following example, an XSS neutralization method intends to replace script tags in user-supplied input with a safe equivalent:. The code only works when the \"script\" tag is in all lower-case, forming an incomplete denylist (CWE-184). Equivalent tags such as \"SCRIPT\" or \"ScRiPt\" will not be neutralized by this method, allowing an XSS attack.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "433", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "289", "View_ID": "1000", "Ordinal": null}]}, {"ID": "179", "Name": "Incorrect Behavior Order: Early Validation", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "Product needs to validate data at the proper time, after data has been canonicalized and cleansed. Early validation is susceptible to various manipulations that result in dangerous inputs that are produced by canonicalization and cleansing.", "Modes_Of_Introduction": "Implementation: Since early validation errors usually arise from improperly implemented defensive mechanisms, it is likely that these will be introduced more frequently as secure programming becomes implemented more widely.", "Common_Consequences": "Scopes: Access ControlIntegrity. Impacts: Bypass Protection MechanismExecute Unauthorized Code or Commands. Note: An attacker could include dangerous input that bypasses validation protection mechanisms which can be used to launch various attacks including injection attacks, execute arbitrary code or cause other unintended behavior.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "The following code attempts to validate a given input path by checking it against an allowlist and then return the canonical path. In this specific case, the path is considered valid if it starts with the string \"/safe_dir/\".. The problem with the above code is that the validation step occurs before canonicalization occurs. An attacker could provide an input path of \"/safe_dir/../\" that would pass the validation step. However, the canonicalization process sees the double dot as a traversal to the parent directory and hence when canonicized the path would become just \"/\".This script creates a subdirectory within a user directory and sets the user as the owner.. While the script attempts to screen for '..' sequences, an attacker can submit a directory path including \".~.\", which will then become \"..\" after the filtering step. This allows a Path Traversal (CWE-21) attack to occur.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "696", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "180", "Name": "Incorrect Behavior Order: Validate Before Canonicalize", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This can be used by an attacker to bypass the validation and launch attacks that expose weaknesses that would otherwise be prevented, such as injection.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "The following code attempts to validate a given input path by checking it against an allowlist and then return the canonical path. In this specific case, the path is considered valid if it starts with the string \"/safe_dir/\".. The problem with the above code is that the validation step occurs before canonicalization occurs. An attacker could provide an input path of \"/safe_dir/../\" that would pass the validation step. However, the canonicalization process sees the double dot as a traversal to the parent directory and hence when canonicized the path would become just \"/\".", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "179", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "181", "Name": "Incorrect Behavior Order: Validate Before Filter", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being filtered.", "Extended_Description": "This can be used by an attacker to bypass the validation and launch attacks that expose weaknesses that would otherwise be prevented, such as injection.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being filtered.", "Demonstrative_Examples": "This script creates a subdirectory within a user directory and sets the user as the owner.. While the script attempts to screen for '..' sequences, an attacker can submit a directory path including \".~.\", which will then become \"..\" after the filtering step. This allows a Path Traversal (CWE-21) attack to occur.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "179", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "182", "Name": "Collapse of Data into Unsafe Value", "Description": "Canonicalize the name to match that of the file system's representation of the name. This can sometimes be achieved with an available API (e.g. in Win32 the GetFullPathName function).", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.N/A : Canonicalize the name to match that of the file system's representation of the name. This can sometimes be achieved with an available API (e.g. in Win32 the GetFullPathName function).", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "33", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "34", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "35", "View_ID": "1000", "Ordinal": null}]}, {"ID": "183", "Name": "Permissive List of Allowed Inputs", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "434", "View_ID": "1000", "Ordinal": null}]}, {"ID": "184", "Name": "Incomplete List of Disallowed Inputs", "Description": "Do not rely exclusively on detecting disallowed inputs.  There are too many variants to encode a character, especially when different environments are used, so there is a high likelihood of missing some variants.  Only use detection of disallowed inputs as a mechanism for detecting suspicious activity. Ensure that you are using other protection mechanisms that only identify \"good\" input - such as lists of allowed inputs - and ensure that you are properly encoding your outputs.", "Extended_Description": "Developers often try to protect their products against malicious input by performing tests against inputs that are known to be bad, such as special characters that can invoke new commands.  However, such lists often only account for the most well-known bad inputs. Attackers may be able to find other malicious inputs that were not expected by the developer, allowing them to bypass the intended protection mechanism.", "Modes_Of_Introduction": "Implementation: Developers might begin to develop a list of bad inputs as a fast way to fix a particular weakness, instead of fixing the root cause. See [REF-141].Architecture and Design: The design might rely solely on detection of malicious inputs as a protection mechanism.", "Common_Consequences": "", "Detection_Methods": "Method Name: Black Box. Description: Exploitation of a vulnerability with commonly-used manipulations might fail, but minor variations might succeed.", "Potential_Mitigations": "Implementation : Do not rely exclusively on detecting disallowed inputs.  There are too many variants to encode a character, especially when different environments are used, so there is a high likelihood of missing some variants.  Only use detection of disallowed inputs as a mechanism for detecting suspicious activity. Ensure that you are using other protection mechanisms that only identify \"good\" input - such as lists of allowed inputs - and ensure that you are properly encoding your outputs.", "Demonstrative_Examples": "The following code attempts to stop XSS attacks by removing all occurences of \"script\" in an input string.. Because the code only checks for the lower-case \"script\" string, it can be easily defeated with upper-case script tags.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1023", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "79", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "78", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "434", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "98", "View_ID": "1000", "Ordinal": null}]}, {"ID": "185", "Name": "Incorrect Regular Expression", "Description": "Regular expressions can become error prone when defining a complex language even for those experienced in writing grammars. Determine if several smaller regular expressions simplify one large regular expression. Also, subject the regular expression to thorough testing techniques such as equivalence partitioning, boundary value analysis, and robustness. After testing and a reasonable confidence level is achieved, a regular expression may not be foolproof. If an exploit is allowed to slip through, then record the exploit and refactor the regular expression.", "Extended_Description": "When the regular expression is used in protection mechanisms such as filtering or validation, this may allow an attacker to bypass the intended restrictions on the incoming data.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Unexpected StateVaries by Context. Note: When the regular expression is not correctly specified, data might have a different format or type than the rest of the program expects, producing resultant weaknesses or errors.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: In PHP, regular expression checks can sometimes be bypassed with a null byte, leading to any number of weaknesses.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Regular expressions can become error prone when defining a complex language even for those experienced in writing grammars. Determine if several smaller regular expressions simplify one large regular expression. Also, subject the regular expression to thorough testing techniques such as equivalence partitioning, boundary value analysis, and robustness. After testing and a reasonable confidence level is achieved, a regular expression may not be foolproof. If an exploit is allowed to slip through, then record the exploit and refactor the regular expression.", "Demonstrative_Examples": "The following code takes phone numbers as input, and uses a regular expression to reject invalid phone numbers.. An attacker could provide an argument such as: \"; ls -l ; echo 123-456\" This would pass the check, since \"123-456\" is sufficient to match the \"\\d+-\\d+\" portion of the regular expression.This code uses a regular expression to validate an IP string prior to using it in a call to the \"ping\" command.. Since the regular expression does not have anchors (CWE-777), i.e. is unbounded without ^ or $ characters, then prepending a 0 or 0x to the beginning of the IP address will still result in a matched regex pattern. Since the ping command supports octal and hex prepended IP addresses, it will use the unexpectedly valid IP address (CWE-1389). For example, \"0x63.63.63.63\" would be considered equivalent to \"99.63.63.63\". As a result, the attacker could potentially ping systems that the attacker cannot reach directly.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "187", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "182", "View_ID": "1000", "Ordinal": null}]}, {"ID": "186", "Name": "Overly Restrictive Regular Expression", "Description": "Regular expressions can become error prone when defining a complex language even for those experienced in writing grammars. Determine if several smaller regular expressions simplify one large regular expression. Also, subject your regular expression to thorough testing techniques such as equivalence partitioning, boundary value analysis, and robustness. After testing and a reasonable confidence level is achieved, a regular expression may not be foolproof. If an exploit is allowed to slip through, then record the exploit and refactor your regular expression.", "Extended_Description": "This weakness is not about regular expression complexity. Rather, it is about a regular expression that does not match all values that are intended. Consider the use of a regexp to identify acceptable values or to spot unwanted terms. An overly restrictive regexp misses some potentially security-relevant values leading to either false positives *or* false negatives, depending on how the regexp is being used within the code. Consider the expression /[0-8]/ where the intention was /[0-9]/.  This expression is not \"complex\" but the value \"9\" is not matched when maybe the programmer planned to check for it.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Regular expressions can become error prone when defining a complex language even for those experienced in writing grammars. Determine if several smaller regular expressions simplify one large regular expression. Also, subject your regular expression to thorough testing techniques such as equivalence partitioning, boundary value analysis, and robustness. After testing and a reasonable confidence level is achieved, a regular expression may not be foolproof. If an exploit is allowed to slip through, then record the exploit and refactor your regular expression.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "185", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "184", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "183", "View_ID": "1000", "Ordinal": null}]}, {"ID": "187", "Name": "Partial String Comparison", "Description": "Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.", "Extended_Description": "For example, an attacker might succeed in authentication by providing a small password that matches the associated portion of the larger, correct password.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.", "Demonstrative_Examples": "This example defines a fixed username and password. The AuthenticateUser() function is intended to accept a username and a password from an untrusted user, and check to ensure that it matches the username and password. If the username and password match, AuthenticateUser() is intended to indicate that authentication succeeded.. In AuthenticateUser(), the strncmp() call uses the string length of an attacker-provided inPass parameter in order to determine how many characters to check in the password. So, if the attacker only provides a password of length 1, the check will only examine the first byte of the application's password before determining success.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1023", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "188", "Name": "Reliance on Data/Memory Layout", "Description": "Testing: Test that the implementation properly handles each case in the protocol grammar.", "Extended_Description": "When changing platforms or protocol versions, in-memory organization of data may change in unintended ways. For example, some architectures may place local variables A and B right next to each other with A on top; some may place them next to each other with B on top; and others may add some padding to each. The padding size may vary to ensure that each variable is aligned to a proper word size.In protocol implementations, it is common to calculate an offset relative to another field to pick out a specific piece of data. Exceptional conditions, often involving new protocol versions, may add corner cases that change the data layout in an unusual way. The result can be that an implementation accesses an unintended field in the packet, treating data of one type as data of another type.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Modify MemoryRead Memory. Note: Can result in unintended modifications or exposure of sensitive memory.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "Implementation : In flat address space situations, never allow computing memory addresses as offsets from another memory address.Architecture and Design : Fully specify protocol layout unambiguously, providing a structured grammar (e.g., a compilable yacc grammar).Testing : Testing: Test that the implementation properly handles each case in the protocol grammar.", "Demonstrative_Examples": "In this example function, the memory address of variable b is derived by adding 1 to the address of variable a. This derived address is then used to assign the value 0 to b.. Here, b may not be one byte past a. It may be one byte in front of a. Or, they may have three bytes between them because they are aligned on 32-bit boundaries.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1105", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "435", "View_ID": "1000", "Ordinal": null}]}, {"ID": "190", "Name": "Integer Overflow or Wraparound", "Description": "Examine compiler warnings closely and eliminate problems with potential security implications, such as signed / unsigned mismatch in memory operations, or use of uninitialized variables. Even if the weakness is rarely exploitable, a single failure may lead to the compromise of the entire system.", "Extended_Description": "An integer overflow or wraparound occurs when an integer value is incremented to a value that is too large to store in the associated representation. When this occurs, the value may wrap to become a very small or negative number. While this may be intended behavior in circumstances that rely on wrapping, it can have security consequences if the wrap is unexpected. This is especially the case if the integer overflow can be triggered using user-supplied inputs. This becomes security-critical when the result is used to control looping, make a security decision, or determine the offset or size in behaviors such as memory allocation, copying, concatenation, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Instability. Note: This weakness will generally lead to undefined behavior and therefore crashes. In the case of overflows involving loop index variables, the likelihood of infinite loops is also high.Scopes: Integrity. Impacts: Modify Memory. Note: If the value in question is important to data (as opposed to flow), simple data corruption has occurred. Also, if the wrap around results in other conditions such as buffer overflows, further memory corruption may occur.Scopes: ConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsBypass Protection Mechanism. Note: This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives. Method Name: Black Box. Description: Sometimes, evidence of this weakness can be detected using dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual static analysis is useful for evaluating the correctness of allocation calculations. This can be useful for detecting overflow conditions (CWE-190) or similar weaknesses that might have serious security impacts on the program. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Requirements : Ensure that all protocols are strictly defined, such that all out-of-bounds behavior can be identified simply, and require strict conformance to the protocol.Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  If possible, choose a language or compiler that performs automatic bounds checking.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Use libraries or frameworks that make it easier to handle numbers without unexpected consequences.\n                  Examples include safe integer handling packages such as SafeInt (C++) or IntegerLib (C or C++). [REF-106]Implementation : Perform input validation on any numeric input by ensuring that it is within the expected range. Enforce that the input meets both the minimum and maximum requirements for the expected range.\n                  Use unsigned integers where possible. This makes it easier to perform validation for integer overflows. When signed integers are required, ensure that the range check includes minimum values as well as maximum values.Implementation : Understand the programming language's underlying representation and how it interacts with numeric calculation (CWE-681). Pay close attention to byte size discrepancies, precision, signed/unsigned distinctions, truncation, conversion and casting between types, \"not-a-number\" calculations, and how the language handles numbers that are too large or too small for its underlying representation. [REF-7]\n                  Also be careful to account for 32-bit, 64-bit, and other potential differences that may affect the numeric representation.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Implementation : Examine compiler warnings closely and eliminate problems with potential security implications, such as signed / unsigned mismatch in memory operations, or use of uninitialized variables. Even if the weakness is rarely exploitable, a single failure may lead to the compromise of the entire system.", "Demonstrative_Examples": "The following image processing code allocates a table for images.. This code intends to allocate a table of size num_imgs, however as num_imgs grows large, the calculation determining the size of the list will eventually overflow (CWE-190). This will result in a very small list to be allocated instead. If the subsequent code operates on the list as if it were num_imgs long, it may result in many types of out-of-bounds problems (CWE-119).The following code excerpt from OpenSSH 3.3 demonstrates a classic case of integer overflow:. If nresp has the value 1073741824 and sizeof(char*) has its typical value of 4, then the result of the operation nresp*sizeof(char*) overflows, and the argument to xmalloc() will be 0. Most malloc() implementations will happily allocate a 0-byte buffer, causing the subsequent loop iterations to overflow the heap buffer response.Integer overflows can be complicated and difficult to detect. The following example is an attempt to show how an integer overflow may lead to undefined looping behavior:. In the above case, it is entirely possible that bytesRec may overflow, continuously creating a lower number than MAXGET and also overwriting the first MAXGET-1 bytes of buf.In this example the method determineFirstQuarterRevenue is used to determine the first quarter revenue for an accounting/business application. The method retrieves the monthly sales totals for the first three months of the year, calculates the first quarter sales totals from the monthly sales totals, calculates the first quarter revenue based on the first quarter sales, and finally saves the first quarter revenue results to the database.. However, in this example the primitive type short int is used for both the monthly and the quarterly sales variables. In C the short int primitive type has a maximum value of 32768. This creates a potential integer overflow if the value for the three monthly sales adds up to more than the maximum value for the short int primitive type. An integer overflow can lead to data corruption, unexpected behavior, infinite loops and system crashes. To correct the situation the appropriate primitive type should be used, as in the example below, and/or provide some validation mechanism to ensure that the maximum value for the primitive type is not exceeded.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}]}, {"ID": "191", "Name": "Integer Underflow (Wrap or Wraparound)", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "This can happen in signed and unsigned cases.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Instability. Note: This weakness will generally lead to undefined behavior and therefore crashes. In the case of overflows involving loop index variables, the likelihood of infinite loops is also high.Scopes: Integrity. Impacts: Modify Memory. Note: If the value in question is important to data (as opposed to flow), simple data corruption has occurred. Also, if the wrap around results in other conditions such as buffer overflows, further memory corruption may occur.Scopes: ConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsBypass Protection Mechanism. Note: This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The following example subtracts from a 32 bit signed integer.. The example has an integer underflow. The value of i is already at the lowest negative value possible, so after subtracting 1, the new value of i is 2147483647.This code performs a stack allocation based on a length calculation.. Since a and b are declared as signed ints, the \"a - b\" subtraction gives a negative result (-1). However, since len is declared to be unsigned, len is cast to an extremely large positive number (on 32-bit systems - 4294967295). As a result, the buffer buf[len] declaration uses an extremely large size to allocate on the stack, very likely more than the entire computer's memory space.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "681", "Name": "Incorrect Conversion between Numeric Types", "Description": "Avoid making conversion between numeric types. Always check for the allowed ranges.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: OtherIntegrity. Impacts: Unexpected StateQuality Degradation. Note: The program could wind up using the wrong number and generate incorrect results. If the number is used to allocate resources or make a security decision, then this could introduce a vulnerability.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Avoid making conversion between numeric types. Always check for the allowed ranges.", "Demonstrative_Examples": ". In the following Java example, a float literal is cast to an integer, thus causing a loss of precision.This code adds a float and an integer together, casting the result to an integer.. Normally, PHP will preserve the precision of this operation, making $result = 4.8345. After the cast to int, it is reasonable to expect PHP to follow rounding convention and set $result = 5. However, the explicit cast to int always rounds DOWN, so the final value of $result is 4. This behavior may have unintended consequences.In this example the variable amount can hold a negative value when it is returned. Because the function is declared to return an unsigned int, amount will be implicitly converted to unsigned.. If the error condition in the code above is met, then the return value of readdata() will be 4,294,967,295 on a system that uses 32-bit integers.In this example, depending on the return value of accecssmainframe(), the variable amount can hold a negative value when it is returned. Because the function is declared to return an unsigned value, amount will be implicitly cast to an unsigned number.. If the return value of accessmainframe() is -1, then the return value of readdata() will be 4,294,967,295 on a system that uses 32-bit integers.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "704", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "704", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "682", "View_ID": "1000", "Ordinal": null}]}, {"ID": "192", "Name": "Integer Coercion Error", "Description": "Ensure that any data type casting that you must used is entirely understood in order to reduce the plausibility of error in use.", "Extended_Description": "Several flaws fall under the category of integer coercion errors. For the most part, these errors in and of themselves result only in availability and data integrity issues. However, in some circumstances, they may result in other, more complicated security related flaws, such as buffer overflow conditions.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Crash, Exit, or Restart. Note: Integer coercion often leads to undefined states of execution resulting in infinite loops or crashes.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: In some cases, integer coercion errors can lead to exploitable buffer overflow conditions, resulting in the execution of arbitrary code.Scopes: IntegrityOther. Impacts: Other. Note: Integer coercion errors result in an incorrect value being stored for the variable in question.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : A language which throws exceptions on ambiguous data casts might be chosen.Architecture and Design : Design objects and program flow such that multiple or complex casts are unnecessaryImplementation : Ensure that any data type casting that you must used is entirely understood in order to reduce the plausibility of error in use.", "Demonstrative_Examples": "The following code is intended to read an incoming packet from a socket and extract one or more headers.. The code performs a check to make sure that the packet does not contain too many headers. However, numHeaders is defined as a signed int, so it could be negative. If the incoming packet specifies a value such as -3, then the malloc calculation will generate a negative number (say, -300 if each header can be a maximum of 100 bytes). When this result is provided to malloc(), it is first converted to a size_t type. This conversion then produces a large value such as 4294966996, which may cause malloc() to fail or to allocate an extremely large amount of memory (CWE-195). With the appropriate negative numbers, an attacker could trick malloc() into using a very small positive number, which then allocates a buffer that is much smaller than expected, potentially leading to a buffer overflow.The following code reads a maximum size and performs validation on that size. It then performs a strncpy, assuming it will not exceed the boundaries of the array. While the use of \"short s\" is forced in this particular example, short int's are frequently used within real-world code, such as code that processes structured data.. This code first exhibits an example of CWE-839, allowing \"s\" to be a negative number. When the negative short \"s\" is converted to an unsigned integer, it becomes an extremely large positive integer. When this converted integer is used by strncpy() it will lead to a buffer overflow (CWE-119).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "193", "Name": "Off-by-one Error", "Description": "When copying character arrays or using character manipulation methods, the correct size parameter must be used to account for the null terminator that needs to be added at the end of the array. Some examples of functions susceptible to this weakness in C include strcpy(), strncpy(), strcat(), strncat(), printf(), sprintf(), scanf() and sscanf().", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Instability. Note: This weakness will generally lead to undefined behavior and therefore crashes. In the case of overflows involving loop index variables, the likelihood of infinite loops is also high.Scopes: Integrity. Impacts: Modify Memory. Note: If the value in question is important to data (as opposed to flow), simple data corruption has occurred. Also, if the wrap around results in other conditions such as buffer overflows, further memory corruption may occur.Scopes: ConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsBypass Protection Mechanism. Note: This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : When copying character arrays or using character manipulation methods, the correct size parameter must be used to account for the null terminator that needs to be added at the end of the array. Some examples of functions susceptible to this weakness in C include strcpy(), strncpy(), strcat(), strncat(), printf(), sprintf(), scanf() and sscanf().", "Demonstrative_Examples": "The following code allocates memory for a maximum number of widgets. It then gets a user-specified number of widgets, making sure that the user does not request too many. It then initializes the elements of the array using InitializeWidget(). Because the number of widgets can vary for each request, the code inserts a NULL pointer to signify the location of the last widget.. However, this code contains an off-by-one calculation error (CWE-193). It allocates exactly enough space to contain the specified number of widgets, but it does not include the space for the NULL pointer. As a result, the allocated buffer is smaller than it is supposed to be (CWE-131). So if the user ever requests MAX_NUM_WIDGETS, there is an out-of-bounds write (CWE-787) when the NULL is assigned. Depending on the environment and compilation settings, this could cause memory corruption.In this example, the code does not account for the terminating null character, and it writes one byte beyond the end of the buffer.. The first call to strncat() appends up to 20 characters plus a terminating null character to fullname[]. There is plenty of allocated space for this, and there is no weakness associated with this first call. However, the second call to strncat() potentially appends another 20 characters. The code does not account for the terminating null character that is automatically added by strncat(). This terminating null character would be written one byte beyond the end of the fullname[] buffer. Therefore an off-by-one error exists with the second strncat() call, as the third argument should be 19.The Off-by-one error can also be manifested when reading characters from a character array within a for loop that has an incorrect continuation condition.. In this case, the correct continuation condition is shown below.As another example the Off-by-one error can occur when using the sprintf library function to copy a string variable to a formatted string variable and the original string variable comes from an untrusted source. As in the following example where a local function, setFilename is used to store the value of a filename to a database but first uses sprintf to format the filename. The setFilename function includes an input parameter with the name of the file that is used as the copy source in the sprintf function. The sprintf function will copy the file name to a char array of size 20 and specifies the format of the new variable as 16 characters followed by the file extension .dat.. However this will cause an Off-by-one error if the original filename is exactly 16 characters or larger because the format of 16 characters with the file extension is exactly 20 characters and does not take into account the required null terminator that will be placed at the end of the string.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "617", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "170", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}]}, {"ID": "194", "Name": "Unexpected Sign Extension", "Description": "Avoid using signed variables if you don't need to represent negative values. When negative values are needed, perform validation after you save those values to larger data types, or before passing them to functions that are expecting unsigned values.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityOther. Impacts: Read MemoryModify MemoryOther. Note: When an unexpected sign extension occurs in code that operates directly on memory buffers, such as a size value or a memory index, then it could cause the program to write or read outside the boundaries of the intended buffer. If the numeric value is associated with an application-level resource, such as a quantity or price for a product in an e-commerce site, then the sign extension could produce a value that is much higher (or lower) than the application's allowable range.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Avoid using signed variables if you don't need to represent negative values. When negative values are needed, perform validation after you save those values to larger data types, or before passing them to functions that are expecting unsigned values.", "Demonstrative_Examples": "The following code reads a maximum size and performs a sanity check on that size. It then performs a strncpy, assuming it will not exceed the boundaries of the array. While the use of \"short s\" is forced in this particular example, short int's are frequently used within real-world code, such as code that processes structured data.. This code first exhibits an example of CWE-839, allowing \"s\" to be a negative number. When the negative short \"s\" is converted to an unsigned integer, it becomes an extremely large positive integer. When this converted integer is used by strncpy() it will lead to a buffer overflow (CWE-119).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "195", "Name": "Signed to Unsigned Conversion Error", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "It is dangerous to rely on implicit casts between signed and unsigned numbers because the result can take on an unexpected value and violate assumptions made by the program.Often, functions will return negative values to indicate a failure. When the result of a function is to be used as a size parameter, using these negative return values can have unexpected results. For example, if negative size values are passed to the standard memory copy or allocation functions they will be implicitly cast to a large unsigned value. This may lead to an exploitable buffer overflow or underflow condition.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Unexpected State. Note: Conversion between signed and unsigned values can lead to a variety of errors, but from a security standpoint is most commonly associated with integer overflow and buffer overflow vulnerabilities.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "In this example the variable amount can hold a negative value when it is returned. Because the function is declared to return an unsigned int, amount will be implicitly converted to unsigned.. If the error condition in the code above is met, then the return value of readdata() will be 4,294,967,295 on a system that uses 32-bit integers.In this example, depending on the return value of accecssmainframe(), the variable amount can hold a negative value when it is returned. Because the function is declared to return an unsigned value, amount will be implicitly cast to an unsigned number.. If the return value of accessmainframe() is -1, then the return value of readdata() will be 4,294,967,295 on a system that uses 32-bit integers.The following code is intended to read an incoming packet from a socket and extract one or more headers.. The code performs a check to make sure that the packet does not contain too many headers. However, numHeaders is defined as a signed int, so it could be negative. If the incoming packet specifies a value such as -3, then the malloc calculation will generate a negative number (say, -300 if each header can be a maximum of 100 bytes). When this result is provided to malloc(), it is first converted to a size_t type. This conversion then produces a large value such as 4294966996, which may cause malloc() to fail or to allocate an extremely large amount of memory (CWE-195). With the appropriate negative numbers, an attacker could trick malloc() into using a very small positive number, which then allocates a buffer that is much smaller than expected, potentially leading to a buffer overflow.This example processes user input comprised of a series of variable-length structures. The first 2 bytes of input dictate the size of the structure to be processed.. The programmer has set an upper bound on the structure size: if it is larger than 512, the input will not be processed. The problem is that len is a signed short, so the check against the maximum structure length is done with signed values, but len is converted to an unsigned integer for the call to memcpy() and the negative bit will be extended to result in a huge value for the unsigned integer. If len is negative, then it will appear that the structure has an appropriate size (the if branch will be taken), but the amount of memory copied by memcpy() will be quite large, and the attacker will be able to overflow the stack with data in strm.In the following example, it is possible to request that memcpy move a much larger segment of memory than assumed:. If returnChunkSize() happens to encounter an error it will return -1. Notice that the return value is not checked before the memcpy operation (CWE-252), so -1 can be passed as the size argument to memcpy() (CWE-805). Because memcpy() assumes that the value is unsigned, it will be interpreted as MAXINT-1 (CWE-195), and therefore will copy far more memory than is likely available to the destination buffer (CWE-787, CWE-788).This example shows a typical attempt to parse a string with an error resulting from a difference in assumptions between the caller to a function and the function's action.. The buffer length ends up being -1, resulting in a blown out stack. The space character after the colon is included in the function calculation, but not in the caller's calculation. This, unfortunately, is not usually so obvious but exists in an obtuse series of calculations.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}]}, {"ID": "196", "Name": "Unsigned to Signed Conversion Error", "Description": "Error check the return values of all functions. Be aware of implicit casts made, and use unsigned variables for sizes if at all possible.", "Extended_Description": "Although less frequent an issue than signed-to-unsigned conversion, unsigned-to-signed conversion can be the perfect precursor to dangerous buffer underwrite conditions that allow attackers to move down the stack where they otherwise might not have access in a normal buffer overflow condition. Buffer underwrites occur frequently when large unsigned values are cast to signed values, and then used as indexes into a buffer or for pointer arithmetic.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: Incorrect sign conversions generally lead to undefined behavior, and therefore crashes.Scopes: Integrity. Impacts: Modify Memory. Note: If a poor cast lead to a buffer overflow or similar condition, data integrity may be affected.Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsBypass Protection Mechanism. Note: Improper signed-to-unsigned conversions without proper checking can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Choose a language which is not subject to these casting flaws.Architecture and Design : Design object accessor functions to implicitly check values for valid sizes. Ensure that all functions which will be used as a size are checked previous to use as a size. If the language permits, throw exceptions rather than using in-band errors.Implementation : Error check the return values of all functions. Be aware of implicit casts made, and use unsigned variables for sizes if at all possible.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "124", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "120", "View_ID": "1000", "Ordinal": null}]}, {"ID": "197", "Name": "Numeric Truncation Error", "Description": "Ensure that no casts, implicit or explicit, take place that move from a larger size primitive or a smaller size primitive.", "Extended_Description": "When a primitive is cast to a smaller primitive, the high order bits of the large value are lost in the conversion, potentially resulting in an unexpected value that is not equal to the original value. This value may be required as an index into a buffer, a loop iterator, or simply necessary state data. In any case, the value cannot be trusted and the system will be in an undefined state. While this method may be employed viably to isolate the low bits of a value, this usage is rare, and truncation usually implies that an implementation error has occurred.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Memory. Note: The true value of the data is lost and corrupted data is used.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Ensure that no casts, implicit or explicit, take place that move from a larger size primitive or a smaller size primitive.", "Demonstrative_Examples": "This example, while not exploitable, shows the possible mangling of values associated with truncation errors:. The above code, when compiled and run on certain systems, returns the following output:In the following Java example, the method updateSalesForProduct is part of a business application class that updates the sales information for a particular product. The method receives as arguments the product ID and the integer amount sold. The product ID is used to retrieve the total product count from an inventory object which returns the count as an integer. Before calling the method of the sales object to update the sales count the integer values are converted to The primitive type short since the method requires short type for the method arguments.. However, a numeric truncation error can occur if the integer values are higher than the maximum value allowed for the primitive type short. This can cause unexpected results or loss or corruption of data. In this case the sales database may be corrupted with incorrect data. Explicit casting from a from a larger size primitive type to a smaller size primitive type should be prevented. The following example an if statement is added to validate that the integer values less than the maximum value for the primitive type short before the explicit cast and the call to the sales method.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "681", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "195", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "196", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "192", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "194", "View_ID": "1000", "Ordinal": null}]}, {"ID": "198", "Name": "Use of Incorrect Byte Ordering", "Description": "Because byte ordering bugs are usually very noticeable even with normal inputs, this bug is more likely to occur in rarely triggered error conditions, making them difficult to detect using black box methods.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Black Box. Description: Because byte ordering bugs are usually very noticeable even with normal inputs, this bug is more likely to occur in rarely triggered error conditions, making them difficult to detect using black box methods.", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "188", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "201", "Name": "Insertion of Sensitive Information Into Sent Data", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "Sensitive information could include data that is sensitive in and of itself (such as credentials or private messages), or otherwise useful in the further exploitation of the system (such as internal file system structure).", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or DirectoriesRead MemoryRead Application Data. Note: Sensitive data may be exposed to attackers.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : Specify which data in the software should be regarded as sensitive. Consider which types of users should have access to which types of data.Implementation : Ensure that any possibly sensitive data specified in the requirements is verified with designers to ensure that it is either a calculated risk or mitigated elsewhere. Any information that is not necessary to the functionality should be removed in order to lower both the overhead and the possibility of security sensitive data being sent.System Configuration : Setup default error messages so that unexpected errors do not disclose sensitive information.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": "The following is an actual MySQL error statement:. The error clearly exposes the database credentials.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "209", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "202", "View_ID": "1000", "Ordinal": null}]}, {"ID": "202", "Name": "Exposure of Sensitive Information Through Data Queries", "Description": "This is a complex topic. See the book Translucent Databases for a good discussion of best practices.", "Extended_Description": "In situations where data should not be tied to individual users, but a large number of users should be able to make queries that \"scrub\" the identity of users, it may be possible to get information about a user -- e.g., by specifying search terms that are known to be unique to that user.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or DirectoriesRead Application Data. Note: Sensitive information may possibly be leaked through data queries accidentally.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : This is a complex topic. See the book Translucent Databases for a good discussion of best practices.", "Demonstrative_Examples": ". See the book Translucent Databases for examples.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1230", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "204", "Name": "Observable Response Discrepancy", "Description": "Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.", "Extended_Description": "This issue frequently occurs during authentication, where a difference in failed-login messages could allow an attacker to determine if the username is valid or not. These exposures can be inadvertent (bug) or intentional (design).", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.Implementation : Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.", "Demonstrative_Examples": "The following code checks validity of the supplied username and password and notifies the user of a successful or failed login.. In the above code, there are different messages for when an incorrect username is supplied, versus when the username is correct but the password is wrong. This difference enables a potential attacker to understand the state of the login function, and could allow an attacker to discover a valid username by trying different values until the incorrect password message is returned. In essence, this makes it easier for an attacker to obtain half of the necessary authentication credentials.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "203", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "205", "Name": "Observable Behavioral Discrepancy", "Description": "The product's behaviors indicate important differences that may be observed by unauthorized actors in a way that reveals (1) its internal state or decision process, or (2) differences from other products with equivalent functionality.", "Extended_Description": "Ideally, a product should provide as little information about its internal operations as possible.  Otherwise, attackers could use knowledge of these internal operations to simplify or optimize their attack.  In some cases, behavioral discrepancies can be used by attackers to form a side channel.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "203", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "514", "View_ID": "1000", "Ordinal": null}]}, {"ID": "206", "Name": "Observable Internal Behavioral Discrepancy", "Description": "Setup generic response pages for error conditions. The error page should not disclose information about the success or failure of a sensitive operation. For instance, the login page should not confirm that the login is correct and the password incorrect. The attacker who tries random account name may be able to guess some of them. Confirming that the account exists would make the login page more susceptible to brute force attack.", "Extended_Description": "Ideally, a product should provide as little information as possible to an attacker.  Any hints that the attacker may be making progress can then be used to simplify or optimize the attack.  For example, in a login procedure that requires a username and password, ultimately there is only one decision: success or failure.  However, internally, two separate actions are performed: determining if the username exists, and checking if the password is correct.  If the product behaves differently based on whether the username exists or not, then the attacker only needs to concentrate on the password.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Setup generic response pages for error conditions. The error page should not disclose information about the success or failure of a sensitive operation. For instance, the login page should not confirm that the login is correct and the password incorrect. The attacker who tries random account name may be able to guess some of them. Confirming that the account exists would make the login page more susceptible to brute force attack.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "205", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "207", "Name": "Observable Behavioral Discrepancy With Equivalent Products", "Description": "The product operates in an environment in which its existence or specific identity should not be known, but it behaves differently than other products with equivalent functionality, in a way that is observable to an attacker.", "Extended_Description": "For many kinds of products, multiple products may be available that perform the same functionality, such as a web server, network interface, or intrusion detection system.  Attackers often perform \"fingerprinting,\" which uses discrepancies in order to identify which specific product is in use.  Once the specific product has been identified, the attacks can be made more customized and efficient.  Often, an organization might intentionally allow the specific product to be identifiable.  However, in some environments, the ability to identify a distinct product is unacceptable, and it is expected that every product would behave in exactly the same way.  In these more restricted environments, a behavioral difference might pose an unacceptable risk if it makes it easier to identify the product's vendor, model, configuration, version, etc.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "205", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "209", "Name": "Generation of Error Message Containing Sensitive Information", "Description": "Create default error pages or messages that do not leak any information.", "Extended_Description": "The sensitive information may be valuable information on its own (such as a password), or it may be useful for launching other, more serious attacks. The error message may be created in different ways:An attacker may use the contents of error messages to help launch another, more focused attack. For example, an attempt to exploit a path traversal weakness (CWE-22) might yield the full pathname of the installed application. In turn, this could be used to select the proper number of \"..\" sequences to navigate to the targeted file. An attack using SQL injection (CWE-89) might not initially succeed, but an error message could reveal the malformed query, which would expose query logic and possibly even passwords or other sensitive information used within the query.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Often this will either reveal sensitive information which may be used for a later attack or private information stored in the server.", "Detection_Methods": "Method Name: Manual Analysis. Description: This weakness generally requires domain-specific interpretation using manual analysis. However, the number of potential error conditions may be too large to cover completely within limited time constraints. Method Name: Automated Analysis. Description: Automated methods may be able to detect certain idioms automatically, such as exposed stack traces or pathnames, but violation of business rules or privacy requirements is not typically feasible. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.Error conditions may be triggered with a stress-test by calling the software simultaneously from a large number of threads or processes, and look for evidence of any unexpected behavior. Method Name: Manual Dynamic Analysis. Description: Identify error conditions that are not likely to occur during normal usage and trigger them. For example, run the program under low memory conditions, run with insufficient privileges or permissions, interrupt a transaction before it is completed, or disable connectivity to basic network services such as DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled exception or similar error that was discovered and handled by the application's environment, it may still indicate unexpected conditions that were not handled by the application itself. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.Implementation : Handle exceptions internally and do not display errors containing potentially sensitive information to a user.Implementation : Use naming conventions and strong types to make it easier to spot when sensitive data is being used. When creating structures, objects, or other complex entities, separate the sensitive and non-sensitive data as much as possible.Implementation : Debugging information should not make its way into a production release.Implementation : Debugging information should not make its way into a production release.System Configuration : Where available, configure the environment to use less verbose error messages. For example, in PHP, disable the display_errors setting during configuration, or at runtime using the error_reporting() function.System Configuration : Create default error pages or messages that do not leak any information.", "Demonstrative_Examples": "In the following example, sensitive information might be printed depending on the exception that occurs.. If an exception related to SQL is handled by the catch, then the output might contain sensitive information such as SQL query structure or private information. If this output is redirected to a web user, this may represent a security problem.This code tries to open a database connection, and prints any exceptions that occur.. If an exception occurs, the printed message exposes the location of the configuration file the script is using. An attacker can use this information to target the configuration file (perhaps exploiting a Path Traversal weakness). If the file can be read, the attacker could gain credentials for accessing the database. The attacker may also be able to replace the file with a malicious one, causing the application to use an arbitrary database.The following code generates an error message that leaks the full pathname of the configuration file.. If this code is running on a server, such as a web application, then the person making the request should not know what the full pathname of the configuration directory is. By submitting a username that does not produce a $file that exists, an attacker could get this pathname. It could then be used to exploit path traversal or symbolic link following problems that may exist elsewhere in the application.In the example below, the method getUserBankAccount retrieves a bank account object from a database using the supplied username and account number to query the database. If an SQLException is raised when querying the database, an error message is created and output to a log file.. The error message that is created includes information about the database query that may contain sensitive information about the database or query logic. In this case, the error message will expose the table name and column names used in the database. This data could be used to simplify other attacks, such as SQL injection (CWE-89) to directly access the database.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": null}]}, {"ID": "755", "Name": "Improper Handling of Exceptional Conditions", "Description": "The product does not handle or incorrectly handles an exceptional condition.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "210", "Name": "Self-generated Error Message Containing Sensitive Information", "Description": "Debugging information should not make its way into a production release.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Debugging information should not make its way into a production release.Implementation : Debugging information should not make its way into a production release.", "Demonstrative_Examples": "The following code uses custom configuration files for each user in the application. It checks to see if the file exists on the system before attempting to open and use the file. If the configuration file does not exist, then an error is generated, and the application exits.. If this code is running on a server, such as a web application, then the person making the request should not know what the full pathname of the configuration directory is. By submitting a username that is not associated with a configuration file, an attacker could get this pathname from the error message. It could then be used to exploit path traversal, symbolic link following, or other problems that may exist elsewhere in the application.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "209", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "211", "Name": "Externally-Generated Error Message Containing Sensitive Information", "Description": "The best way to prevent this weakness during implementation is to avoid any bugs that could trigger the external error message. This typically happens when the program encounters fatal errors, such as a divide-by-zero. You will not always be able to control the use of error pages, and you might not be using a language that handles exceptions.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: PHP applications are often targeted for having this issue when the PHP interpreter generates the error outside of the application's control. However, other languages/environments exhibit the same issue.Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : Configure the application's environment in a way that prevents errors from being generated. For example, in PHP, disable display_errors.Implementation : Debugging information should not make its way into a production release.Implementation : Debugging information should not make its way into a production release.Implementation : Handle exceptions internally and do not display errors containing potentially sensitive information to a user. Create default error pages if necessary.Implementation : The best way to prevent this weakness during implementation is to avoid any bugs that could trigger the external error message. This typically happens when the program encounters fatal errors, such as a divide-by-zero. You will not always be able to control the use of error pages, and you might not be using a language that handles exceptions.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "209", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "669", "Name": "Incorrect Resource Transfer Between Spheres", "Description": "The product does not properly transfer a resource/behavior to another sphere, or improperly imports a resource/behavior from another sphere, in a manner that provides unintended control over that resource.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "213", "Name": "Exposure of Sensitive Information Due to Incompatible Policies", "Description": "The product's intended functionality exposes information to certain actors in accordance with the developer's security policy, but this information is regarded as sensitive according to the intended security policies of other stakeholders such as the product's administrator, users, or others whose information is being processed.", "Extended_Description": "When handling information, the developer must consider whether the information is regarded as sensitive by different stakeholders, such as users or administrators.  Each stakeholder effectively has its own intended security policy that the product is expected to uphold.  When a developer does not treat that information as sensitive, this can introduce a vulnerability that violates the expectations of the product's users.", "Modes_Of_Introduction": "Policy: This can occur when the product's policy does not account for all relevant stakeholders, or when the policies of other stakeholders are not interpreted properly.Requirements: This can occur when requirements do not explicitly account for all relevant stakeholders.Architecture and Design: Communications or data exchange frameworks may be chosen that exchange or provide access to more information than strictly needed.Implementation: This can occur when the developer does not properly track the flow of sensitive information and how it is exposed, e.g., via an API.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This code displays some information on a web page.. The code displays a user's credit card and social security numbers, even though they aren't absolutely necessary.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "497", "Name": "Exposure of Sensitive System Information to an Unauthorized Control Sphere", "Description": "Production applications should never use methods that generate internal details such as stack traces and error messages unless that information is directly committed to a log that is not viewable by the end user. All error message text should be HTML entity encoded before being written to the log file to protect against potential cross-site scripting attacks against the viewer of the logs", "Extended_Description": "Network-based products, such as web applications, often run on top of an operating system or similar environment.  When the product communicates with outside parties, details about the underlying system are expected to remain hidden, such as path names for data files, other OS users, installed packages, the application environment, etc. This system information may be provided by the product itself, or buried within diagnostic or debugging messages. Debugging information helps an adversary learn about the system and form an attack plan.An information exposure occurs when system data or debugging information leaves the program through an output stream or logging function that makes it accessible to unauthorized parties. Using other weaknesses, an attacker could cause errors to occur; the response to these errors can reveal detailed system information, along with other impacts.  An attacker can use messages that reveal technologies, operating systems, and product versions to tune the attack against known vulnerabilities in these technologies. A product may use diagnostic methods that provide significant implementation details such as stack traces as part of its error handling mechanism.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Production applications should never use methods that generate internal details such as stack traces and error messages unless that information is directly committed to a log that is not viewable by the end user. All error message text should be HTML entity encoded before being written to the log file to protect against potential cross-site scripting attacks against the viewer of the logs", "Demonstrative_Examples": ". The following code prints the path environment variable to the standard error stream:This code prints all of the running processes belonging to the current user.. If invoked by an unauthorized web user, it is providing a web page of potentially sensitive information on the underlying system, such as command-line arguments (CWE-497). This program is also potentially vulnerable to a PATH based attack (CWE-426), as an attacker may be able to create malicious versions of the ps or grep commands. While the program does not explicitly raise privileges to run the system commands, the PHP interpreter may by default be running with higher privileges than users.The following code prints an exception to the standard error stream:. Depending upon the system configuration, this information can be dumped to a console, written to a log file, or exposed to a remote user. In some cases the error message tells the attacker precisely what sort of an attack the system will be vulnerable to. For example, a database error message can reveal that the application is vulnerable to a SQL injection attack. Other error messages can reveal more oblique clues about the system. In the example above, the search path could imply information about the type of operating system, the applications installed on the system, and the amount of care that the administrators have put into configuring the program.The following code constructs a database connection string, uses it to create a new connection to the database, and prints it to the console.. Depending on the system configuration, this information can be dumped to a console, written to a log file, or exposed to a remote user. In some cases the error message tells the attacker precisely what sort of an attack the system is vulnerable to. For example, a database error message can reveal that the application is vulnerable to a SQL injection attack. Other error messages can reveal more oblique clues about the system. In the example above, the search path could imply information about the type of operating system, the applications installed on the system, and the amount of care that the administrators have put into configuring the program.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "214", "Name": "Invocation of Process Using Visible Sensitive Information", "Description": "A process is invoked with sensitive command-line arguments, environment variables, or other elements that can be seen by other processes on the operating system.", "Extended_Description": "Many operating systems allow a user to list information about processes that are owned by other users. Other users could see information such as command line arguments or environment variable settings. When this data contains sensitive information such as credentials, it might allow other users to launch an attack against the product or related resources.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "In the example below, the password for a keystore file is read from a system property.. If the property is defined on the command line when the program is invoked (using the -D... syntax), the password may be displayed in the OS process list.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "497", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "215", "Name": "Insertion of Sensitive Information Into Debugging Code", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "When debugging, it may be necessary to report detailed information to the programmer.  However, if the debugging code is not disabled when the product is operating in a production environment, then this sensitive information may be exposed to attackers.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Do not leave debug statements that could be executed in the source code. Ensure that all debug information is eradicated before releasing the software.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": "The following program changes its behavior based on a debug flag.. The code writes sensitive debug information to the client browser if the \"debugEnabled\" flag is set to true .", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "552", "Name": "Files or Directories Accessible to External Parties", "Description": "When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to disable public access.", "Extended_Description": "Web servers, FTP servers, and similar servers may store a set of files underneath a \"root\" directory that is accessible to the server's users.  Applications may store sensitive files underneath this root without also using access control to limit which users may request those files, if any.  Alternately, an application might package multiple files or directories into an archive file (e.g., ZIP or tar), but the application might not exclude sensitive files that are underneath those directories.In cloud technologies and containers, this weakness might present itself in the form of misconfigured storage accounts that can be read or written by a public or anonymous user.", "Modes_Of_Introduction": "Implementation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.Operation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to disable public access.", "Demonstrative_Examples": "The following Azure command updates the settings for a storage account:. However, \"Allow Blob Public Access\" is set to true, meaning that anonymous/public users can access blobs.The following Google Cloud Storage command gets the settings for a storage account named 'BUCKET_NAME':. Suppose the command returns the following result:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": null}]}, {"ID": "219", "Name": "Storage of File with Sensitive Data Under Web Root", "Description": "Access control permissions should be set to prevent reading/writing of sensitive files inside/outside of the web directory.", "Extended_Description": "Besides public-facing web pages and code, products may store sensitive data, code that is not directly invoked, or other files under the web document root of the web server.  If the server is not configured or otherwise used to prevent direct access to those files, then attackers may obtain this sensitive data.", "Modes_Of_Introduction": "Operation: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.Implementation: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Avoid storing information under the web root directory.System Configuration : Access control permissions should be set to prevent reading/writing of sensitive files inside/outside of the web directory.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "552", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "22", "Name": "Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')", "Description": "When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.", "Extended_Description": "Many file operations are intended to take place within a restricted directory. By using special elements such as \"..\" and \"/\" separators, attackers can escape outside of the restricted location to access files or directories that are elsewhere on the system. One of the most common special elements is the \"../\" sequence, which in most modern operating systems is interpreted as the parent directory of the current location. This is referred to as relative path traversal. Path traversal also covers the use of absolute pathnames such as \"/usr/local/bin\", which may also be useful in accessing unexpected files. This is referred to as absolute path traversal.In many programming languages, the injection of a null byte (the 0 or NUL) may allow an attacker to truncate a generated filename to widen the scope of attack. For example, the product may add \".txt\" to any pathname, thus limiting the attacker to text files, but a null injection may effectively remove this restriction.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: The attacker may be able to create or overwrite critical files that are used to execute code, such as programs or libraries.Scopes: Integrity. Impacts: Modify Files or Directories. Note: The attacker may be able to overwrite or create critical files, such as programs, libraries, or important data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, appending a new account at the end of a password file may allow an attacker to bypass authentication.Scopes: Confidentiality. Impacts: Read Files or Directories. Note: The attacker may be able read the contents of unexpected files and expose sensitive data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, by reading a password file, the attacker could conduct brute force password guessing attacks in order to break into an account on the system.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: The attacker may be able to overwrite, delete, or corrupt unexpected critical files such as programs, libraries, or important data. This may prevent the product from working at all and in the case of a protection mechanisms such as authentication, it has the potential to lockout every user of the product.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated techniques can find areas where path traversal weaknesses exist. However, tuning or customization may be required to remove or de-prioritize path-traversal problems that are only exploitable by the product's administrator - or other privileged users - and thus potentially valid behavior or, at worst, a bug instead of a vulnerability. Method Name: Manual Static Analysis. Description: Manual white box techniques may be able to provide sufficient code coverage and reduction of false positives if all file access operations can be assessed within limited time constraints. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n                  Use a built-in path canonicalization function (such as realpath() in C) that produces the canonical version of the pathname, which effectively removes \"..\" sequences and symbolic links (CWE-23, CWE-59). This includes:\n                     \n                        realpath() in C\n                        getCanonicalPath() in Java\n                        GetFullPath() in ASP.NET\n                        realpath() or abs_path() in Perl\n                        realpath() in PHPArchitecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.Operation : Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n                  For example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\". Features such as the ESAPI AccessReferenceMap [REF-185] provide this capability.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.Architecture and Design : Store library, include, and utility files outside of the web document root, if possible. Otherwise, store them in a separate directory and use the web server's access control capabilities to prevent attackers from directly requesting them. One common practice is to define a fixed constant in each calling program, then check for the existence of the constant in the library/include file; if the constant does not exist, then the file was directly requested, and it can exit immediately.\n                  This significantly reduces the chance of an attacker being able to bypass any protection mechanisms that are in the base program but not in the include files. It will also reduce the attack surface.Implementation : Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n                  In the context of path traversal, error messages which disclose path information can help attackers craft the appropriate attack strings to move through the file system hierarchy.Operation : When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.", "Demonstrative_Examples": "The following code could be for a social networking application in which each user's profile information is stored in a separate file. All files are stored in a single directory.. While the programmer intends to access files such as \"/users/cwe/profiles/alice\" or \"/users/cwe/profiles/bob\", there is no verification of the incoming user parameter. An attacker could provide a string such as:In the example below, the path to a dictionary file is read from a system property and used to initialize a File object.. However, the path is not validated or modified to prevent it from containing relative or absolute path sequences before creating the File object. This allows anyone who can control the system property to determine what file is used. Ideally, the path should be resolved relative to some kind of application or user home directory.The following code takes untrusted input and uses a regular expression to filter \"../\" from the input. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the regular expression does not have the /g global match modifier, it only removes the first instance of \"../\" it comes across. So an input value such as:The following code attempts to validate a given input path by checking it against an allowlist and once validated delete the given file. In this specific case, the path is considered valid if it starts with the string \"/safe_dir/\".. An attacker could provide an input such as this:The following code demonstrates the unrestricted upload of a file with a Java servlet and a path traversal vulnerability. The action attribute of an HTML form is sending the upload file request to the Java servlet.. When submitted the Java servlet's doPost method will receive the request, extract the name of the file from the Http request header, read the file contents from the request and output the file to the local upload directory.This script intends to read a user-supplied file from the current directory. The user inputs the relative path to the file and the script uses Python's os.path.join() function to combine the path to the current working directory with the provided path to the specified file. This results in an absolute path to the desired file. If the file does not exist when the script attempts to read it, an error is printed to the user.. However, if the user supplies an absolute path, the os.path.join() function will discard the path to the current working directory and use only the absolute path provided. For example, if the current working directory is /home/user/documents, but the user inputs /etc/passwd, os.path.join() will use only /etc/passwd, as it is considered an absolute path. In the above scenario, this would cause the script to access and read the /etc/passwd file.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": null}]}, {"ID": "220", "Name": "Storage of File With Sensitive Data Under FTP Root", "Description": "Access control permissions should be set to prevent reading/writing of sensitive files inside/outside of the FTP directory.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Avoid storing information under the FTP root directory.System Configuration : Access control permissions should be set to prevent reading/writing of sensitive files inside/outside of the FTP directory.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "552", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "221", "Name": "Information Loss or Omission", "Description": "The product does not record, or improperly records, security-relevant information that leads to an incorrect decision or hampers later analysis.", "Extended_Description": "This can be resultant, e.g. a buffer overflow might trigger a crash before the product can log the event.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "222", "Name": "Truncation of Security-relevant Information", "Description": "The product truncates the display, recording, or processing of security-relevant information in a way that can obscure the source or nature of an attack.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Non-Repudiation. Impacts: Hide Activities. Note: The source of an attack will be difficult or impossible to determine. This can allow attacks to the system to continue without notice.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "221", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "223", "Name": "Omission of Security-relevant Information", "Description": "The product does not record or display information that would be important for identifying the source or nature of an attack, or determining if an action is safe.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Non-Repudiation. Impacts: Hide Activities. Note: The source of an attack will be difficult or impossible to determine. This can allow attacks to the system to continue without notice.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This code logs suspicious multiple login attempts.. This code only logs failed login attempts when a certain limit is reached. If an attacker knows this limit, they can stop their attack from being discovered by avoiding the limit.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "221", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "224", "Name": "Obscured Security-relevant Information by Alternate Name", "Description": "The product records security-relevant information according to an alternate name of the affected entity, instead of the canonical name.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This code prints the contents of a file if a user has permission.. While the code logs a bad access attempt, it logs the user supplied name for the file, not the canonicalized file name. An attacker can obscure their target by giving the script the name of a link to the file they are attempting to access. Also note this code contains a race condition between the is_link() and readlink() functions (CWE-363).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "221", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "459", "Name": "Incomplete Cleanup", "Description": "Temporary files and other supporting resources should be deleted/released immediately after they are no longer needed.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: OtherConfidentialityIntegrity. Impacts: OtherRead Application DataModify Application DataDoS: Resource Consumption (Other). Note: It is possible to overflow the number of temporary files because directories typically have limits on the number of files allowed. This could create a denial of service problem.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Temporary files and other supporting resources should be deleted/released immediately after they are no longer needed.", "Demonstrative_Examples": ". Stream resources in a Java application should be released in a finally block, otherwise an exception thrown before the call to close() would result in an unreleased I/O resource. In the example below, the close() method is called in the try block (incorrect).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "228", "Name": "Improper Handling of Syntactically Invalid Structure", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityAvailability. Impacts: Unexpected StateDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU). Note: If an input is syntactically invalid, then processing the input could place the system in an unexpected state that could lead to a crash, consume available system resources or other unintended behaviors.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "This Android application has registered to handle a URL when sent an intent:. The application assumes the URL will always be included in the intent. When the URL is not present, the call to getStringExtra() will return null, thus causing a null pointer exception when length() is called.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "229", "Name": "Improper Handling of Values", "Description": "The product does not properly handle when the expected number of values for parameters, fields, or arguments is not provided in input, or if those values are undefined.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "228", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "23", "Name": "Relative Path Traversal", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n                  Use a built-in path canonicalization function (such as realpath() in C) that produces the canonical version of the pathname, which effectively removes \"..\" sequences and symbolic links (CWE-23, CWE-59). This includes:\n                     \n                        realpath() in C\n                        getCanonicalPath() in Java\n                        GetFullPath() in ASP.NET\n                        realpath() or abs_path() in Perl\n                        realpath() in PHP", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: The attacker may be able to create or overwrite critical files that are used to execute code, such as programs or libraries.Scopes: Integrity. Impacts: Modify Files or Directories. Note: The attacker may be able to overwrite or create critical files, such as programs, libraries, or important data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, appending a new account at the end of a password file may allow an attacker to bypass authentication.Scopes: Confidentiality. Impacts: Read Files or Directories. Note: The attacker may be able read the contents of unexpected files and expose sensitive data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, by reading a password file, the attacker could conduct brute force password guessing attacks in order to break into an account on the system.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: The attacker may be able to overwrite, delete, or corrupt unexpected critical files such as programs, libraries, or important data. This may prevent the product from working at all and in the case of a protection mechanisms such as authentication, it has the potential to lockout every user of the product.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n                  Use a built-in path canonicalization function (such as realpath() in C) that produces the canonical version of the pathname, which effectively removes \"..\" sequences and symbolic links (CWE-23, CWE-59). This includes:\n                     \n                        realpath() in C\n                        getCanonicalPath() in Java\n                        GetFullPath() in ASP.NET\n                        realpath() or abs_path() in Perl\n                        realpath() in PHP", "Demonstrative_Examples": "The following URLs are vulnerable to this attack:. A simple way to execute this attack is like this:The following code could be for a social networking application in which each user's profile information is stored in a separate file. All files are stored in a single directory.. While the programmer intends to access files such as \"/users/cwe/profiles/alice\" or \"/users/cwe/profiles/bob\", there is no verification of the incoming user parameter. An attacker could provide a string such as:The following code demonstrates the unrestricted upload of a file with a Java servlet and a path traversal vulnerability. The action attribute of an HTML form is sending the upload file request to the Java servlet.. When submitted the Java servlet's doPost method will receive the request, extract the name of the file from the Http request header, read the file contents from the request and output the file to the local upload directory.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "22", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "22", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "22", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "230", "Name": "Improper Handling of Missing Values", "Description": "The product does not handle or incorrectly handles when a parameter, field, or argument name is specified, but the associated value is missing, i.e. it is empty, blank, or null.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This Android application has registered to handle a URL when sent an intent:. The application assumes the URL will always be included in the intent. When the URL is not present, the call to getStringExtra() will return null, thus causing a null pointer exception when length() is called.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "229", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "231", "Name": "Improper Handling of Extra Values", "Description": "The product does not handle or incorrectly handles when more values are provided than expected.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: This typically occurs in situations when only one value is expected.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "229", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "120", "View_ID": "1000", "Ordinal": null}]}, {"ID": "232", "Name": "Improper Handling of Undefined Values", "Description": "The product does not handle or incorrectly handles when a value is not defined or supported for the associated parameter, field, or argument name.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "In this example, an address parameter is read and trimmed of whitespace.. If the value of the address parameter is null (undefined), the servlet will throw a NullPointerException when the trim() is attempted.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "229", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "233", "Name": "Improper Handling of Parameters", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "This Android application has registered to handle a URL when sent an intent:. The application assumes the URL will always be included in the intent. When the URL is not present, the call to getStringExtra() will return null, thus causing a null pointer exception when length() is called.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "228", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "234", "Name": "Failure to Handle Missing Parameter", "Description": "Forward declare all functions. This is the recommended solution. Properly forward declaration of all used functions will result in a compiler error if too few arguments are sent to a function.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsGain Privileges or Assume Identity. Note: There is the potential for arbitrary code execution with privileges of the vulnerable program if function parameter list is exhausted.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: Potentially a program could fail if it needs more arguments then are available.", "Detection_Methods": "", "Potential_Mitigations": "Build and Compilation : This issue can be simply combated with the use of proper build process.Implementation : Forward declare all functions. This is the recommended solution. Properly forward declaration of all used functions will result in a compiler error if too few arguments are sent to a function.", "Demonstrative_Examples": "The following example demonstrates the weakness.. This can be exploited to disclose information with no work whatsoever. In fact, each time this function is run, it will print out the next 4 bytes on the stack after the two numbers sent to it.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "233", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "235", "Name": "Improper Handling of Extra Parameters", "Description": "The product does not handle or incorrectly handles when the number of parameters, fields, or arguments with the same name exceeds the expected amount.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: This typically occurs in situations when only one element is expected to be specified.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "233", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "236", "Name": "Improper Handling of Undefined Parameters", "Description": "The product does not handle or incorrectly handles when a particular parameter, field, or argument name is not defined or supported by the product.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "233", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "237", "Name": "Improper Handling of Structural Elements", "Description": "The product does not handle or incorrectly handles inputs that are related to complex structures.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "228", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "238", "Name": "Improper Handling of Incomplete Structural Elements", "Description": "The product does not handle or incorrectly handles when a particular structural element is not completely specified.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "237", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "239", "Name": "Failure to Handle Incomplete Element", "Description": "The product does not properly handle when a particular element is not completely specified.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "237", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "404", "View_ID": "1000", "Ordinal": null}]}, {"ID": "24", "Name": "Path Traversal: '../filedir'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The \"../\" manipulation is the canonical manipulation for operating systems that use \"/\" as directory separators, such as UNIX- and Linux-based systems. In some cases, it is useful for bypassing protection schemes in environments for which \"/\" is supported but not the primary separator, such as Windows, which uses \"\\\" but can also accept \"/\".", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "241", "Name": "Improper Handling of Unexpected Data Type", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "228", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "242", "Name": "Use of Inherently Dangerous Function", "Description": "Use grep or static analysis tools to spot usage of dangerous functions.", "Extended_Description": "Certain functions behave in dangerous ways regardless of how they are used. Functions in this category were often implemented without taking security concerns into account. The gets() function is unsafe because it does not perform bounds checking on the size of its input. An attacker can easily send arbitrarily-sized input to gets() and overflow the destination buffer. Similarly, the >> operator is unsafe to use when reading into a statically-allocated character array because it does not perform bounds checking on the size of its input. An attacker can easily send arbitrarily-sized input to the >> operator and overflow the destination buffer.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Ban the use of dangerous functions. Use their safe equivalent.Testing : Use grep or static analysis tools to spot usage of dangerous functions.", "Demonstrative_Examples": "The code below calls gets() to read information into a buffer.. The gets() function in C is inherently unsafe.The code below calls the gets() function to read in data from the command line.. However, gets() is inherently unsafe, because it copies all input from STDIN to the buffer without checking size. This allows the user to provide a string that is larger than the buffer size, resulting in an overflow condition.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1177", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "243", "Name": "Creation of chroot Jail Without Changing Working Directory", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "Improper use of chroot() may allow attackers to escape from the chroot jail. The chroot() function call does not change the process's current working directory, so relative paths may still refer to file system resources outside of the chroot jail after chroot() has been called.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "Consider the following source code from a (hypothetical) FTP server:. This code is responsible for reading a filename from the network, opening the corresponding file on the local machine, and sending the contents over the network. This code could be used to implement the FTP GET command. The FTP server calls chroot() in its initialization routines in an attempt to prevent access to files outside of /var/ftproot. But because the server does not change the current working directory by calling chdir(\"/\"), an attacker could request the file \"../../../../../etc/passwd\" and obtain a copy of the system password file.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "244", "Name": "Improper Clearing of Heap Memory Before Release ('Heap Inspection')", "Description": "Using realloc() to resize buffers that store sensitive information can leave the sensitive information exposed to attack, because it is not removed from memory.", "Extended_Description": "When sensitive data such as a password or an encryption key is not removed from memory, it could be exposed to an attacker using a \"heap inspection\" attack that reads the sensitive data using memory dumps or other methods. The realloc() function is commonly used to increase the size of a block of allocated memory. This operation often requires copying the contents of the old memory block into a new and larger block. This operation leaves the contents of the original block intact but inaccessible to the program, preventing the program from being able to scrub sensitive data from memory. If an attacker can later examine the contents of a memory dump, the sensitive data could be exposed.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityOther. Impacts: Read MemoryOther. Note: Be careful using vfork() and fork() in security sensitive code. The process state will not be cleaned up and will contain traces of data from past use.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code calls realloc() on a buffer containing sensitive data:. There is an attempt to scrub the sensitive data from memory, but realloc() is used, so it could return a pointer to a different part of memory. The memory that was originally allocated for cleartext_buffer could still contain an uncleared copy of the data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "226", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "669", "View_ID": "1000", "Ordinal": null}]}, {"ID": "245", "Name": "J2EE Bad Practices: Direct Management of Connections", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "The J2EE standard forbids the direct management of connections. It requires that applications use the container's resource management facilities to obtain connections to resources. Every major web application container provides pooled database connection management as part of its resource management framework. Duplicating this functionality in an application is difficult and error prone, which is part of the reason it is forbidden under the J2EE standard.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "In the following example, the class DatabaseConnection opens and manages a connection to a database for a J2EE application. The method openDatabaseConnection opens a connection to the database using a DriverManager to create the Connection object conn to the database specified in the string constant CONNECT_STRING.. The use of the DriverManager class to directly manage the connection to the database violates the J2EE restriction against the direct management of connections. The J2EE application should use the web application container's resource management facilities to obtain a connection to the database as shown in the following example.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "695", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "246", "Name": "J2EE Bad Practices: Direct Use of Sockets", "Description": "Use framework method calls instead of using sockets directly.", "Extended_Description": "The J2EE standard permits the use of sockets only for the purpose of communication with legacy systems when no higher-level protocol is available. Authoring your own communication protocol requires wrestling with difficult security issues.Without significant scrutiny by a security expert, chances are good that a custom communication protocol will suffer from security problems. Many of the same issues apply to a custom implementation of a standard protocol. While there are usually more resources available that address security concerns related to implementing a standard protocol, these resources are also available to attackers.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use framework method calls instead of using sockets directly.", "Demonstrative_Examples": "The following example opens a socket to connect to a remote server.. A Socket object is created directly within the Java servlet, which is a dangerous way to manage remote connections.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "695", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "705", "Name": "Incorrect Control Flow Scoping", "Description": "The product does not properly return control flow to the proper location after it has completed a task or detected an unusual condition.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "248", "Name": "Uncaught Exception", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "When an exception is not caught, it may cause the program to crash or expose sensitive information.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityConfidentiality. Impacts: DoS: Crash, Exit, or RestartRead Application Data. Note: An uncaught exception could cause the system to be placed in a state that could lead to a crash, exposure of sensitive information or other unintended behaviors.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The following example attempts to resolve a hostname.. A DNS lookup failure will cause the Servlet to throw an exception.. The _alloca() function allocates memory on the stack. If an allocation request is too large for the available stack space, _alloca() throws an exception. If the exception is not caught, the program will crash, potentially enabling a denial of service attack. _alloca() has been deprecated as of Microsoft Visual Studio 2005(R). It has been replaced with the more secure _alloca_s().. EnterCriticalSection() can raise an exception, potentially causing the program to crash. Under operating systems prior to Windows 2000, the EnterCriticalSection() function can raise an exception in low memory situations. If the exception is not caught, the program will crash, potentially enabling a denial of service attack.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "705", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "25", "Name": "Path Traversal: '/../filedir'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.Sometimes a program checks for \"../\" at the beginning of the input, so a \"/../\" can bypass that check.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "250", "Name": "Execution with Unnecessary Privileges", "Description": "Ensure that the software runs properly under the United States Government Configuration Baseline (USGCB) [REF-199] or an equivalent hardening configuration guide, which many organizations use to limit the attack surface and potential risk of deployed software.", "Extended_Description": "New weaknesses can be exposed because running with extra privileges, such as root or Administrator, can disable the normal security checks being performed by the operating system or surrounding environment. Other pre-existing weaknesses can turn into security vulnerabilities if they occur while operating at raised privileges.Privilege management functions can behave in some less-than-obvious ways, and they have different quirks on different platforms. These inconsistencies are particularly pronounced if you are transitioning from one non-root user to another. Signal handlers and spawned processes run at the privilege of the owning process, so if a process is running as root when a signal fires or a sub-process is executed, the signal handler or sub-process will operate with root privileges.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.Architecture and Design: If an application has this design problem, then it can be easier for the developer to make implementation-related errors such as CWE-271 (Privilege Dropping / Lowering Errors). In addition, the consequences of Privilege Chaining (CWE-268) can become more severe.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess Control. Impacts: Gain Privileges or Assume IdentityExecute Unauthorized Code or CommandsRead Application DataDoS: Crash, Exit, or Restart. Note: An attacker will be able to gain access to any resources that are allowed by the extra privileges. Common results include executing code, disabling services, and reading restricted data.", "Detection_Methods": "Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. Method Name: Black Box. Description: Use monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.Attach the monitor to the process and perform a login. Look for library functions and system calls that indicate when privileges are being raised or dropped. Look for accesses of resources that are restricted to normal users. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : Identify the functionality that requires additional privileges, such as access to privileged operating system resources. Wrap and centralize this functionality if possible, and isolate the privileged code as much as possible from other code [REF-76]. Raise privileges as late as possible, and drop them as soon as possible to avoid CWE-271. Avoid weaknesses such as CWE-288 and CWE-420 by protecting all possible communication channels that could interact with the privileged code, such as a secondary socket that is only intended to be accessed by administrators.Architecture and Design : Identify the functionality that requires additional privileges, such as access to privileged operating system resources. Wrap and centralize this functionality if possible, and isolate the privileged code as much as possible from other code [REF-76]. Raise privileges as late as possible, and drop them as soon as possible to avoid CWE-271. Avoid weaknesses such as CWE-288 and CWE-420 by protecting all possible communication channels that could interact with the privileged code, such as a secondary socket that is only intended to be accessed by administrators.Implementation : Perform extensive input validation for any privileged code that must be exposed to the user and reject anything that does not fit your strict requirements.Implementation : When dropping privileges, ensure that they have been dropped successfully to avoid CWE-273. As protection mechanisms in the environment get stronger, privilege-dropping calls may fail even if it seems like they would always succeed.Implementation : If circumstances force you to run with extra privileges, then determine the minimum access level necessary. First identify the different permissions that the software and its users will need to perform their actions, such as file read and write permissions, network socket permissions, and so forth. Then explicitly allow those actions while denying all else [REF-76]. Perform extensive input validation and canonicalization to minimize the chances of introducing a separate vulnerability. This mitigation is much more prone to error than dropping the privileges in the first place.Operation : Ensure that the software runs properly under the United States Government Configuration Baseline (USGCB) [REF-199] or an equivalent hardening configuration guide, which many organizations use to limit the attack surface and potential risk of deployed software.", "Demonstrative_Examples": "This code temporarily raises the program's privileges to allow creation of a new user folder.. While the program only raises its privilege level to create the folder and immediately lowers it again, if the call to os.mkdir() throws an exception, the call to lowerPrivileges() will not occur. As a result, the program is indefinitely operating in a raised privilege state, possibly allowing further exploitation to occur.The following code calls chroot() to restrict the application to a subset of the filesystem below APP_HOME in order to prevent an attacker from using the program to gain unauthorized access to files located elsewhere. The code then opens a file specified by the user and processes the contents of the file.. Constraining the process inside the application's home directory before opening any files is a valuable security measure. However, the absence of a call to setuid() with some non-zero value means the application is continuing to operate with unnecessary root privileges. Any successful exploit carried out by an attacker against the application can now result in a privilege escalation attack because any malicious operations will be performed with the privileges of the superuser. If the application drops to the privilege level of a non-root user, the potential for damage is substantially reduced.This application intends to use a user's location to determine the timezone the user is in:. This is unnecessary use of the location API, as this information is already available using the Android Time API. Always be sure there is not another way to obtain needed information before resorting to using the location API.This code uses location to determine the user's current US State location.. First the application must declare that it requires the ACCESS_FINE_LOCATION permission in the application's manifest.xml:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "269", "View_ID": "1000", "Ordinal": null}]}, {"ID": "269", "Name": "Improper Privilege Management", "Description": "Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Follow the principle of least privilege when assigning access rights to entities in a software system.Architecture and Design : Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.", "Demonstrative_Examples": "This code temporarily raises the program's privileges to allow creation of a new user folder.. While the program only raises its privilege level to create the folder and immediately lowers it again, if the call to os.mkdir() throws an exception, the call to lowerPrivileges() will not occur. As a result, the program is indefinitely operating in a raised privilege state, possibly allowing further exploitation to occur.. The following example demonstrates the weakness.. The following example demonstrates the weakness.This code intends to allow only Administrators to print debug information about a system.. While the intention was to only allow Administrators to print the debug information, the code as written only excludes those with the role of \"GUEST\". Someone with the role of \"ADMIN\" or \"USER\" will be allowed access, which goes against the original intent. An attacker may be able to use this debug information to craft an attack on the system.This code allows someone with the role of \"ADMIN\" or \"OPERATOR\" to reset a user's password. The role of \"OPERATOR\" is intended to have less privileges than an \"ADMIN\", but still be able to help users with small issues such as forgotten passwords.. This code does not check the role of the user whose password is being reset. It is possible for an Operator to gain Admin privileges by resetting the password of an Admin account and taking control of that account.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "754", "Name": "Improper Check for Unusual or Exceptional Conditions", "Description": "Use system limits, which should help to prevent resource exhaustion. However, the product should still handle low resource conditions since they may still occur.", "Extended_Description": "The programmer may assume that certain events or conditions will never occur or do not need to be worried about, such as low memory conditions, lack of access to resources due to restrictive permissions, or misbehaving clients or components. However, attackers may intentionally trigger these unusual conditions, thus violating the programmer's assumptions, possibly introducing instability, incorrect behavior, or a vulnerability.Note that this entry is not exclusively about the use of exceptions and exception handling, which are mechanisms for both checking and handling unusual or unexpected conditions.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityAvailability. Impacts: DoS: Crash, Exit, or RestartUnexpected State. Note: The data which were produced as a result of a function call could be in a bad state upon return. If the return value is not checked, then this bad data may be used in operations, possibly leading to a crash or other unintended behaviors.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis may be useful for detecting unusual conditions involving system resources or common programming idioms, but not for violations of business rules. Method Name: Manual Dynamic Analysis. Description: Identify error conditions that are not likely to occur during normal usage and trigger them. For example, run the program under low memory conditions, run with insufficient privileges or permissions, interrupt a transaction before it is completed, or disable connectivity to basic network services such as DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled exception or similar error that was discovered and handled by the application's environment, it may still indicate unexpected conditions that were not handled by the application itself.", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Choose languages with features such as exception handling that force the programmer to anticipate unusual conditions that may generate exceptions. Custom exceptions may need to be developed to handle unusual business-logic conditions. Be careful not to pass sensitive exceptions back to the user (CWE-209, CWE-248).Implementation : Check the results of all functions that return a value and verify that the value is expected.Implementation : If using exception handling, catch and throw specific exceptions instead of overly-general exceptions (CWE-396, CWE-397). Catch and handle exceptions as locally as possible so that exceptions do not propagate too far up the call stack (CWE-705). Avoid unchecked or uncaught exceptions where feasible (CWE-248).Implementation : Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n\t\t  Exposing additional information to a potential attacker in the context of an exceptional condition can help the attacker determine what attack vectors are most likely to succeed beyond DoS.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Architecture and Design : If the program must fail, ensure that it fails gracefully (fails closed). There may be a temptation to simply let the program fail poorly in cases such as low memory conditions, but an attacker may be able to assert control before the software has fully exited. Alternately, an uncontrolled failure could cause cascading problems with other downstream components; for example, the program could send a signal to a downstream process so the process immediately knows that a problem has occurred and has a better chance of recovery.Architecture and Design : Use system limits, which should help to prevent resource exhaustion. However, the product should still handle low resource conditions since they may still occur.", "Demonstrative_Examples": "Consider the following code segment:. The programmer expects that when fgets() returns, buf will contain a null-terminated string of length 9 or less. But if an I/O error occurs, fgets() will not null-terminate buf. Furthermore, if the end of the file is reached before any characters are read, fgets() returns without writing anything to buf. In both of these situations, fgets() signals that something unusual has happened by returning NULL, but in this code, the warning will not be noticed. The lack of a null terminator in buf can result in a buffer overflow in the subsequent call to strcpy().The following code does not check to see if memory allocation succeeded before attempting to use the pointer returned by malloc().. The traditional defense of this coding error is: \"If my program runs out of memory, it will fail. It doesn't matter whether I handle the error or simply allow the program to die with a segmentation fault when it tries to dereference the null pointer.\" This argument ignores three important considerations:The following examples read a file into a byte array.. The code loops through a set of users, reading a private data file for each user. The programmer assumes that the files are always 1 kilobyte in size and therefore ignores the return value from Read(). If an attacker can create a smaller file, the program will recycle the remainder of the data from the previous user and treat it as though it belongs to the attacker.The following code does not check to see if the string returned by getParameter() is null before calling the member function compareTo(), potentially causing a NULL dereference.. The following code does not check to see if the string returned by the Item property is null before calling the member function Equals(), potentially causing a NULL dereference.The following code shows a system property that is set to null and later dereferenced by a programmer who mistakenly assumes it will always be defined.. The traditional defense of this coding error is: \"I know the requested value will always exist because.... If it does not exist, the program cannot perform the desired behavior so it doesn't matter whether I handle the error or simply allow the program to die dereferencing a null value.\" But attackers are skilled at finding unexpected paths through programs, particularly when exceptions are involved.The following VB.NET code does not check to make sure that it has read 50 bytes from myfile.txt. This can cause DoDangerousOperation() to operate on an unexpected value.. In .NET, it is not uncommon for programmers to misunderstand Read() and related methods that are part of many System.IO classes. The stream and reader classes do not consider it to be unusual or exceptional if only a small amount of data becomes available. These classes simply add the small amount of data to the return buffer, and set the return value to the number of bytes or characters read. There is no guarantee that the amount of data returned is equal to the amount of data requested.This example takes an IP address from a user, verifies that it is well formed and then looks up the hostname and copies it into a buffer.. If an attacker provides an address that appears to be well-formed, but the address does not resolve to a hostname, then the call to gethostbyaddr() will return NULL. Since the code does not check the return value from gethostbyaddr (CWE-252), a NULL pointer dereference\n\t       (CWE-476) would then occur in the call to strcpy().In the following C/C++ example the method outputStringToFile opens a file in the local filesystem and outputs a string to the file. The input parameters output and filename contain the string to output to the file and the name of the file respectively.. However, this code does not check the return values of the methods openFileToWrite, writeToFile, closeFile to verify that the file was properly opened and closed and that the string was successfully written to the file. The return values for these methods should be checked to determine if the method was successful and allow for detection of errors or unexpected conditions as in the following example.In the following Java example the method readFromFile uses a FileReader object to read the contents of a file. The FileReader object is created using the File object readFile, the readFile object is initialized using the setInputFile method. The setInputFile method should be called before calling the readFromFile method.. However, the readFromFile method does not check to see if the readFile object is null, i.e. has not been initialized, before creating the FileReader object and reading from the input file. The readFromFile method should verify whether the readFile object is null and output an error message and raise an exception if the readFile object is null, as in the following code.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "252", "Name": "Unchecked Return Value", "Description": "When designing a function, make sure you return a value or throw an exception in case of an error.", "Extended_Description": "Two common programmer assumptions are \"this function call can never fail\" and \"it doesn't matter if this function call fails\". If an attacker can force the function to fail or otherwise return a value that is not expected, then the subsequent program logic could lead to a vulnerability, because the product is not in a state that the programmer assumes. For example, if the program calls a function to drop privileges but does not check the return code to ensure that privileges were successfully dropped, then the program will continue to operate with the higher privileges.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityIntegrity. Impacts: Unexpected StateDoS: Crash, Exit, or Restart. Note: An unexpected return value could place the system in a state that could lead to a crash or other unintended behaviors.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Check the results of all functions that return a value and verify that the value is expected.Implementation : Ensure that you account for all possible return values from the function.Implementation : When designing a function, make sure you return a value or throw an exception in case of an error.", "Demonstrative_Examples": "Consider the following code segment:. The programmer expects that when fgets() returns, buf will contain a null-terminated string of length 9 or less. But if an I/O error occurs, fgets() will not null-terminate buf. Furthermore, if the end of the file is reached before any characters are read, fgets() returns without writing anything to buf. In both of these situations, fgets() signals that something unusual has happened by returning NULL, but in this code, the warning will not be noticed. The lack of a null terminator in buf can result in a buffer overflow in the subsequent call to strcpy().In the following example, it is possible to request that memcpy move a much larger segment of memory than assumed:. If returnChunkSize() happens to encounter an error it will return -1. Notice that the return value is not checked before the memcpy operation (CWE-252), so -1 can be passed as the size argument to memcpy() (CWE-805). Because memcpy() assumes that the value is unsigned, it will be interpreted as MAXINT-1 (CWE-195), and therefore will copy far more memory than is likely available to the destination buffer (CWE-787, CWE-788).The following code does not check to see if memory allocation succeeded before attempting to use the pointer returned by malloc().. The traditional defense of this coding error is: \"If my program runs out of memory, it will fail. It doesn't matter whether I handle the error or allow the program to die with a segmentation fault when it tries to dereference the null pointer.\" This argument ignores three important considerations:The following examples read a file into a byte array.. The code loops through a set of users, reading a private data file for each user. The programmer assumes that the files are always 1 kilobyte in size and therefore ignores the return value from Read(). If an attacker can create a smaller file, the program will recycle the remainder of the data from the previous user and treat it as though it belongs to the attacker.The following code does not check to see if the string returned by getParameter() is null before calling the member function compareTo(), potentially causing a NULL dereference.. The following code does not check to see if the string returned by the Item property is null before calling the member function Equals(), potentially causing a NULL dereference.The following code shows a system property that is set to null and later dereferenced by a programmer who mistakenly assumes it will always be defined.. The traditional defense of this coding error is: \"I know the requested value will always exist because.... If it does not exist, the program cannot perform the desired behavior so it doesn't matter whether I handle the error or allow the program to die dereferencing a null value.\" But attackers are skilled at finding unexpected paths through programs, particularly when exceptions are involved.The following VB.NET code does not check to make sure that it has read 50 bytes from myfile.txt. This can cause DoDangerousOperation() to operate on an unexpected value.. In .NET, it is not uncommon for programmers to misunderstand Read() and related methods that are part of many System.IO classes. The stream and reader classes do not consider it to be unusual or exceptional if only a small amount of data becomes available. These classes simply add the small amount of data to the return buffer, and set the return value to the number of bytes or characters read. There is no guarantee that the amount of data returned is equal to the amount of data requested.. It is not uncommon for Java programmers to misunderstand read() and related methods that are part of many java.io classes. Most errors and unusual events in Java result in an exception being thrown. But the stream and reader classes do not consider it unusual or exceptional if only a small amount of data becomes available. These classes simply add the small amount of data to the return buffer, and set the return value to the number of bytes or characters read. There is no guarantee that the amount of data returned is equal to the amount of data requested. This behavior makes it important for programmers to examine the return value from read() and other IO methods to ensure that they receive the amount of data they expect.This example takes an IP address from a user, verifies that it is well formed and then looks up the hostname and copies it into a buffer.. If an attacker provides an address that appears to be well-formed, but the address does not resolve to a hostname, then the call to gethostbyaddr() will return NULL. Since the code does not check the return value from gethostbyaddr (CWE-252), a NULL pointer dereference\n\t       (CWE-476) would then occur in the call to strcpy().The following function attempts to acquire a lock in order to perform operations on a shared resource.. However, the code does not check the value returned by pthread_mutex_lock() for errors. If pthread_mutex_lock() cannot acquire the mutex for any reason, the function may introduce a race condition into the program and result in undefined behavior.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "476", "View_ID": "1000", "Ordinal": null}]}, {"ID": "253", "Name": "Incorrect Check of Function Return Value", "Description": "When designing any function make sure you return a value or throw an exception in case of an error.", "Extended_Description": "Important and common functions will return some value about the success of its actions. This will alert the program whether or not to handle any errors caused by that function.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityIntegrity. Impacts: Unexpected StateDoS: Crash, Exit, or Restart. Note: An unexpected return value could place the system in a state that could lead to a crash or other unintended behaviors.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use a language or compiler that uses exceptions and requires the catching of those exceptions.Implementation : Properly check all functions which return a value.Implementation : When designing any function make sure you return a value or throw an exception in case of an error.", "Demonstrative_Examples": "This code attempts to allocate memory for 4 integers and checks if the allocation succeeds.. The code assumes that only a negative return value would indicate an error, but malloc() may return a null pointer when there is an error. The value of tmp could then be equal to 0, and the error would be missed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1000", "Ordinal": null}]}, {"ID": "522", "Name": "Insufficiently Protected Credentials", "Description": "Use industry standards to protect the credentials (e.g. LDAP, keystore, etc.).", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker could gain access to user accounts and access sensitive data used by the user accounts.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use an appropriate security mechanism to protect the credentials.Architecture and Design : Make appropriate use of cryptography to protect the credentials.Implementation : Use industry standards to protect the credentials (e.g. LDAP, keystore, etc.).", "Demonstrative_Examples": "This code changes a user's password.. While the code confirms that the requesting user typed the same new password twice, it does not confirm that the user requesting the password change is the same user whose password will be changed. An attacker can request a change of another user's password and gain control of the victim's account.The following code reads a password from a properties file and uses the password to connect to a database.. This code will run successfully, but anyone who has access to config.properties can read the value of password. If a devious employee has access to this information, they can use it to break into the system.The following code reads a password from the registry and uses the password to create a new network credential.. This code will run successfully, but anyone who has access to the registry key used to store the password can read the value of password. If a devious employee has access to this information, they can use it to break into the systemBoth of these examples verify a password by comparing it to a stored compressed version.. Because a compression algorithm is used instead of a one way hashing algorithm, an attacker can recover compressed passwords stored in the database.The following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but they are stored in cleartext.. This Java example shows a properties file with a cleartext username / password pair.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors used cleartext transmission or storage of passwords in their OT products.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": null}]}, {"ID": "256", "Name": "Plaintext Storage of a Password", "Description": "A programmer might attempt to remedy the password management problem by obscuring the password with an encoding function, such as base 64 encoding, but this effort does not adequately protect the password because the encoding can be detected and decoded easily.", "Extended_Description": "Password management issues occur when a password is stored in plaintext in an application's properties, configuration file, or memory. Storing a plaintext password in a configuration file allows anyone who can read the file access to the password-protected resource. In some contexts, even storage of a plaintext password in memory is considered a security risk if the password is not cleared immediately after it is used.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.Architecture and Design: Developers sometimes believe that they cannot defend the application from someone who has access to the configuration, but this belief makes an attacker's job easier.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Avoid storing passwords in easily accessible locations.Architecture and Design : Consider storing cryptographic hashes of passwords as an alternative to storing in plaintext.N/A : A programmer might attempt to remedy the password management problem by obscuring the password with an encoding function, such as base 64 encoding, but this effort does not adequately protect the password because the encoding can be detected and decoded easily.", "Demonstrative_Examples": "The following code reads a password from a properties file and uses the password to connect to a database.. This code will run successfully, but anyone who has access to config.properties can read the value of password. If a devious employee has access to this information, they can use it to break into the system.The following code reads a password from the registry and uses the password to create a new network credential.. This code will run successfully, but anyone who has access to the registry key used to store the password can read the value of password. If a devious employee has access to this information, they can use it to break into the systemThe following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but they are stored in cleartext.. This Java example shows a properties file with a cleartext username / password pair.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. At least one OT product stored a password in plaintext.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "522", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "257", "Name": "Storing Passwords in a Recoverable Format", "Description": "Use strong, non-reversible encryption to protect stored passwords.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityAccess Control. Impacts: Gain Privileges or Assume Identity. Note: User's passwords may be revealed.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Revealed passwords may be reused elsewhere to impersonate the users in question.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use strong, non-reversible encryption to protect stored passwords.", "Demonstrative_Examples": "Both of these examples verify a password by comparing it to a stored compressed version.. Because a compression algorithm is used instead of a one way hashing algorithm, an attacker can recover compressed passwords stored in the database.The following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but they are stored in cleartext.. This Java example shows a properties file with a cleartext username / password pair.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "522", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "259", "View_ID": "1000", "Ordinal": null}]}, {"ID": "258", "Name": "Empty Password in Configuration File", "Description": "Passwords should be at least eight characters long -- the longer the better. Avoid passwords that are in any way similar to other passwords you have. Avoid using words that may be found in a dictionary, names book, on a map, etc. Consider incorporating numbers and/or punctuation into your password. If you do use common words, consider replacing letters in that word with numbers and punctuation. However, do not use \"similar-looking\" punctuation. For example, it is not a good idea to change cat to c@t, ca+, (@+, or anything similar. Finally, it is never appropriate to use an empty string as a password.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : Passwords should be at least eight characters long -- the longer the better. Avoid passwords that are in any way similar to other passwords you have. Avoid using words that may be found in a dictionary, names book, on a map, etc. Consider incorporating numbers and/or punctuation into your password. If you do use common words, consider replacing letters in that word with numbers and punctuation. However, do not use \"similar-looking\" punctuation. For example, it is not a good idea to change cat to c@t, ca+, (@+, or anything similar. Finally, it is never appropriate to use an empty string as a password.", "Demonstrative_Examples": "The following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but the password is provided as an empty string.. This Java example shows a properties file with an empty password string.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "260", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "521", "View_ID": "1000", "Ordinal": null}]}, {"ID": "521", "Name": "Weak Password Requirements", "Description": "Consider implementing a password complexity meter to inform users when a chosen password meets the required attributes.", "Extended_Description": "Authentication mechanisms often rely on a memorized secret (also known as a password) to provide an assertion of identity for a user of a system. It is therefore important that this password be of sufficient complexity and impractical for an adversary to guess. The specific requirements around how complex a password needs to be depends on the type of system being protected. Selecting the correct password requirements and enforcing them through implementation are critical to the overall success of the authentication mechanism.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.Implementation: Not enforcing the password policy stated in a products design can allow users to create passwords that do not provide the necessary level of protection.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker could easily guess user passwords and gain access user accounts.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : A product's design should require adherance to an appropriate password policy. Specific password requirements depend strongly on contextual factors, but it is recommended to contain the following attributes:\n                 \n                   Enforcement of a minimum and maximum length\n                   Restrictions against password reuse\n                   Restrictions against using common passwords\n                   Restrictions against using contextual string in the password (e.g., user id, app name)\n                 \n                 Depending on the threat model, the password policy may include several additional attributes.\n                 \n                   Complex passwords requiring mixed character sets (alpha, numeric, special, mixed case)\n                     \n                       Increasing the range of characters makes the password harder to crack and may be appropriate for systems relying on single factor authentication.\n                       Unfortunately, a complex password may be difficult to memorize, encouraging a user to select a short password or to incorrectly manage the password (write it down).\n                       Another disadvantage of this approach is that it often does not result in a significant increases in overal password complexity due to people's predictable usage of various symbols.\n                     \n                   \n                   Large Minimum Length (encouraging passphrases instead of passwords)\n                     \n                       Increasing the number of characters makes the password harder to crack and may be appropriate for systems relying on single factor authentication.\n                       A disadvantage of this approach is that selecting a good passphrase is not easy and poor passwords can still be generated. Some prompting may be needed to encourage long un-predictable passwords.\n                     \n                   \n                   Randomly Chosen Secrets\n                     \n                       Generating a password for the user can help make sure that length and complexity requirements are met, and can result in secure passwords being used.\n                       A disadvantage of this approach is that the resulting password or passpharse may be too difficult to memorize, encouraging them to be written down.\n                     \n                   \n                   Password Expiration\n                     \n                       Requiring a periodic password change can reduce the time window that an adversary has to crack a password, while also limiting the damage caused by password exposures at other locations.\n\t\t\t\t\t   Password expiration may be a good mitigating technique when long complex passwords are not desired.\n                     \n                   \n                 \n                 See NIST 800-63B [REF-1053] for further information on password requirements.Architecture and Design : Consider a second\n                 authentication factor beyond the password, which prevents the\n                 password from being a single point of failure. See CWE-308 for\n                 further information.Implementation : Consider implementing a password complexity meter to inform users when a chosen password meets the required attributes.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1391", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "798", "Name": "Use of Hard-coded Credentials", "Description": "For front-end to back-end connections: Three solutions are possible, although none are complete.\n                     \n                        The first suggestion involves the use of generated passwords or keys that are changed automatically and must be entered at given time intervals by a system administrator. These passwords will be held in memory and only be valid for the time intervals.\n                        Next, the passwords or keys should be limited at the back end to only performing actions valid for the front end, as opposed to having full access.\n                        Finally, the messages sent should be tagged and checksummed with time sensitive values so as to prevent replay-style attacks.", "Extended_Description": "Hard-coded credentials typically create a significant hole that allows an attacker to bypass the authentication that has been configured by the product administrator. This hole might be difficult for the system administrator to detect. Even if detected, it can be difficult to fix, so the administrator may be forced into disabling the product entirely. There are two main variations:In the Inbound variant, a default administration account is created, and a simple password is hard-coded into the product and associated with that account. This hard-coded password is the same for each installation of the product, and it usually cannot be changed or disabled by system administrators without manually modifying the program, or otherwise patching the product. If the password is ever discovered or published (a common occurrence on the Internet), then anybody with knowledge of this password can access the product. Finally, since all installations of the product will have the same password, even across different organizations, this enables massive attacks such as worms to take place.The Outbound variant applies to front-end systems that authenticate with a back-end service. The back-end service may require a fixed password which can be easily discovered. The programmer may simply hard-code those back-end credentials into the front-end product. Any user of that program may be able to extract the password. Client-side systems with hard-coded passwords pose even more of a threat, since the extraction of a password from a binary is usually very simple.", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If hard-coded passwords are used, it is almost certain that malicious users will gain access to the account in question.Scopes: IntegrityConfidentialityAvailabilityAccess ControlOther. Impacts: Read Application DataGain Privileges or Assume IdentityExecute Unauthorized Code or CommandsOther. Note: This weakness can lead to the exposure of resources or functionality to unintended actors, possibly providing attackers with sensitive information or even execute arbitrary code.", "Detection_Methods": "Method Name: Black Box. Description: Credential storage in configuration files is findable using black box methods, but the use of hard-coded credentials for an incoming authentication routine typically involves an account that is not visible outside of the code. Method Name: Automated Static Analysis. Description: Automated white box techniques have been published for detecting hard-coded credentials for incoming authentication, but there is some expert disagreement regarding their effectiveness and applicability to a broad range of methods. Method Name: Manual Static Analysis. Description: This weakness may be detectable using manual code analysis. Unless authentication is decentralized and applied throughout the product, there can be sufficient time for the analyst to find incoming authentication routines and examine the program logic looking for usage of hard-coded credentials. Configuration files could also be analyzed. Method Name: Manual Dynamic Analysis. Description: For hard-coded credentials in incoming authentication: use monitoring tools that examine the product's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the product was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.Attach the monitor to the process and perform a login. Using call trees or similar artifacts from the output, examine the associated behaviors and see if any of them appear to be comparing the input to a fixed string or value. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : For outbound authentication: store passwords, keys, and other credentials outside of the code in a strongly-protected, encrypted configuration file or database that is protected from access by all outsiders, including other local users on the same system. Properly protect the key (CWE-320). If you cannot use encryption to protect the file, then make sure that the permissions are as restrictive as possible [REF-7].\n                  In Windows environments, the Encrypted File System (EFS) may provide some protection.Architecture and Design : For inbound authentication: Rather than hard-code a default username and password, key, or other authentication credentials for first time logins, utilize a \"first login\" mode that requires the user to enter a unique strong password or key.Architecture and Design : If the product must contain hard-coded credentials or they cannot be removed, perform access control checks and limit which entities can access the feature that requires the hard-coded credentials. For example, a feature might only be enabled through the system console instead of through a network connection.Architecture and Design : For inbound authentication using passwords: apply strong one-way hashes to passwords and store those hashes in a configuration file or database with appropriate access control. That way, theft of the file/database still requires the attacker to try to crack the password. When handling an incoming password during authentication, take the hash of the password and compare it to the saved hash.\n                  Use randomly assigned salts for each separate hash that is generated. This increases the amount of computation that an attacker needs to conduct a brute-force attack, possibly limiting the effectiveness of the rainbow table method.Architecture and Design : For front-end to back-end connections: Three solutions are possible, although none are complete.\n                     \n                        The first suggestion involves the use of generated passwords or keys that are changed automatically and must be entered at given time intervals by a system administrator. These passwords will be held in memory and only be valid for the time intervals.\n                        Next, the passwords or keys should be limited at the back end to only performing actions valid for the front end, as opposed to having full access.\n                        Finally, the messages sent should be tagged and checksummed with time sensitive values so as to prevent replay-style attacks.", "Demonstrative_Examples": "The following code uses a hard-coded password to connect to a database:. This is an example of an external hard-coded password on the client-side of a connection. This code will run successfully, but anyone who has access to it will have access to the password. Once the program has shipped, there is no going back from the database user \"scott\" with a password of \"tiger\" unless the program is patched. A devious employee with access to this information can use it to break into the system. Even worse, if attackers have access to the bytecode for application, they can use the javap -c command to access the disassembled code, which will contain the values of the passwords used. The result of this operation might look something like the following for the example above:The following code is an example of an internal hard-coded password in the back-end:. Every instance of this program can be placed into diagnostic mode with the same password. Even worse is the fact that if this program is distributed as a binary-only distribution, it is very difficult to change that password or disable this \"functionality.\"The following code examples attempt to verify a password using a hard-coded cryptographic key.. The cryptographic key is within a hard-coded string value that is compared to the password. It is likely that an attacker will be able to read the key and compromise the system.The following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but they are stored in cleartext.. This Java example shows a properties file with a cleartext username / password pair.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors used hard-coded credentials in their OT products.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1391", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "344", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "671", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "257", "View_ID": "1000", "Ordinal": null}]}, {"ID": "259", "Name": "Use of Hard-coded Password", "Description": "For front-end to back-end connections: Three solutions are possible, although none are complete.\n                  \n                     The first suggestion involves the use of generated passwords which are changed automatically and must be entered at given time intervals by a system administrator. These passwords will be held in memory and only be valid for the time intervals.\n                     Next, the passwords used should be limited at the back end to only performing actions valid for the front end, as opposed to having full access.\n                     Finally, the messages sent should be tagged and checksummed with time sensitive values so as to prevent replay style attacks.", "Extended_Description": "A hard-coded password typically leads to a significant authentication failure that can be difficult for the system administrator to detect. Once detected, it can be difficult to fix, so the administrator may be forced into disabling the product entirely. There are two main variations:In the Inbound variant, a default administration account is created, and a simple password is hard-coded into the product and associated with that account. This hard-coded password is the same for each installation of the product, and it usually cannot be changed or disabled by system administrators without manually modifying the program, or otherwise patching the product. If the password is ever discovered or published (a common occurrence on the Internet), then anybody with knowledge of this password can access the product. Finally, since all installations of the product will have the same password, even across different organizations, this enables massive attacks such as worms to take place.The Outbound variant applies to front-end systems that authenticate with a back-end service. The back-end service may require a fixed password which can be easily discovered. The programmer may simply hard-code those back-end credentials into the front-end product. Any user of that program may be able to extract the password. Client-side systems with hard-coded passwords pose even more of a threat, since the extraction of a password from a binary is usually very simple.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: If hard-coded passwords are used, it is almost certain that malicious users will gain access through the account in question.", "Detection_Methods": "Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. Method Name: Black Box. Description: Use monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.Attach the monitor to the process and perform a login. Using disassembled code, look at the associated instructions and see if any of them appear to be comparing the input to a fixed string or value. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : For outbound authentication: store passwords outside of the code in a strongly-protected, encrypted configuration file or database that is protected from access by all outsiders, including other local users on the same system. Properly protect the key (CWE-320). If you cannot use encryption to protect the file, then make sure that the permissions are as restrictive as possible.Architecture and Design : For inbound authentication: Rather than hard-code a default username and password for first time logins, utilize a \"first login\" mode that requires the user to enter a unique strong password.Architecture and Design : Perform access control checks and limit which entities can access the feature that requires the hard-coded password. For example, a feature might only be enabled through the system console instead of through a network connection.Architecture and Design : For inbound authentication: apply strong one-way hashes to your passwords and store those hashes in a configuration file or database with appropriate access control. That way, theft of the file/database still requires the attacker to try to crack the password. When receiving an incoming password during authentication, take the hash of the password and compare it to the hash that you have saved.\n                  Use randomly assigned salts for each separate hash that you generate. This increases the amount of computation that an attacker needs to conduct a brute-force attack, possibly limiting the effectiveness of the rainbow table method.Architecture and Design : For front-end to back-end connections: Three solutions are possible, although none are complete.\n                  \n                     The first suggestion involves the use of generated passwords which are changed automatically and must be entered at given time intervals by a system administrator. These passwords will be held in memory and only be valid for the time intervals.\n                     Next, the passwords used should be limited at the back end to only performing actions valid for the front end, as opposed to having full access.\n                     Finally, the messages sent should be tagged and checksummed with time sensitive values so as to prevent replay style attacks.", "Demonstrative_Examples": "The following code uses a hard-coded password to connect to a database:. This is an example of an external hard-coded password on the client-side of a connection. This code will run successfully, but anyone who has access to it will have access to the password. Once the program has shipped, there is no going back from the database user \"scott\" with a password of \"tiger\" unless the program is patched. A devious employee with access to this information can use it to break into the system. Even worse, if attackers have access to the bytecode for application, they can use the javap -c command to access the disassembled code, which will contain the values of the passwords used. The result of this operation might look something like the following for the example above:The following code is an example of an internal hard-coded password in the back-end:. Every instance of this program can be placed into diagnostic mode with the same password. Even worse is the fact that if this program is distributed as a binary-only distribution, it is very difficult to change that password or disable this \"functionality.\"The following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but they are stored in cleartext.. This Java example shows a properties file with a cleartext username / password pair.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors used hard-coded credentials in their OT products.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "798", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "798", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "798", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "321", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "257", "View_ID": "1000", "Ordinal": null}]}, {"ID": "26", "Name": "Path Traversal: '/dir/../filename'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The '/dir/../filename' manipulation is useful for bypassing some path traversal protection schemes. Sometimes a program only checks for \"../\" at the beginning of the input, so a \"/../\" can bypass that check.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "261", "Name": "Weak Encoding for Password", "Description": "Passwords should be encrypted with keys that are at least 128 bits in length for adequate security.", "Extended_Description": "Password management issues occur when a password is stored in plaintext in an application's properties or configuration file. A programmer can attempt to remedy the password management problem by obscuring the password with an encoding function, such as base 64 encoding, but this effort does not adequately protect the password.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "N/A : Passwords should be encrypted with keys that are at least 128 bits in length for adequate security.", "Demonstrative_Examples": "The following code reads a password from a properties file and uses the password to connect to a database.. This code will run successfully, but anyone with access to config.properties can read the value of password and easily determine that the value has been base 64 encoded. If a devious employee has access to this information, they can use it to break into the system.The following code reads a password from the registry and uses the password to create a new network credential.. This code will run successfully, but anyone who has access to the registry key used to store the password can read the value of password. If a devious employee has access to this information, they can use it to break into the system.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "522", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "262", "Name": "Not Using Password Aging", "Description": "Developers might disable clipboard paste operations into password fields as a way to discourage users from pasting a password into a clipboard. However, this might encourage users to choose less-secure passwords that are easier to type, and it can reduce the usability of password managers [REF-1294].", "Extended_Description": "Password aging (or password rotation) is a policy that forces users to change their passwords after a defined time period passes, such as every 30 or 90 days. Without mechanisms such as aging, users might not change their passwords in a timely manner.Note that while password aging was once considered an important security feature, it has since fallen out of favor by many, because it is not as effective against modern threats compared to other mechanisms such as slow hashes. In addition, forcing frequent changes can unintentionally encourage users to select less-secure passwords. However, password aging is still in use due to factors such as compliance requirements, e.g., Payment Card Industry Data Security Standard (PCI DSS).", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: As passwords age, the probability that they are compromised grows.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : As part of a product's design, require users to change their passwords regularly and avoid reusing previous passwords.Implementation : Developers might disable clipboard paste operations into password fields as a way to discourage users from pasting a password into a clipboard. However, this might encourage users to choose less-secure passwords that are easier to type, and it can reduce the usability of password managers [REF-1294].", "Demonstrative_Examples": ". A system does not enforce the changing of passwords every certain period.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "309", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "324", "View_ID": "1000", "Ordinal": null}]}, {"ID": "263", "Name": "Password Aging with Long Expiration", "Description": "Developers might disable clipboard paste operations into password fields as a way to discourage users from pasting a password into a clipboard. However, this might encourage users to choose less-secure passwords that are easier to type, and it can reduce the usability of password managers [REF-1294].", "Extended_Description": "Password aging (or password rotation) is a policy that forces users to change their passwords after a defined time period passes, such as every 30 or 90 days. A long expiration provides more time for attackers to conduct password cracking before users are forced to change to a new password.Note that while password aging was once considered an important security feature, it has since fallen out of favor by many, because it is not as effective against modern threats compared to other mechanisms such as slow hashes. In addition, forcing frequent changes can unintentionally encourage users to select less-secure passwords. However, password aging is still in use due to factors such as compliance requirements, e.g., Payment Card Industry Data Security Standard (PCI DSS).", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: As passwords age, the probability that they are compromised grows.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Ensure that password aging is limited so that there is a defined maximum age for passwords. Note that if the expiration window is too short, it can cause users to generate poor or predictable passwords.Architecture and Design : Ensure that the user is notified several times leading up to the password expiration.Architecture and Design : Create mechanisms to prevent users from reusing passwords or creating similar passwords.Implementation : Developers might disable clipboard paste operations into password fields as a way to discourage users from pasting a password into a clipboard. However, this might encourage users to choose less-secure passwords that are easier to type, and it can reduce the usability of password managers [REF-1294].", "Demonstrative_Examples": ". A system requires the changing of passwords every five years.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "267", "Name": "Privilege Defined With Unsafe Actions", "Description": "Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: A user can access restricted functionality and/or sensitive information that may include administrative functionality and user accounts.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.", "Demonstrative_Examples": "This code intends to allow only Administrators to print debug information about a system.. While the intention was to only allow Administrators to print the debug information, the code as written only excludes those with the role of \"GUEST\". Someone with the role of \"ADMIN\" or \"USER\" will be allowed access, which goes against the original intent. An attacker may be able to use this debug information to craft an attack on the system.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "269", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "268", "Name": "Privilege Chaining", "Description": "Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: A user can be given or gain access rights of another user. This can give the user unauthorized access to sensitive information including the access information of another user.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.", "Demonstrative_Examples": "This code allows someone with the role of \"ADMIN\" or \"OPERATOR\" to reset a user's password. The role of \"OPERATOR\" is intended to have less privileges than an \"ADMIN\", but still be able to help users with small issues such as forgotten passwords.. This code does not check the role of the user whose password is being reset. It is possible for an Operator to gain Admin privileges by resetting the password of an Admin account and taking control of that account.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "269", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "27", "Name": "Path Traversal: 'dir/../../filename'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The 'directory/../../filename' manipulation is useful for bypassing some path traversal protection schemes. Sometimes a program only removes one \"../\" sequence, so multiple \"../\" can bypass that check. Alternately, this manipulation could be used to bypass a check for \"../\" at the beginning of the pathname, moving up more than one directory level.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "270", "Name": "Privilege Context Switching Error", "Description": "Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: A user can assume the identity of another user with separate privileges in another context. This will give the user unauthorized access that may allow them to acquire the access information of other users.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "269", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "271", "Name": "Privilege Dropping / Lowering Errors", "Description": "Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.", "Extended_Description": "In some contexts, a system executing with elevated permissions will hand off a process/file/etc. to another process or user. If the privileges of an entity are not reduced, then elevated privileges are spread throughout a system and possibly to an attacker.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: If privileges are not dropped, neither are access rights of the user. Often these rights can be prevented from being dropped.Scopes: Access ControlNon-Repudiation. Impacts: Gain Privileges or Assume IdentityHide Activities. Note: If privileges are not dropped, in some cases the system may record actions as the user which is being impersonated rather than the impersonator.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.", "Demonstrative_Examples": "The following code calls chroot() to restrict the application to a subset of the filesystem below APP_HOME in order to prevent an attacker from using the program to gain unauthorized access to files located elsewhere. The code then opens a file specified by the user and processes the contents of the file.. Constraining the process inside the application's home directory before opening any files is a valuable security measure. However, the absence of a call to setuid() with some non-zero value means the application is continuing to operate with unnecessary root privileges. Any successful exploit carried out by an attacker against the application can now result in a privilege escalation attack because any malicious operations will be performed with the privileges of the superuser. If the application drops to the privilege level of a non-root user, the potential for damage is substantially reduced.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "269", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "272", "Name": "Least Privilege Violation", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlConfidentiality. Impacts: Gain Privileges or Assume IdentityRead Application DataRead Files or Directories. Note: An attacker may be able to access resources with the elevated privilege that could not be accessed with the attacker's original privileges. This is particularly likely in conjunction with another flaw, such as a buffer overflow.", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Follow the principle of least privilege when assigning access rights to entities in a software system.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": ". The following example demonstrates the weakness.. The following example demonstrates the weakness.The following code calls chroot() to restrict the application to a subset of the filesystem below APP_HOME in order to prevent an attacker from using the program to gain unauthorized access to files located elsewhere. The code then opens a file specified by the user and processes the contents of the file.. Constraining the process inside the application's home directory before opening any files is a valuable security measure. However, the absence of a call to setuid() with some non-zero value means the application is continuing to operate with unnecessary root privileges. Any successful exploit carried out by an attacker against the application can now result in a privilege escalation attack because any malicious operations will be performed with the privileges of the superuser. If the application drops to the privilege level of a non-root user, the potential for damage is substantially reduced.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "271", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "273", "Name": "Improper Check for Dropped Privileges", "Description": "In Windows, make sure that the process token has the SeImpersonatePrivilege(Microsoft Server 2003). Code that relies on impersonation for security must ensure that the impersonation succeeded, i.e., that a proper privilege demotion happened.", "Extended_Description": "If the drop fails, the product will continue to run with the raised privileges, which might provide additional access to unprivileged users.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.This issue is likely to occur in restrictive environments in which the operating system or application provides fine-grained control over privilege management.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: If privileges are not dropped, neither are access rights of the user. Often these rights can be prevented from being dropped.Scopes: Access ControlNon-Repudiation. Impacts: Gain Privileges or Assume IdentityHide Activities. Note: If privileges are not dropped, in some cases the system may record actions as the user which is being impersonated rather than the impersonator.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.Implementation : Check the results of all functions that return a value and verify that the value is expected.Implementation : In Windows, make sure that the process token has the SeImpersonatePrivilege(Microsoft Server 2003). Code that relies on impersonation for security must ensure that the impersonation succeeded, i.e., that a proper privilege demotion happened.", "Demonstrative_Examples": "This code attempts to take on the privileges of a user before creating a file, thus avoiding performing the action with unnecessarily high privileges:. The call to ImpersonateNamedPipeClient may fail, but the return value is not checked. If the call fails, the code may execute with higher privileges than intended. In this case, an attacker could exploit this behavior to write a file to a location that the attacker does not have access to.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "271", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "252", "View_ID": "1000", "Ordinal": null}]}, {"ID": "274", "Name": "Improper Handling of Insufficient Privileges", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "269", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "271", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "280", "View_ID": "1000", "Ordinal": null}]}, {"ID": "276", "Name": "Incorrect Default Permissions", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n          Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : The architecture needs to access and modification attributes for files to only those users who actually require those actions.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n          Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "277", "Name": "Insecure Inherited Permissions", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "278", "Name": "Insecure Preserved Inherited Permissions", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "279", "Name": "Incorrect Execution-Assigned Permissions", "Description": "Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "28", "Name": "Path Traversal: '..\\filedir'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The '..\\' manipulation is the canonical manipulation for operating systems that use \"\\\" as directory separators, such as Windows. However, it is also useful for bypassing path traversal protection schemes that only assume that the \"/\" separator is valid.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "280", "Name": "Improper Handling of Insufficient Permissions or Privileges ", "Description": "Always check to see if you have successfully accessed a resource or system functionality, and use proper error handling if it is unsuccessful. Do this even when you are operating in a highly privileged mode, because errors or environmental conditions might still cause a failure. For example, environments with highly granular permissions/privilege models, such as Windows or Linux capabilities, can cause unexpected failures.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.Implementation : Always check to see if you have successfully accessed a resource or system functionality, and use proper error handling if it is unsuccessful. Do this even when you are operating in a highly privileged mode, because errors or environmental conditions might still cause a failure. For example, environments with highly granular permissions/privilege models, such as Windows or Linux capabilities, can cause unexpected failures.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "281", "Name": "Improper Preservation of Permissions", "Description": "The product does not preserve permissions or incorrectly preserves permissions when copying, restoring, or sharing objects, which can cause them to have less restrictive permissions than intended.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "282", "Name": "Improper Ownership Management", "Description": "Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "283", "Name": "Unverified Ownership", "Description": "Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker could gain unauthorized access to system resources.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.Architecture and Design : Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.", "Demonstrative_Examples": "This function is part of a privileged program that takes input from users with potentially lower privileges.. This code does not confirm that the process to be killed is owned by the requesting user, thus allowing an attacker to kill arbitrary processes.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "282", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "286", "Name": "Incorrect User Management", "Description": "The product does not properly manage a user within its environment.", "Extended_Description": "Users can be assigned to the wrong group (class) of permissions resulting in unintended access rights to sensitive objects.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "306", "Name": "Missing Authentication for Critical Function", "Description": "When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to require strong authentication for users who should be allowed to access the data [REF-1297] [REF-1298] [REF-1302].", "Extended_Description": "As data is migrated to the cloud, if access does not require authentication, it can be easier for attackers to access the data from anywhere on the Internet.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Access ControlOther. Impacts: Gain Privileges or Assume IdentityOther. Note: Exposing critical functionality essentially provides an attacker with the privilege level of that functionality. The consequences will depend on the associated functionality, but they can range from reading or modifying sensitive data, access to administrative or other privileged functionality, or possibly even execution of arbitrary code.", "Detection_Methods": "Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual static analysis is useful for evaluating the correctness of custom authentication mechanisms. Method Name: Automated Static Analysis. Description: Automated static analysis is useful for detecting commonly-used idioms for authentication. A tool may be able to analyze related configuration files, such as .htaccess in Apache web servers, or detect the usage of commonly-used authentication libraries.Generally, automated static analysis tools have difficulty detecting custom authentication schemes. In addition, the software's design may include some functionality that is accessible to any user and does not require an established identity; an automated technique that detects the absence of authentication may report false positives. Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Divide the software into anonymous, normal, privileged, and administrative areas. Identify which of these areas require a proven user identity, and use a centralized authentication capability.\n                  Identify all potential communication channels, or other means of interaction with the software, to ensure that all channels are appropriately protected. Developers sometimes perform authentication at the primary channel, but open up a secondary channel that is assumed to be private. For example, a login mechanism may be listening on one network port, but after successful authentication, it may open up a second port where it waits for the connection, but avoids authentication because it assumes that only the authenticated party will connect to the port.\n                  In general, if the software or protocol allows a single session or user state to persist across multiple connections or channels, authentication and appropriate credential management need to be used throughout.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Architecture and Design : Where possible, avoid implementing custom authentication routines and consider using authentication capabilities as provided by the surrounding framework, operating system, or environment. These may make it easier to provide a clear separation between authentication tasks and authorization tasks.\n                  In environments such as the World Wide Web, the line between authentication and authorization is sometimes blurred. If custom authentication routines are required instead of those provided by the server, then these routines must be applied to every single page, since these pages could be requested directly.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using libraries with authentication capabilities such as OpenSSL or the ESAPI Authenticator [REF-45].Implementation : When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to require strong authentication for users who should be allowed to access the data [REF-1297] [REF-1298] [REF-1302].", "Demonstrative_Examples": "In the following Java example the method createBankAccount is used to create a BankAccount object for a bank management application.. However, there is no authentication mechanism to ensure that the user creating this bank account object has the authority to create new bank accounts. Some authentication mechanisms should be used to verify that the user has the authority to create bank account objects.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors did not use any authentication for critical functionality in their OT products.In 2021, a web site operated by PeopleGIS stored data of US municipalities in Amazon Web Service (AWS) Simple Storage Service (S3) buckets.. While it was not publicly disclosed how the data was protected after discovery, multiple options could have been considered.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "289", "Name": "Authentication Bypass by Alternate Name", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "29", "Name": "Path Traversal: '\\..\\filename'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.This is similar to CWE-25, except using \"\\\" instead of \"/\". Sometimes a program checks for \"..\\\" at the beginning of the input, so a \"\\..\\\" can bypass that check. It is also useful for bypassing path traversal protection schemes that only assume that the \"/\" separator is valid.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "290", "Name": "Authentication Bypass by Spoofing", "Description": "This attack-focused weakness is caused by incorrectly implemented authentication schemes that are subject to spoofing attacks.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: This weakness can allow an attacker to access resources which are not otherwise accessible without proper authentication.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code authenticates users.. The authentication mechanism implemented relies on an IP address for source validation. If an attacker is able to spoof the IP, they may be able to bypass the authentication mechanism.Both of these examples check if a request is from a trusted address before responding to the request.. The code only verifies the address as stored in the request packet. An attacker can spoof this address, thus impersonating a trusted client.The following code samples use a DNS lookup in order to decide whether or not an inbound request is from a trusted host. If an attacker can poison the DNS cache, they can gain trusted status.. IP addresses are more reliable than DNS names, but they can also be spoofed. Attackers can easily forge the source IP address of the packets they send, but response packets will return to the forged IP address. To see the response packets, the attacker has to sniff the traffic between the victim machine and the forged IP address. In order to accomplish the required sniffing, attackers typically attempt to locate themselves on the same subnet as the victim machine. Attackers may be able to circumvent this requirement by using source routing, but source routing is disabled across much of the Internet today. In summary, IP address verification can be a useful part of an authentication scheme, but it should not be the single factor required for authentication.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "291", "Name": "Reliance on IP Address for Authentication", "Description": "Use other means of identity verification that cannot be simply spoofed. Possibilities include a username/password or certificate.", "Extended_Description": "IP addresses can be easily spoofed. Attackers can forge the source IP address of the packets they send, but response packets will return to the forged IP address. To see the response packets, the attacker has to sniff the traffic between the victim machine and the forged IP address. In order to accomplish the required sniffing, attackers typically attempt to locate themselves on the same subnet as the victim machine. Attackers may be able to circumvent this requirement by using source routing, but source routing is disabled across much of the Internet today. In summary, IP address verification can be a useful part of an authentication scheme, but it should not be the single factor required for authentication.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlNon-Repudiation. Impacts: Hide ActivitiesGain Privileges or Assume Identity. Note: Malicious users can fake authentication information, impersonating any IP address.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use other means of identity verification that cannot be simply spoofed. Possibilities include a username/password or certificate.", "Demonstrative_Examples": "Both of these examples check if a request is from a trusted address before responding to the request.. The code only verifies the address as stored in the request packet. An attacker can spoof this address, thus impersonating a trusted client.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "290", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "471", "View_ID": "1000", "Ordinal": null}]}, {"ID": "471", "Name": "Modification of Assumed-Immutable Data (MAID)", "Description": "When the data is stored or transmitted through untrusted sources that could modify the data, implement integrity checks to detect unauthorized modification, or store/transmit the data in a trusted location that is free from external influence.", "Extended_Description": "This occurs when a particular input is critical enough to the functioning of the application that it should not be modifiable at all, but it is. Certain resources are often assumed to be immutable when they are not, such as hidden form fields in web applications, cookies, and reverse DNS lookups.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: Common data types that are attacked are environment variables, web application parameters, and HTTP headers.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : When the data is stored or transmitted through untrusted sources that could modify the data, implement integrity checks to detect unauthorized modification, or store/transmit the data in a trusted location that is free from external influence.", "Demonstrative_Examples": ". In the code excerpt below, an array returned by a Java method is modified despite the fact that arrays are mutable.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "293", "Name": "Using Referer Field for Authentication", "Description": "In order to usefully check if a given action is authorized, some means of strong authentication and method protection must be used. Use other means of authorization that cannot be simply spoofed. Possibilities include a username/password or certificate.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Actions, which may not be authorized otherwise, can be carried out as if they were validated by the server referred to.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : In order to usefully check if a given action is authorized, some means of strong authentication and method protection must be used. Use other means of authorization that cannot be simply spoofed. Possibilities include a username/password or certificate.", "Demonstrative_Examples": "The following code samples check a packet's referer in order to decide whether or not an inbound request is from a trusted host.. These examples check if a request is from a trusted referer before responding to a request, but the code only verifies the referer name as stored in the request packet. An attacker can spoof the referer, thus impersonating a trusted client.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "290", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "294", "Name": "Authentication Bypass by Capture-replay", "Description": "Since any attacker who can listen to traffic can see sequence numbers, it is necessary to sign messages with some kind of cryptography to ensure that sequence numbers are not simply doctored along with content.", "Extended_Description": "Capture-replay attacks are common and can be difficult to defeat without cryptography. They are a subset of network injection attacks that rely on observing previously-sent valid commands, then changing them slightly if necessary and resending the same commands to the server.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Messages sent with a capture-relay attack allow access to resources which are not otherwise accessible without proper authentication.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Utilize some sequence or time stamping functionality along with a checksum which takes this into account in order to ensure that messages can be parsed only once.Architecture and Design : Since any attacker who can listen to traffic can see sequence numbers, it is necessary to sign messages with some kind of cryptography to ensure that sequence numbers are not simply doctored along with content.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "295", "Name": "Improper Certificate Validation", "Description": "If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the hostname.", "Extended_Description": "When a certificate is invalid or malicious, it might allow an attacker to spoof a trusted entity by interfering in the communication path between the host and client. The product might connect to a malicious host while believing it is a trusted host, or the product might be deceived into accepting spoofed data that appears to originate from a trusted host.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.Implementation: When the product uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Certificates should be carefully managed and checked to assure that data are encrypted with the intended owner's public key.Implementation : If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the hostname.", "Demonstrative_Examples": "This code checks the certificate of a connected peer.. In this case, because the certificate is self-signed, there was no external authority that could prove the identity of the host. The program could be communicating with a different system that is spoofing the host, e.g. by poisoning the DNS cache or using an Adversary-in-the-Middle (AITM) attack to modify the traffic from server to client.The following OpenSSL code obtains a certificate and verifies it.. Even though the \"verify\" step returns X509_V_OK, this step does not include checking the Common Name against the name of the host. That is, there is no guarantee that the certificate is for the desired host. The SSL connection could have been established with a malicious host that provided a valid certificate.The following OpenSSL code ensures that there is a certificate and allows the use of expired certificates.. If the call to SSL_get_verify_result() returns X509_V_ERR_CERT_HAS_EXPIRED, this means that the certificate has expired. As time goes on, there is an increasing chance for attackers to compromise the certificate.The following OpenSSL code ensures that there is a certificate before continuing execution.. Because this code does not use SSL_get_verify_results() to check the certificate, it could accept certificates that have been revoked (X509_V_ERR_CERT_REVOKED). The software could be communicating with a malicious host.The following OpenSSL code ensures that the host has a certificate.. Note that the code does not call SSL_get_verify_result(ssl), which effectively disables the validation step that checks the certificate.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "322", "View_ID": "1000", "Ordinal": null}]}, {"ID": "296", "Name": "Improper Following of a Certificate's Chain of Trust", "Description": "If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the full chain of trust.", "Extended_Description": "If a system does not follow the chain of trust of a certificate to a root server, the certificate loses all usefulness as a metric of trust. Essentially, the trust gained from a certificate is derived from a chain of trust -- with a reputable trusted entity at the end of that list. The end user must trust that reputable source, and this reputable source must vouch for the resource in question through the medium of the certificate.In some cases, this trust traverses several entities who vouch for one another. The entity trusted by the end user is at one end of this trust chain, while the certificate-wielding resource is at the other end of the chain. If the user receives a certificate at the end of one of these trust chains and then proceeds to check only that the first link in the chain, no real trust has been derived, since the entire chain must be traversed back to a trusted source to verify the certificate.There are several ways in which the chain of trust might be broken, including but not limited to:", "Modes_Of_Introduction": "Implementation: When the product uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Non-Repudiation. Impacts: Hide Activities. Note: Exploitation of this flaw can lead to the trust of data that may have originated with a spoofed source.Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Gain Privileges or Assume IdentityExecute Unauthorized Code or Commands. Note: Data, requests, or actions taken by the attacking entity can be carried out as a spoofed benign entity.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Ensure that proper certificate checking is included in the system design.Implementation : Understand, and properly implement all checks necessary to ensure the integrity of certificate trust integrity.Implementation : If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the full chain of trust.", "Demonstrative_Examples": "This code checks the certificate of a connected peer.. In this case, because the certificate is self-signed, there was no external authority that could prove the identity of the host. The program could be communicating with a different system that is spoofing the host, e.g. by poisoning the DNS cache or using an Adversary-in-the-Middle (AITM) attack to modify the traffic from server to client.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "295", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": null}]}, {"ID": "297", "Name": "Improper Validation of Certificate with Host Mismatch", "Description": "If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the hostname.", "Extended_Description": "Even if a certificate is well-formed, signed, and follows the chain of trust, it may simply be a valid certificate for a different site than the site that the product is interacting with. If the certificate's host-specific data is not properly checked - such as the Common Name (CN) in the Subject or the Subject Alternative Name (SAN) extension of an X.509 certificate - it may be possible for a redirection or spoofing attack to allow a malicious host with a valid certificate to provide data, impersonating a trusted host. In order to ensure data integrity, the certificate must be valid and it must pertain to the site that is being accessed.Even if the product attempts to check the hostname, it is still possible to incorrectly check the hostname. For example, attackers could create a certificate with a name that begins with a trusted name followed by a NUL byte, which could cause some string-based comparisons to only examine the portion that contains the trusted name.This weakness can occur even when the product uses Certificate Pinning, if the product does not verify the hostname at the time a certificate is pinned.", "Modes_Of_Introduction": "Implementation: When the product uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: The data read from the system vouched for by the certificate may not be from the expected system.Scopes: AuthenticationOther. Impacts: Other. Note: Trust afforded to the system in question - based on the malicious certificate - may allow for spoofing or redirection attacks.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.) Method Name: Dynamic Analysis with Manual Results Interpretation. Description: Set up an untrusted endpoint (e.g. a server) with which the product will connect.  Create a test certificate that uses an invalid hostname but is signed by a trusted CA and provide this certificate from the untrusted endpoint. If the product performs any operations instead of disconnecting and reporting an error, then this indicates that the hostname is not being checked and the test certificate has been accepted. Method Name: Black Box. Description: When Certificate Pinning is being used in a mobile application, consider using a tool such as Spinner [REF-955].  This methodology might be extensible to other technologies.", "Potential_Mitigations": "Architecture and Design : Fully check the hostname of the certificate and provide the user with adequate information about the nature of the problem and how to proceed.Implementation : If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the hostname.", "Demonstrative_Examples": "The following OpenSSL code obtains a certificate and verifies it.. Even though the \"verify\" step returns X509_V_OK, this step does not include checking the Common Name against the name of the host. That is, there is no guarantee that the certificate is for the desired host. The SSL connection could have been established with a malicious host that provided a valid certificate.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "295", "View_ID": "1000", "Ordinal": null}]}, {"ID": "298", "Name": "Improper Validation of Certificate Expiration", "Description": "If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the expiration.", "Extended_Description": "When the expiration of a certificate is not taken into account, no trust has necessarily been conveyed through it. Therefore, the validity of the certificate cannot be verified and all benefit of the certificate is lost.", "Modes_Of_Introduction": "Implementation: When the software uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Other. Note: The data read from the system vouched for by the expired certificate may be flawed due to malicious spoofing.Scopes: AuthenticationOther. Impacts: Other. Note: Trust afforded to the system in question - based on the expired certificate - may allow for spoofing attacks.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Check for expired certificates and provide the user with adequate information about the nature of the problem and how to proceed.Implementation : If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the expiration.", "Demonstrative_Examples": "The following OpenSSL code ensures that there is a certificate and allows the use of expired certificates.. If the call to SSL_get_verify_result() returns X509_V_ERR_CERT_HAS_EXPIRED, this means that the certificate has expired. As time goes on, there is an increasing chance for attackers to compromise the certificate.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "295", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1000", "Ordinal": null}]}, {"ID": "672", "Name": "Operation on a Resource after Expiration or Release", "Description": "The product uses, accesses, or otherwise operates on a resource after that resource has been expired, released, or revoked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Modify Application DataRead Application Data. Note: If a released resource is subsequently reused or reallocated, then an attempt to use the original resource might allow access to sensitive data that is associated with a different user or entity.Scopes: OtherAvailability. Impacts: OtherDoS: Crash, Exit, or Restart. Note: When a resource is released it might not be in an expected state, later attempts to access the resource may lead to resultant errors that may lead to a crash.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code shows a simple example of a use after free error:. When an error occurs, the pointer is immediately freed. However, this pointer is later incorrectly used in the logError function.The following code shows a simple example of a double free error:. Double free vulnerabilities have two common (and sometimes overlapping) causes:In the following C/C++ example the method processMessage is used to process a message received in the input array of char arrays. The input message array contains two char arrays: the first is the length of the message and the second is the body of the message. The length of the message is retrieved and used to allocate enough memory for a local char array, messageBody, to be created for the message body. The messageBody is processed in the method processMessageBody that will return an error if an error occurs while processing. If an error occurs then the return result variable is set to indicate an error and the messageBody char array memory is released using the method free and an error message is sent to the logError method.. However, the call to the method logError includes the messageBody after the memory for messageBody has been released using the free method. This can cause unexpected results and may lead to system crashes. A variable should never be used after its memory resources have been released.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "666", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "299", "Name": "Improper Check for Certificate Revocation", "Description": "If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the revoked status.", "Extended_Description": "An improper check for certificate revocation is a far more serious flaw than related certificate failures. This is because the use of any revoked certificate is almost certainly malicious. The most common reason for certificate revocation is compromise of the system in question, with the result that no legitimate servers will be using a revoked certificate, unless they are sorely out of sync.", "Modes_Of_Introduction": "Implementation: When the product uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Trust may be assigned to an entity who is not who it claims to be.Scopes: IntegrityOther. Impacts: Other. Note: Data from an untrusted (and possibly malicious) source may be integrated.Scopes: Confidentiality. Impacts: Read Application Data. Note: Data may be disclosed to an entity impersonating a trusted entity, resulting in information disclosure.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Ensure that certificates are checked for revoked status.Implementation : If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the revoked status.", "Demonstrative_Examples": "The following OpenSSL code ensures that there is a certificate before continuing execution.. Because this code does not use SSL_get_verify_results() to check the certificate, it could accept certificates that have been revoked (X509_V_ERR_CERT_REVOKED). The product could be communicating with a malicious host.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "295", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1000", "Ordinal": null}]}, {"ID": "30", "Name": "Path Traversal: '\\dir\\..\\filename'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.This is similar to CWE-26, except using \"\\\" instead of \"/\". The '\\dir\\..\\filename' manipulation is useful for bypassing some path traversal protection schemes. Sometimes a program only checks for \"..\\\" at the beginning of the input, so a \"\\..\\\" can bypass that check.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "300", "Name": "Channel Accessible by Non-Endpoint", "Description": "A certificate binds an identity to a cryptographic key to authenticate a communicating party. Often, the certificate takes the encrypted form of the hash of the identity of the subject, the public key, and information such as time of issue or expiration using the issuer's private key. The certificate can be validated by deciphering the certificate with the issuer's public key. See also X.509 certificate signature chains and the PGP certification structure.", "Extended_Description": "In order to establish secure communication between two parties, it is often important to adequately verify the identity of entities at each end of the communication channel. Inadequate or inconsistent verification may result in insufficient or incorrect identification of either communicating entity. This can have negative consequences such as misplaced trust in the entity at the other end of the channel. An attacker can leverage this by interposing between the communicating entities and masquerading as the original entity. In the absence of sufficient verification of identity, such an attacker can eavesdrop and potentially modify the communication between the original entities.", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAccess Control. Impacts: Read Application DataModify Application DataGain Privileges or Assume Identity. Note: An attacker could pose as one of the entities and read or possibly modify the communication.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Always fully authenticate both ends of any communications channel.Architecture and Design : Adhere to the principle of complete mediation.Implementation : A certificate binds an identity to a cryptographic key to authenticate a communicating party. Often, the certificate takes the encrypted form of the hash of the identity of the subject, the public key, and information such as time of issue or expiration using the issuer's private key. The certificate can be validated by deciphering the certificate with the issuer's public key. See also X.509 certificate signature chains and the PGP certification structure.", "Demonstrative_Examples": "In the Java snippet below, data is sent over an unencrypted channel to a remote server.. By eavesdropping on the communication channel or posing as the endpoint, an attacker would be able to read all of the transmitted data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "301", "Name": "Reflection Attack in an Authentication Protocol", "Description": "Let the initiator prove its identity before proceeding.", "Extended_Description": "A mutual authentication protocol requires each party to respond to a random challenge by the other party by encrypting it with a pre-shared key. Often, however, such protocols employ the same pre-shared key for communication with a number of different entities. A malicious user or an attacker can easily compromise this protocol without possessing the correct key by employing a reflection attack on the protocol.Reflection attacks capitalize on mutual authentication schemes in order to trick the target into revealing the secret shared between it and another valid user. In a basic mutual-authentication scheme, a secret is known to both the valid user and the server; this allows them to authenticate. In order that they may verify this shared secret without sending it plainly over the wire, they utilize a Diffie-Hellman-style scheme in which they each pick a value, then request the hash of that value as keyed by the shared secret. In a reflection attack, the attacker claims to be a valid user and requests the hash of a random value from the server. When the server returns this value and requests its own value to be hashed, the attacker opens another connection to the server. This time, the hash requested by the attacker is the value which the server requested in the first connection. When the server returns this hashed value, it is used in the first connection, authenticating the attacker successfully as the impersonated valid user.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: The primary result of reflection attacks is successful authentication with a target machine -- as an impersonated user.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use different keys for the initiator and responder or of a different type of challenge for the initiator and responder.Architecture and Design : Let the initiator prove its identity before proceeding.", "Demonstrative_Examples": ". The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "327", "View_ID": "1000", "Ordinal": null}]}, {"ID": "302", "Name": "Authentication Bypass by Assumed-Immutable Data", "Description": "Implement proper protection for immutable data (e.g. environment variable, hidden form fields, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Implement proper protection for immutable data (e.g. environment variable, hidden form fields, etc.)", "Demonstrative_Examples": "In the following example, an \"authenticated\" cookie is used to determine whether or not a user should be granted access to a system.. Modifying the value of a cookie on the client-side is trivial, but many developers assume that cookies are essentially immutable.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "807", "View_ID": "1000", "Ordinal": null}]}, {"ID": "807", "Name": "Reliance on Untrusted Inputs in a Security Decision", "Description": "Understand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n                  Identify all inputs that are used for security decisions and determine if you can modify the design so that you do not have to rely on submitted inputs at all. For example, you may be able to keep critical information about the user's session on the server side instead of recording it within external data.", "Extended_Description": "Developers may assume that inputs such as cookies, environment variables, and hidden form fields cannot be modified. However, an attacker could change these inputs using customized clients or other attacks. This change might not be detected. When security decisions such as authentication and authorization are made based on the values of these inputs, attackers can bypass the security of the software.Without sufficient encryption, integrity checking, or other mechanism, any input that originates from an outsider cannot be trusted.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityAccess ControlAvailabilityOther. Impacts: Bypass Protection MechanismGain Privileges or Assume IdentityVaries by Context. Note: Attackers can bypass the security decision to access whatever is being protected. The consequences will depend on the associated functionality, but they can range from granting additional privileges to untrusted users to bypassing important security checks. Ultimately, this weakness may lead to exposure or modification of sensitive data, system crash, or execution of arbitrary code.", "Detection_Methods": "Method Name: Manual Static Analysis. Description: Since this weakness does not typically appear frequently within a single software package, manual white box techniques may be able to provide sufficient code coverage and reduction of false positives if all potentially-vulnerable operations can be assessed within limited time constraints. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Store state information and sensitive data on the server side only.\n                  Ensure that the system definitively and unambiguously keeps track of its own state and user state and has rules defined for legitimate state transitions. Do not allow any application user to affect state directly in any way other than through legitimate actions leading to state transitions.\n                  If information must be stored on the client, do not do so without encryption and integrity checking, or otherwise having a mechanism on the server side to catch tampering. Use a message authentication code (MAC) algorithm, such as Hash Message Authentication Code (HMAC) [REF-529]. Apply this against the state or sensitive data that has to be exposed, which can guarantee the integrity of the data - i.e., that the data has not been modified. Ensure that a strong hash function is used (CWE-328).Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  With a stateless protocol such as HTTP, use a framework that maintains the state for you.\n                  Examples include ASP.NET View State [REF-756] and the OWASP ESAPI Session Management feature [REF-45].\n                  Be careful of language features that provide state support, since these might be provided as a convenience to the programmer and may not be considering security.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Operation : When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.Architecture and Design : Understand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n                  Identify all inputs that are used for security decisions and determine if you can modify the design so that you do not have to rely on submitted inputs at all. For example, you may be able to keep critical information about the user's session on the server side instead of recording it within external data.", "Demonstrative_Examples": ". The following code excerpt reads a value from a browser cookie to determine the role of the user.The following code could be for a medical records application. It performs authentication by checking if a cookie has been set.. The programmer expects that the AuthenticateUser() check will always be applied, and the \"authenticated\" cookie will only be set when authentication succeeds. The programmer even diligently specifies a 2-hour expiration for the cookie.. In the following example, an authentication flag is read from a browser cookie, thus allowing for external control of user state data.The following code samples use a DNS lookup in order to decide whether or not an inbound request is from a trusted host. If an attacker can poison the DNS cache, they can gain trusted status.. IP addresses are more reliable than DNS names, but they can also be spoofed. Attackers can easily forge the source IP address of the packets they send, but response packets will return to the forged IP address. To see the response packets, the attacker has to sniff the traffic between the victim machine and the forged IP address. In order to accomplish the required sniffing, attackers typically attempt to locate themselves on the same subnet as the victim machine. Attackers may be able to circumvent this requirement by using source routing, but source routing is disabled across much of the Internet today. In summary, IP address verification can be a useful part of an authentication scheme, but it should not be the single factor required for authentication.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "303", "Name": "Incorrect Implementation of Authentication Algorithm", "Description": "The requirements for the product dictate the use of an established authentication algorithm, but the implementation of the algorithm is incorrect.", "Extended_Description": "This incorrect implementation may allow authentication to be bypassed.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "304", "Name": "Missing Critical Step in Authentication", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "Authentication techniques should follow the algorithms that define them exactly, otherwise authentication can be bypassed or more easily subjected to brute force attacks.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlIntegrityConfidentiality. Impacts: Bypass Protection MechanismGain Privileges or Assume IdentityRead Application DataExecute Unauthorized Code or Commands. Note: This weakness can lead to the exposure of resources or functionality to unintended actors, possibly providing attackers with sensitive information or allowing attackers to execute arbitrary code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "303", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": null}]}, {"ID": "305", "Name": "Authentication Bypass by Primary Weakness", "Description": "The authentication algorithm is sound, but the implemented mechanism can be bypassed as the result of a separate weakness that is primary to the authentication error.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "307", "Name": "Improper Restriction of Excessive Authentication Attempts", "Description": "Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Consider using libraries with authentication capabilities such as OpenSSL or the ESAPI Authenticator. [REF-45]", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: An attacker could perform an arbitrary number of authentication attempts using different passwords, and eventually gain access to the targeted account.", "Detection_Methods": "Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Common protection mechanisms include:\n                     \n                        Disconnecting the user after a small number of failed attempts\n                        Implementing a timeout\n                        Locking out a targeted account\n                        Requiring a computational task on the user's part.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Consider using libraries with authentication capabilities such as OpenSSL or the ESAPI Authenticator. [REF-45]", "Demonstrative_Examples": ". In January 2009, an attacker was able to gain administrator access to a Twitter server because the server did not restrict the number of login attempts [REF-236]. The attacker targeted a member of Twitter's support team and was able to successfully guess the member's password using a brute force attack by guessing a large number of common words. After gaining access as the member of the support staff, the attacker used the administrator panel to gain access to 33 accounts that belonged to celebrities and politicians. Ultimately, fake Twitter messages were sent that appeared to come from the compromised accounts.The following code, extracted from a servlet's doPost() method, performs an authentication lookup every time the servlet is invoked.. However, the software makes no attempt to restrict excessive authentication attempts.This code attempts to limit the number of login attempts by causing the process to sleep before completing the authentication.. However, there is no limit on parallel connections, so this does not increase the amount of time an attacker needs to complete an attack.In the following C/C++ example the validateUser method opens a socket connection, reads a username and password from the socket and attempts to authenticate the username and password.. The validateUser method will continuously check for a valid username and password without any restriction on the number of authentication attempts made. The method should limit the number of authentication attempts made to prevent brute force attacks as in the following example code.. Consider this example from a\n\t\t    real-world attack against the iPhone\n\t\t    [REF-1218]. An attacker can use brute force\n\t\t    methods; each time there is a failed guess, the\n\t\t    attacker quickly cuts the power before the failed\n\t\t    entry is recorded, effectively bypassing the\n\t\t    intended limit on the number of failed\n\t\t    authentication attempts. Note that this attack\n\t\t    requires removal of the cell phone battery and\n\t\t    connecting directly to the phone's power source,\n\t\t    and the brute force attack is still\n\t\t    time-consuming.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "799", "View_ID": "1000", "Ordinal": null}]}, {"ID": "799", "Name": "Improper Control of Interaction Frequency", "Description": "The product does not properly limit the number or frequency of interactions that it has with an actor, such as the number of incoming requests.", "Extended_Description": "This can allow the actor to perform actions more frequently than expected. The actor could be a human or an automated process such as a virus or bot. This could be used to cause a denial of service, compromise program logic (such as limiting humans to a single vote), or other consequences. For example, an authentication routine might not limit the number of times an attacker can guess a password. Or, a web site might conduct a poll but only expect humans to vote a maximum of once a day.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "In the following code a username and password is read from a socket and an attempt is made to authenticate the username and password. The code will continuously checked the socket for a username and password until it has been authenticated.. This code does not place any restriction on the number of authentication attempts made. There should be a limit on the number of authentication attempts made to prevent brute force attacks as in the following example code.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "308", "Name": "Use of Single-factor Authentication", "Description": "Use multiple independent authentication schemes, which ensures that -- if one of the methods is compromised -- the system itself is still likely safe from compromise.", "Extended_Description": "While the use of multiple authentication schemes is simply piling on more complexity on top of authentication, it is inestimably valuable to have such measures of redundancy. The use of weak, reused, and common passwords is rampant on the internet. Without the added protection of multiple authentication schemes, a single mistake can result in the compromise of an account. For this reason, if multiple schemes are possible and also easy to use, they should be implemented and required.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If the secret in a single-factor authentication scheme gets compromised, full authentication is possible.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use multiple independent authentication schemes, which ensures that -- if one of the methods is compromised -- the system itself is still likely safe from compromise.", "Demonstrative_Examples": "In both of these examples, a user is logged in if their given password matches a stored password:. This code relies exclusively on a password mechanism (CWE-309) using only one factor of authentication (CWE-308). If an attacker can steal or guess a user's password, they are given full access to their account. Note this code also uses SHA-1, which is a weak hash (CWE-328).  It also does not use a salt (CWE-759).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "654", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "309", "View_ID": "1000", "Ordinal": null}]}, {"ID": "654", "Name": "Reliance on a Single Factor in a Security Decision", "Description": "Use redundant access rules on different choke points (e.g., firewalls).", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: If the single factor is compromised (e.g. by theft or spoofing), then the integrity of the entire security mechanism can be violated with respect to the user that is identified by that factor.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: It can become difficult or impossible for the product to be able to distinguish between legitimate activities by the entity who provided the factor, versus illegitimate activities by an attacker.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use multiple simultaneous checks before granting access to critical operations or granting critical privileges. A weaker but helpful mitigation is to use several successive checks (multiple layers of security).Architecture and Design : Use redundant access rules on different choke points (e.g., firewalls).", "Demonstrative_Examples": ". Password-only authentication is perhaps the most well-known example of use of a single factor. Anybody who knows a user's password can impersonate that user.. When authenticating, use multiple factors, such as \"something you know\" (such as a password) and \"something you have\" (such as a hardware-based one-time password generator, or a biometric device).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": null}]}, {"ID": "309", "Name": "Use of Password System for Primary Authentication", "Description": "Inform the user of why password protections are in place, how they work to protect data integrity, and why it is important to heed their warnings.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: A password authentication mechanism error will almost always result in attackers being authorized as valid users.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : In order to protect password systems from compromise, the following should be noted:\n                     \n                        Passwords should be stored safely to prevent insider attack and to ensure that -- if a system is compromised -- the passwords are not retrievable. Due to password reuse, this information may be useful in the compromise of other systems these users work with. In order to protect these passwords, they should be stored encrypted, in a non-reversible state, such that the original text password cannot be extracted from the stored value.\n                        Password aging should be strictly enforced to ensure that passwords do not remain unchanged for long periods of time. The longer a password remains in use, the higher the probability that it has been compromised. For this reason, passwords should require refreshing periodically, and users should be informed of the risk of passwords which remain in use for too long.\n                        Password strength should be enforced intelligently. Rather than restrict passwords to specific content, or specific length, users should be encouraged to use upper and lower case letters, numbers, and symbols in their passwords. The system should also ensure that no passwords are derived from dictionary words.Architecture and Design : Use a zero-knowledge password protocol, such as SRP.Architecture and Design : Ensure that passwords are stored safely and are not reversible.Architecture and Design : Implement password aging functionality that requires passwords be changed after a certain point.Architecture and Design : Use a mechanism for determining the strength of a password and notify the user of weak password use.Architecture and Design : Inform the user of why password protections are in place, how they work to protect data integrity, and why it is important to heed their warnings.", "Demonstrative_Examples": "In both of these examples, a user is logged in if their given password matches a stored password:. This code relies exclusively on a password mechanism (CWE-309) using only one factor of authentication (CWE-308). If an attacker can steal or guess a user's password, they are given full access to their account. Note this code also uses SHA-1, which is a weak hash (CWE-328).  It also does not use a salt (CWE-759).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "654", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "308", "View_ID": "1000", "Ordinal": null}]}, {"ID": "31", "Name": "Path Traversal: 'dir\\..\\..\\filename'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The 'dir\\..\\..\\filename' manipulation is useful for bypassing some path traversal protection schemes. Sometimes a program only removes one \"..\\\" sequence, so multiple \"..\\\" can bypass that check. Alternately, this manipulation could be used to bypass a check for \"..\\\" at the beginning of the pathname, moving up more than one directory level.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "311", "Name": "Missing Encryption of Sensitive Data", "Description": "Use naming conventions and strong types to make it easier to spot when sensitive data is being used. When creating structures, objects, or other complex entities, separate the sensitive and non-sensitive data as much as possible.", "Extended_Description": "The lack of proper data encryption passes up the guarantees of confidentiality, integrity, and accountability that properly implemented encryption conveys.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: If the application does not use a secure channel, such as SSL, to exchange sensitive information, it is possible for an attacker with access to the network traffic to sniff packets from the connection and uncover the data. This attack is not technically difficult, but does require physical access to some portion of the network over which the sensitive data travels. This access is usually somewhere near where the user is connected to the network (such as a colleague on the company network) but can be anywhere along the path from the user to the end server.Scopes: ConfidentialityIntegrity. Impacts: Modify Application Data. Note: Omitting the use of encryption in any program which transfers data over a network of any kind should be considered on par with delivering the data sent to each user on the local networks of both the sender and receiver. Worse, this omission allows for the injection of data into a stream of communication between two parties -- with no means for the victims to separate valid data from invalid. In this day of widespread network attacks and password collection sniffers, it is an unnecessary risk to omit encryption from the design of any system which might benefit from it.", "Detection_Methods": "Method Name: Manual Analysis. Description: The characterizaton of sensitive data often requires domain-specific understanding, so manual methods are useful. However, manual efforts might not achieve desired code coverage within limited time constraints. Black box methods may produce artifacts (e.g. stored data or unencrypted network transfer) that require manual evaluation. Method Name: Automated Analysis. Description: Automated measurement of the entropy of an input/output source may indicate the use or lack of encryption, but human analysis is still required to distinguish intentionally-unencrypted data (e.g. metadata) from sensitive data. Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Requirements : Clearly specify which data or resources are valuable enough that they should be protected by encryption. Require that any transmission or storage of this data/resource should use well-vetted encryption algorithms.Architecture and Design : Ensure that encryption is properly integrated into the system design, including but not necessarily limited to:\n                     \n                        Encryption that is needed to store or transmit private data of the users of the system\n                        Encryption that is needed to protect the system itself from unauthorized disclosure or tampering\n                     \n                  Identify the separate needs and contexts for encryption:\n                     \n                        One-way (i.e., only the user or recipient needs to have the key). This can be achieved using public key cryptography, or other techniques in which the encrypting party (i.e., the product) does not need to have access to a private key.\n                        Two-way (i.e., the encryption can be automatically performed on behalf of a user, but the key must be available so that the plaintext can be automatically recoverable by that user). This requires storage of the private key in a format that is recoverable only by the user (or perhaps by the operating system) in a way that cannot be recovered by others.\n                     \n                  Using threat modeling or other techniques, assume that data can be compromised through a separate vulnerability or weakness, and determine where encryption will be most effective. Ensure that data that should be private is not being inadvertently exposed using weaknesses such as insecure permissions (CWE-732). [REF-7]Architecture and Design : When there is a need to store or transmit sensitive data, use strong, up-to-date cryptographic algorithms to encrypt that data. Select a well-vetted algorithm that is currently considered to be strong by experts in the field, and use well-tested implementations. As with all cryptographic mechanisms, the source code should be available for analysis.\n                  For example, US government systems require FIPS 140-2 certification.\n                  Do not develop custom or private cryptographic algorithms. They will likely be exposed to attacks that are well-understood by cryptographers. Reverse engineering techniques are mature. If the algorithm can be compromised if attackers find out how it works, then it is especially weak.\n                  Periodically ensure that the cryptography has not become obsolete. Some older algorithms, once thought to require a billion years of computing time, can now be broken in days or hours. This includes MD4, MD5, SHA1, DES, and other algorithms that were once regarded as strong. [REF-267]Architecture and Design : Compartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n                  Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.Implementation : When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.Implementation : Use naming conventions and strong types to make it easier to spot when sensitive data is being used. When creating structures, objects, or other complex entities, separate the sensitive and non-sensitive data as much as possible.", "Demonstrative_Examples": "This code writes a user's login information to a cookie so the user does not have to login again later.. The code stores the user's username and password in plaintext in a cookie on the user's machine. This exposes the user's login information if their computer is compromised by an attacker. Even if the user's machine is not compromised, this weakness combined with cross-site scripting (CWE-79) could allow an attacker to remotely copy the cookie.The following code attempts to establish a connection, read in a password, then store it to a buffer.. While successful, the program does not encrypt the data before writing it to a buffer, possibly exposing it to unauthorized actors.The following code attempts to establish a connection to a site to communicate sensitive information.. Though a connection is successfully made, the connection is unencrypted and it is possible that all sensitive data sent to or received from the server will be read by unintended actors.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "312", "Name": "Cleartext Storage of Sensitive Information", "Description": "When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to encrypt the data at rest. [REF-1297] [REF-1299] [REF-1301]", "Extended_Description": "Because the information is stored in cleartext (i.e., unencrypted), attackers could potentially read it. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.When organizations adopt cloud services, it can be easier for attackers to access the data from anywhere on the Internet.In some systems/environments such as cloud, the use of \"double encryption\" (at both the software and hardware layer) might be required, and the developer might be solely responsible for both layers, instead of shared responsibility with the administrator of the broader system/environment.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: An attacker with access to the system could read sensitive information stored in cleartext.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to encrypt the data at rest. [REF-1297] [REF-1299] [REF-1301]", "Demonstrative_Examples": "The following code excerpt stores a plaintext user account ID in a browser cookie.. Because the account ID is in plaintext, the user's account information is exposed if their computer is compromised by an attacker.This code writes a user's login information to a cookie so the user does not have to login again later.. The code stores the user's username and password in plaintext in a cookie on the user's machine. This exposes the user's login information if their computer is compromised by an attacker. Even if the user's machine is not compromised, this weakness combined with cross-site scripting (CWE-79) could allow an attacker to remotely copy the cookie.The following code attempts to establish a connection, read in a password, then store it to a buffer.. While successful, the program does not encrypt the data before writing it to a buffer, possibly exposing it to unauthorized actors.The following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but they are stored in cleartext.. This Java example shows a properties file with a cleartext username / password pair.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. At least one OT product stored a password in plaintext.In 2021, a web site operated by PeopleGIS stored data of US municipalities in Amazon Web Service (AWS) Simple Storage Service (S3) buckets.. While it was not publicly disclosed how the data was protected after discovery, multiple options could have been considered.Consider the following PowerShell command examples for encryption scopes of Azure storage objects. In the first example, an encryption scope is set for the storage account.. The result (edited and formatted for readability) might be:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "311", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "311", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "922", "View_ID": "1000", "Ordinal": null}]}, {"ID": "922", "Name": "Insecure Storage of Sensitive Information", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "If read access is not properly restricted, then attackers can steal the sensitive information. If write access is not properly restricted, then attackers can modify and possibly delete the data, causing incorrect results and possibly a denial of service.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Files or Directories. Note: Attackers can read sensitive information by accessing the unrestricted storage mechanism.Scopes: Integrity. Impacts: Modify Application DataModify Files or Directories. Note: Attackers can overwrite sensitive information by accessing the unrestricted storage mechanism.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "313", "Name": "Cleartext Storage in a File or on Disk", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "The sensitive information could be read by attackers with access to the file, or with physical or administrator access to the raw disk. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The following examples show a portion of properties and configuration files for Java and ASP.NET applications. The files include username and password information but they are stored in cleartext.. This Java example shows a properties file with a cleartext username / password pair.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "312", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "314", "Name": "Cleartext Storage in the Registry", "Description": "The product stores sensitive information in cleartext in the registry.", "Extended_Description": "Attackers can read the information by accessing the registry key. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "312", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "315", "Name": "Cleartext Storage of Sensitive Information in a Cookie", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "Attackers can use widely-available tools to view the cookie and read the sensitive information. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code excerpt stores a plaintext user account ID in a browser cookie.. Because the account ID is in plaintext, the user's account information is exposed if their computer is compromised by an attacker.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "312", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "316", "Name": "Cleartext Storage of Sensitive Information in Memory", "Description": "The product stores sensitive information in cleartext in memory.", "Extended_Description": "The sensitive memory might be saved to disk, stored in a core dump, or remain uncleared if the product crashes, or if the programmer does not properly clear the memory before freeing it.It could be argued that such problems are usually only exploitable by those with administrator privileges. However, swapping could cause the memory to be written to disk and leave it accessible to physical attack afterwards. Core dump files might have insecure permissions or be stored in archive files that are accessible to untrusted people. Or, uncleared sensitive memory might be inadvertently exposed to attackers due to another weakness.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "312", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "317", "Name": "Cleartext Storage of Sensitive Information in GUI", "Description": "The product stores sensitive information in cleartext within the GUI.", "Extended_Description": "An attacker can often obtain data from a GUI, even if hidden, by using an API to directly access GUI objects such as windows and menus. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "312", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "318", "Name": "Cleartext Storage of Sensitive Information in Executable", "Description": "The product stores sensitive information in cleartext in an executable.", "Extended_Description": "Attackers can reverse engineer binary code to obtain secret data. This is especially easy when the cleartext is plain ASCII. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "312", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "319", "Name": "Cleartext Transmission of Sensitive Information", "Description": "Configure servers to use encrypted channels for communication, which may include SSL or other secure protocols.", "Extended_Description": "Many communication channels can be \"sniffed\" (monitored) by adversaries during data transmission. For example, in networking, packets can traverse many intermediary nodes from the source to the destination, whether across the internet, an internal network, the cloud, etc. Some actors might have privileged access to a network interface or any link along the channel, such as a router, but they might not be authorized to collect the underlying data. As a result, network traffic could be sniffed by adversaries, spilling security-critical data.Applicable communication channels are not limited to software products. Applicable channels include hardware-specific technologies such as internal hardware networks and external debug channels, supporting remote JTAG debugging. When mitigations are not applied to combat adversaries within the product's threat model, this weakness significantly lowers the difficulty of exploitation by such adversaries.When full communications are recorded or logged, such as with a packet dump, an adversary could attempt to obtain the dump long after the transmission has occurred and try to \"sniff\" the cleartext from the recorded communications in the dump itself. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.Architecture and Design: For hardware, this may be introduced when design does not plan for an attacker having physical access while a legitimate user is remotely operating the device.", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Read Application DataModify Files or Directories. Note: Anyone can read the information by gaining access to the channel being used for communication.", "Detection_Methods": "Method Name: Black Box. Description: Use monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.Attach the monitor to the process, trigger the feature that sends the data, and look for the presence or absence of common cryptographic functions in the call tree. Monitor the network and determine if the data packets contain readable commands. Tools exist for detecting if certain encodings are in use. If the traffic contains high entropy, this might indicate the usage of encryption. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Before transmitting, encrypt the data using reliable, confidentiality-protecting cryptographic protocols.Implementation : When using web applications with SSL, use SSL for the entire session from login to logout, not just for the initial login page.Implementation : When designing hardware platforms, ensure that approved encryption algorithms (such as those recommended by NIST) protect paths from security critical data to trusted user applications.Testing : Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.Operation : Configure servers to use encrypted channels for communication, which may include SSL or other secure protocols.", "Demonstrative_Examples": "The following code attempts to establish a connection to a site to communicate sensitive information.. Though a connection is successfully made, the connection is unencrypted and it is possible that all sensitive data sent to or received from the server will be read by unintended actors.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors used cleartext transmission of sensitive information in their OT products.. A TAP accessible register is read/written by a JTAG based tool, for internal use by authorized users. However, an adversary can connect a probing device and collect the values from the unencrypted channel connecting the JTAG interface to the authorized user, if no additional protections are employed.The following Azure CLI command lists the properties of a particular storage account:. Note: to enable secure transfer using Azure's Portal instead of the command line:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "311", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "311", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "32", "Name": "Path Traversal: '...' (Triple Dot)", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The '...' manipulation is useful for bypassing some path traversal protection schemes. On some Windows systems, it is equivalent to \"..\\..\" and might bypass checks that assume only two dots are valid. Incomplete filtering, such as removal of \"./\" sequences, can ultimately produce valid \"..\" sequences due to a collapse into unsafe value (CWE-182).", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "321", "Name": "Use of Hard-coded Cryptographic Key", "Description": "Prevention schemes mirror that of hard-coded password storage.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: If hard-coded cryptographic keys are used, it is almost certain that malicious users will gain access through the account in question.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Prevention schemes mirror that of hard-coded password storage.", "Demonstrative_Examples": "The following code examples attempt to verify a password using a hard-coded cryptographic key.. The cryptographic key is within a hard-coded string value that is compared to the password. It is likely that an attacker will be able to read the key and compromise the system.In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors used hard-coded keys for critical functionality in their OT products.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "798", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "798", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "798", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "322", "Name": "Key Exchange without Entity Authentication", "Description": "Understand and properly implement all checks necessary to ensure the identity of entities involved in encrypted communications.", "Extended_Description": "Performing a key exchange will preserve the integrity of the information sent between two entities, but this will not guarantee that the entities are who they claim they are. This may enable an attacker to impersonate an actor by modifying traffic between the two entities.  Typically, this involves a victim client that contacts a malicious server that is impersonating a trusted server. If the client skips authentication or ignores an authentication failure, the malicious server may request authentication information from the user. The malicious server can then use this authentication information to log in to the trusted server using the victim's credentials, sniff traffic between the victim and trusted server, etc.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: No authentication takes place in this process, bypassing an assumed protection of encryption.Scopes: Confidentiality. Impacts: Read Application Data. Note: The encrypted communication between a user and a trusted host may be subject to sniffing by any actor in the communication path.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Ensure that proper authentication is included in the system design.Implementation : Understand and properly implement all checks necessary to ensure the identity of entities involved in encrypted communications.", "Demonstrative_Examples": ". Many systems have used Diffie-Hellman key exchange without authenticating the entities exchanging keys, allowing attackers to influence communications by redirecting or interfering with the communication path.  Many people using SSL/TLS skip the authentication (often unknowingly).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "306", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "923", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "295", "View_ID": "1000", "Ordinal": null}]}, {"ID": "344", "Name": "Use of Invariant Value in Dynamically Changing Context", "Description": "The product uses a constant value, name, or reference, but this value can (or should) vary across different environments.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "323", "Name": "Reusing a Nonce, Key Pair in Encryption", "Description": "Use techniques such as requiring incrementing, time based and/or challenge response to assure uniqueness of nonces.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: Potentially a replay attack, in which an attacker could send the same data twice, could be crafted if nonces are allowed to be reused. This could allow a user to send a message which masquerades as a valid message from a valid user.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Refuse to reuse nonce values.Implementation : Use techniques such as requiring incrementing, time based and/or challenge response to assure uniqueness of nonces.", "Demonstrative_Examples": "This code takes a password, concatenates it with a nonce, then encrypts it before sending over a network:. Because the nonce used is always the same, an attacker can impersonate a trusted party by intercepting and resending the encrypted password. This attack avoids the need to learn the unencrypted password.This code sends a command to a remote server, using an encrypted password and nonce to prove the command is from a trusted party:. Once again the nonce used is always the same. An attacker may be able to replay previous legitimate commands or execute new arbitrary commands.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "344", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "324", "Name": "Use of a Key Past its Expiration Date", "Description": "Adequate consideration should be put in to the user interface in order to notify users previous to the key's expiration, to explain the importance of new key generation and to walk users through the process as painlessly as possible.", "Extended_Description": "While the expiration of keys does not necessarily ensure that they are compromised, it is a significant concern that keys which remain in use for prolonged periods of time have a decreasing probability of integrity. For this reason, it is important to replace keys within a period of time proportional to their strength.", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: The cryptographic key in question may be compromised, providing a malicious user with a method for authenticating as the victim.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Adequate consideration should be put in to the user interface in order to notify users previous to the key's expiration, to explain the importance of new key generation and to walk users through the process as painlessly as possible.", "Demonstrative_Examples": "The following code attempts to verify that a certificate is valid.. The code checks if the certificate is not yet valid, but it fails to check if a certificate is past its expiration date, thus treating expired certificates as valid.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "298", "View_ID": "1000", "Ordinal": null}]}, {"ID": "325", "Name": "Missing Cryptographic Step", "Description": "The product does not implement a required step in a cryptographic algorithm, resulting in weaker encryption than advertised by the algorithm.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: Developers sometimes omit \"expensive\" (resource-intensive) steps in order to improve performance, especially in devices with limited memory or slower CPUs. This step may be taken under a mistaken impression that the step is unnecessary for the cryptographic algorithm.Requirements: This issue may happen when the requirements for the cryptographic algorithm are not clearly stated.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "358", "View_ID": "1000", "Ordinal": null}]}, {"ID": "326", "Name": "Inadequate Encryption Strength", "Description": "Use an encryption scheme that is currently considered to be strong by experts in the field.", "Extended_Description": "A weak encryption scheme can be subjected to brute force attacks that have a reasonable chance of succeeding using current attack methods and resources.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlConfidentiality. Impacts: Bypass Protection MechanismRead Application Data. Note: An attacker may be able to decrypt the data using brute force attacks.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use an encryption scheme that is currently considered to be strong by experts in the field.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "328", "Name": "Use of Weak Hash", "Description": "Use an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n                  Some hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n                  Note that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.", "Extended_Description": "A hash function is defined as an algorithm that maps arbitrarily sized data into a fixed-sized digest (output) such that the following properties hold:Building on this definition, a cryptographic hash function must also ensure that a malicious actor cannot leverage the hash function to have a reasonable chance of success at determining any of the following:What is regarded as \"reasonable\" varies by context and threat model, but in general, \"reasonable\" could cover any attack that is more efficient than brute force (i.e., on average, attempting half of all possible combinations). Note that some attacks might be more efficient than brute force but are still not regarded as achievable in the real world.Any algorithm does not meet the above conditions will generally be considered weak for general use in hashing.In addition to algorithmic weaknesses, a hash function can be made weak by using the hash in a security context that breaks its security guarantees. For example, using a hash function without a salt for storing passwords (that are sufficiently short) could enable an adversary to create a \"rainbow table\" [REF-637] to recover the password under certain conditions; this attack works against such hash functions as MD5, SHA-1, and SHA-2.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n                  Some hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n                  Note that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.", "Demonstrative_Examples": "In both of these examples, a user is logged in if their given password matches a stored password:. This code relies exclusively on a password mechanism (CWE-309) using only one factor of authentication (CWE-308). If an attacker can steal or guess a user's password, they are given full access to their account. Note this code also uses SHA-1, which is a weak hash (CWE-328).  It also does not use a salt (CWE-759).In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. At least one OT product used weak hashes.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "326", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "327", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "329", "Name": "Generation of Predictable IV with CBC Mode", "Description": "NIST recommends two methods of generating unpredictable IVs for CBC mode [REF-1172]. The first is to generate the IV randomly. The second method is to encrypt a nonce with the same key and cipher to be used to encrypt the plaintext. In this case the nonce must be unique but can be predictable, since the block cipher will act as a pseudo random permutation.", "Extended_Description": "CBC mode eliminates a weakness of Electronic Code\n\t   Book (ECB) mode by allowing identical plaintext blocks to\n\t   be encrypted to different ciphertext blocks. This is\n\t   possible by the XOR-ing of an IV with the initial plaintext\n\t   block so that every plaintext block in the chain is XOR'd\n\t   with a different value before encryption. If IVs are\n\t   reused, then identical plaintexts would be encrypted to\n\t   identical ciphertexts. However, even if IVs are not\n\t   identical but are predictable, then they still break the\n\t   security of CBC mode against Chosen Plaintext Attacks\n\t   (CPA).", "Modes_Of_Introduction": "Implementation: Developers might dismiss the importance of an unpredictable IV and choose an easier implementation to save effort, weakening the scheme in the process.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: If the IV is not properly initialized, data that is encrypted can be compromised and leak information.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : NIST recommends two methods of generating unpredictable IVs for CBC mode [REF-1172]. The first is to generate the IV randomly. The second method is to encrypt a nonce with the same key and cipher to be used to encrypt the plaintext. In this case the nonce must be unique but can be predictable, since the block cipher will act as a pseudo random permutation.", "Demonstrative_Examples": "In the following examples, CBC mode is used when encrypting data:. In both of these examples, the initialization vector (IV) is always a block of zeros. This makes the resulting cipher text much more predictable and susceptible to a dictionary attack.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1204", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": null}]}, {"ID": "33", "Name": "Path Traversal: '....' (Multiple Dot)", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The '....' manipulation is useful for bypassing some path traversal protection schemes. On some Windows systems, it is equivalent to \"..\\..\\..\" and might bypass checks that assume only two dots are valid. Incomplete filtering, such as removal of \"./\" sequences, can ultimately produce valid \"..\" sequences due to a collapse into unsafe value (CWE-182).", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "331", "Name": "Insufficient Entropy", "Description": "Determine the necessary entropy to adequately provide for randomness and predictability. This can be achieved by increasing the number of bits of objects such as keys and seeds.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: An attacker could guess the random numbers generated and could gain unauthorized access to a system if the random numbers are used for authentication and authorization.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Determine the necessary entropy to adequately provide for randomness and predictability. This can be achieved by increasing the number of bits of objects such as keys and seeds.", "Demonstrative_Examples": "This code generates a unique random identifier for a user's session.. Because the seed for the PRNG is always the user's ID, the session ID will always be the same. An attacker could thus predict any user's session ID and potentially hijack the session.The following code uses a statistical PRNG to create a URL for a receipt that remains active for some period of time after a purchase.. This code uses the Random.nextInt() function to generate \"unique\" identifiers for the receipt pages it generates. Because Random.nextInt() is a statistical PRNG, it is easy for an attacker to guess the strings it generates. Although the underlying design of the receipt system is also faulty, it would be more secure if it used a random number generator that did not produce predictable receipt identifiers, such as a cryptographic PRNG.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "332", "Name": "Insufficient Entropy in PRNG", "Description": "When deciding which PRNG to use, look at its sources of entropy. Depending on what your security needs are, you may need to use a random number generator that always uses strong random data -- i.e., a random number generator that attempts to be strong but will fail in a weak way or will always provide some middle ground of protection through techniques like re-seeding. Generally, something that always provides a predictable amount of strength is preferable.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: If a pseudo-random number generator is using a limited entropy source which runs out (if the generator fails closed), the program may pause or crash.Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: If a PRNG is using a limited entropy source which runs out, and the generator fails open, the generator could produce predictable random numbers. Potentially a weak source of random numbers could weaken the encryption method used for authentication of users.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").Implementation : Consider a PRNG that re-seeds itself as needed from high-quality pseudo-random output, such as hardware devices.Architecture and Design : When deciding which PRNG to use, look at its sources of entropy. Depending on what your security needs are, you may need to use a random number generator that always uses strong random data -- i.e., a random number generator that attempts to be strong but will fail in a weak way or will always provide some middle ground of protection through techniques like re-seeding. Generally, something that always provides a predictable amount of strength is preferable.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "331", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "333", "Name": "Improper Handling of Insufficient Entropy in TRNG", "Description": "Rather than failing on a lack of random numbers, it is often preferable to wait for more numbers to be created.", "Extended_Description": "The rate at which true random numbers can be generated is limited. It is important that one uses them only when they are needed for security.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: A program may crash or block if it runs out of random numbers.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Rather than failing on a lack of random numbers, it is often preferable to wait for more numbers to be created.", "Demonstrative_Examples": "This code uses a TRNG to generate a unique session id for new connections to a server:. This code does not attempt to limit the number of new connections or make sure the TRNG can successfully generate a new random number. An attacker may be able to create many new connections and exhaust the entropy of the TRNG. The TRNG may then block and cause the program to crash or hang.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "331", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": null}]}, {"ID": "334", "Name": "Small Space of Random Values", "Description": "Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: An attacker could easily guess the values used. This could lead to unauthorized access to a system if the seed is used for authentication and authorization.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").", "Demonstrative_Examples": "The following XML example code is a deployment descriptor for a Java web application deployed on a Sun Java Application Server. This deployment descriptor includes a session configuration property for configuring the session ID length.. This deployment descriptor has set the session ID length for this Java web application to 8 bytes (or 64 bits). The session ID length for Java web applications should be set to 16 bytes (128 bits) to prevent attackers from guessing and/or stealing a session ID and taking over a user's session.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "335", "Name": "Incorrect Usage of Seeds in Pseudo-Random Number Generator (PRNG)", "Description": "The product uses a Pseudo-Random Number Generator (PRNG) but does not correctly manage seeds.", "Extended_Description": "PRNGs are deterministic and, while their output appears\n\t\t   random, they cannot actually create entropy. They rely on\n\t\t   cryptographically secure and unique seeds for entropy so\n\t\t   proper seeding is critical to the secure operation of the\n\t\t   PRNG.Management of seeds could be broken down into two main areas:PRNGs require a seed as input to generate a stream of\n\t\t\t   numbers that are functionally indistinguishable from\n\t\t\t   random numbers.  While the output is, in many cases,\n\t\t\t   sufficient for cryptographic uses, the output of any\n\t\t\t   PRNG is directly determined by the seed provided as\n\t\t\t   input. If the seed can be ascertained by a third party,\n\t\t\t   the entire output of the PRNG can be made known to\n\t\t\t   them. As such, the seed should be kept secret and\n\t\t\t   should ideally not be able to be guessed. For example,\n\t\t\t   the current time may be a poor seed. Knowing the\n\t\t\t   approximate time the PRNG was seeded greatly reduces\n\t\t\t   the possible key space.Seeds do not necessarily need to be unique, but reusing seeds may open up attacks if the seed is discovered.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: If a PRNG is used incorrectly, such as using the same seed for each initialization or using a predictable seed, then an attacker may be able to easily guess the seed and thus the random numbers. This could lead to unauthorized access to a system if the seed is used for authentication and authorization.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "336", "Name": "Same Seed in Pseudo-Random Number Generator (PRNG)", "Description": "Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.", "Extended_Description": "Given the deterministic nature of PRNGs, using the same seed for each initialization will lead to the same output in the same order. If an attacker can guess (or knows) the seed, then the attacker may be able to determine the random numbers that will be produced from the PRNG.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Do not reuse PRNG seeds. Consider a PRNG that periodically re-seeds itself as needed from a high quality pseudo-random output, such as hardware devices.Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.", "Demonstrative_Examples": "The following code uses a statistical PRNG to generate account IDs.. Because the program uses the same seed value for every invocation of the PRNG, its values are predictable, making the system vulnerable to attack.This code attempts to generate a unique random identifier for a user's session.. Because the seed for the PRNG is always the user's ID, the session ID will always be the same. An attacker could thus predict any user's session ID and potentially hijack the session.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "335", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "337", "Name": "Predictable Seed in Pseudo-Random Number Generator (PRNG)", "Description": "Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.", "Extended_Description": "The use of predictable seeds significantly reduces the number of possible seeds that an attacker would need to test in order to predict which random numbers will be generated by the PRNG.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Use non-predictable inputs for seed generation.Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.Implementation : Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.", "Demonstrative_Examples": "Both of these examples use a statistical PRNG seeded with the current value of the system clock to generate a random number:. An attacker can easily predict the seed used by these PRNGs, and so also predict the stream of random numbers generated. Note these examples also exhibit CWE-338 (Use of Cryptographically Weak PRNG).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "335", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "338", "Name": "Use of Cryptographically Weak Pseudo-Random Number Generator (PRNG)", "Description": "Use functions or hardware which use a hardware-based random number generation for all crypto. This is the recommended solution. Use CyptGenRandom on Windows, or hw_rand() on Linux.", "Extended_Description": "When a non-cryptographic PRNG is used in a cryptographic context, it can expose the cryptography to certain types of attacks.Often a pseudo-random number generator (PRNG) is not designed for cryptography. Sometimes a mediocre source of randomness is sufficient or preferable for algorithms that use random numbers. Weak generators generally take less processing power and/or do not use the precious, finite, entropy sources on a system. While such PRNGs might have very useful features, these same features could be used to break the cryptography.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If a PRNG is used for authentication and authorization, such as a session ID or a seed for generating a cryptographic key, then an attacker may be able to easily guess the ID or cryptographic key and gain access to restricted functionality.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Use functions or hardware which use a hardware-based random number generation for all crypto. This is the recommended solution. Use CyptGenRandom on Windows, or hw_rand() on Linux.", "Demonstrative_Examples": "Both of these examples use a statistical PRNG seeded with the current value of the system clock to generate a random number:. The random number functions used in these examples, rand() and Random.nextInt(), are not considered cryptographically strong. An attacker may be able to predict the random numbers generated by these functions. Note that these example also exhibit CWE-337 (Predictable Seed in PRNG).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "339", "Name": "Small Seed Space in PRNG", "Description": "Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.", "Extended_Description": "PRNGs are entirely deterministic once seeded, so it should be extremely difficult to guess the seed. If an attacker can collect the outputs of a PRNG and then brute force the seed by trying every possibility to see which seed matches the observed output, then the attacker will know the output of any subsequent calls to the PRNG. A small seed space implies that the attacker will have far fewer possible values to try to exhaust all possibilities.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use well vetted pseudo-random number generating algorithms with adequate length seeds. Pseudo-random number generators can produce predictable numbers if the generator is known and the seed can be guessed. A 256-bit seed is a good starting point for producing a \"random enough\" number.Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.", "Demonstrative_Examples": "This code grabs some random bytes and uses them for a seed in a PRNG, in order to generate a new cryptographic key.. Since only 2 bytes is used as a seed, an attacker will only need to guess 2^16 (65,536) values before being able to replicate the state of the PRNG.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "335", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "341", "View_ID": "1000", "Ordinal": null}]}, {"ID": "34", "Name": "Path Traversal: '....//'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The '....//' manipulation is useful for bypassing some path traversal protection schemes. If \"../\" is filtered in a sequential fashion, as done by some regular expression engines, then \"....//\" can collapse into the \"../\" unsafe value (CWE-182). It could also be useful when \"..\" is removed, if the operating system treats \"//\" and \"/\" as equivalent.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "340", "Name": "Generation of Predictable Numbers or Identifiers", "Description": "The product uses a scheme that generates numbers or identifiers that are more predictable than required.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "330", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "341", "Name": "Predictable from Observable State", "Description": "Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Other. Impacts: Varies by Context. Note: This weakness could be exploited by an attacker in a number ways depending on the context. If a predictable number is used to generate IDs or keys that are used within protection mechanisms, then an attacker could gain unauthorized access to the system. If predictable filenames are used for storing sensitive information, then an attacker might gain access to the system and may be able to gain access to the information in the file.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Increase the entropy used to seed a PRNG.Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").Implementation : Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.", "Demonstrative_Examples": "This code generates a unique random identifier for a user's session.. Because the seed for the PRNG is always the user's ID, the session ID will always be the same. An attacker could thus predict any user's session ID and potentially hijack the session.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "340", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "342", "Name": "Predictable Exact Value from Previous Values", "Description": "Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Increase the entropy used to seed a PRNG.Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").Implementation : Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "340", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "343", "Name": "Predictable Value Range from Previous Values", "Description": "Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.", "Extended_Description": "The output of a random number generator should not be predictable based on observations of previous values. In some cases, an attacker cannot predict the exact value that will be produced next, but can narrow down the possibilities significantly. This reduces the amount of effort to perform a brute force attack. For example, suppose the product generates random numbers between 1 and 100, but it always produces a larger value until it reaches 100. If the generator produces an 80, then the attacker knows that the next value will be somewhere between 81 and 100. Instead of 100 possibilities, the attacker only needs to consider 20.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "N/A : Increase the entropy used to seed a PRNG.Architecture and Design : Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").Implementation : Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "340", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "347", "Name": "Improper Verification of Cryptographic Signature", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlIntegrityConfidentiality. Impacts: Gain Privileges or Assume IdentityModify Application DataExecute Unauthorized Code or Commands. Note: An attacker could gain access to sensitive data and possibly execute unauthorized code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "In the following code, a JarFile object is created from a downloaded file.. The JAR file that was potentially downloaded from an untrusted source is created without verifying the signature (if present). An alternate constructor that accepts a boolean verify parameter should be used instead.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "348", "Name": "Use of Less Trusted Source", "Description": "The product has two different sources of the same data or information, but it uses the source that has less support for verification, is less trusted, or is less resistant to attack.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: An attacker could utilize the untrusted data source to bypass protection mechanisms and gain access to sensitive data.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This code attempts to limit the access of a page to certain IP Addresses. It checks the 'HTTP_X_FORWARDED_FOR' header in case an authorized user is sending the request through a proxy.. The 'HTTP_X_FORWARDED_FOR' header can be user controlled and so should never be trusted. An attacker can falsify the header to gain access to the page.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "349", "Name": "Acceptance of Extraneous Untrusted Data With Trusted Data", "Description": "The product, when processing trusted data, accepts any untrusted data that is also included with the trusted data, treating the untrusted data as if it were trusted.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access ControlIntegrity. Impacts: Bypass Protection MechanismModify Application Data. Note: An attacker could package untrusted data with trusted data to bypass protection mechanisms to gain access to and possibly modify sensitive data.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "35", "Name": "Path Traversal: '.../...//'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.The '.../...//' manipulation is useful for bypassing some path traversal protection schemes. If \"../\" is filtered in a sequential fashion, as done by some regular expression engines, then \".../...//\" can collapse into the \"../\" unsafe value (CWE-182). Removing the first \"../\" yields \"....//\"; the second removal yields \"../\". Depending on the algorithm, the product could be susceptible to CWE-34 but not CWE-35, or vice versa.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "23", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "350", "Name": "Reliance on Reverse DNS Resolution for a Security-Critical Action", "Description": "Perform proper forward and reverse DNS lookups to detect DNS spoofing.", "Extended_Description": "Since DNS names can be easily spoofed or misreported, and it may be difficult for the product to detect if a trusted DNS server has been compromised, DNS names do not constitute a valid authentication mechanism.When the product performs a reverse DNS resolution for an IP address, if an attacker controls the DNS server for that IP address, then the attacker can cause the server to return an arbitrary hostname. As a result, the attacker may be able to bypass authentication, cause the wrong hostname to be recorded in log files to hide activities, or perform other attacks.Attackers can spoof DNS names by either (1) compromising a DNS server and modifying its records (sometimes called DNS cache poisoning), or (2) having legitimate control over a DNS server associated with their IP address.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume IdentityBypass Protection Mechanism. Note: Malicious users can fake authentication information by providing false DNS information.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use other means of identity verification that cannot be simply spoofed. Possibilities include a username/password or certificate.Implementation : Perform proper forward and reverse DNS lookups to detect DNS spoofing.", "Demonstrative_Examples": "The following code samples use a DNS lookup in order to decide whether or not an inbound request is from a trusted host. If an attacker can poison the DNS cache, they can gain trusted status.. IP addresses are more reliable than DNS names, but they can also be spoofed. Attackers can easily forge the source IP address of the packets they send, but response packets will return to the forged IP address. To see the response packets, the attacker has to sniff the traffic between the victim machine and the forged IP address. In order to accomplish the required sniffing, attackers typically attempt to locate themselves on the same subnet as the victim machine. Attackers may be able to circumvent this requirement by using source routing, but source routing is disabled across much of the Internet today. In summary, IP address verification can be a useful part of an authentication scheme, but it should not be the single factor required for authentication.In these examples, a connection is established if a request is made by a trusted host.. These examples check if a request is from a trusted host before responding to a request, but the code only verifies the hostname as stored in the request packet. An attacker can spoof the hostname, thus impersonating a trusted client.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "290", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "807", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "923", "View_ID": "1000", "Ordinal": null}]}, {"ID": "351", "Name": "Insufficient Type Distinction", "Description": "The product does not properly distinguish between different types of elements in a way that leads to insecure behavior.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": null}]}, {"ID": "352", "Name": "Cross-Site Request Forgery (CSRF)", "Description": "Check the HTTP Referer header to see if the request originated from an expected page. This could break legitimate functionality, because users or proxies may have disabled sending the Referer for privacy reasons.", "Extended_Description": "When a web server is designed to receive a request from a client without any mechanism for verifying that it was intentionally sent, then it might be possible for an attacker to trick a client into making an unintentional request to the web server which will be treated as an authentic request. This can be done via a URL, image load, XMLHttpRequest, etc. and can result in exposure of data or unintended code execution.", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityNon-RepudiationAccess Control. Impacts: Gain Privileges or Assume IdentityBypass Protection MechanismRead Application DataModify Application DataDoS: Crash, Exit, or Restart. Note: The consequences will vary depending on the nature of the functionality that is vulnerable to CSRF. An attacker could effectively perform any operations as the victim. If the victim is an administrator or privileged user, the consequences may include obtaining complete control over the web application - deleting or stealing data, uninstalling the product, or using it to launch other attacks against all of the product's users. Because the attacker has the identity of the victim, the scope of CSRF is limited only by the victim's privileges.", "Detection_Methods": "Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual analysis can be useful for finding this weakness, and for minimizing false positives assuming an understanding of business logic. However, it might not achieve desired code coverage within limited time constraints. For black-box analysis, if credentials are not known for privileged accounts, then the most security-critical portions of the application may not receive sufficient attention.Consider using OWASP CSRFTester to identify potential issues and aid in manual analysis. Method Name: Automated Static Analysis. Description: CSRF is currently difficult to detect reliably using automated techniques. This is because each application has its own implicit security policy that dictates which requests can be influenced by an outsider and automatically performed on behalf of a user, versus which requests require strong confidence that the user intends to make the request. For example, a keyword search of the public portion of a web site is typically expected to be encoded within a link that can be launched automatically when the user clicks on the link. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, use anti-CSRF packages such as the OWASP CSRFGuard. [REF-330]\n                  Another example is the ESAPI Session Management control, which includes a component for CSRF. [REF-45]Implementation : Ensure that the application is free of cross-site scripting issues (CWE-79), because most CSRF defenses can be bypassed using attacker-controlled script.Architecture and Design : Generate a unique nonce for each form, place the nonce into the form, and verify the nonce upon receipt of the form. Be sure that the nonce is not predictable (CWE-330). [REF-332]Architecture and Design : Identify especially dangerous operations. When the user performs a dangerous operation, send a separate confirmation request to ensure that the user intended to perform that operation.Architecture and Design : Use the \"double-submitted cookie\" method as described by Felten and Zeller:\n                  When a user visits a site, the site should generate a pseudorandom value and set it as a cookie on the user's machine. The site should require every form submission to include this value as a form value and also as a cookie value. When a POST request is sent to the site, the request should only be considered valid if the form value and the cookie value are the same.\n                  Because of the same-origin policy, an attacker cannot read or modify the value stored in the cookie. To successfully submit a form on behalf of the user, the attacker would have to correctly guess the pseudorandom value. If the pseudorandom value is cryptographically strong, this will be prohibitively difficult.\n                  This technique requires Javascript, so it may not work for browsers that have Javascript disabled. [REF-331]Architecture and Design : Do not use the GET method for any request that triggers a state change.Implementation : Check the HTTP Referer header to see if the request originated from an expected page. This could break legitimate functionality, because users or proxies may have disabled sending the Referer for privacy reasons.", "Demonstrative_Examples": "This example PHP code attempts to secure the form submission process by validating that the user submitting the form has a valid session. A CSRF attack would not be prevented by this countermeasure because the attacker forges a request through the user's web browser in which a valid session already exists.. The following HTML is intended to allow a user to update a profile.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "Requires", "CWE_ID": "346", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "441", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "642", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "613", "View_ID": "1000", "Ordinal": null}]}, {"ID": "353", "Name": "Missing Support for Integrity Check", "Description": "Ensure that the checksums present in the protocol design are properly implemented and added to each message before it is sent.", "Extended_Description": "If integrity check values or \"checksums\" are omitted from a protocol, there is no way of determining if data has been corrupted in transmission. The lack of checksum functionality in a protocol removes the first application-level check of data that can be used. The end-to-end philosophy of checks states that integrity checks should be performed at the lowest level that they can be completely implemented. Excluding further sanity checks and input validation performed by applications, the protocol's checksum is the most important level of checksum, since it can be performed more completely than at any previous level and takes into account entire messages, as opposed to single packets.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Other. Note: Data that is parsed and used may be corrupted.Scopes: Non-RepudiationOther. Impacts: Hide ActivitiesOther. Note: Without a checksum it is impossible to determine if any changes have been made to the data after it was sent.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Add an appropriately sized checksum to the protocol, ensuring that data received may be simply validated before it is parsed and used.Implementation : Ensure that the checksums present in the protocol design are properly implemented and added to each message before it is sent.", "Demonstrative_Examples": "In this example, a request packet is received, and privileged information is sent to the requester:. The response containing secret data has no integrity check associated with it, allowing an attacker to alter the message without detection.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "354", "View_ID": "1000", "Ordinal": null}]}, {"ID": "354", "Name": "Improper Validation of Integrity Check Value", "Description": "Ensure that the checksums present in messages are properly checked in accordance with the protocol specification before they are parsed and used.", "Extended_Description": "Improper validation of checksums before use results in an unnecessary risk that can easily be mitigated. The protocol specification describes the algorithm used for calculating the checksum. It is then a simple matter of implementing the calculation and verifying that the calculated checksum and the received checksum match. Improper verification of the calculated checksum and the received checksum can lead to far greater consequences.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Modify Application DataOther. Note: Integrity checks usually use a secret key that helps authenticate the data origin. Skipping integrity checking generally opens up the possibility that new data from an invalid source can be injected.Scopes: IntegrityOther. Impacts: Other. Note: Data that is parsed and used may be corrupted.Scopes: Non-RepudiationOther. Impacts: Hide ActivitiesOther. Note: Without a checksum check, it is impossible to determine if any changes have been made to the data after it was sent.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Ensure that the checksums present in messages are properly checked in accordance with the protocol specification before they are parsed and used.", "Demonstrative_Examples": ". The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "353", "View_ID": "1000", "Ordinal": null}]}, {"ID": "356", "Name": "Product UI does not Warn User of Unsafe Actions", "Description": "The product's user interface does not warn the user before undertaking an unsafe action on behalf of that user. This makes it easier for attackers to trick users into inflicting damage to their system.", "Extended_Description": "Product systems should warn users that a potentially dangerous action may occur if the user proceeds. For example, if the user downloads a file from an unknown source and attempts to execute the file on their machine, then the application's GUI can indicate that the file is unsafe.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "221", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "357", "Name": "Insufficient UI Warning of Dangerous Operations", "Description": "The user interface provides a warning to a user regarding dangerous or sensitive operations, but the warning is not noticeable enough to warrant attention.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "358", "Name": "Improperly Implemented Security Check for Standard", "Description": "The product does not implement or incorrectly implements one or more security-relevant checks as specified by the design of a standardized algorithm, protocol, or technique.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: This is an implementation error, in which the algorithm/technique requires certain security-related behaviors or conditions that are not implemented or checked properly, thus causing a vulnerability.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "345", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "290", "View_ID": "1000", "Ordinal": null}]}, {"ID": "359", "Name": "Exposure of Private Personal Information to an Unauthorized Actor", "Description": "Carefully evaluate how secure design may interfere with privacy, and vice versa.  Security and privacy concerns often seem to compete with each other. From a security perspective, all important operations should be recorded so that any anomalous activity can later be identified. However, when private data is involved, this practice can in fact create risk. Although there are many ways in which private data can be handled unsafely, a common risk stems from misplaced trust. Programmers often trust the operating environment in which a program runs, and therefore believe that it is acceptable store private information on the file system, in the registry, or in other locally-controlled resources. However, even if access to certain resources is restricted, this does not guarantee that the individuals who do have access can be trusted.", "Extended_Description": "There are many types of sensitive information that products must protect from attackers, including system data, communications, configuration, business secrets, intellectual property, and an individual's personal (private) information.  Private personal information may include a password, phone number, geographic location, personal messages, credit card number, etc.  Private information is important to consider whether the person is a user of the product, or part of a data set that is processed by the product.  An exposure of private information does not necessarily prevent the product from working properly, and in fact the exposure might be intended by the developer, e.g. as part of data sharing with other organizations.  However, the exposure of personal private information can still be undesirable or explicitly prohibited by law or regulation.Some types of private information include:Some of this information may be characterized as PII (Personally Identifiable Information), Protected Health Information (PHI), etc. Categories of private information may overlap or vary based on the intended usage or the policies and practices of a particular industry.Sometimes data that is not labeled as private can have a privacy implication in a different context. For example, student identification numbers are usually not considered private because there is no explicit and publicly-available mapping to an individual student's personal information. However, if a school generates identification numbers based on student social security numbers, then the identification numbers should be considered private.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Architecture or Design Review. Description: Private personal data can enter a program in a variety of ways:If the data is written to an external location - such as the console, file system, or network - a privacy violation may occur. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : Identify and consult all relevant regulations for personal privacy.  An organization may be required to comply with certain federal and state regulations, depending on its location, the type of business it conducts, and the nature of any private data it handles.  Regulations may include Safe Harbor Privacy Framework [REF-340], Gramm-Leach Bliley Act (GLBA) [REF-341], Health Insurance Portability and Accountability Act (HIPAA) [REF-342], General Data Protection Regulation (GDPR) [REF-1047], California Consumer Privacy Act (CCPA) [REF-1048], and others.Architecture and Design : Carefully evaluate how secure design may interfere with privacy, and vice versa.  Security and privacy concerns often seem to compete with each other. From a security perspective, all important operations should be recorded so that any anomalous activity can later be identified. However, when private data is involved, this practice can in fact create risk. Although there are many ways in which private data can be handled unsafely, a common risk stems from misplaced trust. Programmers often trust the operating environment in which a program runs, and therefore believe that it is acceptable store private information on the file system, in the registry, or in other locally-controlled resources. However, even if access to certain resources is restricted, this does not guarantee that the individuals who do have access can be trusted.", "Demonstrative_Examples": "The following code contains a logging statement that tracks the contents of records added to a database by storing them in a log file. Among other values that are stored, the getPassword() function returns the user-supplied plaintext password associated with the account.. The code in the example above logs a plaintext password to the filesystem. Although many developers trust the filesystem as a safe storage location for data, it should not be trusted implicitly, particularly when privacy is a concern.This code uses location to determine the user's current US State location.. First the application must declare that it requires the ACCESS_FINE_LOCATION permission in the application's manifest.xml:. In 2004, an employee at AOL sold approximately 92 million private customer e-mail addresses to a spammer marketing an offshore gambling web site [REF-338]. In response to such high-profile exploits, the collection and management of private data is becoming increasingly regulated.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "36", "Name": "Absolute Path Traversal", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "This allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: The attacker may be able to create or overwrite critical files that are used to execute code, such as programs or libraries.Scopes: Integrity. Impacts: Modify Files or Directories. Note: The attacker may be able to overwrite or create critical files, such as programs, libraries, or important data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, appending a new account at the end of a password file may allow an attacker to bypass authentication.Scopes: Confidentiality. Impacts: Read Files or Directories. Note: The attacker may be able read the contents of unexpected files and expose sensitive data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, by reading a password file, the attacker could conduct brute force password guessing attacks in order to break into an account on the system.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: The attacker may be able to overwrite, delete, or corrupt unexpected critical files such as programs, libraries, or important data. This may prevent the product from working at all and in the case of a protection mechanisms such as authentication, it has the potential to lockout every user of the product.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "In the example below, the path to a dictionary file is read from a system property and used to initialize a File object.. However, the path is not validated or modified to prevent it from containing relative or absolute path sequences before creating the File object. This allows anyone who can control the system property to determine what file is used. Ideally, the path should be resolved relative to some kind of application or user home directory.This script intends to read a user-supplied file from the current directory. The user inputs the relative path to the file and the script uses Python's os.path.join() function to combine the path to the current working directory with the provided path to the specified file. This results in an absolute path to the desired file. If the file does not exist when the script attempts to read it, an error is printed to the user.. However, if the user supplies an absolute path, the os.path.join() function will discard the path to the current working directory and use only the absolute path provided. For example, if the current working directory is /home/user/documents, but the user inputs /etc/passwd, os.path.join() will use only /etc/passwd, as it is considered an absolute path. In the above scenario, this would cause the script to access and read the /etc/passwd file.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "22", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "22", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "22", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "360", "Name": "Trust of System Event Data", "Description": "Never trust or rely any of the information in an Event for security.", "Extended_Description": "Events are a messaging system which may provide control data to programs listening for events. Events often do not have any type of authentication framework to allow them to be verified from a trusted source. Any application, in Windows, on a given desktop can send a message to any window on the same desktop. There is no authentication framework for these messages. Therefore, any message can be used to manipulate any process on the desktop if the process does not check the validity and safeness of those messages.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Gain Privileges or Assume IdentityExecute Unauthorized Code or Commands. Note: If one trusts the system-event information and executes commands based on it, one could potentially take actions based on a spoofed identity.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Never trust or rely any of the information in an Event for security.", "Demonstrative_Examples": "This example code prints out secret information when an authorized user activates a button:. This code does not attempt to prevent unauthorized users from activating the button. Even if the button is rendered non-functional to unauthorized users in the application UI, an attacker can easily send a false button press event to the application window and expose the secret information.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "367", "Name": "Time-of-check Time-of-use (TOCTOU) Race Condition", "Description": "Ensure that locking occurs before the check, as opposed to afterwards, such that the resource, as checked, is the same as it is when in use.", "Extended_Description": "This weakness can be security-relevant when an attacker can influence the state of the resource between check and use. This can happen with shared resources such as files, memory, or even variables in multithreaded programs.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Alter Execution LogicUnexpected State. Note: The attacker can gain access to otherwise unauthorized resources.Scopes: IntegrityOther. Impacts: Modify Application DataModify Files or DirectoriesModify MemoryOther. Note: Race conditions such as this kind may be employed to gain read or write access to resources which are not normally readable or writable by the user in question.Scopes: IntegrityOther. Impacts: Other. Note: The resource in question, or other resources (through the corrupted one), may be changed in undesirable ways by a malicious user.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: If a file or other resource is written in this method, as opposed to in a valid way, logging of the activity may not occur.Scopes: Non-RepudiationOther. Impacts: Other. Note: In some cases it may be possible to delete files a malicious user might not otherwise have access to, such as log files.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : The most basic advice for TOCTOU vulnerabilities is to not perform a check before the use. This does not resolve the underlying issue of the execution of a function on a resource whose state and identity cannot be assured, but it does help to limit the false sense of security given by the check.Implementation : When the file being altered is owned by the current user and group, set the effective gid and uid to that of the current user and group when executing this statement.Architecture and Design : Limit the interleaving of operations on files from multiple processes.Implementation : If you cannot perform operations atomically and you must share access to the resource between multiple processes or threads, then try to limit the amount of time (CPU cycles) between the check and use of the resource. This will not fix the problem, but it could make it more difficult for an attack to succeed.Implementation : Recheck the resource after the use call to verify that the action was taken appropriately.Architecture and Design : Ensure that some environmental locking mechanism can be used to protect resources effectively.Implementation : Ensure that locking occurs before the check, as opposed to afterwards, such that the resource, as checked, is the same as it is when in use.", "Demonstrative_Examples": "The following code checks a file, then updates its contents.. Potentially the file could have been updated between the time of the check and the lstat, especially since the printf has latency.The following code is from a program installed setuid root. The program performs certain file operations on behalf of non-privileged users, and uses access checks to ensure that it does not use its root privileges to perform operations that should otherwise be unavailable the current user. The program uses the access() system call to check if the person running the program has permission to access the specified file before it opens the file and performs the necessary operations.. The call to access() behaves as expected, and returns 0 if the user running the program has the necessary permissions to write to the file, and -1 otherwise. However, because both access() and fopen() operate on filenames rather than on file handles, there is no guarantee that the file variable still refers to the same file on disk when it is passed to fopen() that it did when it was passed to access(). If an attacker replaces file after the call to access() with a symbolic link to a different file, the program will use its root privileges to operate on the file even if it is a file that the attacker would otherwise be unable to modify. By tricking the program into performing an operation that would otherwise be impermissible, the attacker has gained elevated privileges. This type of vulnerability is not limited to programs with root privileges. If the application is capable of performing any operation that the attacker would not otherwise be allowed perform, then it is a possible target.This code prints the contents of a file if a user has permission.. This code attempts to resolve symbolic links before checking the file and printing its contents. However, an attacker may be able to change the file from a real file to a symbolic link between the calls to is_link() and file_get_contents(), allowing the reading of arbitrary files. Note that this code fails to log the attempted access (CWE-778).This example is adapted from [REF-18]. Assume that this code block is invoked from multiple threads. The switch statement will execute different code depending on the time when MYFILE.txt was last changed.. If this code block were executed within multiple threads, and MYFILE.txt changed between the operation of one thread and another, then the switch could produce different, possibly unexpected results.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "363", "Name": "Race Condition Enabling Link Following", "Description": "The product checks the status of a file or directory before accessing it, which produces a race condition in which the file can be replaced with a link before the access is performed, causing the product to access the wrong file.", "Extended_Description": "While developers might expect that there is a very narrow time window between the time of check and time of use, there is still a race condition. An attacker could cause the product to slow down (e.g. with memory consumption), causing the time window to become larger. Alternately, in some situations, the attacker could win the race by performing a large number of attacks.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This code prints the contents of a file if a user has permission.. This code attempts to resolve symbolic links before checking the file and printing its contents. However, an attacker may be able to change the file from a real file to a symbolic link between the calls to is_link() and file_get_contents(), allowing the reading of arbitrary files. Note that this code fails to log the attempted access (CWE-778).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "367", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "59", "View_ID": "1000", "Ordinal": null}]}, {"ID": "364", "Name": "Signal Handler Race Condition", "Description": "Only use reentrant functions within signal handlers. Also, use validation to ensure that state is consistent while performing asynchronous actions that affect the state of execution.", "Extended_Description": "Race conditions frequently occur in signal handlers, since signal handlers support asynchronous actions. These race conditions have a variety of root causes and symptoms. Attackers may be able to exploit a signal handler race condition to cause the product state to be corrupted, possibly leading to a denial of service or even code execution.These issues occur when non-reentrant functions, or state-sensitive actions occur in the signal handler, where they may be called at any time. These behaviors can violate assumptions being made by the \"regular\" code that is interrupted, or by other signal handlers that may also be invoked. If these functions are called at an inopportune moment - such as while a non-reentrant function is already running - memory corruption could occur that may be exploitable for code execution. Another signal race condition commonly found occurs when free is called within a signal handler, resulting in a double free and therefore a write-what-where condition. Even if a given pointer is set to NULL after it has been freed, a race condition still exists between the time the memory was freed and the pointer was set to NULL. This is especially problematic if the same signal handler has been set for more than one signal -- since it means that the signal handler itself may be reentered.There are several known behaviors related to signal handlers that have received the label of \"signal handler race condition\":Signal handler vulnerabilities are often classified based on the absence of a specific protection mechanism, although this style of classification is discouraged in CWE because programmers often have a choice of several different mechanisms for addressing the weakness. Such protection mechanisms may preserve exclusivity of access to the shared resource, and behavioral atomicity for the relevant code:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Modify Application DataModify MemoryDoS: Crash, Exit, or RestartExecute Unauthorized Code or Commands. Note: It may be possible to cause data corruption and possibly execute arbitrary code by modifying global variables or data structures at unexpected times, violating the assumptions of code that uses this global data.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: If a signal handler interrupts code that is executing with privileges, it may be possible that the signal handler will also be executed with elevated privileges, possibly making subsequent exploits more severe.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.Architecture and Design : Design signal handlers to only set flags, rather than perform complex functionality. These flags can then be checked and acted upon within the main program loop.Implementation : Only use reentrant functions within signal handlers. Also, use validation to ensure that state is consistent while performing asynchronous actions that affect the state of execution.", "Demonstrative_Examples": "This code registers the same signal handler function with two different signals (CWE-831). If those signals are sent to the process, the handler creates a log message (specified in the first argument to the program) and exits.. The handler function uses global state (globalVar and logMessage), and it can be called by both the SIGHUP and SIGTERM signals. An attack scenario might follow these lines:The following code registers a signal handler with multiple signals in order to log when a specific event occurs and to free associated memory before exiting.. However, the following sequence of events may result in a double-free (CWE-415):", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "415", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "416", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "123", "View_ID": "1000", "Ordinal": null}]}, {"ID": "366", "Name": "Race Condition within a Thread", "Description": "Create resource-locking validation checks. If no inherent locking mechanisms exist, use flags and signals to enforce your own blocking scheme when resources are being used by other threads of execution.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Alter Execution LogicUnexpected State. Note: The main problem is that -- if a lock is overcome -- data could be altered in a bad state.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use locking functionality. This is the recommended solution. Implement some form of locking mechanism around code which alters or reads persistent data in a multithreaded environment.Architecture and Design : Create resource-locking validation checks. If no inherent locking mechanisms exist, use flags and signals to enforce your own blocking scheme when resources are being used by other threads of execution.", "Demonstrative_Examples": ". The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "368", "Name": "Context Switching Race Condition", "Description": "A product performs a series of non-atomic actions to switch between contexts that cross privilege or other security boundaries, but a race condition allows an attacker to modify or misrepresent the product's behavior during the switch.", "Extended_Description": "This is commonly seen in web browser vulnerabilities in which the attacker can perform certain actions while the browser is transitioning from a trusted to an untrusted domain, or vice versa, and the browser performs the actions on one domain using the trust level and resources of the other domain.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "364", "View_ID": "1000", "Ordinal": null}]}, {"ID": "369", "Name": "Divide By Zero", "Description": "Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Extended_Description": "This weakness typically occurs when an unexpected value is provided to the product, or if an error occurs that is not properly detected. It frequently occurs in calculations involving physical dimensions such as size, length, width, and height.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: A Divide by Zero results in a crash.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.) Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "", "Demonstrative_Examples": "The following Java example contains a function to compute an average but does not validate that the input value used as the denominator is not zero. This will create an exception for attempting to divide by zero. If this error is not handled by Java exception handling, unexpected results can occur.. By validating the input value used as the denominator the following code will ensure that a divide by zero error will not cause unexpected results. The following Java code example will validate the input value, output an error message, and throw an exception.The following C/C++ example contains a function that divides two numeric values without verifying that the input value used as the denominator is not zero. This will create an error for attempting to divide by zero, if this error is not caught by the error handling capabilities of the language, unexpected results can occur.. By validating the input value used as the denominator the following code will ensure that a divide by zero error will not cause unexpected results. If the method is called and a zero is passed as the second argument a DivideByZero error will be thrown and should be caught by the calling block with an output message indicating the error.The following C# example contains a function that divides two numeric values without verifying that the input value used as the denominator is not zero. This will create an error for attempting to divide by zero, if this error is not caught by the error handling capabilities of the language, unexpected results can occur.. The method can be modified to raise, catch and handle the DivideByZeroException if the input value used as the denominator is zero.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "37", "Name": "Path Traversal: '/absolute/pathname/here'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "36", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "160", "View_ID": "1000", "Ordinal": null}]}, {"ID": "370", "Name": "Missing Check for Certificate Revocation after Initial Check", "Description": "Ensure that certificates are checked for revoked status before each use of a protected resource. If the certificate is checked before each access of a protected resource, the delay subject to a possible race condition becomes almost negligible and significantly reduces the risk associated with this issue.", "Extended_Description": "If the revocation status of a certificate is not checked before each action that requires privileges, the system may be subject to a race condition. If a certificate is revoked after the initial check, all subsequent actions taken with the owner of the revoked certificate will lose all benefits guaranteed by the certificate. In fact, it is almost certain that the use of a revoked certificate indicates malicious activity.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Trust may be assigned to an entity who is not who it claims to be.Scopes: Integrity. Impacts: Modify Application Data. Note: Data from an untrusted (and possibly malicious) source may be integrated.Scopes: Confidentiality. Impacts: Read Application Data. Note: Data may be disclosed to an entity impersonating a trusted entity, resulting in information disclosure.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Ensure that certificates are checked for revoked status before each use of a protected resource. If the certificate is checked before each access of a protected resource, the delay subject to a possible race condition becomes almost negligible and significantly reduces the risk associated with this issue.", "Demonstrative_Examples": "The following code checks a certificate before performing an action.. While the code performs the certificate verification before each action, it does not check the result of the verification after the initial attempt. The certificate may have been revoked in the time between the privileged actions.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "299", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "296", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "297", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "298", "View_ID": "1000", "Ordinal": null}]}, {"ID": "372", "Name": "Incomplete Internal State Distinction", "Description": "The product does not properly determine which state it is in, causing it to assume it is in state X when in fact it is in state Y, causing it to perform incorrect operations in a security-relevant manner.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "374", "Name": "Passing Mutable Objects to an Untrusted Method", "Description": "Clone all mutable data before passing it into an external function . This is the preferred mitigation. This way, regardless of what changes are made to the data, a valid copy is retained for use by the class.", "Extended_Description": "The function or method that has been called can alter or delete the mutable data. This could violate assumptions that the calling function has made about its state. In situations where unknown code is called with references to mutable data, this external code could make changes to the data sent. If this data was not previously cloned, the modified data might not be valid in the context of execution.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Memory. Note: Potentially data could be tampered with by another function which should not have been tampered with.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Pass in data which should not be altered as constant or immutable.Implementation : Clone all mutable data before passing it into an external function . This is the preferred mitigation. This way, regardless of what changes are made to the data, a valid copy is retained for use by the class.", "Demonstrative_Examples": "The following example demonstrates the weakness.. In this example, bar and baz will be passed by reference to doOtherStuff() which may change them.In the following Java example, the BookStore class manages the sale of books in a bookstore, this class includes the member objects for the bookstore inventory and sales database manager classes. The BookStore class includes a method for updating the sales database and inventory when a book is sold. This method retrieves a Book object from the bookstore inventory object using the supplied ISBN number for the book class, then calls a method for the sales object to update the sales information and then calls a method for the inventory object to update inventory for the BookStore.. However, in this example the Book object that is retrieved and passed to the method of the sales object could have its contents modified by the method. This could cause unexpected results when the book object is sent to the method for the inventory object to update the inventory.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "375", "Name": "Returning a Mutable Object to an Untrusted Caller", "Description": "Clone all mutable data before returning references to it. This is the preferred mitigation. This way, regardless of what changes are made to the data, a valid copy is retained for use by the class.", "Extended_Description": "In situations where functions return references to mutable data, it is possible that the external code which called the function may make changes to the data sent. If this data was not previously cloned, the class will then be using modified data which may violate assumptions about its internal state.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access ControlIntegrity. Impacts: Modify Memory. Note: Potentially data could be tampered with by another function which should not have been tampered with.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Declare returned data which should not be altered as constant or immutable.Implementation : Clone all mutable data before returning references to it. This is the preferred mitigation. This way, regardless of what changes are made to the data, a valid copy is retained for use by the class.", "Demonstrative_Examples": "This class has a private list of patients, but provides a way to see the list :. While this code only means to allow reading of the patient list, the getPatients() method returns a reference to the class's original patient list instead of a reference to a copy of the list. Any caller of this method can arbitrarily modify the contents of the patient list even though it is a private member of the class.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "377", "Name": "Insecure Temporary File", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code uses a temporary file for storing intermediate data gathered from the network before it is processed.. This otherwise unremarkable code is vulnerable to a number of different attacks because it relies on an insecure method for creating temporary files. The vulnerabilities introduced by this function and others are described in the following sections. The most egregious security problems related to temporary file creation have occurred on Unix-based operating systems, but Windows applications have parallel risks. This section includes a discussion of temporary file creation on both Unix and Windows systems. Methods and behaviors can vary between systems, but the fundamental risks introduced by each are reasonably constant.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "378", "Name": "Creation of Temporary File With Insecure Permissions", "Description": "Randomize temporary file names. This can also be achieved by using a safe temp-file function. This will ensure that temporary files will not be created in predictable places.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: If the temporary file can be read by the attacker, sensitive information may be in that file which could be revealed.Scopes: AuthorizationOther. Impacts: Other. Note: If that file can be written to by the attacker, the file might be moved into a place to which the attacker does not have access. This will allow the attacker to gain selective resource access-control privileges.Scopes: IntegrityOther. Impacts: Other. Note: Depending on the data stored in the temporary file, there is the potential for an attacker to gain an additional input vector which is trusted as non-malicious. It may be possible to make arbitrary changes to data structures, user information, or even process ownership.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Many contemporary languages have functions which properly handle this condition. Older C temp file functions are especially susceptible.Implementation : Ensure that you use proper file permissions. This can be achieved by using a safe temp file function. Temporary files should be writable and readable only by the process that owns the file.Implementation : Randomize temporary file names. This can also be achieved by using a safe temp-file function. This will ensure that temporary files will not be created in predictable places.", "Demonstrative_Examples": "In the following code examples a temporary file is created and written to.  After using the temporary file, the file is closed and deleted from the file system.. However, within this C/C++ code the method tmpfile() is used to create and open the temp file. The tmpfile() method works the same way as the fopen() method would with read/write permission, allowing attackers to read potentially sensitive information contained in the temp file or modify the contents of the file.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "377", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "379", "Name": "Creation of Temporary File in Directory with Insecure Permissions", "Description": "Avoid using vulnerable temp file functions.", "Extended_Description": "On some operating systems, the fact that the temporary file exists may be apparent to any user with sufficient privileges to access that directory. Since the file is visible, the application that is using the temporary file could be known. If one has access to list the processes on the system, the attacker has gained information about what the user is doing at that time. By correlating this with the applications the user is running, an attacker could potentially discover what a user's actions are. From this, higher levels of security could be breached.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Since the file is visible and the application which is using the temp file could be known, the attacker has gained information about what the user is doing at that time.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : Many contemporary languages have functions which properly handle this condition. Older C temp file functions are especially susceptible.Implementation : Try to store sensitive tempfiles in a directory which is not world readable -- i.e., per-user directories.Implementation : Avoid using vulnerable temp file functions.", "Demonstrative_Examples": "In the following code examples a temporary file is created and written to.  After using the temporary file, the file is closed and deleted from the file system.. However, within this C/C++ code the method tmpfile() is used to create and open the temp file. The tmpfile() method works the same way as the fopen() method would with read/write permission, allowing attackers to read potentially sensitive information contained in the temp file or modify the contents of the file.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "377", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "38", "Name": "Path Traversal: '\\absolute\\pathname\\here'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "36", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "382", "Name": "J2EE Bad Practices: Use of System.exit()", "Description": "Non-web applications may have a main() method that contains a System.exit(), but generally should not call System.exit() from other locations in the code", "Extended_Description": "It is never a good idea for a web application to attempt to shut down the application container. Access to a function that can shut down the application is an avenue for Denial of Service (DoS) attacks.", "Modes_Of_Introduction": "Implementation: A call to System.exit() is probably part of leftover debug code or code imported from a non-J2EE application.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : The shutdown function should be a privileged function available only to a properly authorized administrative userImplementation : Web applications should not call methods that cause the virtual machine to exit, such as System.exit()Implementation : Web applications should also not throw any Throwables to the application server as this may adversely affect the container.Implementation : Non-web applications may have a main() method that contains a System.exit(), but generally should not call System.exit() from other locations in the code", "Demonstrative_Examples": ". Included in the doPost() method defined below is a call to System.exit() in the event of a specific exception.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "705", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "383", "Name": "J2EE Bad Practices: Direct Use of Threads", "Description": "For EJB, use framework approaches for parallel execution, instead of using threads.", "Extended_Description": "Thread management in a web application is forbidden by the J2EE standard in some circumstances and is always highly error prone. Managing threads is difficult and is likely to interfere in unpredictable ways with the behavior of the application container. Even without interfering with the container, thread management usually leads to bugs that are hard to detect and diagnose like deadlock, race conditions, and other synchronization errors.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : For EJB, use framework approaches for parallel execution, instead of using threads.", "Demonstrative_Examples": ". In the following example, a new Thread object is created and invoked directly from within the body of a doGet() method in a Java servlet.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "695", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "384", "Name": "Session Fixation", "Description": "For platforms such as ASP that do not generate new values for sessionid cookies, utilize a secondary cookie. In this approach, set a secondary cookie on the user's browser to a random value and set a session variable to the same value. If the session variable and the cookie value ever don't match, invalidate the session, and force the user to log on again.", "Extended_Description": "Such a scenario is commonly observed when:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Invalidate any existing session identifiers prior to authorizing a new user session.Architecture and Design : For platforms such as ASP that do not generate new values for sessionid cookies, utilize a secondary cookie. In this approach, set a secondary cookie on the user's browser to a random value and set a session variable to the same value. If the session variable and the cookie value ever don't match, invalidate the session, and force the user to log on again.", "Demonstrative_Examples": "The following example shows a snippet of code from a J2EE web application where the application authenticates users with LoginContext.login() without first calling HttpSession.invalidate().. In order to exploit the code above, an attacker could first create a session (perhaps by logging into the application) from a public terminal, record the session identifier assigned by the application, and reset the browser to the login page. Next, a victim sits down at the same public terminal, notices the browser open to the login page of the site, and enters credentials to authenticate against the application. The code responsible for authenticating the victim continues to use the pre-existing session identifier, now the attacker simply uses the session identifier recorded earlier to access the victim's active session, providing nearly unrestricted access to the victim's account for the lifetime of the session. Even given a vulnerable application, the success of the specific attack described here is dependent on several factors working in the favor of the attacker: access to an unmonitored public terminal, the ability to keep the compromised session active and a victim interested in logging into the vulnerable application on the public terminal.. The following example shows a snippet of code from a J2EE web application where the application authenticates users with a direct post to the <code>j_security_check</code>, which typically does not invalidate the existing session before processing the login request.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "Requires", "CWE_ID": "346", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "472", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "441", "View_ID": "1000", "Ordinal": null}]}, {"ID": "514", "Name": "Covert Channel", "Description": "According to SOAR, the following detection techniques may be useful:", "Extended_Description": "Typically the system has not given authorization for the transmission and has no knowledge of its occurrence.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1229", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "385", "Name": "Covert Timing Channel", "Description": "It is reasonable to add artificial or random delays so that the amount of CPU time consumed is independent of the action being taken by the application.", "Extended_Description": "In some instances, knowing when data is transmitted between parties can provide a malicious user with privileged information. Also, externally monitoring the timing of operations can potentially reveal sensitive data. For example, a cryptographic operation can expose its internal state if the time it takes to perform the operation varies, based on the state.Covert channels are frequently classified as either storage or timing channels. Some examples of covert timing channels are the system's paging rate, the time a certain transaction requires to execute, and the time it takes to gain access to a shared bus.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityOther. Impacts: Read Application DataOther. Note: Information exposure.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Whenever possible, specify implementation strategies that do not introduce time variances in operations.Implementation : Often one can artificially manipulate the time which operations take or -- when operations occur -- can remove information from the attacker.Implementation : It is reasonable to add artificial or random delays so that the amount of CPU time consumed is independent of the action being taken by the application.", "Demonstrative_Examples": "In this example, the attacker observes how long an authentication takes when the user types in the correct password.. When the attacker tries their own values, they can first try strings of various length. When they find a string of the right length, the computation will take a bit longer, because the for loop will run at least once. Additionally, with this code, the attacker can possibly learn one character of the password at a time, because when they guess the first character right, the computation will take longer than a wrong guesses. Such an attack can break even the most sophisticated password with a few hundred guesses.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "514", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "386", "Name": "Symbolic Name not Mapping to Correct Object", "Description": "A constant symbolic reference to an object is used, even though the reference can resolve to a different object over time.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: The attacker can gain access to otherwise unauthorized resources.Scopes: IntegrityConfidentialityOther. Impacts: Modify Application DataModify Files or DirectoriesRead Application DataRead Files or DirectoriesOther. Note: Race conditions such as this kind may be employed to gain read or write access to resources not normally readable or writable by the user in question.Scopes: IntegrityOther. Impacts: Modify Application DataOther. Note: The resource in question, or other resources (through the corrupted one) may be changed in undesirable ways by a malicious user.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: If a file or other resource is written in this method, as opposed to a valid way, logging of the activity may not occur.Scopes: Non-RepudiationIntegrity. Impacts: Modify Files or Directories. Note: In some cases it may be possible to delete files that a malicious user might not otherwise have access to -- such as log files.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "367", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "610", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "486", "View_ID": "1000", "Ordinal": null}]}, {"ID": "39", "Name": "Path Traversal: 'C:dirname'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: The attacker may be able to create or overwrite critical files that are used to execute code, such as programs or libraries.Scopes: Integrity. Impacts: Modify Files or Directories. Note: The attacker may be able to overwrite or create critical files, such as programs, libraries, or important data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, appending a new account at the end of a password file may allow an attacker to bypass authentication.Scopes: Confidentiality. Impacts: Read Files or Directories. Note: The attacker may be able read the contents of unexpected files and expose sensitive data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, by reading a password file, the attacker could conduct brute force password guessing attacks in order to break into an account on the system.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: The attacker may be able to overwrite, delete, or corrupt unexpected critical files such as programs, libraries, or important data. This may prevent the software from working at all and in the case of a protection mechanisms such as authentication, it has the potential to lockout every user of the software.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "36", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "390", "Name": "Detection of Error Condition Without Action", "Description": "Subject the product to extensive testing to discover some of the possible instances of where/how errors or return values are not handled. Consider testing techniques such as ad hoc, equivalence partitioning, robustness and fault tolerance, mutation, and fuzzing.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Varies by ContextUnexpected StateAlter Execution Logic. Note: An attacker could utilize an ignored error condition to place the system in an unexpected state that could lead to the execution of unintended logic and could cause other unintended behavior.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Properly handle each exception. This is the recommended solution. Ensure that all exceptions are handled in such a way that you can be sure of the state of your system at any given moment.Implementation : If a function returns an error, it is important to either fix the problem and try again, alert the user that an error has happened and let the program continue, or alert the user and close and cleanup the program.Testing : Subject the product to extensive testing to discover some of the possible instances of where/how errors or return values are not handled. Consider testing techniques such as ad hoc, equivalence partitioning, robustness and fault tolerance, mutation, and fuzzing.", "Demonstrative_Examples": "The following example attempts to allocate memory for a character. After the call to malloc, an if statement is used to check whether the malloc function failed.. The conditional successfully detects a NULL return value from malloc indicating a failure, however it does not do anything to handle the problem. Unhandled errors may have unexpected results and may cause the program to crash or terminate.In the following C++ example the method readFile() will read the file whose name is provided in the input parameter and will return the contents of the file in char string. The method calls open() and read() may result in errors if the file does not exist or does not contain any data to read. These errors will be thrown when the is_open() method and good() method indicate errors opening or reading the file. However, these errors are not handled within the catch statement. Catch statements that do not perform any processing will have unexpected results. In this case an empty char string will be returned, and the file will not be properly closed.. The catch statement should contain statements that either attempt to fix the problem or notify the user that an error has occurred and continue processing or perform some cleanup and gracefully terminate the program. The following C++ example contains two catch statements. The first of these will catch a specific error thrown within the try block, and the second catch statement will catch all other errors from within the catch block. Both catch statements will notify the user that an error has occurred, close the file, and rethrow to the block that called the readFile() method for further handling or possible termination of the program.In the following Java example the method readFile will read the file whose name is provided in the input parameter and will return the contents of the file in a String object. The constructor of the FileReader object and the read method call may throw exceptions and therefore must be within a try/catch block. While the catch statement in this example will catch thrown exceptions in order for the method to compile, no processing is performed to handle the thrown exceptions. Catch statements that do not perform any processing will have unexpected results. In this case, this will result in the return of a null String.. The catch statement should contain statements that either attempt to fix the problem, notify the user that an exception has been raised and continue processing, or perform some cleanup and gracefully terminate the program. The following Java example contains three catch statements. The first of these will catch the FileNotFoundException that may be thrown by the FileReader constructor called within the try/catch block. The second catch statement will catch the IOException that may be thrown by the read method called within the try/catch block. The third catch statement will catch all other exceptions thrown within the try block. For all catch statements the user is notified that the exception has been thrown and the exception is rethrown to the block that called the readFile() method for further processing or possible termination of the program. Note that with Java it is usually good practice to use the getMessage() method of the exception class to provide more information to the user about the exception raised.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "401", "View_ID": "1000", "Ordinal": null}]}, {"ID": "391", "Name": "Unchecked Error Condition", "Description": "Catch all relevant exceptions. This is the recommended solution. Ensure that all exceptions are handled in such a way that you can be sure of the state of your system at any given moment.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : The choice between a language which has named or unnamed exceptions needs to be done. While unnamed exceptions exacerbate the chance of not properly dealing with an exception, named exceptions suffer from the up call version of the weak base class problem.Requirements : A language can be used which requires, at compile time, to catch all serious exceptions. However, one must make sure to use the most current version of the API as new exceptions could be added.Implementation : Catch all relevant exceptions. This is the recommended solution. Ensure that all exceptions are handled in such a way that you can be sure of the state of your system at any given moment.", "Demonstrative_Examples": "The following code excerpt ignores a rarely-thrown exception from doExchange().. If a RareException were to ever be thrown, the program would continue to execute as though nothing unusual had occurred. The program records no evidence indicating the special situation, potentially frustrating any later attempt to explain the program's behavior.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "392", "Name": "Missing Report of Error Condition", "Description": "The product encounters an error but does not provide a status code or return value to indicate that an error has occurred.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Varies by ContextUnexpected State. Note: Errors that are not properly reported could place the system in an unexpected state that could lead to unintended behaviors.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". In the following snippet from a doPost() servlet method, the server returns \"200 OK\" (default) even if an error occurs.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "684", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "393", "Name": "Return of Wrong Status Code", "Description": "Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Extended_Description": "This can lead to unpredictable behavior. If the function is used to make security-critical decisions or provide security-critical information, then the wrong status code can cause the product to assume that an action is safe, even when it is not.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Unexpected StateAlter Execution Logic. Note: This weakness could place the system in a state that could lead unexpected logic to be executed or other unintended behaviors.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "", "Demonstrative_Examples": ". In the following example, an HTTP 404 status code is returned in the event of an IOException encountered in a Java servlet. A 404 code is typically meant to indicate a non-existent resource and would be somewhat misleading in this case.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "684", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": null}]}, {"ID": "394", "Name": "Unexpected Status Code or Return Value", "Description": "The product does not properly check when a function or operation returns a value that is legitimate for the function, but is not expected by the product.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "395", "Name": "Use of NullPointerException Catch to Detect NULL Pointer Dereference", "Description": "Do not extensively rely on catching exceptions (especially for validating user input) to handle errors. Handling exceptions can decrease the performance of an application.", "Extended_Description": "Programmers typically catch NullPointerException under three circumstances:Of these three circumstances, only the last is acceptable.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Do not extensively rely on catching exceptions (especially for validating user input) to handle errors. Handling exceptions can decrease the performance of an application.", "Demonstrative_Examples": ". The following code mistakenly catches a NullPointerException.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "705", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": null}]}, {"ID": "396", "Name": "Declaration of Catch for Generic Exception", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "Multiple catch blocks can get ugly and repetitive, but \"condensing\" catch blocks by catching a high-level class like Exception can obscure exceptions that deserve special treatment or that should not be caught at this point in the program. Catching an overly broad exception essentially defeats the purpose of a language's typed exceptions, and can become particularly dangerous if the program grows and begins to throw new types of exceptions. The new exception types will not receive any attention.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code excerpt handles three types of exceptions in an identical fashion.. At first blush, it may seem preferable to deal with these exceptions in a single catch block, as follows:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "705", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "221", "View_ID": "1000", "Ordinal": null}]}, {"ID": "397", "Name": "Declaration of Throws for Generic Exception", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "Declaring a method to throw Exception or Throwable makes it difficult for callers to perform proper error handling and error recovery. Java's exception mechanism, for example, is set up to make it easy for callers to anticipate what can go wrong and write code to handle each specific exceptional circumstance. Declaring that a method throws a generic form of exception defeats this system.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The following method throws three types of exceptions.. While it might seem tidier to writeEarly versions of C++ (C++98, C++03, C++11) included a feature known as Dynamic Exception Specification. This allowed functions to declare what type of exceptions it may throw. It is possible to declare a general class of exception to cover any derived exceptions that may be throw.. In the example above, the code declares that myfunction() can throw an exception of type \"std::exception\" thus hiding details about the possible derived exceptions that could potentially be thrown.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "705", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "221", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "703", "View_ID": "1000", "Ordinal": null}]}, {"ID": "40", "Name": "Path Traversal: '\\\\UNC\\share\\name\\' (Windows UNC Share)", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "36", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "401", "Name": "Missing Release of Memory after Effective Lifetime", "Description": "The Boehm-Demers-Weiser Garbage Collector or valgrind can be used to detect leaks in code.", "Extended_Description": "This is often triggered by improper handling of malformed data or unexpectedly interrupted sessions.  In some languages, developers are responsible for tracking memory allocation and releasing the memory.  If there are no more pointers or references to the memory, then it can no longer be tracked and identified for release.", "Modes_Of_Introduction": "Implementation: Memory leaks have two common and sometimes overlapping causes:", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartDoS: InstabilityDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: Most memory leaks result in general product reliability problems, but if an attacker can intentionally trigger a memory leak, the attacker might be able to launch a denial of service attack (by crashing or hanging the program) or take advantage of other unexpected program behavior resulting from a low memory condition.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Choose a language or tool that provides automatic memory management, or makes manual memory management less error-prone.\n                  For example, glibc in Linux provides protection against free of invalid pointers.\n                  When using Xcode to target OS X or iOS, enable automatic reference counting (ARC) [REF-391].\n                  To help correctly and consistently manage memory when programming in C++, consider using a smart pointer class such as std::auto_ptr (defined by ISO/IEC ISO/IEC 14882:2003), std::shared_ptr and std::unique_ptr (specified by an upcoming revision of the C++ standard, informally referred to as C++ 1x), or equivalent solutions such as Boost.Architecture and Design : Use an abstraction library to abstract away risky APIs. Not a complete solution.Architecture and Design : The Boehm-Demers-Weiser Garbage Collector or valgrind can be used to detect leaks in code.", "Demonstrative_Examples": ". The following C function leaks a block of allocated memory if the call to read() does not return the expected number of bytes:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "772", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1305", "Ordinal": "Primary"}]}, {"ID": "402", "Name": "Transmission of Private Resources into a New Sphere ('Resource Leak')", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "403", "Name": "Exposure of File Descriptor to Unintended Control Sphere ('File Descriptor Leak')", "Description": "A process does not close sensitive file descriptors before invoking a child process, which allows the child to perform unauthorized I/O operations using those descriptors.", "Extended_Description": "When a new process is forked or executed, the child process inherits any open file descriptors. When the child process has fewer privileges than the parent process, this might introduce a vulnerability if the child process can access the file descriptor but does not have the privileges to access the associated file.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "402", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "406", "Name": "Insufficient Control of Network Message Volume (Network Amplification)", "Description": "An application must, at all times, keep track of network resources and meter their usage appropriately.", "Extended_Description": "In the absence of a policy to restrict asymmetric resource consumption, the application or system cannot distinguish between legitimate transmissions and traffic intended to serve as an amplifying attack on target systems. Systems can often be configured to restrict the amount of traffic sent out on behalf of a client, based on the client's origin or access level. This is usually defined in a resource allocation policy. In the absence of a mechanism to keep track of transmissions, the system or application can be easily abused to transmit asymmetrically greater traffic than the request or client should be permitted to.", "Modes_Of_Introduction": "Architecture and Design: If the application uses UDP, then it could potentially be subject to spoofing attacks that use the inherent weaknesses of UDP to perform traffic amplification, although this problem can exist in other protocols or contexts.", "Common_Consequences": "Scopes: Availability. Impacts: DoS: AmplificationDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Resource Consumption (Other). Note: System resources can be quickly consumed leading to poor application performance or system crash. This may affect network performance and could be used to attack other systems and applications relying on network performance.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : An application must make network resources available to a client commensurate with the client's access level.Policy : Define a clear policy for network resource allocation and consumption.Implementation : An application must, at all times, keep track of network resources and meter their usage appropriately.", "Demonstrative_Examples": "This code listens on a port for DNS requests and sends the result to the requesting address.. This code sends a DNS record to a requesting IP address. UDP allows the source IP address to be easily changed ('spoofed'), thus allowing an attacker to redirect responses to a target, which may be then be overwhelmed by the network traffic.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "408", "Name": "Incorrect Behavior Order: Early Amplification", "Description": "The product allows an entity to perform a legitimate but expensive operation before authentication or authorization has taken place.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: AmplificationDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: System resources, CPU and memory, can be quickly consumed. This can lead to poor system performance or system crash.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This data prints the contents of a specified file requested by a user.. This code first reads a specified file into memory, then prints the file if the user is authorized to see its contents. The read of the file into memory may be resource intensive and is unnecessary if the user is not allowed to see the file anyway.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "696", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "409", "Name": "Improper Handling of Highly Compressed Data (Data Amplification)", "Description": "The product does not handle or incorrectly handles a compressed input with a very high compression ratio that produces a large output.", "Extended_Description": "An example of data amplification is a \"decompression bomb,\" a small ZIP file that can produce a large amount of data when it is decompressed.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: AmplificationDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: System resources, CPU and memory, can be quickly consumed. This can lead to poor system performance or system crash.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". The DTD and the very brief XML below illustrate what is meant by an XML bomb. The ZERO entity contains one character, the letter A. The choice of entity name ZERO is being used to indicate length equivalent to that exponent on two, that is, the length of ZERO is 2^0. Similarly, ONE refers to ZERO twice, therefore the XML parser will expand ONE to a length of 2, or 2^1. Ultimately, we reach entity THIRTYTWO, which will expand to 2^32 characters in length, or 4 GB, probably consuming far more data than expected.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "41", "Name": "Improper Resolution of Path Equivalence", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "Path equivalence is usually employed in order to circumvent access controls expressed using an incomplete set of file name or file path representations. This is different from path traversal, wherein the manipulations are performed to generate a name for a different object.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAccess Control. Impacts: Read Files or DirectoriesModify Files or DirectoriesBypass Protection Mechanism. Note: An attacker may be able to traverse the file system to unintended locations and read or overwrite the contents of unexpected files. If the files are used for a security mechanism than an attacker may be able to bypass the mechanism.", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "410", "Name": "Insufficient Resource Pool", "Description": "Identify the system's resource intensive operations and consider protecting them from abuse (e.g. malicious automated script which runs the resources out).", "Extended_Description": "Frequently the consequence is a \"flood\" of connection or sessions.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityIntegrityOther. Impacts: DoS: Crash, Exit, or RestartOther. Note: Floods often cause a crash or other problem besides denial of the resource itself; these are likely examples of *other* vulnerabilities, not an insufficient resource pool.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not perform resource-intensive transactions for unauthenticated users and/or invalid requests.Architecture and Design : Consider implementing a velocity check mechanism which would detect abusive behavior.Operation : Consider load balancing as an option to handle heavy loads.Implementation : Make sure that resource handles are properly closed when no longer needed.Architecture and Design : Identify the system's resource intensive operations and consider protecting them from abuse (e.g. malicious automated script which runs the resources out).", "Demonstrative_Examples": ". In the following snippet from a Tomcat configuration file, a JDBC connection pool is defined with a maximum of 5 simultaneous connections (with a 60 second timeout). In this case, it may be trivial for an attacker to instigate a denial of service (DoS) by using up all of the available connections in the pool.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "400", "View_ID": "1000", "Ordinal": null}]}, {"ID": "412", "Name": "Unrestricted Externally Accessible Lock", "Description": "Consider modifying your code to use non-blocking synchronization methods.", "Extended_Description": "This prevents the product from acting on associated resources or performing other behaviors that are controlled by the presence of the lock. Relevant locks might include an exclusive lock or mutex, or modifying a shared resource that is treated as a lock. If the lock can be held for an indefinite period of time, then the denial of service could be permanent.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: When an attacker can control a lock, the program may wait indefinitely until the attacker releases the lock, causing a denial of service to other users of the program. This is especially problematic if there is a blocking operation on the lock.", "Detection_Methods": "Method Name: White Box. Description: Automated code analysis techniques might not be able to reliably detect this weakness, since the application's behavior and general security model dictate which resource locks are critical. Interpretation of the weakness might require knowledge of the environment, e.g. if the existence of a file is used as a lock, but the file is created in a world-writable directory.", "Potential_Mitigations": "Architecture and Design : Use any access control that is offered by the functionality that is offering the lock.Architecture and Design : Use unpredictable names or identifiers for the locks. This might not always be possible or feasible.Architecture and Design : Consider modifying your code to use non-blocking synchronization methods.", "Demonstrative_Examples": "This code tries to obtain a lock for a file, then writes to it.. PHP by default will wait indefinitely until a file lock is released. If an attacker is able to obtain the file lock, this code will pause execution, possibly leading to denial of service for other users. Note that in this case, if an attacker can perform an flock() on the file, they may already have privileges to destroy the log file. However, this still impacts the execution of other programs that depend on flock().", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "410", "View_ID": "1000", "Ordinal": null}]}, {"ID": "413", "Name": "Improper Resource Locking", "Description": "Use synchronization when locking a resource.", "Extended_Description": "When a resource is not properly locked, an attacker could modify the resource while it is being operated on by the product. This might violate the product's assumption that the resource will not change, potentially leading to unexpected behaviors.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use a non-conflicting privilege scheme.Architecture and Design : Use synchronization when locking a resource.", "Demonstrative_Examples": "The following function attempts to acquire a lock in order to perform operations on a shared resource.. However, the code does not check the value returned by pthread_mutex_lock() for errors. If pthread_mutex_lock() cannot acquire the mutex for any reason, the function may introduce a race condition into the program and result in undefined behavior.This Java example shows a simple BankAccount class with deposit and withdraw methods.. However, the deposit and withdraw methods have shared access to the account balance private class variable. This can result in a race condition if multiple threads attempt to call the deposit and withdraw methods simultaneously where the account balance is modified by one thread before another thread has completed modifying the account balance. For example, if a thread attempts to withdraw funds using the withdraw method before another thread that is depositing funds using the deposit method completes the deposit then there may not be sufficient funds for the withdraw transaction.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "414", "Name": "Missing Lock Check", "Description": "Implement a reliable lock mechanism.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Implement a reliable lock mechanism.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "825", "Name": "Expired Pointer Dereference", "Description": "When freeing pointers, be sure to set them to NULL once they are freed. However, the utilization of multiple or complex data structures may lower the usefulness of this strategy.", "Extended_Description": "When a product releases memory, but it maintains a pointer to that memory, then the memory might be re-allocated at a later time. If the original pointer is accessed to read or write data, then this could cause the product to read or modify data that is in use by a different function or process. Depending on how the newly-allocated memory is used, this could lead to a denial of service, information exposure, or code execution.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Memory. Note: If the expired pointer is used in a read operation, an attacker might be able to control data read in by the application.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: If the expired pointer references a memory location that is not accessible to the product, or points to a location that is \"malformed\" (such as NULL) or larger than expected by a read or write operation, then a crash may occur.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: If the expired pointer is used in a function call, or points to unexpected data in a write operation, then code execution may be possible.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Choose a language that provides automatic memory management.Implementation : When freeing pointers, be sure to set them to NULL once they are freed. However, the utilization of multiple or complex data structures may lower the usefulness of this strategy.", "Demonstrative_Examples": "The following code shows a simple example of a use after free error:. When an error occurs, the pointer is immediately freed. However, this pointer is later incorrectly used in the logError function.The following code shows a simple example of a double free error:. Double free vulnerabilities have two common (and sometimes overlapping) causes:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "125", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "787", "View_ID": "1000", "Ordinal": null}]}, {"ID": "415", "Name": "Double Free", "Description": "Use a static analysis tool to find double free instances.", "Extended_Description": "When a program calls free() twice with the same argument, the program's memory management data structures become corrupted. This corruption can cause the program to crash or, in some circumstances, cause two later calls to malloc() to return the same pointer. If malloc() returns the same value twice and the program later gives the attacker control over the data that is written into this doubly-allocated memory, the program becomes vulnerable to a buffer overflow attack.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Modify MemoryExecute Unauthorized Code or Commands. Note: Doubly freeing memory may result in a write-what-where condition, allowing an attacker to execute arbitrary code.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Choose a language that provides automatic memory management.Implementation : Ensure that each allocation is freed only once. After freeing a chunk, set the pointer to NULL to ensure the pointer cannot be freed again. In complicated error conditions, be sure that clean-up routines respect the state of allocation properly. If the language is object oriented, ensure that object destructors delete each chunk of memory only once.Implementation : Use a static analysis tool to find double free instances.", "Demonstrative_Examples": "The following code shows a simple example of a double free vulnerability.. Double free vulnerabilities have two common (and sometimes overlapping) causes:. While contrived, this code should be exploitable on Linux distributions that do not ship with heap-chunk check summing turned on.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "825", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1341", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "666", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "416", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "123", "View_ID": "1000", "Ordinal": null}]}, {"ID": "666", "Name": "Operation on Resource in Wrong Phase of Lifetime", "Description": "Follow the resource's lifecycle from creation to release.", "Extended_Description": "A resource's lifecycle includes several phases: initialization, use, and release. For each phase, it is important to follow the specifications outlined for how to operate on the resource and to ensure that the resource is in the expected phase. Otherwise, if a resource is in one phase but the operation is not valid for that phase (i.e., an incorrect phase of the resource's lifetime), then this can produce resultant weaknesses. For example, using a resource before it has been fully initialized could cause corruption or incorrect data to be used.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Follow the resource's lifecycle from creation to release.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "416", "Name": "Use After Free", "Description": "When freeing pointers, be sure to set them to NULL once they are freed. However, the utilization of multiple or complex data structures may lower the usefulness of this strategy.", "Extended_Description": "The use of previously-freed memory can have any number of adverse consequences, ranging from the corruption of valid data to the execution of arbitrary code, depending on the instantiation and timing of the flaw. The simplest way data corruption may occur involves the system's reuse of the freed memory. Use-after-free errors have two common and sometimes overlapping causes:In this scenario, the memory in question is allocated to another pointer validly at some point after it has been freed. The original pointer to the freed memory is used again and points to somewhere within the new allocation. As the data is changed, it corrupts the validly used memory; this induces undefined behavior in the process.If the newly allocated data happens to hold a class, in C++ for example, various function pointers may be scattered within the heap data. If one of these function pointers is overwritten with an address to valid shellcode, execution of arbitrary code can be achieved.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Memory. Note: The use of previously freed memory may corrupt valid data, if the memory area in question has been allocated and used properly elsewhere.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: If chunk consolidation occurs after the use of previously freed data, the process may crash when invalid data is used as chunk information.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: If malicious data is entered before chunk consolidation can take place, it may be possible to take advantage of a write-what-where primitive to execute arbitrary code.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Choose a language that provides automatic memory management.Implementation : When freeing pointers, be sure to set them to NULL once they are freed. However, the utilization of multiple or complex data structures may lower the usefulness of this strategy.", "Demonstrative_Examples": ". The following example demonstrates the weakness.The following code illustrates a use after free error:. When an error occurs, the pointer is immediately freed. However, this pointer is later incorrectly used in the logError function.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "825", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "120", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "123", "View_ID": "1000", "Ordinal": null}]}, {"ID": "419", "Name": "Unprotected Primary Channel", "Description": "Protect the administrative/restricted functionality with a strong authentication mechanism.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not expose administrative functionnality on the user UI.Architecture and Design : Protect the administrative/restricted functionality with a strong authentication mechanism.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "42", "Name": "Path Equivalence: 'filename.' (Trailing Dot)", "Description": "The product accepts path input in the form of trailing dot ('filedir.') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "162", "View_ID": "1000", "Ordinal": null}]}, {"ID": "421", "Name": "Race Condition During Access to Alternate Channel", "Description": "The product opens an alternate channel to communicate with an authorized user, but the channel is accessible to other actors.", "Extended_Description": "This creates a race condition that allows an attacker to access the channel before the authorized user does.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "420", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1000", "Ordinal": null}]}, {"ID": "422", "Name": "Unprotected Windows Messaging Channel ('Shatter')", "Description": "Always verify and authenticate the source of the message.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Always verify and authenticate the source of the message.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "420", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "360", "View_ID": "1000", "Ordinal": null}]}, {"ID": "424", "Name": "Improper Protection of Alternate Path", "Description": "Deploy different layers of protection to implement security in depth.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Deploy different layers of protection to implement security in depth.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "638", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "638", "Name": "Not Using Complete Mediation", "Description": "Identify all possible code paths that might access sensitive resources. If possible, create and use a single interface that performs the access checks, and develop code standards that require use of this interface.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityAccess ControlOther. Impacts: Gain Privileges or Assume IdentityExecute Unauthorized Code or CommandsBypass Protection MechanismRead Application DataOther. Note: A user might retain access to a critical resource even after privileges have been revoked, possibly allowing access to privileged functionality or sensitive information, depending on the role of the resource.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Invalidate cached privileges, file handles or descriptors, or other access credentials whenever identities, processes, policies, roles, capabilities or permissions change. Perform complete authentication checks before accepting, caching and reusing data, dynamic content and code (scripts). Avoid caching access control decisions as much as possible.Architecture and Design : Identify all possible code paths that might access sensitive resources. If possible, create and use a single interface that performs the access checks, and develop code standards that require use of this interface.", "Demonstrative_Examples": ". When executable library files are used on web servers, which is common in PHP applications, the developer might perform an access check in any user-facing executable, and omit the access check from the library file itself. By directly requesting the library file (CWE-425), an attacker can bypass this access check.. When a developer begins to implement input validation for a web application, often the validation is performed in each area of the code that uses externally-controlled input. In complex applications with many inputs, the developer often misses a parameter here or a cookie there. One frequently-applied solution is to centralize all input validation, store these validated inputs in a separate data structure, and require that all access of those inputs must be through that data structure. An alternate approach would be to use an external input validation framework such as Struts, which performs the validation before the inputs are ever processed by the code.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "862", "View_ID": "1000", "Ordinal": null}]}, {"ID": "425", "Name": "Direct Request ('Forced Browsing')", "Description": "Consider using MVC based frameworks such as Struts.", "Extended_Description": "Web applications susceptible to direct request attacks often make the false assumption that such resources can only be reached through a given navigation path and so only apply authorization at certain points in the path.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Apply appropriate access control authorizations for each access to all restricted URLs, scripts or files.Architecture and Design : Consider using MVC based frameworks such as Struts.", "Demonstrative_Examples": ". If forced browsing is possible, an attacker may be able to directly access a sensitive page by entering a URL similar to the following.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "862", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "862", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "288", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "424", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "471", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "98", "View_ID": "1000", "Ordinal": null}]}, {"ID": "426", "Name": "Untrusted Search Path", "Description": "Use other functions that require explicit paths. Making use of any of the other readily available functions that require explicit paths is a safe way to avoid this problem. For example, system() in C does not require a full path since the shell can take care of it, while execl() and execv() require a full path.", "Extended_Description": "This might allow attackers to execute their own programs, access unauthorized data files, or modify configuration in unexpected ways. If the product uses a search path to locate critical resources such as programs, then an attacker could modify that search path to point to a malicious program, which the targeted product would then execute. The problem extends to any type of critical resource that the product trusts.Some of the most common variants of untrusted search path are:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Gain Privileges or Assume IdentityExecute Unauthorized Code or Commands. Note: There is the potential for arbitrary code execution with privileges of the vulnerable program.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: The program could be redirected to the wrong files, potentially triggering a crash or hang when the targeted file is too large or does not have the expected format.Scopes: Confidentiality. Impacts: Read Files or Directories. Note: The program could send the output of unauthorized files to the attacker.", "Detection_Methods": "Method Name: Black Box. Description: Use monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.Attach the monitor to the process and look for library functions and system calls that suggest when a search path is being used. One pattern is when the program performs multiple accesses of the same file but in different directories, with repeated failures until the proper filename is found. Library calls such as getenv() or their equivalent can be checked to see if any path-related variables are being accessed. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.) Method Name: Manual Analysis. Description: Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Potential_Mitigations": "Architecture and Design : Hard-code the search path to a set of known-safe values (such as system directories), or only allow them to be specified by the administrator in a configuration file. Do not allow these settings to be modified by an external party. Be careful to avoid related weaknesses such as CWE-426 and CWE-428.Implementation : When invoking other programs, specify those programs using fully-qualified pathnames. While this is an effective approach, code that uses fully-qualified pathnames might not be portable to other systems that do not use the same pathnames. The portability can be improved by locating the full-qualified paths in a centralized, easily-modifiable location within the source code, and having the code refer to these paths.Implementation : Remove or restrict all environment settings before invoking other programs. This includes the PATH environment variable, LD_LIBRARY_PATH, and other settings that identify the location of code libraries, and any application-specific search paths.Implementation : Check your search path before use and remove any elements that are likely to be unsafe, such as the current working directory or a temporary files directory.Implementation : Use other functions that require explicit paths. Making use of any of the other readily available functions that require explicit paths is a safe way to avoid this problem. For example, system() in C does not require a full path since the shell can take care of it, while execl() and execv() require a full path.", "Demonstrative_Examples": "This program is intended to execute a command that lists the contents of a restricted directory, then performs other actions. Assume that it runs with setuid privileges in order to bypass the permissions check by the operating system.. This code may look harmless at first, since both the directory and the command are set to fixed values that the attacker can't control. The attacker can only see the contents for DIR, which is the intended program behavior. Finally, the programmer is also careful to limit the code that executes with raised privileges.This code prints all of the running processes belonging to the current user.. If invoked by an unauthorized web user, it is providing a web page of potentially sensitive information on the underlying system, such as command-line arguments (CWE-497). This program is also potentially vulnerable to a PATH based attack (CWE-426), as an attacker may be able to create malicious versions of the ps or grep commands. While the program does not explicitly raise privileges to run the system commands, the PHP interpreter may by default be running with higher privileges than users.The following code is from a web application that allows users access to an interface through which they can update their password on the system. In this environment, user passwords can be managed using the Network Information System (NIS), which is commonly used on UNIX systems. When performing NIS updates, part of the process for updating passwords is to run a make command in the /var/yp directory. Performing NIS updates requires extra privileges.. The problem here is that the program does not specify an absolute path for make and does not clean its environment prior to executing the call to Runtime.exec(). If an attacker can modify the $PATH variable to point to a malicious binary called make and cause the program to be executed in their environment, then the malicious binary will be loaded instead of the one intended. Because of the nature of the application, it runs with the privileges necessary to perform system operations, which means the attacker's make will now be run with these privileges, possibly giving the attacker complete control of the system.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "642", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "673", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "427", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "428", "View_ID": "1000", "Ordinal": null}]}, {"ID": "673", "Name": "External Influence of Sphere Definition", "Description": "The product does not prevent the definition of control spheres from external actors.", "Extended_Description": "Typically, a product defines its control sphere within the code itself, or through configuration by the product's administrator. In some cases, an external party can change the definition of the control sphere. This is typically a resultant weakness.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". Consider a blog publishing tool, which might have three explicit control spheres: the creation of articles, only accessible to a \"publisher;\" commenting on articles, only accessible to a \"commenter\" who is a registered user; and reading articles, only accessible to an anonymous reader. Suppose that the application is deployed on a web server that is shared with untrusted parties. If a local user can modify the data files that define who a publisher is, then this user has modified the control sphere. In this case, the issue would be resultant from another weakness such as insufficient permissions.. In Untrusted Search Path (CWE-426), a user might be able to define the PATH environment variable to cause the product to search in the wrong directory for a library to load. The product's intended sphere of control would include \"resources that are only modifiable by the person who installed the product.\" The PATH effectively changes the definition of this sphere so that it overlaps the attacker's sphere of control.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "427", "Name": "Uncontrolled Search Path Element", "Description": "Use other functions that require explicit paths. Making use of any of the other readily available functions that require explicit paths is a safe way to avoid this problem. For example, system() in C does not require a full path since the shell can take care of finding the program using the PATH environment variable, while execl() and execv() require a full path.", "Extended_Description": "Although this weakness can occur with any type of resource, it is frequently introduced when a product uses a directory search path to find executables or code libraries, but the path contains a directory that can be modified by an attacker, such as \"/tmp\" or the current working directory.In Windows-based systems, when the LoadLibrary or LoadLibraryEx function is called with a DLL name that does not contain a fully qualified path, the function follows a search order that includes two path elements that might be uncontrolled:In some cases, the attack can be conducted remotely, such as when SMB or WebDAV network shares are used.One or more locations in that path could include the Windows drive root or its subdirectories. This often exists in Linux-based code assuming the controlled nature of the root directory (/) or its subdirectories (/etc, etc), or a code that recursively accesses the parent directory.  In Windows, the drive root and some of its subdirectories have weak permissions by default, which makes them uncontrolled.In some Unix-based systems, a PATH might be created that contains an empty element, e.g. by splicing an empty variable into the PATH. This empty element can be interpreted as equivalent to the current working directory, which might be an untrusted search element.In software package management frameworks (e.g., npm, RubyGems, or PyPi), the framework may identify dependencies on third-party libraries or other packages, then consult a repository that contains the desired package. The framework may search a public repository before a private repository. This could be exploited by attackers by placing a malicious package in the public repository that has the same name as a package from the private repository. The search path might not be directly under control of the developer relying on the framework, but this search order effectively contains an untrusted element.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Hard-code the search path to a set of known-safe values (such as system directories), or only allow them to be specified by the administrator in a configuration file. Do not allow these settings to be modified by an external party. Be careful to avoid related weaknesses such as CWE-426 and CWE-428.Implementation : When invoking other programs, specify those programs using fully-qualified pathnames. While this is an effective approach, code that uses fully-qualified pathnames might not be portable to other systems that do not use the same pathnames. The portability can be improved by locating the full-qualified paths in a centralized, easily-modifiable location within the source code, and having the code refer to these paths.Implementation : Remove or restrict all environment settings before invoking other programs. This includes the PATH environment variable, LD_LIBRARY_PATH, and other settings that identify the location of code libraries, and any application-specific search paths.Implementation : Check your search path before use and remove any elements that are likely to be unsafe, such as the current working directory or a temporary files directory. Since this is a denylist approach, it might not be a complete solution.Implementation : Use other functions that require explicit paths. Making use of any of the other readily available functions that require explicit paths is a safe way to avoid this problem. For example, system() in C does not require a full path since the shell can take care of finding the program using the PATH environment variable, while execl() and execv() require a full path.", "Demonstrative_Examples": "The following code is from a web application that allows users access to an interface through which they can update their password on the system. In this environment, user passwords can be managed using the Network Information System (NIS), which is commonly used on UNIX systems. When performing NIS updates, part of the process for updating passwords is to run a make command in the /var/yp directory. Performing NIS updates requires extra privileges.. The problem here is that the program does not specify an absolute path for make and does not clean its environment prior to executing the call to Runtime.exec(). If an attacker can modify the $PATH variable to point to a malicious binary called make and cause the program to be executed in their environment, then the malicious binary will be loaded instead of the one intended. Because of the nature of the application, it runs with the privileges necessary to perform system operations, which means the attacker's make will now be run with these privileges, possibly giving the attacker complete control of the system.In versions of Go prior to v1.19, the LookPath function would follow the conventions of the runtime OS and look for a program in the directiories listed in the current path [REF-1325].. Therefore, Go would prioritize searching the current directory when the provided command name does not contain a directory separator and continued to search for programs even when the specified program name is empty.In February 2021 [REF-1169], a researcher was able to demonstrate the ability to breach major technology companies by using \"dependency confusion\" where the companies would download and execute untrusted packages.. The researcher discovered the names of some internal, private packages by looking at dependency lists in public source code, such as package.json. The researcher then created new, untrusted packages with the same name as the internal packages, then uploaded them to package hosting services. These services included the npm registry for Node, PyPi for Python, and RubyGems. In affected companies, their dependency resolution would search the public hosting services first before consulting their internal service, causing the untrusted packages to be automatically downloaded and executed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "428", "Name": "Unquoted Search Path or Element", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "If a malicious individual has access to the file system, it is possible to elevate privileges by inserting such a file as \"C:\\Program.exe\" to be run by a privileged program making use of WinExec.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Properly quote the full search path before executing a program on the system.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": ". The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "43", "Name": "Path Equivalence: 'filename....' (Multiple Trailing Dot)", "Description": "The product accepts path input in the form of multiple trailing dot ('filedir....') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "42", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "163", "View_ID": "1000", "Ordinal": null}]}, {"ID": "430", "Name": "Deployment of Wrong Handler", "Description": "Reject any inconsistent types, such as a file with a .GIF extension that appears to consist of PHP code.", "Extended_Description": "An example of deploying the wrong handler would be calling a servlet to reveal source code of a .JSP file, or automatically \"determining\" type of the object even if it is contradictory to an explicitly specified type.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Perform a type check before interpreting an object.Architecture and Design : Reject any inconsistent types, such as a file with a .GIF extension that appears to consist of PHP code.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "433", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "434", "View_ID": "1000", "Ordinal": null}]}, {"ID": "431", "Name": "Missing Handler", "Description": "If an operation can throw an Exception, implement a handler for that specific exception.", "Extended_Description": "When an exception is thrown and not caught, the process has given up an opportunity to decide if a given failure or event is worth a change in execution.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Handle all possible situations (e.g. error condition).Implementation : If an operation can throw an Exception, implement a handler for that specific exception.", "Demonstrative_Examples": "If a Servlet does not catch all exceptions, it may reveal debugging information that will help an adversary form a plan of attack. In the following method a DNS lookup failure will cause the Servlet to throw an exception.. When a Servlet throws an exception, the default error response the Servlet container sends back to the user typically includes debugging information. This information is of great value to an attacker.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "433", "View_ID": "1000", "Ordinal": null}]}, {"ID": "432", "Name": "Dangerous Signal Handler not Disabled During Sensitive Operations", "Description": "Turn off dangerous handlers when performing sensitive operations.", "Extended_Description": "During the execution of a signal handler, it can be interrupted by another handler when a different signal is sent. If the two handlers share state - such as global variables - then an attacker can corrupt the state by sending another signal before the first handler has completed execution.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Turn off dangerous handlers when performing sensitive operations.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "364", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "433", "Name": "Unparsed Raw Web Content Delivery", "Description": "Do not store sensitive information in files which may be misinterpreted.", "Extended_Description": "If code is stored in a file with an extension such as \".inc\" or \".pl\", and the web server does not have a handler for that extension, then the server will likely send the contents of the file directly to the requester without the pre-processing that was expected. When that file contains sensitive information such as database credentials, this may allow the attacker to compromise the application or associated components.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Perform a type check before interpreting files.Architecture and Design : Do not store sensitive information in files which may be misinterpreted.", "Demonstrative_Examples": "The following code uses an include file to store database credentials:. database.inc", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "219", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "434", "Name": "Unrestricted Upload of File with Dangerous Type", "Description": "Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: Arbitrary code execution is possible if an uploaded file is interpreted and executed as code by the recipient. This is especially true for .asp and .php extensions uploaded to web servers because these file types are often treated as automatically executable, even when file system permissions do not specify execution. For example, in Unix environments, programs typically cannot run unless the execute bit is set, but PHP programs may be executed by the web server without directly invoking them on the operating system.", "Detection_Methods": "Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Generate a new, unique filename for an uploaded file instead of using the user-supplied filename, so that no external input is used at all.[REF-422] [REF-423]Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.Architecture and Design : Consider storing the uploaded files outside of the web document root entirely. Then, use other mechanisms to deliver the files dynamically. [REF-423]Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  For example, limiting filenames to alphanumeric characters can help to restrict the introduction of unintended file extensions.Architecture and Design : Define a very limited set of allowable extensions and only generate filenames that end in these extensions. Consider the possibility of XSS (CWE-79) before allowing .html or .htm file types.Implementation : Ensure that only one extension is used in the filename. Some web servers, including some versions of Apache, may process files based on inner extensions so that \"filename.php.gif\" is fed to the PHP interpreter.[REF-422] [REF-423]Implementation : When running on a web server that supports case-insensitive filenames, perform case-insensitive evaluations of the extensions that are provided.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Implementation : Do not rely exclusively on sanity checks of file contents to ensure that the file is of the expected type and size. It may be possible for an attacker to hide code in some file segments that will still be executed by the server. For example, GIF images may contain a free-form comments field.Implementation : Do not rely exclusively on the MIME content type or filename attribute when determining how to render a file. Validating the MIME content type and ensuring that it matches the extension is only a partial solution.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Demonstrative_Examples": "The following code intends to allow a user to upload a picture to the web server. The HTML code that drives the form on the user end has an input field of type \"file\".. Once submitted, the form above sends the file to upload_picture.php on the web server. PHP stores the file in a temporary location until it is retrieved (or discarded) by the server side code. In this example, the file is moved to a more permanent pictures/ directory.The following code demonstrates the unrestricted upload of a file with a Java servlet and a path traversal vulnerability. The action attribute of an HTML form is sending the upload file request to the Java servlet.. When submitted the Java servlet's doPost method will receive the request, extract the name of the file from the Http request header, read the file contents from the request and output the file to the local upload directory.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "351", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "430", "View_ID": "1000", "Ordinal": null}]}, {"ID": "437", "Name": "Incomplete Model of Endpoint Features", "Description": "A product acts as an intermediary or monitor between two or more endpoints, but it does not have a complete model of an endpoint's features, behaviors, or state, potentially causing the product to perform incorrect actions based on this incomplete model.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". HTTP request smuggling is an attack against an intermediary such as a proxy. This attack works because the proxy expects the client to parse HTTP headers one way, but the client parses them differently.. Anti-virus products that reside on mail servers can suffer from this issue if they do not know how a mail client will handle a particular attachment. The product might treat an attachment type as safe, not knowing that the client's configuration treats it as executable.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "439", "Name": "Behavioral Change in New Version or Environment", "Description": "A's behavior or functionality changes with a new version of A, or a new environment, which is not known (or manageable) by B.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "435", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "44", "Name": "Path Equivalence: 'file.name' (Internal Dot)", "Description": "The product accepts path input in the form of internal dot ('file.ordir') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "440", "Name": "Expected Behavior Violation", "Description": "A feature, API, or function does not perform according to its specification.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "684", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "444", "Name": "Inconsistent Interpretation of HTTP Requests ('HTTP Request/Response Smuggling')", "Description": "Turn all pages to non-cacheable.", "Extended_Description": "HTTP requests or responses (\"messages\") can be\n\t   malformed or unexpected in ways that cause web servers or\n\t   clients to interpret the messages in different ways than\n\t   intermediary HTTP agents such as load balancers, reverse\n\t   proxies, web caching proxies, application firewalls,\n\t   etc. For example, an adversary may be able to add duplicate\n\t   or different header fields that a client or server might\n\t   interpret as one set of messages, whereas the intermediary\n\t   might interpret the same sequence of bytes as a different\n\t   set of messages. For example, discrepancies can arise in\n\t   how to handle duplicate headers like two Transfer-encoding\n\t   (TE) or two Content-length (CL), or the malicious HTTP\n\t   message will have different headers for TE and\n\t   CL.The inconsistent parsing and interpretation of messages\n\t   can allow the adversary to \"smuggle\" a message to the\n\t   client/server without the intermediary being aware of it.This weakness is usually the result of the usage\n\t   of outdated or incompatible HTTP protocol versions in the\n\t   HTTP agents.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityNon-RepudiationAccess Control. Impacts: Unexpected StateHide ActivitiesBypass Protection Mechanism. Note: An attacker could create HTTP messages to exploit a number of weaknesses including 1) the message can trick the web server to associate a URL with another URL's webpage and caching the contents of the webpage (web cache poisoning attack), 2) the message can be structured to bypass the firewall protection mechanisms and gain unauthorized access to a web application, and 3) the message can invoke a script or a page that returns client credentials (similar to a Cross Site Scripting attack).", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use a web server that employs a strict HTTP parsing procedure, such as Apache [REF-433].Implementation : Use only SSL communication.Implementation : Terminate the client session after each request.System Configuration : Turn all pages to non-cacheable.", "Demonstrative_Examples": "In the following example, a malformed HTTP request is sent to a website that includes a proxy server and a web server with the intent of poisoning the cache to associate one webpage with another malicious webpage.. When this request is sent to the proxy server, the proxy server parses the first four lines of the POST request and encounters the two \"Content-Length\" headers. The proxy server ignores the first header, so it assumes the request has a body of length 54 bytes. Therefore, it treats the data in the next three lines that contain exactly 54 bytes as the first request's body:In the following example, a malformed HTTP request is sent to a website that includes a web server with a firewall with the intent of bypassing the web server firewall to smuggle malicious code into the system.. When this request is sent to the web server, the first POST request has a content-length of 49,223 bytes, and the firewall treats the line with 49,152 copies of \"z\" and the lines with an additional lines with 71 bytes as its body (49,152+71=49,223). The firewall then continues to parse what it thinks is the second request starting with the line with the third POST request.. The interpretation of HTTP responses can be manipulated if response headers include a space between the header name and colon, or if HTTP 1.1 headers are sent through a proxy configured for HTTP 1.0, allowing for HTTP response smuggling. This can be exploited in web browsers and other applications when used in combination with various proxy servers. For instance, the HTTP response interpreted by the front-end/client HTTP agent/entity - in this case the web browser - can interpret a single response from an adversary-compromised web server as being two responses from two different web sites. In the Example below, notice the extra space after the Content-Length and Set-Cookie headers.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "436", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "446", "Name": "UI Discrepancy for Security Feature", "Description": "The user interface does not correctly enable or configure a security feature, but the interface provides feedback that causes the user to believe that the feature is in a secure state.", "Extended_Description": "When the user interface does not properly reflect what the user asks of it, then it can lead the user into a false sense of security. For example, the user might check a box to enable a security option to enable encrypted communications, but the product does not actually enable the encryption. Alternately, the user might provide a \"restrict ALL\" access control rule, but the product only implements \"restrict SOME\".", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "684", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "447", "Name": "Unimplemented or Unsupported Feature in UI", "Description": "Perform functionality testing before deploying the application.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Perform functionality testing before deploying the application.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "446", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "671", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "671", "Name": "Lack of Administrator Control over Security", "Description": "The product uses security features in a way that prevents the product's administrator from tailoring security settings to reflect the environment in which the product is being used. This introduces resultant weaknesses or prevents it from operating at a level of security that is desired by the administrator.", "Extended_Description": "If the product's administrator does not have the ability to manage security-related decisions at all times, then protecting the product from outside threats - including the product's developer - can become impossible. For example, a hard-coded account name and password cannot be changed by the administrator, thus exposing that product to attacks that the administrator can not prevent.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "448", "Name": "Obsolete Feature in UI", "Description": "Remove the obsolete feature from the UI. Warn the user that the feature is no longer supported.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Remove the obsolete feature from the UI. Warn the user that the feature is no longer supported.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "446", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "449", "Name": "The UI Performs the Wrong Action", "Description": "Perform extensive functionality testing of the UI. The UI should behave as specified.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Perform extensive functionality testing of the UI. The UI should behave as specified.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "446", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "45", "Name": "Path Equivalence: 'file...name' (Multiple Internal Dot)", "Description": "The product accepts path input in the form of multiple internal dot ('file...dir') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "44", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "165", "View_ID": "1000", "Ordinal": null}]}, {"ID": "450", "Name": "Multiple Interpretations of UI Input", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "357", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "453", "Name": "Insecure Default Variable Initialization", "Description": "Disable or change default settings when they can be used to abuse the system. Since those default settings are shipped with the product they are likely to be known by a potential attacker who is familiar with the product. For instance, default credentials should be changed or the associated accounts should be disabled.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: An attacker could gain access to and modify sensitive data or system information.", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : Disable or change default settings when they can be used to abuse the system. Since those default settings are shipped with the product they are likely to be known by a potential attacker who is familiar with the product. For instance, default credentials should be changed or the associated accounts should be disabled.", "Demonstrative_Examples": "This code attempts to login a user using credentials from a POST request:. Because the $authorized variable is never initialized, PHP will automatically set $authorized to any value included in the POST request if register_globals is enabled. An attacker can send a POST request with an unexpected third value 'authorized' set to 'true' and gain authorized status without supplying valid credentials.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1188", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "454", "Name": "External Initialization of Trusted Variables or Data Stores", "Description": "Avoid any external control of variables. If necessary, restrict the variables that can be modified using an allowlist, and use a different namespace or naming convention if possible.", "Extended_Description": "A product system should be reluctant to trust variables that have been initialized outside of its trust boundary, especially if they are initialized by users. The variables may have been initialized incorrectly. If an attacker can initialize the variable, then they can influence what the vulnerable system will do.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: An attacker could gain access to and modify sensitive data or system information.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : A product system should be reluctant to trust variables that have been initialized outside of its trust boundary. Ensure adequate checking (e.g. input validation) is performed when relying on input from outside a trust boundary.Architecture and Design : Avoid any external control of variables. If necessary, restrict the variables that can be modified using an allowlist, and use a different namespace or naming convention if possible.", "Demonstrative_Examples": "In the Java example below, a system property controls the debug level of the application.. If an attacker is able to modify the system property, then it may be possible to coax the application into divulging sensitive information by virtue of the fact that additional debug information is printed/exposed as the debug level increases.This code checks the HTTP POST request for a debug switch, and enables a debug mode if the switch is set.. Any user can activate the debug mode, gaining administrator privileges. An attacker may also use the information printed by the phpinfo() function to further exploit the system. .", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "456", "View_ID": "1000", "Ordinal": null}]}, {"ID": "455", "Name": "Non-exit on Failed Initialization", "Description": "Follow the principle of failing securely when an error occurs. The system should enter a state where it is not vulnerable and will not display sensitive error messages to a potential attacker.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Modify Application DataAlter Execution Logic. Note: The application could be placed in an insecure state that may allow an attacker to modify sensitive data or allow unintended logic to be executed.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Follow the principle of failing securely when an error occurs. The system should enter a state where it is not vulnerable and will not display sensitive error messages to a potential attacker.", "Demonstrative_Examples": "The following code intends to limit certain operations to the administrator only.. If the application is unable to extract the state information - say, due to a database timeout - then the $uid variable will not be explicitly set by the programmer. This will cause $uid to be regarded as equivalent to \"0\" in the conditional, allowing the original user to perform administrator actions. Even if the attacker cannot directly influence the state data, unexpected errors could cause incorrect privileges to be assigned to a user just by accident.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "705", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "636", "View_ID": "1000", "Ordinal": null}]}, {"ID": "636", "Name": "Not Failing Securely ('Failing Open')", "Description": "Subdivide and allocate resources and components so that a failure in one part does not affect the entire product.", "Extended_Description": "By entering a less secure state, the product inherits the weaknesses associated with that state, making it easier to compromise. At the least, it causes administrators to have a false sense of security. This weakness typically occurs as a result of wanting to \"fail functional\" to minimize administration and support costs, instead of \"failing safe.\"", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: Intended access restrictions can be bypassed, which is often contradictory to what the product's administrator expects.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Subdivide and allocate resources and components so that a failure in one part does not affect the entire product.", "Demonstrative_Examples": ". Switches may revert their functionality to that of hubs when the table used to map ARP information to the switch interface overflows, such as when under a spoofing attack. This results in traffic being broadcast to an eavesdropper, instead of being sent only on the relevant switch interface. To mitigate this type of problem, the developer could limit the number of ARP entries that can be recorded for a given switch interface, while other interfaces may keep functioning normally. Configuration options can be provided on the appropriate actions to be taken in case of a detected failure, but safe defaults should be used.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "280", "View_ID": "1000", "Ordinal": null}]}, {"ID": "456", "Name": "Missing Initialization of a Variable", "Description": "Use a static analysis tool to spot non-initialized variables.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Unexpected StateQuality DegradationVaries by Context. Note: The uninitialized data may be invalid, causing logic errors within the program. In some cases, this could result in a security problem.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Check that critical variables are initialized.Testing : Use a static analysis tool to spot non-initialized variables.", "Demonstrative_Examples": "This function attempts to extract a pair of numbers from a user-supplied string.. This code attempts to extract two integer values out of a formatted, user-supplied input. However, if an attacker were to provide an input of the form:. Here, an uninitialized field in a Java class is used in a seldom-called method, which would cause a NullPointerException to be thrown.This code first authenticates a user, then allows a delete command if the user is an administrator.. The $isAdmin variable is set to true if the user is an admin, but is uninitialized otherwise. If PHP's register_globals feature is enabled, an attacker can set uninitialized variables like $isAdmin to arbitrary values, in this case gaining administrator privileges by setting $isAdmin to true.In the following Java code the BankManager class uses the user variable of the class User to allow authorized users to perform bank manager tasks. The user variable is initialized within the method setUser that retrieves the User from the User database. The user is then authenticated as unauthorized user through the method authenticateUser.. However, if the method setUser is not called before authenticateUser then the user variable will not have been initialized and will result in a NullPointerException. The code should verify that the user variable has been initialized before it is used, as in the following code.This example will leave test_string in an\n\t\t\t  unknown condition when i is the same value as err_val,\n\t\t\t  because test_string is not initialized\n\t\t\t  (CWE-456). Depending on where this code segment appears\n\t\t\t  (e.g. within a function body), test_string might be\n\t\t\t  random if it is stored on the heap or stack. If the\n\t\t\t  variable is declared in static memory, it might be zero\n\t\t\t  or NULL. Compiler optimization might contribute to the\n\t\t\t  unpredictability of this address.. When the printf() is reached,\n              test_string might be an unexpected address, so the\n              printf might print junk strings (CWE-457).To fix this code, there are a couple approaches to\n\t\t\t  making sure that test_string has been properly set once\n\t\t\t  it reaches the printf().One solution would be to set test_string to an\n\t\t\t  acceptable default before the conditional:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "909", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "89", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "120", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "98", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "457", "View_ID": "1000", "Ordinal": null}]}, {"ID": "908", "Name": "Use of Uninitialized Resource", "Description": "Run or compile the product with settings that generate warnings about uninitialized variables or data.", "Extended_Description": "When a resource has not been properly initialized, the product may behave unexpectedly. This may lead to a crash or invalid memory access, but the consequences vary depending on the type of resource and how it is used within the product.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read MemoryRead Application Data. Note: When reusing a resource such as memory or a program variable, the original contents of that resource may not be cleared before it is sent to an untrusted party.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: The uninitialized resource may contain values that cause program flow to change in ways that the programmer did not intend.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Explicitly initialize the resource before use. If this is performed through an API function or standard procedure, follow all required steps.Implementation : Pay close attention to complex conditionals that affect initialization, since some branches might not perform the initialization.Implementation : Avoid race conditions (CWE-362) during initialization routines.Build and Compilation : Run or compile the product with settings that generate warnings about uninitialized variables or data.", "Demonstrative_Examples": ". Here, a boolean initiailized field is consulted to ensure that initialization tasks are only completed once. However, the field is mistakenly set to true during static initialization, so the initialization code is never reached.The following code intends to limit certain operations to the administrator only.. If the application is unable to extract the state information - say, due to a database timeout - then the $uid variable will not be explicitly set by the programmer. This will cause $uid to be regarded as equivalent to \"0\" in the conditional, allowing the original user to perform administrator actions. Even if the attacker cannot directly influence the state data, unexpected errors could cause incorrect privileges to be assigned to a user just by accident.The following code intends to concatenate a string to a variable and print the string.. This might seem innocent enough, but str was not initialized, so it contains random memory. As a result, str[0] might not contain the null terminator, so the copy might start at an offset other than 0. The consequences can vary, depending on the underlying memory.This example will leave test_string in an\n\t\t\t  unknown condition when i is the same value as err_val,\n\t\t\t  because test_string is not initialized\n\t\t\t  (CWE-456). Depending on where this code segment appears\n\t\t\t  (e.g. within a function body), test_string might be\n\t\t\t  random if it is stored on the heap or stack. If the\n\t\t\t  variable is declared in static memory, it might be zero\n\t\t\t  or NULL. Compiler optimization might contribute to the\n\t\t\t  unpredictability of this address.. When the printf() is reached,\n              test_string might be an unexpected address, so the\n              printf might print junk strings (CWE-457).To fix this code, there are a couple approaches to\n\t\t\t  making sure that test_string has been properly set once\n\t\t\t  it reaches the printf().One solution would be to set test_string to an\n\t\t\t  acceptable default before the conditional:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "457", "Name": "Use of Uninitialized Variable", "Description": "Mitigating technologies such as safe string libraries and container abstractions could be introduced.", "Extended_Description": "In some languages such as C and C++, stack variables are not initialized by default. They generally contain junk data with the contents of stack memory before the function was invoked. An attacker can sometimes control or read these contents. In other languages or conditions, a variable that is not explicitly initialized can be given a default value that has security implications, depending on the logic of the program. The presence of an uninitialized variable can sometimes indicate a typographic error in the code.", "Modes_Of_Introduction": "Implementation: In C, using an uninitialized char * in some string libraries will return incorrect results, as the libraries expect the null terminator to always be at the end of a string, even if the string is empty.", "Common_Consequences": "Scopes: AvailabilityIntegrityOther. Impacts: Other. Note: Initial variables usually contain junk, which can not be trusted for consistency. This can lead to denial of service conditions, or modify control flow in unexpected ways. In some cases, an attacker can \"pre-initialize\" the variable using previous actions, which might enable code execution. This can cause a race condition if a lock variable check passes when it should not.Scopes: AuthorizationOther. Impacts: Other. Note: Strings that are not initialized are especially dangerous, since many functions expect a null at the end -- and only at the end -- of a string.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assign all variables to an initial value.Build and Compilation : Most compilers will complain about the use of uninitialized variables if warnings are turned on.Implementation : When using a language that does not require explicit declaration of variables, run or compile the software in a mode that reports undeclared or unknown variables. This may indicate the presence of a typographic error in the variable's name.Requirements : The choice could be made to use a language that is not susceptible to these issues.Architecture and Design : Mitigating technologies such as safe string libraries and container abstractions could be introduced.", "Demonstrative_Examples": "This code prints a greeting using information stored in a POST request:. This code checks if the POST array 'names' is set before assigning it to the $nameArray variable. However, if the array is not in the POST request, $nameArray will remain uninitialized. This will cause an error when the array is accessed to print the greeting message, which could lead to further exploit.The following switch statement is intended to set the values of the variables aN and bN before they are used:. In the default case of the switch statement, the programmer has accidentally set the value of aN twice. As a result, bN will have an undefined value. Most uninitialized variable issues result in general software reliability problems, but if attackers can intentionally trigger the use of an uninitialized variable, they might be able to launch a denial of service attack by crashing the program. Under the right circumstances, an attacker may be able to control the value of an uninitialized variable by affecting the values on the stack prior to the invocation of the function.This example will leave test_string in an\n\t\t\t  unknown condition when i is the same value as err_val,\n\t\t\t  because test_string is not initialized\n\t\t\t  (CWE-456). Depending on where this code segment appears\n\t\t\t  (e.g. within a function body), test_string might be\n\t\t\t  random if it is stored on the heap or stack. If the\n\t\t\t  variable is declared in static memory, it might be zero\n\t\t\t  or NULL. Compiler optimization might contribute to the\n\t\t\t  unpredictability of this address.. When the printf() is reached,\n              test_string might be an unexpected address, so the\n              printf might print junk strings (CWE-457).To fix this code, there are a couple approaches to\n\t\t\t  making sure that test_string has been properly set once\n\t\t\t  it reaches the printf().One solution would be to set test_string to an\n\t\t\t  acceptable default before the conditional:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "908", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "665", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "46", "Name": "Path Equivalence: 'filename ' (Trailing Space)", "Description": "The product accepts path input in the form of trailing space ('filedir ') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "162", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "289", "View_ID": "1000", "Ordinal": null}]}, {"ID": "460", "Name": "Improper Cleanup on Thrown Exception", "Description": "If one breaks from a loop or function by throwing an exception, make sure that cleanup happens or that you should exit the program. Use throwing exceptions sparsely.", "Extended_Description": "Often, when functions or loops become complicated, some level of resource cleanup is needed throughout execution. Exceptions can disturb the flow of the code and prevent the necessary cleanup from happening.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Other. Impacts: Varies by Context. Note: The code could be left in a bad state.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : If one breaks from a loop or function by throwing an exception, make sure that cleanup happens or that you should exit the program. Use throwing exceptions sparsely.", "Demonstrative_Examples": "The following example demonstrates the weakness.. In this case, you may leave a thread locked accidentally.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "459", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": null}]}, {"ID": "462", "Name": "Duplicate Key in Associative List (Alist)", "Description": "Use an alist which checks the uniqueness of hash keys with each entry before inserting the entry.", "Extended_Description": "A duplicate key entry -- if the alist is designed properly -- could be used as a constant time replace function. However, duplicate key entries could be inserted by mistake. Because of this ambiguity, duplicate key entries in an association list are not recommended and should not be allowed.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use a hash table instead of an alist.Architecture and Design : Use an alist which checks the uniqueness of hash keys with each entry before inserting the entry.", "Demonstrative_Examples": "The following code adds data to a list and then attempts to sort the data.. Since basename is not necessarily unique, this may not sort how one would like it to be.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "694", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "463", "Name": "Deletion of Data Structure Sentinel", "Description": "Use OS-level preventative functionality. Not a complete solution.", "Extended_Description": "Often times data-structure sentinels are used to mark structure of the data structure. A common example of this is the null character at the end of strings. Another common example is linked lists which may contain a sentinel to mark the end of the list. It is dangerous to allow this type of control data to be easily accessible. Therefore, it is important to protect from the deletion or modification outside of some wrapper interface which provides safety.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityOther. Impacts: Other. Note: Generally this error will cause the data structure to not work properly.Scopes: AuthorizationOther. Impacts: Other. Note: If a control character, such as NULL is removed, one may cause resource access control problems.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use an abstraction library to abstract away risky APIs. Not a complete solution.Build and Compilation : Run or compile the software using features or extensions that automatically provide a protection mechanism that mitigates or eliminates buffer overflows.\n                  For example, certain compilers and extensions provide automatic buffer overflow detection mechanisms that are built into the compiled code. Examples include the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice.Operation : Use OS-level preventative functionality. Not a complete solution.", "Demonstrative_Examples": "This example creates a null terminated string and prints it contents.. The string foo has space for 9 characters and a null terminator, but 10 characters are written to it. As a result, the string foo is not null terminated and calling printf() on it will have unpredictable and possibly dangerous results.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "707", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "464", "View_ID": "1000", "Ordinal": null}]}, {"ID": "464", "Name": "Addition of Data Structure Sentinel", "Description": "Use OS-level preventative functionality. This is not a complete solution.", "Extended_Description": "Data-structure sentinels are often used to mark the structure of data. A common example of this is the null character at the end of strings or a special sentinel to mark the end of a linked list. It is dangerous to allow this type of control data to be easily accessible. Therefore, it is important to protect from the addition or modification of sentinels.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: Generally this error will cause the data structure to not work properly by truncating the data.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Encapsulate the user from interacting with data sentinels. Validate user input to verify that sentinels are not present.Implementation : Proper error checking can reduce the risk of inadvertently introducing sentinel values into data. For example, if a parsing function fails or encounters an error, it might return a value that is the same as the sentinel.Architecture and Design : Use an abstraction library to abstract away risky APIs. This is not a complete solution.Operation : Use OS-level preventative functionality. This is not a complete solution.", "Demonstrative_Examples": "The following example assigns some character values to a list of characters and prints them each individually, and then as a string. The third character value is intended to be an integer taken from user input and converted to an int.. The first print statement will print each character separated by a space. However, if a non-integer is read from stdin by getc, then atoi will not make a conversion and return 0. When foo is printed as a string, the 0 at character foo[2] will act as a NULL terminator and foo[3] will never be printed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "466", "Name": "Return of Pointer Value Outside of Expected Range", "Description": "A function can return a pointer to memory that is outside of the buffer that the pointer is expected to reference.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "467", "Name": "Use of sizeof() on a Pointer Type", "Description": "Use expressions such as \"sizeof(*pointer)\" instead of \"sizeof(pointer)\", unless you intend to run sizeof() on a pointer type to gain some platform independence or if you are allocating a variable on the stack.", "Extended_Description": "The use of sizeof() on a pointer can sometimes generate useful information. An obvious case is to find out the wordsize on a platform. More often than not, the appearance of sizeof(pointer) indicates a bug.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Modify MemoryRead Memory. Note: This error can often cause one to allocate a buffer that is much smaller than what is needed, leading to resultant weaknesses such as buffer overflows.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Use expressions such as \"sizeof(*pointer)\" instead of \"sizeof(pointer)\", unless you intend to run sizeof() on a pointer type to gain some platform independence or if you are allocating a variable on the stack.", "Demonstrative_Examples": "Care should be taken to ensure sizeof returns the size of the data structure itself, and not the size of the pointer to the data structure.. In this example, sizeof(foo) returns the size of the pointer.This example defines a fixed username and password. The AuthenticateUser() function is intended to accept a username and a password from an untrusted user, and check to ensure that it matches the username and password. If the username and password match, AuthenticateUser() is intended to indicate that authentication succeeded.. In AuthenticateUser(), because sizeof() is applied to a parameter with an array type, the sizeof() call might return 4 on many modern architectures. As a result, the strncmp() call only checks the first four characters of the input password, resulting in a partial comparison (CWE-187), leading to improper authentication (CWE-287).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "131", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "468", "Name": "Incorrect Pointer Scaling", "Description": "Use technologies for preventing buffer overflows.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: Programmers may try to index from a pointer by adding a number of bytes. This is incorrect because C and C++ implicitly scale the operand by the size of the data type.", "Common_Consequences": "Scopes: ConfidentialityIntegrity. Impacts: Read MemoryModify Memory. Note: Incorrect pointer scaling will often result in buffer overflow conditions. Confidentiality can be compromised if the weakness is in the context of a buffer over-read or under-read.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use a platform with high-level memory abstractions.Implementation : Always use array indexing instead of direct pointer manipulation.Architecture and Design : Use technologies for preventing buffer overflows.", "Demonstrative_Examples": "This example attempts to calculate the position of the second byte of a pointer.. In this example, second_char is intended to point to the second byte of p. But, adding 1 to p actually adds sizeof(int) to p, giving a result that is incorrect (3 bytes off on 32-bit platforms). If the resulting memory address is read, this could potentially be an information leak. If it is a write, it could be a security-critical write to unauthorized memory-- whether or not it is a buffer overflow. Note that the above code may also be wrong in other ways, particularly in a little endian environment.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "469", "Name": "Use of Pointer Subtraction to Determine Size", "Description": "Save an index variable. This is the recommended solution. Rather than subtract pointers from one another, use an index variable of the same size as the pointers in question. Use this variable to \"walk\" from one pointer to the other and calculate the difference. Always validate this number.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access ControlIntegrityConfidentialityAvailability. Impacts: Modify MemoryRead MemoryExecute Unauthorized Code or CommandsGain Privileges or Assume Identity. Note: There is the potential for arbitrary code execution with privileges of the vulnerable program.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Save an index variable. This is the recommended solution. Rather than subtract pointers from one another, use an index variable of the same size as the pointers in question. Use this variable to \"walk\" from one pointer to the other and calculate the difference. Always validate this number.", "Demonstrative_Examples": "The following example contains the method size that is used to determine the number of nodes in a linked list. The method is passed a pointer to the head of the linked list.. However, the method creates a pointer that points to the end of the list and uses pointer subtraction to determine the number of nodes in the list by subtracting the tail pointer from the head pointer. There no guarantee that the pointers exist in the same memory area, therefore using pointer subtraction in this way could return incorrect results and allow other unintended behavior. In this example a counter should be used to determine the number of nodes in the list, as shown in the following code.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "682", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "47", "Name": "Path Equivalence: ' filename' (Leading Space)", "Description": "The product accepts path input in the form of leading space (' filedir') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "470", "Name": "Use of Externally-Controlled Input to Select Classes or Code ('Unsafe Reflection')", "Description": "Apply strict input validation by using allowlists or indirect selection to ensure that the user is only selecting allowable classes or code.", "Extended_Description": "If the product uses external inputs to determine which class to instantiate or which method to invoke, then an attacker could supply values to select unexpected classes or methods. If this occurs, then the attacker could create control flow paths that were not intended by the developer. These paths could bypass authentication or access control checks, or otherwise cause the product to behave in an unexpected manner. This situation becomes a doomsday scenario if the attacker can upload files into a location that appears on the product's classpath (CWE-427) or add new entries to the product's classpath (CWE-426). Under either of these conditions, the attacker can use reflection to introduce new, malicious behavior into the product.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityOther. Impacts: Execute Unauthorized Code or CommandsAlter Execution Logic. Note: The attacker might be able to execute code that is not directly accessible to the attacker. Alternately, the attacker could call unexpected code in the wrong place or the wrong time, possibly modifying critical system state.Scopes: AvailabilityOther. Impacts: DoS: Crash, Exit, or RestartOther. Note: The attacker might be able to use reflection to call the wrong code, possibly with unexpected arguments that violate the API (CWE-227). This could cause the product to exit or hang.Scopes: Confidentiality. Impacts: Read Application Data. Note: By causing the wrong code to be invoked, the attacker might be able to trigger a runtime error that leaks sensitive information in the error message, such as CWE-536.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Refactor your code to avoid using reflection.Architecture and Design : Do not use user-controlled inputs to select and load classes or code.Implementation : Apply strict input validation by using allowlists or indirect selection to ensure that the user is only selecting allowable classes or code.", "Demonstrative_Examples": "A common reason that programmers use the reflection API is to implement their own command dispatcher. The following example shows a command dispatcher that does not use reflection:. A programmer might refactor this code to use reflection as follows:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "913", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "913", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "472", "Name": "External Control of Assumed-Immutable Web Parameter", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "If a web product does not properly protect assumed-immutable values from modification in hidden form fields, parameters, cookies, or URLs, this can lead to modification of critical data. Web applications often mistakenly make the assumption that data passed to the client in hidden fields or cookies is not susceptible to tampering. Improper validation of data that are user-controllable can lead to the application processing incorrect, and often malicious, input.For example, custom cookies commonly store session data or persistent data across sessions. This kind of session data is normally involved in security related decisions on the server side, such as user authentication and access control. Thus, the cookies might contain sensitive data such as user credentials and privileges. This is a dangerous practice, as it can often lead to improper reliance on the value of the client-provided cookie by the server side application.", "Modes_Of_Introduction": "Implementation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: Without appropriate protection mechanisms, the client can easily tamper with cookies and similar web data. Reliance on the cookies without detailed validation can lead to problems such as SQL injection. If you use cookie values for security related decisions on the server side, manipulating the cookies might lead to violations of security policies such as authentication bypassing, user impersonation and privilege escalation. In addition, storing sensitive data in the cookie without appropriate protection can also lead to disclosure of sensitive user data, especially data stored in persistent cookies.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": ". In this example, a web application uses the value of a hidden form field (accountID) without having done any input validation because it was assumed to be immutable.Hidden fields should not be trusted as secure parameters.. An attacker can intercept and alter hidden fields in a post to the server as easily as user input fields. An attacker can simply parse the HTML for the substring:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "642", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "471", "View_ID": "1000", "Ordinal": null}]}, {"ID": "473", "Name": "PHP External Variable Modification", "Description": "Carefully identify which variables can be controlled or influenced by an external user, and consider adopting a naming convention to emphasize when externally modifiable variables are being used. An application should be reluctant to trust variables that have been initialized outside of its trust boundary. Ensure adequate checking is performed when relying on input from outside a trust boundary. Do not allow your application to run with register_globals enabled. If you implement a register_globals emulator, be extremely careful of variable extraction, dynamic evaluation, and similar issues, since weaknesses in your emulation could allow external variable modification to take place even without register_globals.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Carefully identify which variables can be controlled or influenced by an external user, and consider adopting a naming convention to emphasize when externally modifiable variables are being used. An application should be reluctant to trust variables that have been initialized outside of its trust boundary. Ensure adequate checking is performed when relying on input from outside a trust boundary. Do not allow your application to run with register_globals enabled. If you implement a register_globals emulator, be extremely careful of variable extraction, dynamic evaluation, and similar issues, since weaknesses in your emulation could allow external variable modification to take place even without register_globals.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "471", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "98", "View_ID": "1000", "Ordinal": null}]}, {"ID": "474", "Name": "Use of Function with Inconsistent Implementations", "Description": "Do not accept inconsistent behavior from the API specifications when the deviant behavior increase the risk level.", "Extended_Description": "The use of inconsistent implementations can cause changes in behavior when the code is ported or built under a different environment than the programmer expects, which can lead to security problems in some cases.The implementation of many functions varies by platform, and at times, even by different versions of the same platform. Implementation differences can include:", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Do not accept inconsistent behavior from the API specifications when the deviant behavior increase the risk level.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "758", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "475", "Name": "Undefined Behavior for Input to API", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "476", "Name": "NULL Pointer Dereference", "Description": "Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.", "Extended_Description": "NULL pointer dereference issues can occur through a number of flaws, including race conditions, and simple programming omissions.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: NULL pointer dereferences usually result in the failure of the process unless exception handling (on some platforms) is available and implemented. Even when exception handling is being used, it can still be very difficult to return the software to a safe state of operation.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or CommandsRead MemoryModify Memory. Note: In rare circumstances, when NULL is equivalent to the 0x0 memory address and privileged code can access it, then writing or reading memory is possible, which may lead to code execution.", "Detection_Methods": "Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Dynamic Analysis. Description: Identify error conditions that are not likely to occur during normal usage and trigger them. For example, run the program under low memory conditions, run with insufficient privileges or permissions, interrupt a transaction before it is completed, or disable connectivity to basic network services such as DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled exception or similar error that was discovered and handled by the application's environment, it may still indicate unexpected conditions that were not handled by the application itself. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : If all pointers that could have been modified are sanity-checked previous to use, nearly all NULL pointer dereferences can be prevented.Requirements : The choice could be made to use a language that is not susceptible to these issues.Implementation : Check the results of all functions that return a value and verify that the value is non-null before acting upon it.Architecture and Design : Identify all variables and data stores that receive information from external sources, and apply input validation to make sure that they are only initialized to expected values.Implementation : Explicitly initialize all your variables and other data stores, either during declaration or just before the first usage.Testing : Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.", "Demonstrative_Examples": "While there are no complete fixes aside from conscientious programming, the following steps will go a long way to ensure that NULL pointer dereferences do not occur.. If you are working with a multithreaded or otherwise asynchronous environment, ensure that proper locking APIs are used to lock before the if statement; and unlock when it has finished.This example takes an IP address from a user, verifies that it is well formed and then looks up the hostname and copies it into a buffer.. If an attacker provides an address that appears to be well-formed, but the address does not resolve to a hostname, then the call to gethostbyaddr() will return NULL. Since the code does not check the return value from gethostbyaddr (CWE-252), a NULL pointer dereference (CWE-476) would then occur in the call to strcpy().. In the following code, the programmer assumes that the system always has a property named \"cmd\" defined. If an attacker can control the program's environment so that \"cmd\" is not defined, the program throws a NULL pointer exception when it attempts to call the trim() method.This Android application has registered to handle a URL when sent an intent:. The application assumes the URL will always be included in the intent. When the URL is not present, the call to getStringExtra() will return null, thus causing a null pointer exception when length() is called.Consider the following example of a typical client server exchange. The HandleRequest function is intended to perform a request and use a defer to close the connection whenever the function returns.. If a user supplies a malformed request or violates the client policy, the Do method can return a nil response and a non-nil err.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "754", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "477", "Name": "Use of Obsolete Function", "Description": "Consider seriously the security implications of using an obsolete function. Consider using alternate functions.", "Extended_Description": "As programming languages evolve, functions occasionally become obsolete due to:Functions that are removed are usually replaced by newer counterparts that perform the same task in some different and hopefully improved way.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Implementation : Refer to the documentation for the obsolete function in order to determine why it is deprecated or obsolete and to learn about alternative ways to achieve the same functionality.Requirements : Consider seriously the security implications of using an obsolete function. Consider using alternate functions.", "Demonstrative_Examples": "The following code uses the deprecated function getpw() to verify that a plaintext password matches a user's encrypted password. If the password is valid, the function sets result to 1; otherwise it is set to 0.. Although the code often behaves correctly, using the getpw() function can be problematic from a security standpoint, because it can overflow the buffer passed to its second parameter. Because of this vulnerability, getpw() has been supplanted by getpwuid(), which performs the same lookup as getpw() but returns a pointer to a statically-allocated structure to mitigate the risk. Not all functions are deprecated or replaced because they pose a security risk. However, the presence of an obsolete function often indicates that the surrounding code has been neglected and may be in a state of disrepair. Software security has not been a priority, or even a consideration, for very long. If the program uses deprecated or obsolete functions, it raises the probability that there are security problems lurking nearby.. In the following code, the programmer assumes that the system always has a property named \"cmd\" defined. If an attacker can control the program's environment so that \"cmd\" is not defined, the program throws a null pointer exception when it attempts to call the \"Trim()\" method.The following code constructs a string object from an array of bytes and a value that specifies the top 8 bits of each 16-bit Unicode character.. In this example, the constructor may not correctly convert bytes to characters depending upon which charset is used to encode the string represented by nameBytes. Due to the evolution of the charsets used to encode strings, this constructor was deprecated and replaced by a constructor that accepts as one of its parameters the name of the charset used to encode the bytes for conversion.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "478", "Name": "Missing Default Case in Multiple Condition Expression", "Description": "Ensure that there are no cases unaccounted for when adjusting program flow or values based on the value of a given variable. In the case of switch style statements, the very simple act of creating a default case can, if done correctly, mitigate this situation. Often however, the default case is used simply to represent an assumed option, as opposed to working as a check for invalid input. This is poor practice and in some cases is as bad as omitting a default case entirely.", "Extended_Description": "If a multiple-condition expression (such as a switch in C) omits the default case but does not consider or handle all possible values that could occur, then this might lead to complex logical errors and resultant weaknesses. Because of this, further decisions are made based on poor information, and cascading failure results. This cascading failure may result in any number of security issues, and constitutes a significant failure in the system.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Varies by ContextAlter Execution Logic. Note: Depending on the logical circumstances involved, any consequences may result: e.g., issues of confidentiality, authentication, authorization, availability, integrity, accountability, or non-repudiation.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Ensure that there are no cases unaccounted for when adjusting program flow or values based on the value of a given variable. In the case of switch style statements, the very simple act of creating a default case can, if done correctly, mitigate this situation. Often however, the default case is used simply to represent an assumed option, as opposed to working as a check for invalid input. This is poor practice and in some cases is as bad as omitting a default case entirely.", "Demonstrative_Examples": "The following does not properly check the return code in the case where the security_check function returns a -1 value when an error occurs. If an attacker can supply data that will invoke an error, the attacker can bypass the security check:. Instead a default label should be used for unaccounted conditions:In the following Java example the method getInterestRate retrieves the interest rate for the number of points for a mortgage. The number of points is provided within the input parameter and a switch statement will set the interest rate value to be returned based on the number of points.. However, this code assumes that the value of the points input parameter will always be 0, 1 or 2 and does not check for other incorrect values passed to the method. This can be easily accomplished by providing a default label in the switch statement that outputs an error message indicating an invalid value for the points input parameter and returning a null value.In the following Python example the match-case statements (available in Python version 3.10 and later) perform actions based on the result of the process_data() function. The expected return is either 0 or 1. However, if an unexpected result (e.g., -1 or 2) is obtained then no actions will be taken potentially leading to an unexpected program state.. The recommended approach is to add a default case that captures any unexpected result conditions, regardless of how improbable these unexpected conditions might be, and properly handles them.In the following JavaScript example the switch-case statements (available in JavaScript version 1.2 and later) are used to process a given step based on the result of a calcuation involving two inputs. The expected return is either 1, 2, or 3. However, if an unexpected result (e.g., 4) is obtained then no action will be taken potentially leading to an unexpected program state.. The recommended approach is to add a default case that captures any unexpected result conditions and properly handles them.The Finite State Machine (FSM) shown in the \"bad\" code snippet below assigns the output (\"out\") based on the value of state, which is determined based on the user provided input (\"user_input\").. The case statement does not include a default to handle the scenario when the user provides inputs of 3'h6 and 3'h7.  Those inputs push the system to an undefined state and might cause a crash (denial of service) or any other unanticipated outcome.Adding a default statement to handle undefined inputs mitigates this issue.  This is shown in the \"Good\" code snippet below.  The default statement is in bold.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1023", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "828", "Name": "Signal Handler with Functionality that is not Asynchronous-Safe", "Description": "Where non-reentrant functionality must be leveraged within a signal handler, be sure to block or mask signals appropriately. This includes blocking other signals within the signal handler itself that may also leverage the functionality. It also includes blocking all signals reliant upon the functionality when it is being accessed or modified by the normal behaviors of the product.", "Extended_Description": "This can lead to an unexpected system state with a variety of potential consequences depending on context, including denial of service and code execution.Signal handlers are typically intended to interrupt normal functionality of a program, or even other signals, in order to notify the process of an event. When a signal handler uses global or static variables, or invokes functions that ultimately depend on such state or its associated metadata, then it could corrupt system state that is being used by normal functionality. This could subject the program to race conditions or other weaknesses that allow an attacker to cause the program state to be corrupted. While denial of service is frequently the consequence, in some cases this weakness could be leveraged for code execution.There are several different scenarios that introduce this issue:Note that in some environments or contexts, it might be possible for the signal handler to be interrupted itself.If both a signal handler and the normal behavior of the product have to operate on the same set of state variables, and a signal is received in the middle of the normal execution's modifications of those variables, the variables may be in an incorrect or corrupt state during signal handler execution, and possibly still incorrect or corrupt upon return.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: DoS: Crash, Exit, or RestartExecute Unauthorized Code or Commands. Note: The most common consequence will be a corruption of the state of the product, possibly leading to a crash or exit. However, if the signal handler is operating on state variables for security relevant libraries or protection mechanisms, the consequences can be far more severe, including protection mechanism bypass, privilege escalation, or information exposure.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Eliminate the usage of non-reentrant functionality inside of signal handlers. This includes replacing all non-reentrant library calls with reentrant calls.\n                  Note: This will not always be possible and may require large portions of the product to be rewritten or even redesigned. Sometimes reentrant-safe library alternatives will not be available. Sometimes non-reentrant interaction between the state of the system and the signal handler will be required by design.Implementation : Where non-reentrant functionality must be leveraged within a signal handler, be sure to block or mask signals appropriately. This includes blocking other signals within the signal handler itself that may also leverage the functionality. It also includes blocking all signals reliant upon the functionality when it is being accessed or modified by the normal behaviors of the product.", "Demonstrative_Examples": "This code registers the same signal handler function with two different signals (CWE-831). If those signals are sent to the process, the handler creates a log message (specified in the first argument to the program) and exits.. The handler function uses global state (globalVar and logMessage), and it can be called by both the SIGHUP and SIGTERM signals. An attack scenario might follow these lines:The following code registers a signal handler with multiple signals in order to log when a specific event occurs and to free associated memory before exiting.. However, the following sequence of events may result in a double-free (CWE-415):", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "364", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "479", "Name": "Signal Handler Use of a Non-reentrant Function", "Description": "Use sanity checks to reduce the timing window for exploitation of race conditions. This is only a partial solution, since many attacks might fail, but other attacks still might work within the narrower window, even accidentally.", "Extended_Description": "Non-reentrant functions are functions that cannot safely be called, interrupted, and then recalled before the first call has finished without resulting in memory corruption. This can lead to an unexpected system state and unpredictable results with a variety of potential consequences depending on context, including denial of service and code execution.Many functions are not reentrant, but some of them can result in the corruption of memory if they are used in a signal handler. The function call syslog() is an example of this. In order to perform its functionality, it allocates a small amount of memory as \"scratch space.\" If syslog() is suspended by a signal call and the signal handler calls syslog(), the memory used by both of these functions enters an undefined, and possibly, exploitable state. Implementations of malloc() and free() manage metadata in global structures in order to track which memory is allocated versus which memory is available, but they are non-reentrant. Simultaneous calls to these functions can cause corruption of the metadata.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: It may be possible to execute arbitrary code through the use of a write-what-where condition.Scopes: Integrity. Impacts: Modify MemoryModify Application Data. Note: Signal race conditions often result in data corruption.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Requirements : Require languages or libraries that provide reentrant functionality, or otherwise make it easier to avoid this weakness.Architecture and Design : Design signal handlers to only set flags rather than perform complex functionality.Implementation : Ensure that non-reentrant functions are not found in signal handlers.Implementation : Use sanity checks to reduce the timing window for exploitation of race conditions. This is only a partial solution, since many attacks might fail, but other attacks still might work within the narrower window, even accidentally.", "Demonstrative_Examples": ". In this example, a signal handler uses syslog() to log a message:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "828", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "663", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "123", "View_ID": "1000", "Ordinal": null}]}, {"ID": "663", "Name": "Use of a Non-reentrant Function in a Concurrent Context", "Description": "In Java, use the ReentrantLock Class.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use reentrant functions if available.Implementation : Add synchronization to your non-reentrant function.Implementation : In Java, use the ReentrantLock Class.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "48", "Name": "Path Equivalence: 'file name' (Internal Whitespace)", "Description": "The product accepts path input in the form of internal space ('file(SPACE)name') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "670", "Name": "Always-Incorrect Control Flow Implementation", "Description": "The code contains a control flow path that does not reflect the algorithm that the path is intended to implement, leading to incorrect behavior any time this path is navigated.", "Extended_Description": "This weakness captures cases in which a particular code segment is always incorrect with respect to the algorithm that it is implementing. For example, if a C programmer intends to include multiple statements in a single block but does not include the enclosing braces (CWE-483), then the logic is always incorrect. This issue is in contrast to most weaknesses in which the code usually behaves correctly, except when it is externally manipulated in malicious ways.", "Modes_Of_Introduction": "Implementation: This issue typically appears in rarely-tested code, since the \"always-incorrect\" nature will be detected as a bug during normal usage.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "480", "Name": "Use of Incorrect Operator", "Description": "This weakness can be found easily using static analysis. However in some cases an operator might appear to be incorrect, but is actually correct and reflects unusual logic within the program.", "Extended_Description": "These types of errors are generally the result of a typo by the programmer.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Alter Execution Logic. Note: This weakness can cause unintended logic to be executed and other unexpected application behavior.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can be found easily using static analysis. However in some cases an operator might appear to be incorrect, but is actually correct and reflects unusual logic within the program. Method Name: Manual Static Analysis. Description: This weakness can be found easily using static analysis. However in some cases an operator might appear to be incorrect, but is actually correct and reflects unusual logic within the program.", "Potential_Mitigations": "", "Demonstrative_Examples": "The following C/C++ and C# examples attempt to validate an int input parameter against the integer value 100.. However, the expression to be evaluated in the if statement uses the assignment operator \"=\" rather than the comparison operator \"==\". The result of using the assignment operator instead of the comparison operator causes the int variable to be reassigned locally and the expression in the if statement will always evaluate to the value on the right hand side of the expression. This will result in the input value not being properly validated, which can cause unexpected results.The following C/C++ example shows a simple implementation of a stack that includes methods for adding and removing integer values from the stack. The example uses pointers to add and remove integer values to the stack array variable.. The push method includes an expression to assign the integer value to the location in the stack pointed to by the pointer variable.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "670", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "481", "Name": "Assigning instead of Comparing", "Description": "Place constants on the left. If one attempts to assign a constant with a variable, the compiler will produce an error.", "Extended_Description": "In many languages the compare statement is very close in appearance to the assignment statement and are often confused. This bug is generally the result of a typo and usually causes obvious problems with program execution. If the comparison is in an if statement, the if statement will usually evaluate the value of the right-hand side of the predicate.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Testing : Many IDEs and static analysis products will detect this problem.Implementation : Place constants on the left. If one attempts to assign a constant with a variable, the compiler will produce an error.", "Demonstrative_Examples": "The following C/C++ and C# examples attempt to validate an int input parameter against the integer value 100.. However, the expression to be evaluated in the if statement uses the assignment operator \"=\" rather than the comparison operator \"==\". The result of using the assignment operator instead of the comparison operator causes the int variable to be reassigned locally and the expression in the if statement will always evaluate to the value on the right hand side of the expression. This will result in the input value not being properly validated, which can cause unexpected results.. In this example, we show how assigning instead of comparing can impact code when values are being passed by reference instead of by value. Consider a scenario in which a string is being processed from user input. Assume the string has already been formatted such that different user inputs are concatenated with the colon character. When the processString function is called, the test for the colon character will result in an insertion of the colon character instead, adding new input separators. Since the string was passed by reference, the data sentinels will be inserted in the original string (CWE-464), and further processing of the inputs will be altered, possibly malformed..The following Java example attempts to perform some processing based on the boolean value of the input parameter. However, the expression to be evaluated in the if statement uses the assignment operator \"=\" rather than the comparison operator \"==\". As with the previous examples, the variable will be reassigned locally and the expression in the if statement will evaluate to true and unintended processing may occur.. While most Java compilers will catch the use of an assignment operator when a comparison operator is required, for boolean variables in Java the use of the assignment operator within an expression is allowed. If possible, try to avoid using comparison operators on boolean variables in java. Instead, let the values of the variables stand for themselves, as in the following code.. The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "480", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "697", "View_ID": "1000", "Ordinal": null}]}, {"ID": "482", "Name": "Comparing instead of Assigning", "Description": "Many IDEs and static analysis products will detect this problem.", "Extended_Description": "In many languages, the compare statement is very close in appearance to the assignment statement; they are often confused.", "Modes_Of_Introduction": "Implementation: This bug primarily originates from a typo.", "Common_Consequences": "Scopes: AvailabilityIntegrity. Impacts: Unexpected State. Note: The assignment will not take place, which should cause obvious program execution problems.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Testing : Many IDEs and static analysis products will detect this problem.", "Demonstrative_Examples": ". The following example demonstrates the weakness.The following C/C++ example shows a simple implementation of a stack that includes methods for adding and removing integer values from the stack. The example uses pointers to add and remove integer values to the stack array variable.. The push method includes an expression to assign the integer value to the location in the stack pointed to by the pointer variable.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "480", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "483", "Name": "Incorrect Block Delimitation", "Description": "Always use explicit block delimitation and use static-analysis technologies to enforce this practice.", "Extended_Description": "In some languages, braces (or other delimiters) are optional for blocks. When the delimiter is omitted, it is possible to insert a logic error in which a statement is thought to be in a block but is not. In some cases, the logic error can have security implications.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Alter Execution Logic. Note: This is a general logic error which will often lead to obviously-incorrect behaviors that are quickly noticed and fixed. In lightly tested or untested code, this error may be introduced it into a production environment and provide additional attack vectors by creating a control flow path leading to an unexpected state in the application. The consequences will depend on the types of behaviors that are being incorrectly executed.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Always use explicit block delimitation and use static-analysis technologies to enforce this practice.", "Demonstrative_Examples": "In this example, the programmer has indented the statements to call Do_X() and Do_Y(), as if the intention is that these functions are only called when the condition is true. However, because there are no braces to signify the block, Do_Y() will always be executed, even if the condition is false.. This might not be what the programmer intended. When the condition is critical for security, such as in making a security decision or detecting a critical error, this may produce a vulnerability.In this example, the programmer has indented the Do_Y() statement as if the intention is that the function should be associated with the preceding conditional and should only be called when the condition is true. However, because Do_X() was called on the same line as the conditional and there are no braces to signify the block, Do_Y() will always be executed, even if the condition is false.. This might not be what the programmer intended. When the condition is critical for security, such as in making a security decision or detecting a critical error, this may produce a vulnerability.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "670", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "484", "Name": "Omitted Break Statement in Switch", "Description": "The functionality of omitting a break statement could be clarified with an if statement. This method is much safer.", "Extended_Description": "This can lead to critical code executing in situations where it should not.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Alter Execution Logic. Note: This weakness can cause unintended logic to be executed and other unexpected application behavior.", "Detection_Methods": "Method Name: White Box. Description: Omission of a break statement might be intentional, in order to support fallthrough. Automated detection methods might therefore be erroneous. Semantic understanding of expected product behavior is required to interpret whether the code is correct. Method Name: Black Box. Description: Since this weakness is associated with a code construct, it would be indistinguishable from other errors that produce the same behavior. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Omitting a break statement so that one may fall through is often indistinguishable from an error, and therefore should be avoided. If you need to use fall-through capabilities, make sure that you have clearly documented this within the switch statement, and ensure that you have examined all the logical possibilities.Implementation : The functionality of omitting a break statement could be clarified with an if statement. This method is much safer.", "Demonstrative_Examples": "In both of these examples, a message is printed based on the month passed into the function:. Both examples do not use a break statement after each case, which leads to unintended fall-through behavior. For example, calling \"printMessage(10)\" will result in the text \"OctoberNovemberDecember is a great month\" being printed.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "670", "View_ID": "1000", "Ordinal": null}]}, {"ID": "486", "Name": "Comparison of Classes by Name", "Description": "Use class equivalency to determine type. Rather than use the class name to determine if an object is of a given type, use the getClass() method, and == operator.", "Extended_Description": "If the decision to trust the methods and data of an object is based on the name of a class, it is possible for malicious users to send objects of the same name as trusted classes and thereby gain the trust afforded to known classes and types.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: If a product relies solely on the name of an object to determine identity, it may execute the incorrect or unintended code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Use class equivalency to determine type. Rather than use the class name to determine if an object is of a given type, use the getClass() method, and == operator.", "Demonstrative_Examples": "In this example, the expression in the if statement compares the class of the inputClass object to a trusted class by comparing the class names.. However, multiple classes can have the same name therefore comparing an object's class by name can allow untrusted classes of the same name as the trusted class to be use to execute unintended or incorrect code. To compare the class of an object to the intended class the getClass() method and the comparison operator \"==\" should be used to ensure the correct trusted class is used, as shown in the following example.In this example, the Java class, TrustedClass, overrides the equals method of the parent class Object to determine equivalence of objects of the class. The overridden equals method first determines if the object, obj, is the same class as the TrustedClass object and then compares the object's fields to determine if the objects are equivalent.. However, the equals method compares the class names of the object, obj, and the TrustedClass object to determine if they are the same class. As with the previous example using the name of the class to compare the class of objects can lead to the execution of unintended or incorrect code if the object passed to the equals method is of another class with the same name. To compare the class of an object to the intended class, the getClass() method and the comparison operator \"==\" should be used to ensure the correct trusted class is used, as shown in the following example.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1025", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "487", "Name": "Reliance on Package-level Scope", "Description": "Data should be private static and final whenever possible. This will assure that your code is protected by instantiating early, preventing access and tampering.", "Extended_Description": "The purpose of package scope is to prevent accidental access by other parts of a program. This is an ease-of-software-development feature but not a security feature.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Any data in a Java package can be accessed outside of the Java framework if the package is distributed.Scopes: Integrity. Impacts: Modify Application Data. Note: The data in a Java class can be modified by anyone outside of the Java framework if the packages is distributed.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Data should be private static and final whenever possible. This will assure that your code is protected by instantiating early, preventing access and tampering.", "Demonstrative_Examples": ". The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "488", "Name": "Exposure of Data Element to Wrong Session", "Description": "In a multithreading environment, storing user data in Servlet member fields introduces a data access race condition. Do not use member fields to store information in the Servlet.", "Extended_Description": "Data can \"bleed\" from one session to another through member variables of singleton objects, such as Servlets, and objects from a shared pool.In the case of Servlets, developers sometimes do not understand that, unless a Servlet implements the SingleThreadModel interface, the Servlet is a singleton; there is only one instance of the Servlet, and that single instance is used and re-used to handle multiple requests that are processed simultaneously by different threads. A common result is that developers use Servlet member fields in such a way that one user may inadvertently see another user's data. In other words, storing user data in Servlet member fields introduces a data access race condition.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Protect the application's sessions from information leakage. Make sure that a session's data is not used or visible by other sessions.Testing : Use a static analysis tool to scan the code for information leakage vulnerabilities (e.g. Singleton Member Field).Architecture and Design : In a multithreading environment, storing user data in Servlet member fields introduces a data access race condition. Do not use member fields to store information in the Servlet.", "Demonstrative_Examples": "The following Servlet stores the value of a request parameter in a member field and then later echoes the parameter value to the response output stream.. While this code will work perfectly in a single-user environment, if two users access the Servlet at approximately the same time, it is possible for the two request handler threads to interleave in the following way: Thread 1: assign \"Dick\" to name Thread 2: assign \"Jane\" to name Thread 1: print \"Jane, thanks for visiting!\" Thread 2: print \"Jane, thanks for visiting!\" Thereby showing the first user the second user's name.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "49", "Name": "Path Equivalence: 'filename/' (Trailing Slash)", "Description": "The product accepts path input in the form of trailing slash ('filedir/') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "162", "View_ID": "1000", "Ordinal": null}]}, {"ID": "491", "Name": "Public cloneable() Method Without Final ('Object Hijack')", "Description": "Make the cloneable() method final.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Make the cloneable() method final.", "Demonstrative_Examples": ". In this example, a public class \"BankAccount\" implements the cloneable() method which declares \"Object clone(string accountnumber)\":. In the example below, a clone() method is defined without being declared final.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "492", "Name": "Use of Inner Class Containing Sensitive Data", "Description": "Inner Classes do not provide security. Warning: Never reduce the security of the object from an outer class, going to an inner class. If an outer class is final or private, ensure that its inner class is private as well.", "Extended_Description": "Inner classes quietly introduce several security concerns because of the way they are translated into Java bytecode. In Java source code, it appears that an inner class can be declared to be accessible only by the enclosing class, but Java bytecode has no concept of an inner class, so the compiler must transform an inner class declaration into a peer class with package level access to the original outer class. More insidiously, since an inner class can access private fields in its enclosing class, once an inner class becomes a peer class in bytecode, the compiler converts private fields accessed by the inner class into protected fields.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: \"Inner Classes\" data confidentiality aspects can often be overcome.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Using sealed classes protects object-oriented encapsulation paradigms and therefore protects code from being extended in unforeseen ways.Implementation : Inner Classes do not provide security. Warning: Never reduce the security of the object from an outer class, going to an inner class. If an outer class is final or private, ensure that its inner class is private as well.", "Demonstrative_Examples": ". The following Java Applet code mistakenly makes use of an inner class.The following example shows a basic use of inner classes. The class OuterClass contains the private member inner class InnerClass. The private inner class InnerClass includes the method concat that accesses the private member variables of the class OuterClass to output the value of one of the private member variables of the class OuterClass and returns a string that is a concatenation of one of the private member variables of the class OuterClass, the separator input parameter of the method and the private member variable of the class InnerClass.. Although this is an acceptable use of inner classes it demonstrates one of the weaknesses of inner classes that inner classes have complete access to all member variables and methods of the enclosing class even those that are declared private and protected. When inner classes are compiled and translated into Java bytecode the JVM treats the inner class as a peer class with package level access to the enclosing class.In the following example the BankAccount class contains the private member inner class InterestAdder that adds interest to the bank account balance. The start method of the BankAccount class creates an object of the inner class InterestAdder, the InterestAdder inner class implements the ActionListener interface with the method actionPerformed. A Timer object created within the start method of the BankAccount class invokes the actionPerformed method of the InterestAdder class every 30 days to add the interest to the bank account balance based on the interest rate passed to the start method as an input parameter. The inner class InterestAdder needs access to the private member variable balance of the BankAccount class in order to add the interest to the bank account balance.. However as demonstrated in the previous example, because InterestAdder is a non-static member inner class of the BankAccount class, InterestAdder also has access to the private member variables of the BankAccount class - including the sensitive data contained in the private member variables for the bank account owner's name, Social Security number, and the bank account number.In the following Java example a simple applet provides the capability for a user to input a URL into a text field and have the URL opened in a new browser window. The applet contains an inner class that is an action listener for the submit button, when the user clicks the submit button the inner class action listener's actionPerformed method will open the URL entered into the text field in a new browser window. As with the previous examples using inner classes in this manner creates a security risk by exposing private variables and methods. Inner classes create an additional security risk with applets as applets are executed on a remote machine through a web browser within the same JVM and therefore may run side-by-side with other potentially malicious code.. As with the previous examples a solution to this problem would be to use a static inner class, a local inner class or an anonymous inner class. An alternative solution would be to have the applet implement the action listener rather than using it as an inner class as shown in the following example.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "493", "Name": "Critical Public Variable Without Final Modifier", "Description": "Declare all public fields as final when possible, especially if it is used to maintain internal state of an Applet or of classes used by an Applet. If a field must be public, then perform all appropriate sanity checks before accessing the field from your code.", "Extended_Description": "If a field is non-final and public, it can be changed once the value is set by any function that has access to the class which contains the field. This could lead to a vulnerability if other parts of the program make assumptions about the contents of that field.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: The object could potentially be tampered with.Scopes: Confidentiality. Impacts: Read Application Data. Note: The object could potentially allow the object to be read.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Declare all public fields as final when possible, especially if it is used to maintain internal state of an Applet or of classes used by an Applet. If a field must be public, then perform all appropriate sanity checks before accessing the field from your code.", "Demonstrative_Examples": "Suppose this WidgetData class is used for an e-commerce web site. The programmer attempts to prevent price-tampering attacks by setting the price of the widget using the constructor.. The price field is not final. Even though the value is set by the constructor, it could be modified by anybody that has access to an instance of WidgetData.Assume the following code is intended to provide the location of a configuration file that controls execution of the application.. While this field is readable from any function, and thus might allow an information leak of a pathname, a more serious problem is that it can be changed by any function.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "494", "Name": "Download of Code Without Integrity Check", "Description": "Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Extended_Description": "An attacker can execute malicious code by compromising the host server, performing DNS spoofing, or modifying the code in transit.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: IntegrityAvailabilityConfidentialityOther. Impacts: Execute Unauthorized Code or CommandsAlter Execution LogicOther. Note: Executing untrusted code could compromise the control flow of the program. The untrusted code could execute attacker-controlled commands, read or modify sensitive resources, or prevent the software from functioning correctly for legitimate users.", "Detection_Methods": "Method Name: Manual Analysis. Description: This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.Specifically, manual static analysis is typically required to find the behavior that triggers the download of code, and to determine whether integrity-checking methods are in use. Method Name: Black Box. Description: Use monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.Attach the monitor to the process and also sniff the network connection. Trigger features related to product updates or plugin installation, which is likely to force a code download. Monitor when files are downloaded and separately executed, or if they are otherwise read back into the process. Look for evidence of cryptographic library calls that use integrity checking. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Perform proper forward and reverse DNS lookups to detect DNS spoofing.Architecture and Design : Encrypt the code with a reliable encryption scheme before transmitting.\n                  This will only be a partial solution, since it will not detect DNS spoofing and it will not prevent your code from being modified on the hosting site.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Speficially, it may be helpful to use tools or frameworks to perform integrity checking on the transmitted code.\n                     \n                        When providing the code that is to be downloaded, such as for automatic updates of the software, then use cryptographic signatures for the code and modify the download clients to verify the signatures. Ensure that the implementation does not contain CWE-295, CWE-320, CWE-347, and related weaknesses.\n                        Use code signing technologies such as Authenticode. See references [REF-454] [REF-455] [REF-456].Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Demonstrative_Examples": "This example loads an external class from a local subdirectory.. This code does not ensure that the class loaded is the intended one, for example by verifying the class's checksum. An attacker may be able to modify the class file to execute malicious code.This code includes an external script to get database credentials, then authenticates a user against the database, allowing access to the application.. This code does not verify that the external domain accessed is the intended one. An attacker may somehow cause the external domain name to resolve to an attack server, which would provide the information for a false database. The attacker may then steal the usernames and encrypted passwords from real user login attempts, or simply allow themself to access the application without a real user account.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "79", "View_ID": "1000", "Ordinal": null}]}, {"ID": "495", "Name": "Private Data Structure Returned From A Public Method", "Description": "Use public setter methods that govern how a private member can be modified.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: The contents of the data structure can be modified from outside the intended scope.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Declare the method private.Implementation : Clone the member data and keep an unmodified version of the data private to the object.Implementation : Use public setter methods that govern how a private member can be modified.", "Demonstrative_Examples": ". Here, a public method in a Java class returns a reference to a private array. Given that arrays in Java are mutable, any modifications made to the returned reference would be reflected in the original private array.. In this example, the Color class defines functions that return non-const references to private members (an array type and an integer type), which are then arbitrarily altered from outside the control of the class.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "496", "Name": "Public Data Assigned to Private Array-Typed Field", "Description": "Do not allow objects to modify private members of a class.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: The contents of the array can be modified from outside the intended scope.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Do not allow objects to modify private members of a class.", "Demonstrative_Examples": ". In the example below, the setRoles() method assigns a publically-controllable array to a private field, thus allowing the caller to modify the private array directly by virtue of the fact that arrays in Java are mutable.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "498", "Name": "Cloneable Class Containing Sensitive Information", "Description": "If you do make your classes clonable, ensure that your clone method is final and throw super.clone().", "Extended_Description": "Cloneable classes are effectively open classes, since data cannot be hidden in them. Classes that do not explicitly deny cloning can be cloned by any other class without running the constructor.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: A class that can be cloned can be produced without executing the constructor. This is dangerous since the constructor may perform security-related checks. By allowing the object to be cloned, those checks may be bypassed.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : If you do make your classes clonable, ensure that your clone method is final and throw super.clone().", "Demonstrative_Examples": "The following example demonstrates the weakness.. Make classes uncloneable by defining a clone function like:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "200", "View_ID": "1000", "Ordinal": null}]}, {"ID": "499", "Name": "Serializable Class Containing Sensitive Data", "Description": "Make sure to prevent serialization of your objects.", "Extended_Description": "Serializable classes are effectively open classes since data cannot be hidden in them. Classes that do not explicitly deny serialization can be serialized by any other class, which can then in turn use the data stored inside it.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: an attacker can write out the class to a byte stream, then extract the important data from it.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : In Java, explicitly define final writeObject() to prevent serialization. This is the recommended solution. Define the writeObject() function to throw an exception explicitly denying serialization.Implementation : Make sure to prevent serialization of your objects.", "Demonstrative_Examples": "This code creates a new record for a medical patient:. This object does not explicitly deny serialization, allowing an attacker to serialize an instance of this object and gain a patient's name and Social Security number even though those fields are private.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "200", "View_ID": "1000", "Ordinal": null}]}, {"ID": "5", "Name": "J2EE Misconfiguration: Data Transmission Without Encryption", "Description": "The product configuration should ensure that SSL or an encryption mechanism of equivalent strength and vetted reputation is used for all access-controlled pages.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : The product configuration should ensure that SSL or an encryption mechanism of equivalent strength and vetted reputation is used for all access-controlled pages.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "319", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "50", "Name": "Path Equivalence: '//multiple/leading/slash'", "Description": "The product accepts path input in the form of multiple leading slash ('//multiple/leading/slash') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "161", "View_ID": "1000", "Ordinal": null}]}, {"ID": "500", "Name": "Public Static Field Not Marked Final", "Description": "Make any static fields private and constant.\n                  A constant field is denoted by the keyword 'const' in C/C++ and ' final' in Java", "Extended_Description": "Public static variables can be read without an accessor and changed without a mutator by any classes in the application.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: The object could potentially be tampered with.Scopes: Confidentiality. Impacts: Read Application Data. Note: The object could potentially allow the object to be read.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Clearly identify the scope for all critical data elements, including whether they should be regarded as static.Implementation : Make any static fields private and constant.\n                  A constant field is denoted by the keyword 'const' in C/C++ and ' final' in Java", "Demonstrative_Examples": "The following examples use of a public static String variable to contain the name of a property/configuration file for the application.. Having a public static variable that is not marked final (constant) may allow the variable to the altered in a way not intended by the application. In this example the String variable can be modified to indicate a different on nonexistent properties file which could cause the application to crash or caused unexpected behavior.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "493", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "501", "Name": "Trust Boundary Violation", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "A trust boundary can be thought of as line drawn through a program. On one side of the line, data is untrusted. On the other side of the line, data is assumed to be trustworthy. The purpose of validation logic is to allow data to safely cross the trust boundary - to move from untrusted to trusted. A trust boundary violation occurs when a program blurs the line between what is trusted and what is untrusted. By combining trusted and untrusted data in the same data structure, it becomes easier for programmers to mistakenly trust unvalidated data.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code accepts an HTTP request and stores the username parameter in the HTTP session object before checking to ensure that the user has been authenticated.. Without well-established and maintained trust boundaries, programmers will inevitably lose track of which pieces of data have been validated and which have not. This confusion will eventually allow some data to be used without first being validated.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "502", "Name": "Deserialization of Untrusted Data", "Description": "Avoid having unnecessary types or gadgets available that can be leveraged for malicious ends. This limits the potential for unintended or unauthorized types and gadgets to be leveraged by the attacker. Add only acceptable classes to an allowlist. Note: new gadgets are constantly being discovered, so this alone is not a sufficient mitigation.", "Extended_Description": "It is often convenient to serialize objects for communication or to save them for later use. However, deserialized data or code can often be modified without using the provided accessor functions if it does not use cryptography to protect itself. Furthermore, any cryptography would still be client-side security -- which is a dangerous security assumption.Data that is untrusted can not be trusted to be well-formed.When developers place no restrictions on \"gadget chains,\" or series of instances and method invocations that can self-execute during the deserialization process (i.e., before the object is returned to the caller), it is sometimes possible for attackers to leverage them to perform unauthorized actions, like generating a shell.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application DataUnexpected State. Note: Attackers can modify unexpected objects or data that was assumed to be safe from modification.Scopes: Availability. Impacts: DoS: Resource Consumption (CPU). Note: If a function is making an assumption on when to terminate, based on a sentry in a string, it could easily never terminate.Scopes: Other. Impacts: Varies by Context. Note: The consequences can vary widely, because it depends on which objects or methods are being deserialized, and how they are used. Making an assumption that the code in the deserialized object is valid is dangerous and can enable exploitation.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : If available, use the signing/sealing features of the programming language to assure that deserialized data has not been tainted. For example, a hash-based message authentication code (HMAC) could be used to ensure that data has not been modified.Implementation : When deserializing data, populate a new object rather than just deserializing. The result is that the data flows through safe input validation and that the functions are safe.Implementation : Explicitly define a final object() to prevent deserialization.Architecture and Design : Make fields transient to protect them from deserialization.\n                  An attempt to serialize and then deserialize a class containing transient fields will result in NULLs where the transient data should be. This is an excellent way to prevent time, environment-based, or sensitive variables from being carried over and used improperly.Implementation : Avoid having unnecessary types or gadgets available that can be leveraged for malicious ends. This limits the potential for unintended or unauthorized types and gadgets to be leveraged by the attacker. Add only acceptable classes to an allowlist. Note: new gadgets are constantly being discovered, so this alone is not a sufficient mitigation.", "Demonstrative_Examples": "This code snippet deserializes an object from a file and uses it as a UI button:. This code does not attempt to verify the source or contents of the file before deserializing it. An attacker may be able to replace the intended file with a file that contains arbitrary malicious code which will be executed when the button is pressed.In Python, the Pickle library handles the serialization and deserialization processes. In this example derived from [REF-467], the code receives and parses data, and afterwards tries to authenticate a user based on validating a token.. Unfortunately, the code does not verify that the incoming data is legitimate. An attacker can construct a illegitimate, serialized object \"AuthToken\" that instantiates one of Python's subprocesses to execute arbitrary commands. For instance,the attacker could construct a pickle that leverages Python's subprocess module, which spawns new processes and includes a number of arguments for various uses. Since Pickle allows objects to define the process for how they should be unpickled, the attacker can direct the unpickle process to call Popen in the subprocess module and execute /bin/sh.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "913", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "913", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "915", "View_ID": "1000", "Ordinal": null}]}, {"ID": "912", "Name": "Hidden Functionality", "Description": "Conduct a code coverage analysis using live testing, then closely inspect any code that is not covered.", "Extended_Description": "Hidden functionality can take many forms, such as intentionally malicious code, \"Easter Eggs\" that contain extraneous functionality such as games, developer-friendly shortcuts that reduce maintenance or support costs such as hard-coded accounts, etc. From a security perspective, even when the functionality is not intentionally malicious or damaging, it can increase the product's attack surface and expose additional weaknesses beyond what is already exposed by the intended functionality. Even if it is not easily accessible, the hidden functionality could be useful for attacks that modify the control flow of the application.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Installation : Always verify the integrity of the product that is being installed.Testing : Conduct a code coverage analysis using live testing, then closely inspect any code that is not covered.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "684", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "506", "Name": "Embedded Malicious Code", "Description": "Remove the malicious code and start an effort to ensure that no more malicious code exists. This may require a detailed review of all code, as it is possible to hide a serious attack in only one or two lines of code. These lines may be located almost anywhere in an application and may have been intentionally obfuscated by the attacker.", "Extended_Description": "Malicious flaws have acquired colorful names, including Trojan horse, trapdoor, timebomb, and logic-bomb. A developer might insert malicious code with the intent to subvert the security of a product or its host system at some time in the future. It generally refers to a program that performs a useful service but exploits rights of the program's user in a way the user does not intend.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Testing : Remove the malicious code and start an effort to ensure that no more malicious code exists. This may require a detailed review of all code, as it is possible to hide a serious attack in only one or two lines of code. These lines may be located almost anywhere in an application and may have been intentionally obfuscated by the attacker.", "Demonstrative_Examples": ". In the example below, a malicous developer has injected code to send credit card numbers to the developer's own email address.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "912", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "507", "Name": "Trojan Horse", "Description": "Verify the integrity of the product that is being installed.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Operation : Most antivirus software scans for Trojan Horses.Installation : Verify the integrity of the product that is being installed.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "506", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "508", "Name": "Non-Replicating Malicious Code", "Description": "Verify the integrity of the software that is being installed.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Operation : Antivirus software can help mitigate known malicious code.Installation : Verify the integrity of the software that is being installed.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "507", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "509", "Name": "Replicating Malicious Code (Virus or Worm)", "Description": "Always verify the integrity of the software that is being installed.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Operation : Antivirus software scans for viruses or worms.Installation : Always verify the integrity of the software that is being installed.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "507", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "51", "Name": "Path Equivalence: '/multiple//internal/slash'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "510", "Name": "Trapdoor", "Description": "Identify and closely inspect the conditions for entering privileged areas of the code, especially those related to authentication, process invocation, and network communications.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Installation : Always verify the integrity of the software that is being installed.Testing : Identify and closely inspect the conditions for entering privileged areas of the code, especially those related to authentication, process invocation, and network communications.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "506", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "511", "Name": "Logic/Time Bomb", "Description": "Conduct a code coverage analysis using live testing, then closely inspect any code that is not covered.", "Extended_Description": "When the time bomb or logic bomb is detonated, it may perform a denial of service such as crashing the system, deleting critical data, or degrading system response time. This bomb might be placed within either a replicating or non-replicating Trojan horse.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Installation : Always verify the integrity of the product that is being installed.Testing : Conduct a code coverage analysis using live testing, then closely inspect any code that is not covered.", "Demonstrative_Examples": ". Typical examples of triggers include system date or time mechanisms, random number generators, and counters that wait for an opportunity to launch their payload. When triggered, a time-bomb may deny service by crashing the system, deleting files, or degrading system response-time.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "506", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "512", "Name": "Spyware", "Description": "Always verify the integrity of the product that is being installed.", "Extended_Description": "\"Spyware\" is a commonly used term with many definitions and interpretations. In general, it is meant to refer to products that collect information or install functionality that human users might not allow if they were fully aware of the actions being taken by the software. For example, a user might expect that tax software would collect a social security number and include it when filing a tax return, but that same user would not expect gaming software to obtain the social security number from that tax software's data.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Operation : Use spyware detection and removal software.Installation : Always verify the integrity of the product that is being installed.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "506", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "515", "Name": "Covert Storage Channel", "Description": "Ensure that all reserved fields are set to zero before messages are sent and that no unnecessary information is included.", "Extended_Description": "Covert storage channels occur when out-of-band data is stored in messages for the purpose of memory reuse. Covert channels are frequently classified as either storage or timing channels. Examples would include using a file intended to hold only audit information to convey user passwords--using the name of a file or perhaps status bits associated with it that can be read by all users to signal the contents of the file. Steganography, concealing information in such a manner that no one but the intended recipient knows of the existence of the message, is a good example of a covert storage channel.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Covert storage channels may provide attackers with important information about the system in question.Scopes: IntegrityConfidentiality. Impacts: Read Application Data. Note: If these messages or packets are sent with unnecessary data contained within, it may tip off malicious listeners as to the process that created the message. With this information, attackers may learn any number of things, including the hardware platform, operating system, or algorithms used by the sender. This information can be of significant value to the user in launching further attacks.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Ensure that all reserved fields are set to zero before messages are sent and that no unnecessary information is included.", "Demonstrative_Examples": ". An excellent example of covert storage channels in a well known application is the ICMP error message echoing functionality. Due to ambiguities in the ICMP RFC, many IP implementations use the memory within the packet for storage or calculation. For this reason, certain fields of certain packets -- such as ICMP error packets which echo back parts of received messages -- may contain flaws or extra information which betrays information about the identity of the target operating system. This information is then used to build up evidence to decide the environment of the target. This is the first crucial step in determining if a given system is vulnerable to a particular flaw and what changes must be made to malicious code to mount a successful attack.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "514", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "52", "Name": "Path Equivalence: '/multiple/trailing/slash//'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "163", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "289", "View_ID": "1000", "Ordinal": null}]}, {"ID": "520", "Name": ".NET Misconfiguration: Use of Impersonation", "Description": "Run the application with limited privilege to the underlying operating and file system.", "Extended_Description": ".NET server applications can optionally execute using the identity of the user authenticated to the client. The intention of this functionality is to bypass authentication and access control checks within the .NET application code. Authentication is done by the underlying web server (Microsoft Internet Information Service IIS), which passes the authenticated token, or unauthenticated anonymous token, to the .NET application. Using the token to impersonate the client, the application then relies on the settings within the NTFS directories and files to control access. Impersonation enables the application, on the server running the .NET application, to both execute code and access resources in the context of the authenticated and authorized user.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Operation : Run the application with limited privilege to the underlying operating and file system.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "266", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "523", "Name": "Unprotected Transport of Credentials", "Description": "Enforce SSL use for the login page or any page used to transmit user credentials or other sensitive information. Even if the entire site does not use SSL, it MUST use SSL for login. Additionally, to help prevent phishing attacks, make sure that SSL serves the login page. SSL allows the user to verify the identity of the server to which they are connecting. If the SSL serves login page, the user can be certain they are talking to the proper end system. A phishing attack would typically redirect a user to a site that does not have a valid trusted server certificate issued from an authorized supplier.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Operation : Enforce SSL use for the login page or any page used to transmit user credentials or other sensitive information. Even if the entire site does not use SSL, it MUST use SSL for login. Additionally, to help prevent phishing attacks, make sure that SSL serves the login page. SSL allows the user to verify the identity of the server to which they are connecting. If the SSL serves login page, the user can be certain they are talking to the proper end system. A phishing attack would typically redirect a user to a site that does not have a valid trusted server certificate issued from an authorized supplier.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "522", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "312", "View_ID": "1000", "Ordinal": null}]}, {"ID": "524", "Name": "Use of Cache Containing Sensitive Information", "Description": "Consider using encryption in the cache.", "Extended_Description": "Applications may use caches to improve efficiency when communicating with remote entities or performing intensive calculations.  A cache maintains a pool of objects, threads, connections, pages, financial data, passwords, or other resources to minimize the time it takes to initialize and access these resources.  If the cache is accessible to unauthorized actors, attackers can read the cache and obtain this sensitive information.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Protect information stored in cache.Architecture and Design : Do not store unnecessarily sensitive information in the cache.Architecture and Design : Consider using encryption in the cache.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "525", "Name": "Use of Web Browser Cache Containing Sensitive Information", "Description": "Consider using encryption in the cache.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Browsers often store information in a client-side cache, which can leave behind sensitive information for other users to find and exploit, such as passwords or credit card numbers. The locations at most risk include public terminals, such as those in libraries and Internet cafes.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Protect information stored in cache.Architecture and Design : Use a restrictive caching policy for forms and web pages that potentially contain sensitive information.Architecture and Design : Do not store unnecessarily sensitive information in the cache.Architecture and Design : Consider using encryption in the cache.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "524", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "526", "Name": "Cleartext Storage of Sensitive Information in an Environment Variable", "Description": "If the environment variable is not necessary for the desired behavior, then remove it entirely, or clear it to an empty value.", "Extended_Description": "Information stored in an environment variable can be accessible by other processes with the execution context, including child processes that dependencies are executed in, or serverless functions in cloud environments. An environment variable's contents can also be inserted into messages, headers, log files, or other outputs. Often these other dependencies have no need to use the environment variable in question. A weakness that discloses environment variables could expose this information.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Encrypt information stored in the environment variable to protect it from being exposed to an unauthorized user. If encryption is not feasible or is considered too expensive for the business use of the application, then consider using a properly protected configuration file instead of an environment variable. It should be understood that unencrypted information in a config file is also not guaranteed to be protected, but it is still a better choice, because it reduces attack surface related to weaknesses such as CWE-214. In some settings, vaults might be a feasible option for safer data transfer. Users should be notified of the business choice made to not protect the sensitive information through encryption.Implementation : If the environment variable is not necessary for the desired behavior, then remove it entirely, or clear it to an empty value.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "312", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "214", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "527", "Name": "Exposure of Version-Control Repository to an Unauthorized Control Sphere", "Description": "Recommendations include removing any CVS directories and repositories from the production server, disabling the use of remote CVS repositories, and ensuring that the latest CVS patches and version updates have been performed.", "Extended_Description": "Version control repositories such as CVS or git store version-specific metadata and other details within subdirectories. If these subdirectories are stored on a web server or added to an archive, then these could be used by an attacker. This information may include usernames, filenames, path root, IP addresses, and detailed \"diff\" data about how files have been changed - which could reveal source code snippets that were never intended to be made public.", "Modes_Of_Introduction": "Operation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Operation : Recommendations include removing any CVS directories and repositories from the production server, disabling the use of remote CVS repositories, and ensuring that the latest CVS patches and version updates have been performed.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "552", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "528", "Name": "Exposure of Core Dump File to an Unauthorized Control Sphere", "Description": "Protect the core dump files from unauthorized access.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Operation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "System Configuration : Protect the core dump files from unauthorized access.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "552", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "529", "Name": "Exposure of Access Control List Files to an Unauthorized Control Sphere", "Description": "Protect access control list files.", "Extended_Description": "Exposure of these access control list files may give the attacker information about the configuration of the site or system. This information may then be used to bypass the intended security policy or identify trusted systems from which an attack can be launched.", "Modes_Of_Introduction": "Operation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : Protect access control list files.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "552", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "53", "Name": "Path Equivalence: '\\multiple\\\\internal\\backslash'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "165", "View_ID": "1000", "Ordinal": null}]}, {"ID": "530", "Name": "Exposure of Backup File to an Unauthorized Control Sphere", "Description": "Recommendations include implementing a security policy within your organization that prohibits backing up web application source code in the webroot.", "Extended_Description": "Often, older backup files are renamed with an extension such as .~bk to distinguish them from production files. The source code for old files that have been renamed in this manner and left in the webroot can often be retrieved. This renaming may have been performed automatically by the web server, or manually by the administrator.", "Modes_Of_Introduction": "Operation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: At a minimum, an attacker who retrieves this file would have all the information contained in it, whether that be database calls, the format of parameters accepted by the application, or simply information regarding the architectural structure of your site.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Policy : Recommendations include implementing a security policy within your organization that prohibits backing up web application source code in the webroot.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "552", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "540", "Name": "Inclusion of Sensitive Information in Source Code", "Description": "Recommendations include removing this script from the web server and moving it to a location not accessible from the Internet.", "Extended_Description": "There are situations where it is critical to remove source code from an area or server. For example, obtaining Perl source code on a system allows an attacker to understand the logic of the script and extract extremely useful information such as code bugs or logins and passwords.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Recommendations include removing this script from the web server and moving it to a location not accessible from the Internet.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "538", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "531", "Name": "Inclusion of Sensitive Information in Test Code", "Description": "Remove test code before deploying the application into production.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Distribution : Remove test code before deploying the application into production.", "Demonstrative_Examples": ". Examples of common issues with test applications include administrative functions, listings of usernames, passwords or session identifiers and information about the system, server or application configuration.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "540", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "538", "Name": "Insertion of Sensitive Information into Externally-Accessible File or Directory", "Description": "Do not expose file and directory information to the user.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.Operation: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Do not expose file and directory information to the user.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "532", "Name": "Insertion of Sensitive Information into Log File", "Description": "Adjust configurations appropriately when software is transitioned from a debug state to production.", "Extended_Description": "While logging all information may be helpful during development stages, it is important that logging levels be set appropriately before a product ships so that sensitive user data and system information are not accidentally exposed to potential attackers.Different log files may be produced and stored for:", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Logging sensitive user data often provides attackers with an additional, less-protected path to acquiring the information.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Consider seriously the sensitivity of the information written into log files. Do not write secrets into the log files.Distribution : Remove debug log files before deploying the application into production.Operation : Protect log files against unauthorized read/write.Implementation : Adjust configurations appropriately when software is transitioned from a debug state to production.", "Demonstrative_Examples": ". In the following code snippet, a user's full name and credit card number are written to a log file.This code stores location information about the current user:. When the application encounters an exception it will write the user object to the log. Because the user object contains location information, the user's location is also written to the log.In the example below, the method getUserBankAccount retrieves a bank account object from a database using the supplied username and account number to query the database. If an SQLException is raised when querying the database, an error message is created and output to a log file.. The error message that is created includes information about the database query that may contain sensitive information about the database or query logic. In this case, the error message will expose the table name and column names used in the database. This data could be used to simplify other attacks, such as SQL injection (CWE-89) to directly access the database.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "538", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "200", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "535", "Name": "Exposure of Information Through Shell Error Message", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "211", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "536", "Name": "Servlet Runtime Error Message Containing Sensitive Information", "Description": "A servlet error message indicates that there exists an unhandled exception in your web application code and may provide useful information to an attacker.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: The error message may contain the location of the file in which the offending function is located. This may disclose the web root's absolute path as well as give the attacker the location of application files or configuration information. It may even disclose the portion of code that failed. In many cases, an attacker can use the data to launch further attacks against the system.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". The following servlet code does not catch runtime exceptions, meaning that if such an exception were to occur, the container may display potentially dangerous information (such as a full stack trace).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "211", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "537", "Name": "Java Runtime Error Message Containing Sensitive Information", "Description": "Do not expose sensitive error information to the user.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Do not expose sensitive error information to the user.", "Demonstrative_Examples": "In the following Java example the class InputFileRead enables an input file to be read using a FileReader object. In the constructor of this class a default input file path is set to some directory on the local file system and the method setInputFile must be called to set the name of the input file to be read in the default directory. The method readInputFile will create the FileReader object and will read the contents of the file. If the method setInputFile is not called prior to calling the method readInputFile then the File object will remain null when initializing the FileReader object. A Java RuntimeException will be raised, and an error message will be output to the user.. However, the error message output to the user contains information regarding the default directory on the local file system. This information can be exploited and may lead to unauthorized access or use of the system. Any Java RuntimeExceptions that are handled should not expose sensitive information to the user.In the example below, the BankManagerLoginServlet servlet class will process a login request to determine if a user is authorized to use the BankManager Web service. The doPost method will retrieve the username and password from the servlet request and will determine if the user is authorized. If the user is authorized the servlet will go to the successful login page. Otherwise, the servlet will raise a FailedLoginException and output the failed login message to the error page of the service.. However, the output message generated by the FailedLoginException includes the user-supplied password. Even if the password is erroneous, it is probably close to the correct password. Since it is printed to the user's page, anybody who can see the screen display will be able to see the password. Also, if the page is cached, the password might be written to disk.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "211", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "539", "Name": "Use of Persistent Cookies Containing Sensitive Information", "Description": "Do not store sensitive information in persistent cookies.", "Extended_Description": "Cookies are small bits of data that are sent by the web application but stored locally in the browser. This lets the application use the cookie to pass information between pages and store variable information. The web application controls what information is stored in a cookie and how it is used. Typical types of information stored in cookies are session identifiers, personalization and customization information, and in rare cases even usernames to enable automated logins. There are two different types of cookies: session cookies and persistent cookies. Session cookies just live in the browser's memory and are not stored anywhere, but persistent cookies are stored on the browser's hard drive.   This can cause security and privacy issues depending on the information stored in the cookie and how it is accessed.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Do not store sensitive information in persistent cookies.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "552", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "54", "Name": "Path Equivalence: 'filedir\\' (Trailing Backslash)", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "162", "View_ID": "1000", "Ordinal": null}]}, {"ID": "541", "Name": "Inclusion of Sensitive Information in an Include File", "Description": "Protect include files from being exposed.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not store sensitive information in include files.Architecture and Design : Protect include files from being exposed.", "Demonstrative_Examples": "The following code uses an include file to store database credentials:. database.inc", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "540", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "543", "Name": "Use of Singleton Pattern Without Synchronization in a Multithreaded Context", "Description": "Avoid using the double-checked locking pattern in language versions that cannot guarantee thread safety. This pattern may be used to avoid the overhead of a synchronized call, but in certain versions of Java (for example), this has been shown to be unsafe because it still introduces a race condition (CWE-209).", "Extended_Description": "The use of a singleton pattern may not be thread-safe.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use the Thread-Specific Storage Pattern. See References.Implementation : Do not use member fields to store information in the Servlet. In multithreading environments, storing user data in Servlet member fields introduces a data access race condition.Implementation : Avoid using the double-checked locking pattern in language versions that cannot guarantee thread safety. This pattern may be used to avoid the overhead of a synchronized call, but in certain versions of Java (for example), this has been shown to be unsafe because it still introduces a race condition (CWE-209).", "Demonstrative_Examples": "This method is part of a singleton pattern, yet the following singleton() pattern is not thread-safe. It is possible that the method will create two objects instead of only one.. Consider the following course of events:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "820", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "544", "Name": "Missing Standardized Error Handling Mechanism", "Description": "define a strategy for handling errors of different severities, such as fatal errors versus basic log events. Use or create built-in language features, or an external package, that provides an easy-to-use API and define coding standards for the detection and handling of errors.", "Extended_Description": "If the product handles error messages individually, on a one-by-one basis, this is likely to result in inconsistent error handling. The causes of errors may be lost. Also, detailed information about the causes of an error may be unintentionally returned to the user.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : define a strategy for handling errors of different severities, such as fatal errors versus basic log events. Use or create built-in language features, or an external package, that provides an easy-to-use API and define coding standards for the detection and handling of errors.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "755", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "546", "Name": "Suspicious Comment", "Description": "Remove comments that suggest the presence of bugs, incomplete functionality, or weaknesses, before deploying the application.", "Extended_Description": "Many suspicious comments, such as BUG, HACK, FIXME, LATER, LATER2, TODO, in the code indicate missing security functionality and checking. Others indicate code problems that programmers should fix, such as hard-coded variables, error handling, not using stored procedures, and performance issues.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Quality Degradation. Note: Suspicious comments could be an indication that there are problems in the source code that may need to be fixed and is an indication of poor quality. This could lead to further bugs and the introduction of weaknesses.", "Detection_Methods": "", "Potential_Mitigations": "Documentation : Remove comments that suggest the presence of bugs, incomplete functionality, or weaknesses, before deploying the application.", "Demonstrative_Examples": ". The following excerpt demonstrates the use of a suspicious comment in an incomplete code block that may have security repercussions.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "547", "Name": "Use of Hard-coded, Security-relevant Constants", "Description": "Avoid using hard-coded constants. Configuration files offer a more flexible solution.", "Extended_Description": "If the developer does not find all occurrences of the hard-coded constants, an incorrect policy decision may be made if one of the constants is not changed. Making changes to these values will require code changes that may be difficult or impossible once the system is released to the field. In addition, these hard-coded values may become available to attackers if the code is ever disclosed.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Varies by ContextQuality Degradation. Note: The existence of hardcoded constants could cause unexpected behavior and the introduction of weaknesses during code maintenance or when making changes to the code if all occurrences are not modified. The use of hardcoded constants is an indication of poor quality.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Avoid using hard-coded constants. Configuration files offer a more flexible solution.", "Demonstrative_Examples": "The usage of symbolic names instead of hard-coded constants is preferred.. The following is an example of using a hard-coded constant instead of a symbolic name.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1078", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "548", "Name": "Exposure of Information Through Directory Listing", "Description": "Recommendations include restricting access to important directories or files by adopting a need to know requirement for both the document and server root, and turning off features such as Automatic Directory Listings that could expose private files and provide information that could be utilized by an attacker when formulating or conducting an attack.", "Extended_Description": "A directory listing provides an attacker with the complete index of all the resources located inside of the directory. The specific risks and consequences vary depending on which files are listed and accessible.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or Directories. Note: Exposing the contents of a directory can lead to an attacker gaining access to source code or providing useful information for the attacker to devise exploits, such as creation times of files or any information that may be encoded in file names. The directory listing may also compromise private or confidential data.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Recommendations include restricting access to important directories or files by adopting a need to know requirement for both the document and server root, and turning off features such as Automatic Directory Listings that could expose private files and provide information that could be utilized by an attacker when formulating or conducting an attack.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "497", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "549", "Name": "Missing Password Field Masking", "Description": "Recommendations include requiring all password fields in your web application be masked to prevent other users from seeing this information.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Recommendations include requiring all password fields in your web application be masked to prevent other users from seeing this information.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "522", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "55", "Name": "Path Equivalence: '/./' (Single Dot Directory)", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "550", "Name": "Server-generated Error Message Containing Sensitive Information", "Description": "Recommendations include designing and adding consistent error handling mechanisms which are capable of handling any user input to your web application, providing meaningful detail to end-users, and preventing error messages that might provide information useful to an attacker from being displayed.", "Extended_Description": "While error messages in and of themselves are not dangerous, per se, it is what an attacker can glean from them that might cause eventual problems.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Recommendations include designing and adding consistent error handling mechanisms which are capable of handling any user input to your web application, providing meaningful detail to end-users, and preventing error messages that might provide information useful to an attacker from being displayed.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "209", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "551", "Name": "Incorrect Behavior Order: Authorization Before Parsing and Canonicalization", "Description": "URL Inputs should be decoded and canonicalized to the application's current internal representation before being validated and processed for authorization. Make sure that your application does not decode the same input twice. Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "For instance, the character strings /./ and / both mean current directory. If /SomeDirectory is a protected directory and an attacker requests /./SomeDirectory, the attacker may be able to gain access to the resource if /./ is not converted to / before the authorization check is performed.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : URL Inputs should be decoded and canonicalized to the application's current internal representation before being validated and processed for authorization. Make sure that your application does not decode the same input twice. Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "863", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "696", "View_ID": "1000", "Ordinal": null}]}, {"ID": "553", "Name": "Command Shell in Externally Accessible Directory", "Description": "Remove any Shells accessible under the web root folder and children directories.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Installation : Remove any Shells accessible under the web root folder and children directories.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "552", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "554", "Name": "ASP.NET Misconfiguration: Not Using Input Validation Framework", "Description": "Use the ASP.NET validation framework to check all program input before it is processed by the application. Example uses of the validation framework include checking to ensure that:\n                     \n                        Phone number fields contain only valid characters in phone numbers\n                        Boolean values are only \"T\" or \"F\"\n                        Free-form strings are of a reasonable length and composition", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Unexpected State. Note: Unchecked input leads to cross-site scripting, process control, and SQL injection vulnerabilities, among others.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use the ASP.NET validation framework to check all program input before it is processed by the application. Example uses of the validation framework include checking to ensure that:\n                     \n                        Phone number fields contain only valid characters in phone numbers\n                        Boolean values are only \"T\" or \"F\"\n                        Free-form strings are of a reasonable length and composition", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1173", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "555", "Name": "J2EE Misconfiguration: Plaintext Password in Configuration File", "Description": "Use industry standard libraries to encrypt passwords before storage in configuration files.", "Extended_Description": "Storing a plaintext password in a configuration file allows anyone who can read the file to access the password-protected resource, making it an easy target for attackers.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not hardwire passwords into your software.Architecture and Design : Use industry standard libraries to encrypt passwords before storage in configuration files.", "Demonstrative_Examples": ". Below is a snippet from a Java properties file in which the LDAP server password is stored in plaintext.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "260", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "556", "Name": "ASP.NET Misconfiguration: Use of Identity Impersonation", "Description": "Use the least privilege principle.", "Extended_Description": "The use of impersonated credentials allows an ASP.NET application to run with either the privileges of the client on whose behalf it is executing or with arbitrary privileges granted in its configuration.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use the least privilege principle.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "266", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "558", "Name": "Use of getlogin() in Multithreaded Application", "Description": "Use getlogin_r() instead, which is reentrant, meaning that other processes are locked out from changing the username.", "Extended_Description": "The getlogin() function returns a pointer to a string that contains the name of the user associated with the calling process. The function is not reentrant, meaning that if it is called from another process, the contents are not locked out and the value of the string can be changed by another process. This makes it very risky to use because the username can be changed by other processes, so the results of the function cannot be trusted.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Using names for security purposes is not advised. Names are easy to forge and can have overlapping user IDs, potentially causing confusion or impersonation.Implementation : Use getlogin_r() instead, which is reentrant, meaning that other processes are locked out from changing the username.", "Demonstrative_Examples": ". The following code relies on getlogin() to determine whether or not a user is trusted. It is easily subverted.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "663", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "56", "Name": "Path Equivalence: 'filedir*' (Wildcard)", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "155", "View_ID": "1000", "Ordinal": null}]}, {"ID": "687", "Name": "Function Call With Incorrectly Specified Argument Value", "Description": "This might require an understanding of intended program behavior or design to determine whether the value is incorrect.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Manual Static Analysis. Description: This might require an understanding of intended program behavior or design to determine whether the value is incorrect.", "Potential_Mitigations": "", "Demonstrative_Examples": ". This Perl code intends to record whether a user authenticated successfully or not, and to exit if the user fails to authenticate. However, when it calls ReportAuth(), the third argument is specified as 0 instead of 1, so it does not exit.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "628", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "560", "Name": "Use of umask() with chmod-style Argument", "Description": "If you suspect misuse of umask(), you can use grep to spot call instances of umask().", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use umask() with the correct argument.Testing : If you suspect misuse of umask(), you can use grep to spot call instances of umask().", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "687", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "561", "Name": "Dead Code", "Description": "Use a static analysis tool to spot dead code.", "Extended_Description": "Dead code is code that can never be executed in a running program. The surrounding code makes it impossible for a section of code to ever be executed.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Quality Degradation. Note: Dead code that results from code that can never be executed is an indication of problems with the source code that needs to be fixed and is an indication of poor quality.", "Detection_Methods": "Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Implementation : Remove dead code before deploying the application.Testing : Use a static analysis tool to spot dead code.", "Demonstrative_Examples": ". The condition for the second if statement is impossible to satisfy. It requires that the variables be non-null, while on the only path where s can be assigned a non-null value there is a return statement.In the following class, two private methods call each other, but since neither one is ever invoked from anywhere else, they are both dead code.. (In this case it is a good thing that the methods are dead: invoking either one would cause an infinite loop.). The field named glue is not used in the following class. The author of the class has accidentally put quotes around the field name, transforming it into a string constant.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1164", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "562", "Name": "Return of Stack Variable Address", "Description": "Use static analysis tools to spot return of the address of a stack variable.", "Extended_Description": "Because local variables are allocated on the stack, when a program returns a pointer to a local variable, it is returning a stack address. A subsequent function call is likely to re-use this same stack address, thereby overwriting the value of the pointer, which no longer corresponds to the same variable since a function's stack frame is invalidated when it returns. At best this will cause the value of the pointer to change unexpectedly. In many cases it causes the program to crash the next time the pointer is dereferenced.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityIntegrityConfidentiality. Impacts: Read MemoryModify MemoryExecute Unauthorized Code or CommandsDoS: Crash, Exit, or Restart. Note: If the returned stack buffer address is dereferenced after the return, then an attacker may be able to modify or read memory, depending on how the address is used.  If the address is used for reading, then the address itself may be exposed, or the contents that the address points to.  If the address is used for writing, this can lead to a crash and possibly code execution.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Testing : Use static analysis tools to spot return of the address of a stack variable.", "Demonstrative_Examples": ". The following function returns a stack address.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "758", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "672", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "825", "View_ID": "1000", "Ordinal": null}]}, {"ID": "563", "Name": "Assignment to Variable without Use", "Description": "Remove unused variables from the code.", "Extended_Description": "After the assignment, the variable is either assigned another value or goes out of scope. It is likely that the variable is simply vestigial, but it is also possible that the unused variable points out a bug.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Quality DegradationVaries by Context. Note: This weakness could be an indication of a bug in the program or a deprecated variable that was not removed and is an indication of poor quality. This could lead to further bugs and the introduction of weaknesses.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Remove unused variables from the code.", "Demonstrative_Examples": ". The following code excerpt assigns to the variable r and then overwrites the value without using it.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1164", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "89", "Name": "Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection')", "Description": "When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.", "Extended_Description": "Without sufficient removal or quoting of SQL syntax in user-controllable inputs, the generated SQL query can cause those inputs to be interpreted as SQL instead of ordinary user data. This can be used to alter query logic to bypass security checks, or to insert additional statements that modify the back-end database, possibly including execution of system commands.SQL injection has become a common issue with database-driven web sites. The flaw is easily detected, and easily exploited, and as such, any site or product package with even a minimal user base is likely to be subject to an attempted attack of this kind. This flaw depends on the fact that SQL makes no real distinction between the control and data planes.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.Implementation: This weakness typically appears in data-rich applications that save user inputs in a database.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Since SQL databases generally hold sensitive data, loss of confidentiality is a frequent problem with SQL injection vulnerabilities.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If poor SQL commands are used to check user names and passwords, it may be possible to connect to a system as another user with no previous knowledge of the password.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: If authorization information is held in a SQL database, it may be possible to change this information through the successful exploitation of a SQL injection vulnerability.Scopes: Integrity. Impacts: Modify Application Data. Note: Just as it may be possible to read sensitive information, it is also possible to make changes or even delete this information with a SQL injection attack.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.Automated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or do not require any code changes.Automated static analysis might not be able to detect the usage of custom API functions or third-party libraries that indirectly invoke SQL commands, leading to false negatives - especially if the API/library code is not available for analysis. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Analysis. Description: Manual analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. This becomes difficult for weaknesses that must be considered for all inputs, since the attack surface can be too large. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using persistence layers such as Hibernate or Enterprise Java Beans, which can provide significant protection against SQL injection if used properly.Architecture and Design : If available, use structured mechanisms that automatically enforce the separation between data and code. These mechanisms may be able to provide the relevant quoting, encoding, and validation automatically, instead of relying on the developer to provide this capability at every point where output is generated.\n                  Process SQL queries using prepared statements, parameterized queries, or stored procedures. These features should accept parameters or variables and support strong typing. Do not dynamically construct and execute query strings within these features using \"exec\" or similar functionality, since this may re-introduce the possibility of SQL injection. [REF-867]Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n                  Specifically, follow the principle of least privilege when creating user accounts to a SQL database. The database users should only have the minimum privileges necessary to use their account. If the requirements of the system indicate that a user can read and modify their own data, then limit their privileges so they cannot read/write others' data. Use the strictest permissions possible on all database objects, such as execute-only for stored procedures.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n                  Instead of building a new implementation, such features may be available in the database or programming language. For example, the Oracle DBMS_ASSERT package can check or enforce that parameters have certain properties that make them less vulnerable to SQL injection. For MySQL, the mysql_real_escape_string() API function is available in both C and PHP.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When constructing SQL query strings, use stringent allowlists that limit the character set based on the expected value of the parameter in the request. This will indirectly limit the scope of an attack, but this technique is less important than proper output encoding and escaping.\n                  Note that proper output encoding, escaping, and quoting is the most effective solution for preventing SQL injection, although input validation may provide some defense-in-depth. This is because it effectively limits what will appear in output. Input validation will not always prevent SQL injection, especially if you are required to support free-form text fields that could contain arbitrary characters. For example, the name \"O'Reilly\" would likely pass the validation step, since it is a common last name in the English language. However, it cannot be directly inserted into the database because it contains the \"'\" apostrophe character, which would need to be escaped or otherwise handled. In this case, stripping the apostrophe might reduce the risk of SQL injection, but it would produce incorrect behavior because the wrong name would be recorded.\n                  When feasible, it may be safest to disallow meta-characters entirely, instead of escaping them. This will provide some defense in depth. After the data is entered into the database, later processes may neglect to escape meta-characters before use, and you may not have control over those processes.Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.Implementation : Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n                  In the context of SQL Injection, error messages revealing the structure of a SQL query can help attackers tailor successful attack strings.Operation : Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.Operation : When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.", "Demonstrative_Examples": ". In 2008, a large number of web servers were compromised using the same SQL injection attack string. This single string worked against many different programs. The SQL injection was then used to modify the web sites to serve malicious code.The following code dynamically constructs and executes a SQL query that searches for items matching a specified name. The query restricts the items displayed to those where owner matches the user name of the currently-authenticated user.. The query that this code intends to execute follows:This example examines the effects of a different malicious value passed to the query constructed and executed in the previous example.. If an attacker with the user name wiley enters the string:MS SQL has a built in function that enables shell command execution. An SQL injection in such a context could be disastrous. For example, a query of the form:. Where $user_input is taken from an untrusted source.This code intends to print a message summary given the message ID.. The programmer may have skipped any input validation on $id under the assumption that attackers cannot modify the cookie. However, this is easy to do with custom client code or even in the web browser.This example attempts to take a last name provided by a user and enter it into a database.. While the programmer applies an allowlist to the user input, it has shortcomings. First of all, the user is still allowed to provide hyphens, which are used as comment structures in SQL. If a user specifies \"--\" then the remainder of the statement will be treated as a comment, which may bypass security logic. Furthermore, the allowlist permits the apostrophe, which is also a data / command separator in SQL. If a user supplies a name with an apostrophe, they may be able to alter the structure of the whole statement and even change control flow of the program, possibly accessing or modifying confidential information. In this situation, both the hyphen and apostrophe are legitimate characters for a last name and permitting them is required. Instead, a programmer may want to use a prepared statement or apply an encoding routine to the input to prevent any data / directive misinterpretations.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "943", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "564", "Name": "SQL Injection: Hibernate", "Description": "Use vigorous allowlist style checking on any user input that may be used in a SQL command. Rather than escape meta-characters, it is safest to disallow them entirely. Reason: Later use of data that have been entered in the database may neglect to escape meta-characters before use. Narrowly define the set of safe characters based on the expected value of the parameter in the request.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : A non-SQL style database which is not subject to this flaw may be chosen.Architecture and Design : Follow the principle of least privilege when creating user accounts to a SQL database. Users should only have the minimum privileges necessary to use their account. If the requirements of the system indicate that a user can read and modify their own data, then limit their privileges so they cannot read/write others' data.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Implementation : Implement SQL strings using prepared statements that bind variables. Prepared statements that do not bind variables can be vulnerable to attack.Implementation : Use vigorous allowlist style checking on any user input that may be used in a SQL command. Rather than escape meta-characters, it is safest to disallow them entirely. Reason: Later use of data that have been entered in the database may neglect to escape meta-characters before use. Narrowly define the set of safe characters based on the expected value of the parameter in the request.", "Demonstrative_Examples": ". The following code excerpt uses Hibernate's HQL syntax to build a dynamic query that's vulnerable to SQL injection.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "89", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "89", "View_ID": "928", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "89", "View_ID": "1305", "Ordinal": "Primary"}]}, {"ID": "565", "Name": "Reliance on Cookies without Validation and Integrity Checking", "Description": "Protect critical cookies from replay attacks, since cross-site scripting or other attacks may allow attackers to steal a strongly-encrypted cookie that also passes integrity checks. This mitigation applies to cookies that should only be valid during a single transaction or session. By enforcing timeouts, you may limit the scope of an attack. As part of your integrity check, use an unpredictable, server-side value that is not exposed to the client.", "Extended_Description": "Attackers can easily modify cookies, within the browser or by implementing the client-side code outside of the browser. Reliance on cookies without detailed validation and integrity checking can allow attackers to bypass authentication, conduct injection attacks such as SQL injection and cross-site scripting, or otherwise modify inputs in unexpected ways.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: It is dangerous to use cookies to set a user's privileges. The cookie can be manipulated to escalate an attacker's privileges to an administrative level.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Avoid using cookie data for a security-related decision.Implementation : Perform thorough input validation (i.e.: server side validation) on the cookie data if you're going to use it for a security related decision.Architecture and Design : Add integrity checks to detect tampering.Architecture and Design : Protect critical cookies from replay attacks, since cross-site scripting or other attacks may allow attackers to steal a strongly-encrypted cookie that also passes integrity checks. This mitigation applies to cookies that should only be valid during a single transaction or session. By enforcing timeouts, you may limit the scope of an attack. As part of your integrity check, use an unpredictable, server-side value that is not exposed to the client.", "Demonstrative_Examples": "The following code excerpt reads a value from a browser cookie to determine the role of the user.. It is easy for an attacker to modify the \"role\" value found in the locally stored cookie, allowing privilege escalation.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "642", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "602", "View_ID": "1000", "Ordinal": null}]}, {"ID": "602", "Name": "Client-Side Enforcement of Server-Side Security", "Description": "Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Extended_Description": "When the server relies on protection mechanisms placed on the client side, an attacker can modify the client-side behavior to bypass the protection mechanisms, resulting in potentially unexpected interactions between the client and server. The consequences will vary, depending on what the mechanisms are trying to protect.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.Architecture and Design: Consider a product that consists of two or more processes or nodes that must interact closely, such as a client/server model. If the product uses protection schemes in the client in order to defend from attacks against the server, and the server does not use the same schemes, then an attacker could modify the client in a way that bypasses those schemes. This is a fundamental design flaw that is primary to many weaknesses.", "Common_Consequences": "Scopes: Access ControlAvailability. Impacts: Bypass Protection MechanismDoS: Crash, Exit, or Restart. Note: Client-side validation checks can be easily bypassed, allowing malformed or unexpected input to pass into the application, potentially as trusted data. This may lead to unexpected states, behaviors and possibly a resulting crash.Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: Client-side checks for authentication can be easily bypassed, allowing clients to escalate their access levels and perform unintended actions.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n                  Even though client-side checks provide minimal benefits with respect to server-side security, they are still useful. First, they can support intrusion detection. If the server receives input that should have been rejected by the client, then it may be an indication of an attack. Second, client-side error-checking can provide helpful feedback to the user about the expectations for valid input. Third, there may be a reduction in server-side processing time for accidental input errors, although this is typically a small savings.Architecture and Design : If some degree of trust is required between the two entities, then use integrity checking and strong authentication to ensure that the inputs are coming from a trusted source. Design the product so that this trust is managed in a centralized fashion, especially if there are complex or numerous communication channels, in order to reduce the risks that the implementer will mistakenly omit a check in a single code path.Testing : Use dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.Testing : Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.", "Demonstrative_Examples": "This example contains client-side code that checks if the user authenticated successfully before sending a command. The server-side code performs the authentication in one step, and executes the command in a separate step.. CLIENT-SIDE (client.pl)In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors used client-side authentication in their OT products.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "471", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "290", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "300", "View_ID": "1000", "Ordinal": null}]}, {"ID": "639", "Name": "Authorization Bypass Through User-Controlled Key", "Description": "Use encryption in order to make it more difficult to guess other legitimate values of the key or associate a digital signature with the key so that the server can verify that there has been no tampering.", "Extended_Description": "Retrieval of a user record occurs in the system based on some key value that is under user control. The key would typically identify a user-related record stored in the system and would be used to lookup that record for presentation to the user. It is likely that an attacker would have to be an authenticated user in the system. However, the authorization process would not properly check the data access operation to ensure that the authenticated user performing the operation has sufficient entitlements to perform the requested data access, hence bypassing any other authorization checks present in the system.For example, attackers can look at places where user specific data is retrieved (e.g. search screens) and determine whether the key for the item being looked up is controllable externally. The key may be a hidden field in the HTML form field, might be passed as a URL parameter or as an unencrypted cookie variable, then in each of these cases it will be possible to tamper with the key value.One manifestation of this weakness is when a system uses sequential or otherwise easily-guessable session IDs that would allow one user to easily switch to another user's session and read/modify their data.", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: Access control checks for specific user data or functionality can be bypassed.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Horizontal escalation of privilege is possible (one user can view/modify information of another user).Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Vertical escalation of privilege is possible if the user-controlled key is actually a flag that indicates administrator status, allowing the attacker to gain administrative access.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : For each and every data access, ensure that the user has sufficient privilege to access the record that is being requested.Architecture and Design : Make sure that the key that is used in the lookup of a specific user's record is not controllable externally by the user or that any tampering can be detected.Architecture and Design : Use encryption in order to make it more difficult to guess other legitimate values of the key or associate a digital signature with the key so that the server can verify that there has been no tampering.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "863", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "863", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "566", "Name": "Authorization Bypass Through User-Controlled SQL Primary Key", "Description": "Use a parameterized query AND make sure that the accepted values conform to the business rules. Construct your SQL statement accordingly.", "Extended_Description": "When a user can set a primary key to any value, then the user can modify the key to point to unauthorized records.Database access control errors occur when:", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use a standard input validation mechanism to validate all input for length, type, syntax, and business rules before accepting the data. Use an \"accept known good\" validation strategy.Implementation : Use a parameterized query AND make sure that the accepted values conform to the business rules. Construct your SQL statement accordingly.", "Demonstrative_Examples": "The following code uses a parameterized statement, which escapes metacharacters and prevents SQL injection vulnerabilities, to construct and execute a SQL query that searches for an invoice matching the specified identifier [1]. The identifier is selected from a list of all invoices associated with the current authenticated user.. The problem is that the developer has not considered all of the possible values of id. Although the interface generates a list of invoice identifiers that belong to the current user, an attacker can bypass this interface to request any desired invoice. Because the code in this example does not check to ensure that the user has permission to access the requested invoice, it will display any invoice, even if it does not belong to the current user.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "639", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "567", "Name": "Unsynchronized Access to Shared Data in a Multithreaded Context", "Description": "Remove the use of static variables used between servlets. If this cannot be avoided, use synchronized access for these variables.", "Extended_Description": "Within servlets, shared static variables are not protected from concurrent access, but servlets are multithreaded. This is a typical programming mistake in J2EE applications, since the multithreading is handled by the framework. When a shared variable can be influenced by an attacker, one thread could wind up modifying the variable to contain data that is not valid for a different thread that is also using the data within the variable.Note that this weakness is not unique to servlets.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Read Application DataModify Application DataDoS: InstabilityDoS: Crash, Exit, or Restart. Note: If the shared variable contains sensitive data, it may be manipulated or displayed in another user session. If this data is used to control the application, its value can be manipulated to cause the application to crash or perform poorly.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Remove the use of static variables used between servlets. If this cannot be avoided, use synchronized access for these variables.", "Demonstrative_Examples": "The following code implements a basic counter for how many times the page has been accesed.. Consider when two separate threads, Thread A and Thread B, concurrently handle two different requests:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "820", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "488", "View_ID": "1000", "Ordinal": null}]}, {"ID": "568", "Name": "finalize() Method Without super.finalize()", "Description": "Use static analysis tools to spot such issues in your code.", "Extended_Description": "The Java Language Specification states that it is a good practice for a finalize() method to call super.finalize().", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Call the super.finalize() method.Testing : Use static analysis tools to spot such issues in your code.", "Demonstrative_Examples": ". The following method omits the call to super.finalize().", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "459", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "57", "Name": "Path Equivalence: 'fakedir/../realdir/filename'", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "570", "Name": "Expression is Always False", "Description": "Use Static Analysis tools to spot such conditions.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Testing : Use Static Analysis tools to spot such conditions.", "Demonstrative_Examples": "In the following Java example the updateUserAccountOrder() method used within an e-business product ordering/inventory application will validate the product number that was ordered and the user account number. If they are valid, the method will update the product inventory, the user account, and the user order appropriately.. However, the method never sets the isValidAccount variable after initializing it to false so the isValidProduct is mistakenly used twice. The result is that the expression \"isValidProduct && isValidAccount\" will always evaluate to false, so the updateAccountOrder() method will never be invoked. This will create serious problems with the product ordering application since the user account and inventory databases will be updated but the order will not be updated.In the following example, the hasReadWriteAccess method uses bit masks and bit operators to determine if a user has read and write privileges for a particular process. The variable mask is defined as a bit mask from the BIT_READ and BIT_WRITE constants that have been defined. The variable mask is used within the predicate of the hasReadWriteAccess method to determine if the userMask input parameter has the read and write bits set.. However the bit operator used to initialize the mask variable is the AND operator rather than the intended OR operator (CWE-480), this resulted in the variable mask being set to 0. As a result, the if statement will always evaluate to false and never get executed.In the following example, the updateInventory method used within an e-business inventory application will update the inventory for a particular product. This method includes an if statement with an expression that will always evaluate to false. This is a common practice in C/C++ to introduce debugging statements quickly by simply changing the expression to evaluate to true and then removing those debugging statements by changing expression to evaluate to false. This is also a common practice for disabling features no longer needed.. Using this practice for introducing debugging statements or disabling features creates dead code that can cause problems during code maintenance and potentially introduce vulnerabilities. To avoid using expressions that evaluate to false for debugging purposes a logging API or debugging API should be used for the output of debugging messages.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "561", "View_ID": "1000", "Ordinal": null}]}, {"ID": "571", "Name": "Expression is Always True", "Description": "Use Static Analysis tools to spot such conditions.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Testing : Use Static Analysis tools to spot such conditions.", "Demonstrative_Examples": "In the following Java example the updateInventory() method used within an e-business product ordering/inventory application will check if the input product number is in the store or in the warehouse. If the product is found, the method will update the store or warehouse database as well as the aggregate product database. If the product is not found, the method intends to do some special processing without updating any database.. However, the method never sets the isDelayed variable and instead will always update the isProductAvailable variable to true. The result is that the predicate testing the isProductAvailable boolean will always evaluate to true and therefore always update the product database. Further, since the isDelayed variable is initialized to false and never changed, the expression always evaluates to false and the customer will never be warned of a delay on their product.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "561", "View_ID": "1000", "Ordinal": null}]}, {"ID": "572", "Name": "Call to Thread run() instead of start()", "Description": "Use the start() method instead of the run() method.", "Extended_Description": "In most cases a direct call to a Thread object's run() method is a bug. The programmer intended to begin a new thread of control, but accidentally called run() instead of start(), so the run() method will execute in the caller's thread of control.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Use the start() method instead of the run() method.", "Demonstrative_Examples": ". The following excerpt from a Java program mistakenly calls run() instead of start().", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "821", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "574", "Name": "EJB Bad Practices: Use of Synchronization Primitives", "Description": "Do not use Synchronization Primitives when writing EJBs.", "Extended_Description": "The Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"An enterprise bean must not use thread synchronization primitives to synchronize execution of multiple instances.\" The specification justifies this requirement in the following way: \"This rule is required to ensure consistent runtime semantics because while some EJB containers may use a single JVM to execute all enterprise bean's instances, others may distribute the instances across multiple JVMs.\"", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Do not use Synchronization Primitives when writing EJBs.", "Demonstrative_Examples": "In the following Java example a Customer Entity EJB provides access to customer information in a database for a business application.. However, the customer entity EJB uses the synchronized keyword for the set methods to attempt to provide thread safe synchronization for the member variables. The use of synchronized methods violate the restriction of the EJB specification against the use synchronization primitives within EJBs. Using synchronization primitives may cause inconsistent behavior of the EJB when used within different EJB containers.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "695", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "821", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "575", "Name": "EJB Bad Practices: Use of AWT Swing", "Description": "Do not use AWT/Swing when writing EJBs.", "Extended_Description": "The Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"An enterprise bean must not use the AWT functionality to attempt to output information to a display, or to input information from a keyboard.\" The specification justifies this requirement in the following way: \"Most servers do not allow direct interaction between an application program and a keyboard/display attached to the server system.\"", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not use AWT/Swing when writing EJBs.", "Demonstrative_Examples": "The following Java example is a simple converter class for converting US dollars to Yen. This converter class demonstrates the improper practice of using a stateless session Enterprise JavaBean that implements an AWT Component and AWT keyboard event listener to retrieve keyboard input from the user for the amount of the US dollars to convert to Yen.. This use of the AWT and Swing APIs within any kind of Enterprise JavaBean not only violates the restriction of the EJB specification against using AWT or Swing within an EJB but also violates the intended use of Enterprise JavaBeans to separate business logic from presentation logic.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "695", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "576", "Name": "EJB Bad Practices: Use of Java I/O", "Description": "Do not use Java I/O when writing EJBs.", "Extended_Description": "The Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"An enterprise bean must not use the java.io package to attempt to access files and directories in the file system.\" The specification justifies this requirement in the following way: \"The file system APIs are not well-suited for business components to access data. Business components should use a resource manager API, such as JDBC, to store data.\"", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Do not use Java I/O when writing EJBs.", "Demonstrative_Examples": "The following Java example is a simple stateless Enterprise JavaBean that retrieves the interest rate for the number of points for a mortgage. In this example, the interest rates for various points are retrieved from an XML document on the local file system, and the EJB uses the Java I/O API to retrieve the XML document from the local file system.. This use of the Java I/O API within any kind of Enterprise JavaBean violates the EJB specification by using the java.io package for accessing files within the local filesystem.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "695", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "577", "Name": "EJB Bad Practices: Use of Sockets", "Description": "Do not use Sockets when writing EJBs.", "Extended_Description": "The Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"An enterprise bean must not attempt to listen on a socket, accept connections on a socket, or use a socket for multicast.\" The specification justifies this requirement in the following way: \"The EJB architecture allows an enterprise bean instance to be a network socket client, but it does not allow it to be a network server. Allowing the instance to become a network server would conflict with the basic function of the enterprise bean-- to serve the EJB clients.\"", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not use Sockets when writing EJBs.", "Demonstrative_Examples": "The following Java example is a simple stateless Enterprise JavaBean that retrieves stock symbols and stock values. The Enterprise JavaBean creates a socket and listens for and accepts connections from clients on the socket.. And the following Java example is similar to the previous example but demonstrates the use of multicast socket connections within an Enterprise JavaBean.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "578", "Name": "EJB Bad Practices: Use of Class Loader", "Description": "Do not use the Class Loader when writing EJBs.", "Extended_Description": "The Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"The enterprise bean must not attempt to create a class loader; obtain the current class loader; set the context class loader; set security manager; create a new security manager; stop the JVM; or change the input, output, and error streams.\" The specification justifies this requirement in the following way: \"These functions are reserved for the EJB container. Allowing the enterprise bean to use these functions could compromise security and decrease the container's ability to properly manage the runtime environment.\"", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not use the Class Loader when writing EJBs.", "Demonstrative_Examples": "The following Java example is a simple stateless Enterprise JavaBean that retrieves the interest rate for the number of points for a mortgage. The interest rates for various points are retrieved from an XML document on the local file system, and the EJB uses the Class Loader for the EJB class to obtain the XML document from the local file system as an input stream.. This use of the Java Class Loader class within any kind of Enterprise JavaBean violates the restriction of the EJB specification against obtaining the current class loader as this could compromise the security of the application using the EJB.. An EJB is also restricted from creating a custom class loader and creating a class and instance of a class from the class loader, as shown in the following example.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "579", "Name": "J2EE Bad Practices: Non-serializable Object Stored in Session", "Description": "In order for session replication to work, the values the product stores as attributes in the session must implement the Serializable interface.", "Extended_Description": "A J2EE application can make use of multiple JVMs in order to improve application reliability and performance. In order to make the multiple JVMs appear as a single application to the end user, the J2EE container can replicate an HttpSession object across multiple JVMs so that if one JVM becomes unavailable another can step in and take its place without disrupting the flow of the application. This is only possible if all session data is serializable, allowing the session to be duplicated between the JVMs.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : In order for session replication to work, the values the product stores as attributes in the session must implement the Serializable interface.", "Demonstrative_Examples": ". The following class adds itself to the session, but because it is not serializable, the session can no longer be replicated.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "58", "Name": "Path Equivalence: Windows 8.3 Filename", "Description": "Disable Windows from supporting 8.3 filenames by editing the Windows registry. Preventing 8.3 filenames will not remove previously generated 8.3 filenames.", "Extended_Description": "On later Windows operating systems, a file can have a \"long name\" and a short name that is compatible with older Windows file systems, with up to 8 characters in the filename and 3 characters for the extension. These \"8.3\" filenames, therefore, act as an alternate name for files with long names, so they are useful pathname equivalence manipulations.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : Disable Windows from supporting 8.3 filenames by editing the Windows registry. Preventing 8.3 filenames will not remove previously generated 8.3 filenames.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "41", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "580", "Name": "clone() Method Without super.clone()", "Description": "In some cases, you can eliminate the clone method altogether and use copy constructors.", "Extended_Description": "All implementations of clone() should obtain the new object by calling super.clone(). If a class does not follow this convention, a subclass's clone() method will return an object of the wrong type.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Call super.clone() within your clone() method, when obtaining a new object.Implementation : In some cases, you can eliminate the clone method altogether and use copy constructors.", "Demonstrative_Examples": ". The following two classes demonstrate a bug introduced by not calling super.clone(). Because of the way Kibitzer implements clone(), FancyKibitzer's clone method will return an object of type Kibitzer instead of FancyKibitzer.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": null}]}, {"ID": "581", "Name": "Object Model Violation: Just One of Equals and Hashcode Defined", "Description": "Both Equals() and Hashcode() should be defined.", "Extended_Description": "Java objects are expected to obey a number of invariants related to equality. One of these invariants is that equal objects must have equal hashcodes. In other words, if a.equals(b) == true then a.hashCode() == b.hashCode().", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityOther. Impacts: Other. Note: If this invariant is not upheld, it is likely to cause trouble if objects of this class are stored in a collection. If the objects of the class in question are used as a key in a Hashtable or if they are inserted into a Map or Set, it is critical that equal objects have equal hashcodes.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Both Equals() and Hashcode() should be defined.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "697", "View_ID": "1000", "Ordinal": null}]}, {"ID": "582", "Name": "Array Declared Public, Final, and Static", "Description": "In most situations the array should be made private.", "Extended_Description": "Because arrays are mutable objects, the final constraint requires that the array object itself be assigned only once, but makes no guarantees about the values of the array elements. Since the array is public, a malicious program can change the values stored in the array. As such, in most cases an array declared public, final and static is a bug.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : In most situations the array should be made private.", "Demonstrative_Examples": ". The following Java Applet code mistakenly declares an array public, final and static.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "583", "Name": "finalize() Method Declared Public", "Description": "If you are using finalize() as it was designed, there is no reason to declare finalize() with anything other than protected access.", "Extended_Description": "A product should never call finalize explicitly, except to call super.finalize() inside an implementation of finalize(). In mobile code situations, the otherwise error prone practice of manual garbage collection can become a security threat if an attacker can maliciously invoke a finalize() method because it is declared with public access.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : If you are using finalize() as it was designed, there is no reason to declare finalize() with anything other than protected access.", "Demonstrative_Examples": "The following Java Applet code mistakenly declares a public finalize() method.. Mobile code, in this case a Java Applet, is code that is transmitted across a network and executed on a remote machine. Because mobile code developers have little if any control of the environment in which their code will execute, special security concerns become relevant. One of the biggest environmental threats results from the risk that the mobile code will run side-by-side with other, potentially malicious, mobile code. Because all of the popular web browsers execute code from multiple sources together in the same JVM, many of the security guidelines for mobile code are focused on preventing manipulation of your objects' state and behavior by adversaries who have access to the same virtual machine where your product is running.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "584", "Name": "Return Inside Finally Block", "Description": "Do not use a return statement inside the finally block. The finally block should have \"cleanup\" code.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Do not use a return statement inside the finally block. The finally block should have \"cleanup\" code.", "Demonstrative_Examples": ". In the following code excerpt, the IllegalArgumentException will never be delivered to the caller. The finally block will cause the exception to be discarded.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "705", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "585", "Name": "Empty Synchronized Block", "Description": "When you come across an empty synchronized statement, or a synchronized statement in which the code has been commented out, try to determine what the original intentions were and whether or not the synchronized block is still necessary.", "Extended_Description": "An empty synchronized block does not actually accomplish any synchronization and may indicate a troubled section of code. An empty synchronized block can occur because code no longer needed within the synchronized block is commented out without removing the synchronized block.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Other. Note: An empty synchronized block will wait until nobody else is using the synchronizer being specified. While this may be part of the desired behavior, because you haven't protected the subsequent code by placing it inside the synchronized block, nothing is stopping somebody else from modifying whatever it was you were waiting for while you run the subsequent code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : When you come across an empty synchronized statement, or a synchronized statement in which the code has been commented out, try to determine what the original intentions were and whether or not the synchronized block is still necessary.", "Demonstrative_Examples": "The following code attempts to synchronize on an object, but does not execute anything in the synchronized block. This does not actually accomplish anything and may be a sign that a programmer is wrestling with synchronization but has not yet achieved the result they intend.. Instead, in a correct usage, the synchronized statement should contain procedures that access or modify data that is exposed to multiple threads. For example, consider a scenario in which several threads are accessing student records at the same time. The method which sets the student ID to a new value will need to make sure that nobody else is accessing this data at the same time and will require synchronization.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1071", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "586", "Name": "Explicit Call to Finalize()", "Description": "Do not make explicit calls to finalize(). Use static analysis tools to spot such instances.", "Extended_Description": "While the Java Language Specification allows an object's finalize() method to be called from outside the finalizer, doing so is usually a bad idea. For example, calling finalize() explicitly means that finalize() will be called more than once: the first time will be the explicit call and the last time will be the call that is made after the object is garbage collected.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Do not make explicit calls to finalize(). Use static analysis tools to spot such instances.", "Demonstrative_Examples": ". The following code fragment calls finalize() explicitly:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1076", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "587", "Name": "Assignment of a Fixed Address to a Pointer", "Description": "Never set a pointer to a fixed address.", "Extended_Description": "Using a fixed address is not portable, because that address will probably not be valid in all environments or platforms.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: If one executes code at a known location, an attacker might be able to inject code there beforehand.Scopes: Availability. Impacts: DoS: Crash, Exit, or RestartReduce MaintainabilityReduce Reliability. Note: If the code is ported to another platform or environment, the pointer is likely to be invalid and cause a crash.Scopes: ConfidentialityIntegrity. Impacts: Read MemoryModify Memory. Note: The data at a known pointer location can be easily read or influenced by an attacker.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Never set a pointer to a fixed address.", "Demonstrative_Examples": "This code assumes a particular function will always be found at a particular address. It assigns a pointer to that address and calls the function.. The same function may not always be found at the same memory address. This could lead to a crash, or an attacker may alter the memory at the expected address, leading to arbitrary code execution.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "344", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "758", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "588", "Name": "Attempt to Access Child of a Non-structure Pointer", "Description": "Review of type casting operations can identify locations where incompatible types are cast.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Memory. Note: Adjacent variables in memory may be corrupted by assignments performed on fields after the cast.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: Execution may end due to a memory access error.", "Detection_Methods": "", "Potential_Mitigations": "Requirements : The choice could be made to use a language that is not susceptible to these issues.Implementation : Review of type casting operations can identify locations where incompatible types are cast.", "Demonstrative_Examples": ". The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "704", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "758", "View_ID": "1000", "Ordinal": null}]}, {"ID": "589", "Name": "Call to Non-ubiquitous API", "Description": "Develop a system to test for API functions that are not portable.", "Extended_Description": "Some functions that offer security features supported by the OS are not available on all versions of the OS in common use. Likewise, functions are often deprecated or made obsolete for security reasons and should not be used.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Always test your code on any platform on which it is targeted to run on.Testing : Test your code on the newest and oldest platform on which it is targeted to run on.Testing : Develop a system to test for API functions that are not portable.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "474", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "762", "Name": "Mismatched Memory Management Routines", "Description": "Use a tool that dynamically detects memory management problems, such as valgrind.", "Extended_Description": "This weakness can be generally described as mismatching memory management routines, such as:When the memory management functions are mismatched, the consequences may be as severe as code execution, memory corruption, or program crash. Consequences and ease of exploit will vary depending on the implementation of the routines and the object being managed.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Only call matching memory management functions. Do not mix and match routines. For example, when you allocate a buffer with malloc(), dispose of the original pointer with free().Implementation : Choose a language or tool that provides automatic memory management, or makes manual memory management less error-prone.\n                  For example, glibc in Linux provides protection against free of invalid pointers.\n                  When using Xcode to target OS X or iOS, enable automatic reference counting (ARC) [REF-391].\n                  To help correctly and consistently manage memory when programming in C++, consider using a smart pointer class such as std::auto_ptr (defined by ISO/IEC ISO/IEC 14882:2003), std::shared_ptr and std::unique_ptr (specified by an upcoming revision of the C++ standard, informally referred to as C++ 1x), or equivalent solutions such as Boost.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, glibc in Linux provides protection against free of invalid pointers.Architecture and Design : Use a language that provides abstractions for memory allocation and deallocation.Testing : Use a tool that dynamically detects memory management problems, such as valgrind.", "Demonstrative_Examples": "This example allocates a BarObj object using the new operator in C++, however, the programmer then deallocates the object using free(), which may lead to unexpected behavior.. Instead, the programmer should have either created the object with one of the malloc family functions, or else deleted the object with the delete operator.. In this example, the program does not use matching functions such as malloc/free, new/delete, and new[]/delete[] to allocate/deallocate the resource.. In this example, the program calls the delete[] function on non-heap memory.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "763", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "590", "Name": "Free of Memory not on the Heap", "Description": "Use a tool that dynamically detects memory management problems, such as valgrind.", "Extended_Description": "When free() is called on an invalid pointer, the program's memory management data structures may become corrupted. This corruption can cause the program to crash or, in some circumstances, an attacker may be able to cause free() to operate on controllable memory locations to modify critical program variables or execute code.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or CommandsModify Memory. Note: There is the potential for arbitrary code execution with privileges of the vulnerable program via a \"write, what where\" primitive. If pointers to memory which hold user information are freed, a malicious user will be able to write 4 bytes anywhere in memory.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Only free pointers that you have called malloc on previously. This is the recommended solution. Keep track of which pointers point at the beginning of valid chunks and free them only once.Implementation : Before freeing a pointer, the programmer should make sure that the pointer was previously allocated on the heap and that the memory belongs to the programmer. Freeing an unallocated pointer will cause undefined behavior in the program.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, glibc in Linux provides protection against free of invalid pointers.Architecture and Design : Use a language that provides abstractions for memory allocation and deallocation.Testing : Use a tool that dynamically detects memory management problems, such as valgrind.", "Demonstrative_Examples": "In this example, an array of record_t structs, bar, is allocated automatically on the stack as a local variable and the programmer attempts to call free() on the array. The consequences will vary based on the implementation of free(), but it will not succeed in deallocating the memory.. This example shows the array allocated globally, as part of the data segment of memory and the programmer attempts to call free() on the array.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "762", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "123", "View_ID": "1000", "Ordinal": null}]}, {"ID": "591", "Name": "Sensitive Data Storage in Improperly Locked Memory", "Description": "Check return values to ensure locking operations are successful.", "Extended_Description": "On Windows systems the VirtualLock function can lock a page of memory to ensure that it will remain present in memory and not be swapped to disk. However, on older versions of Windows, such as 95, 98, or Me, the VirtualLock() function is only a stub and provides no protection. On POSIX systems the mlock() call ensures that a page will stay resident in memory but does not guarantee that the page will not appear in the swap. Therefore, it is unsuitable for use as a protection mechanism for sensitive data. Some platforms, in particular Linux, do make the guarantee that the page will not be swapped, but this is non-standard and is not portable. Calls to mlock() also require supervisor privilege. Return values for both of these calls must be checked to ensure that the lock operation was actually successful.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Memory. Note: Sensitive data that is written to a swap file may be exposed.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Identify data that needs to be protected from swapping and choose platform-appropriate protection mechanisms.Implementation : Check return values to ensure locking operations are successful.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "413", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "593", "Name": "Authentication Bypass: OpenSSL CTX Object Modified after SSL Objects are Created", "Description": "Applications should set up an SSL_CTX completely, before creating SSL objects from it.", "Extended_Description": "If the program modifies the SSL_CTX object after creating SSL objects from it, there is the possibility that older SSL objects created from the original context could all be affected by that change.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: No authentication takes place in this process, bypassing an assumed protection of encryption.Scopes: Confidentiality. Impacts: Read Application Data. Note: The encrypted communication between a user and a trusted host may be subject to a sniffing attack.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use a language or a library that provides a cryptography framework at a higher level of abstraction.Implementation : Most SSL_CTX functions have SSL counterparts that act on SSL-type objects.Implementation : Applications should set up an SSL_CTX completely, before creating SSL objects from it.", "Demonstrative_Examples": ". The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "666", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": null}]}, {"ID": "594", "Name": "J2EE Framework: Saving Unserializable Objects to Disk", "Description": "All objects that become part of session and application scope must implement the java.io.Serializable interface to ensure serializability of containing objects.", "Extended_Description": "In heavy load conditions, most J2EE application frameworks flush objects to disk to manage memory requirements of incoming requests. For example, session scoped objects, and even application scoped objects, are written to disk when required. While these application frameworks do the real work of writing objects to disk, they do not enforce that those objects be serializable, thus leaving the web application vulnerable to crashes induced by serialization failure. An attacker may be able to mount a denial of service attack by sending enough requests to the server to force the web application to save objects to disk.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: Data represented by unserializable objects can be corrupted.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: Non-serializability of objects can lead to system crash.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : All objects that become part of session and application scope must implement the java.io.Serializable interface to ensure serializability of containing objects.", "Demonstrative_Examples": "In the following Java example, a Customer Entity JavaBean provides access to customer information in a database for a business application. The Customer Entity JavaBean is used as a session scoped object to return customer information to a Session EJB.. However, the Customer Entity JavaBean is an unserialized object which can cause serialization failure and crash the application when the J2EE container attempts to write the object to the system. Session scoped objects must implement the Serializable interface to ensure that the objects serialize properly.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "710", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "597", "Name": "Use of Wrong Operator in String Comparison", "Description": "Within Java, use .equals() to compare string values.\n               Within JavaScript, use == to compare string values.\n               Within PHP, use == to compare a numeric value to a string value. (PHP converts the string to a number.)", "Extended_Description": "In Java, using == or != to compare two strings for equality actually compares two objects for equality rather than their string values for equality. Chances are good that the two references will never be equal. While this weakness often only affects program correctness, if the equality is used for a security decision, the unintended comparison result could be leveraged to affect program security.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Within Java, use .equals() to compare string values.\n               Within JavaScript, use == to compare string values.\n               Within PHP, use == to compare a numeric value to a string value. (PHP converts the string to a number.)", "Demonstrative_Examples": "In the example below, two Java String objects are declared and initialized with the same string values. An if statement is used to determine if the strings are equivalent.. However, the if statement will not be executed as the strings are compared using the \"==\" operator. For Java objects, such as String objects, the \"==\" operator compares object references, not object values. While the two String objects above contain the same string values, they refer to different object references, so the System.out.println statement will not be executed. To compare object values, the previous code could be modified to use the equals method:In the example below, three JavaScript variables are declared and initialized with the same values. Note that JavaScript will change a value between numeric and string as needed, which is the reason an integer is included with the strings. An if statement is used to determine whether the values are the same.. However, the body of the if statement will not be executed, as the \"===\" compares both the type of the variable AND the value. As the types of the first comparison are number and string, it fails. The types in the second are int and reference, so this one fails as well. The types in the third are reference and string, so it also fails.While the variables above contain the same values, they are contained in different types, so the document.getElementById... statement will not be executed in any of the cases.To compare object values, the previous code is modified and shown below to use the \"==\" for value comparison so the comparison in this example executes the HTML statement:In the example below, two PHP variables are declared and initialized with the same numbers - one as a string, the other as an integer. Note that PHP will change the string value to a number for a comparison. An if statement is used to determine whether the values are the same.. However, the body of the if statement will not be executed, as the \"===\" compares both the type of the variable AND the value. As the types of the first comparison are number and string, it fails.While the variables above contain the same values, they are contained in different types, so the TRUE portion of the if statement will not be executed.To compare object values, the previous code is modified and shown below to use the \"==\" for value comparison (string converted to number) so the comparison in this example executes the TRUE statement:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "595", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "595", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "480", "View_ID": "1000", "Ordinal": null}]}, {"ID": "598", "Name": "Use of GET Request Method With Sensitive Query Strings", "Description": "When sensitive information is sent, use the POST method (e.g. registration form).", "Extended_Description": "The query string for the URL could be saved in the browser's history, passed through Referers to other web sites, stored in web logs, or otherwise recorded in other sources.  If the query string contains sensitive information such as session identifiers, then attackers can use this information to launch further attacks.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: At a minimum, attackers can garner information from query strings that can be utilized in escalating their method of attack, such as information about the internal workings of the application or database column names. Successful exploitation of query string parameter vulnerabilities could lead to an attacker impersonating a legitimate user, obtaining proprietary data, or simply executing actions not intended by the application developers.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : When sensitive information is sent, use the POST method (e.g. registration form).", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "201", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "599", "Name": "Missing Validation of OpenSSL Certificate", "Description": "Understand and properly implement all checks necessary to ensure the identity of entities involved in encrypted communications.", "Extended_Description": "This could allow an attacker to use an invalid certificate to claim to be a trusted host, use expired certificates, or conduct other attacks that could be detected if the certificate is properly validated.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: The data read may not be properly secured, it might be viewed by an attacker.Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: Trust afforded to the system in question may allow for spoofing or redirection attacks.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: If the certificate is not checked, it may be possible for a redirection or spoofing attack to allow a malicious host with a valid certificate to provide data under the guise of a trusted host. While the attacker in question may have a valid certificate, it may simply be a valid certificate for a different site. In order to ensure data integrity, we must check that the certificate is valid, and that it pertains to the site we wish to access.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Ensure that proper authentication is included in the system design.Implementation : Understand and properly implement all checks necessary to ensure the identity of entities involved in encrypted communications.", "Demonstrative_Examples": "The following OpenSSL code ensures that the host has a certificate.. Note that the code does not call SSL_get_verify_result(ssl), which effectively disables the validation step that checks the certificate.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "295", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "6", "Name": "J2EE Misconfiguration: Insufficient Session-ID Length", "Description": "A lower bound on the number of valid session identifiers that are available to be guessed is the number of users that are active on a site at any given moment. However, any users that abandon their sessions without logging out will increase this number. (This is one of many good reasons to have a short inactive session timeout.) With a 64 bit session identifier, assume 32 bits of entropy. For a large web site, assume that the attacker can try 1,000 guesses per second and that there are 10,000 valid session identifiers at any given moment. Given these assumptions, the expected time for an attacker to successfully guess a valid session identifier is less than 4 minutes. Now assume a 128 bit session identifier that provides 64 bits of entropy. With a very large web site, an attacker might try 10,000 guesses per second with 100,000 valid session identifiers available to be guessed. Given these assumptions, the expected time for an attacker to successfully guess a valid session identifier is greater than 292 years.", "Extended_Description": "If an attacker can guess or steal a session ID, then they may be able to take over the user's session (called session hijacking). The number of possible session IDs increases with increased session ID length, making it more difficult to guess or steal a session ID.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: If an attacker can guess an authenticated user's session identifier, they can take over the user's session.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Session identifiers should be at least 128 bits long to prevent brute-force session guessing. A shorter session identifier leaves the application open to brute-force session guessing attacks.Implementation : A lower bound on the number of valid session identifiers that are available to be guessed is the number of users that are active on a site at any given moment. However, any users that abandon their sessions without logging out will increase this number. (This is one of many good reasons to have a short inactive session timeout.) With a 64 bit session identifier, assume 32 bits of entropy. For a large web site, assume that the attacker can try 1,000 guesses per second and that there are 10,000 valid session identifiers at any given moment. Given these assumptions, the expected time for an attacker to successfully guess a valid session identifier is less than 4 minutes. Now assume a 128 bit session identifier that provides 64 bits of entropy. With a very large web site, an attacker might try 10,000 guesses per second with 100,000 valid session identifiers available to be guessed. Given these assumptions, the expected time for an attacker to successfully guess a valid session identifier is greater than 292 years.", "Demonstrative_Examples": "The following XML example code is a deployment descriptor for a Java web application deployed on a Sun Java Application Server. This deployment descriptor includes a session configuration property for configuring the session ID length.. This deployment descriptor has set the session ID length for this Java web application to 8 bytes (or 64 bits). The session ID length for Java web applications should be set to 16 bytes (128 bits) to prevent attackers from guessing and/or stealing a session ID and taking over a user's session.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "334", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "600", "Name": "Uncaught Exception in Servlet ", "Description": "Implement Exception blocks to handle all types of Exceptions.", "Extended_Description": "When a Servlet throws an exception, the default error response the Servlet container sends back to the user typically includes debugging information. This information is of great value to an attacker. For example, a stack trace might show the attacker a malformed SQL query string, the type of database being used, and the version of the application container. This information enables the attacker to target known vulnerabilities in these components.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Implement Exception blocks to handle all types of Exceptions.", "Demonstrative_Examples": "The following example attempts to resolve a hostname.. A DNS lookup failure will cause the Servlet to throw an exception.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "248", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "209", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "390", "View_ID": "1000", "Ordinal": null}]}, {"ID": "601", "Name": "URL Redirection to Untrusted Site ('Open Redirect')", "Description": "Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.", "Extended_Description": "An http parameter may contain a URL value and could cause the web application to redirect the request to the specified URL. By modifying the URL value to a malicious site, an attacker may successfully launch a phishing scam and steal user credentials. Because the server name in the modified link is identical to the original site, phishing attempts have a more trustworthy appearance. Whether this issue poses a vulnerability will be subject to the intended behavior of the application. For example, a search engine might intentionally provide redirects to arbitrary URLs.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: The user may be redirected to an untrusted page that contains malware which may then compromise the user's machine. This will expose the user to extensive risk and the user's interaction with the web server may also be compromised if the malware conducts keylogging or other attacks that steal credentials, personally identifiable information (PII), or other important data.Scopes: Access ControlConfidentialityOther. Impacts: Bypass Protection MechanismGain Privileges or Assume IdentityOther. Note: The user may be subjected to phishing attacks by being redirected to an untrusted page. The phishing attack may point to an attacker controlled web page that appears to be a trusted web site. The phishers may then steal the user's credentials and then use these credentials to access the legitimate web site.", "Detection_Methods": "Method Name: Manual Static Analysis. Description: Since this weakness does not typically appear frequently within a single software package, manual white box techniques may be able to provide sufficient code coverage and reduction of false positives if all potentially-vulnerable operations can be assessed within limited time constraints. Method Name: Automated Dynamic Analysis. Description: Automated black box tools that supply URLs to every input may be able to spot Location header modifications, but test case coverage is a factor, and custom redirects may not be detected. Method Name: Automated Static Analysis. Description: Automated static analysis tools may not be able to determine whether input influences the beginning of a URL, which is important for reducing false positives. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.) Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  Use a list of approved URLs or domains to be used for redirection.Architecture and Design : Use an intermediate disclaimer page that provides the user with a clear warning that they are leaving the current site. Implement a long timeout before the redirect occurs, or force the user to click on the link. Be careful to avoid XSS problems (CWE-79) when generating the disclaimer page.Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n                  For example, ID 1 could map to \"/login.asp\" and ID 2 could map to \"http://www.example.com/\". Features such as the ESAPI AccessReferenceMap [REF-45] provide this capability.Architecture and Design : Ensure that no externally-supplied requests are honored by requiring that all redirect requests include a unique nonce generated by the application [REF-483]. Be sure that the nonce is not predictable (CWE-330).Architecture and Design : Understand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n                  Many open redirect problems occur because the programmer assumed that certain inputs could not be modified, such as cookies and hidden form fields.Operation : Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.", "Demonstrative_Examples": "The following code obtains a URL from the query string and then redirects the user to that URL.. The problem with the above code is that an attacker could use this page as part of a phishing scam by redirecting users to a malicious site. For example, assume the above code is in the file example.php. An attacker could supply a user with the following link:The following code is a Java servlet that will receive a GET request with a url parameter in the request to redirect the browser to the address specified in the url parameter. The servlet will retrieve the url parameter value from the request and send a response to redirect the browser to the url address.. The problem with this Java servlet code is that an attacker could use the RedirectServlet as part of a e-mail phishing scam to redirect users to a malicious site. An attacker could send an HTML formatted e-mail directing the user to log into their account by including in the e-mail the following link:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "603", "Name": "Use of Client-Side Authentication", "Description": "Do not rely on client side data. Always perform server side authentication.", "Extended_Description": "Client-side authentication is extremely weak and may be breached easily. Any attacker may read the source code and reverse-engineer the authentication mechanism to access parts of the application which would otherwise be protected.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not rely on client side data. Always perform server side authentication.", "Demonstrative_Examples": "In 2022, the OT:ICEFALL study examined products by 10 different Operational Technology (OT) vendors. The researchers reported 56 vulnerabilities and said that the products were \"insecure by design\" [REF-1283]. If exploited, these vulnerabilities often allowed adversaries to change how the products operated, ranging from denial of service to changing the code that the products executed. Since these products were often used in industries such as power, electrical, water, and others, there could even be safety implications.. Multiple vendors used client-side authentication in their OT products.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "602", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "300", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "656", "View_ID": "1000", "Ordinal": null}]}, {"ID": "605", "Name": "Multiple Binds to the Same Port", "Description": "Restrict server socket address to known local addresses.", "Extended_Description": "On most systems, a combination of setting the SO_REUSEADDR socket option, and a call to bind() allows any process to bind to a port to which a previous process has bound with INADDR_ANY. This allows a user to bind to the specific address of a server bound to INADDR_ANY on an unprivileged port, and steal its UDP packets/TCP connection.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrity. Impacts: Read Application Data. Note: Packets from a variety of network services may be stolen or the services spoofed.", "Detection_Methods": "", "Potential_Mitigations": "Policy : Restrict server socket address to known local addresses.", "Demonstrative_Examples": "This code binds a server socket to port 21, allowing the server to listen for traffic on that port.. This code may result in two servers binding a socket to same port, thus receiving each other's traffic. This could be used by an attacker to steal packets meant for another process, such as a secure FTP server.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "675", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "666", "View_ID": "1000", "Ordinal": null}]}, {"ID": "606", "Name": "Unchecked Input for Loop Condition", "Description": "Perform input validation.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Do not use user-controlled data for loop conditions.Implementation : Perform input validation.", "Demonstrative_Examples": ". The following example demonstrates the weakness.In the following C/C++ example the method processMessageFromSocket() will get a message from a socket, placed into a buffer, and will parse the contents of the buffer into a structure that contains the message length and the message body. A for loop is used to copy the message body into a local character string which will be passed to another method for processing.. However, the message length variable from the structure is used as the condition for ending the for loop without validating that the message length variable accurately reflects the length of the message body (CWE-606). This can result in a buffer over-read (CWE-125) by reading from memory beyond the bounds of the buffer if the message length variable indicates a length that is longer than the size of a message body (CWE-130).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1284", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "834", "View_ID": "1000", "Ordinal": null}]}, {"ID": "607", "Name": "Public Static Final Field References Mutable Object", "Description": "Protect mutable objects by making them private. Restrict access to the getter and setter as well.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Protect mutable objects by making them private. Restrict access to the getter and setter as well.", "Demonstrative_Examples": ". Here, an array (which is inherently mutable) is labeled public static final.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "471", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "608", "Name": "Struts: Non-private Field in ActionForm Class", "Description": "Make all fields private. Use getter to get the value of the field. Setter should be used only by the framework; setting an action form field from other actions is bad practice and should be avoided.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Make all fields private. Use getter to get the value of the field. Setter should be used only by the framework; setting an action form field from other actions is bad practice and should be avoided.", "Demonstrative_Examples": "In the following Java example the class RegistrationForm is a Struts framework ActionForm Bean that will maintain user input data from a registration webpage for a online business site. The user will enter registration data and through the Struts framework the RegistrationForm bean will maintain the user data.. However, within the RegistrationForm the member variables for the registration form input data are declared public not private. All member variables within a Struts framework ActionForm class must be declared private to prevent the member variables from being modified without using the getter and setter methods. The following example shows the member variables being declared private and getter and setter methods declared for accessing the member variables.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "609", "Name": "Double-Checked Locking", "Description": "While double-checked locking can be achieved in some languages, it is inherently flawed in Java before 1.5, and cannot be achieved without compromising platform independence. Before Java 1.5, only use of the synchronized keyword is known to work. Beginning in Java 1.5, use of the \"volatile\" keyword allows double-checked locking to work successfully, although there is some debate as to whether it achieves sufficient performance gains. See references.", "Extended_Description": "Double-checked locking refers to the situation where a programmer checks to see if a resource has been initialized, grabs a lock, checks again to see if the resource has been initialized, and then performs the initialization if it has not occurred yet. This should not be done, as it is not guaranteed to work in all languages and on all architectures. In summary, other threads may not be operating inside the synchronous block and are not guaranteed to see the operations execute in the same order as they would appear inside the synchronous block.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : While double-checked locking can be achieved in some languages, it is inherently flawed in Java before 1.5, and cannot be achieved without compromising platform independence. Before Java 1.5, only use of the synchronized keyword is known to work. Beginning in Java 1.5, use of the \"volatile\" keyword allows double-checked locking to work successfully, although there is some debate as to whether it achieves sufficient performance gains. See references.", "Demonstrative_Examples": "It may seem that the following bit of code achieves thread safety while avoiding unnecessary synchronization.... The programmer wants to guarantee that only one Helper() object is ever allocated, but does not want to pay the cost of synchronization every time this code is called.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "367", "View_ID": "1000", "Ordinal": null}]}, {"ID": "61", "Name": "UNIX Symbolic Link (Symlink) Following", "Description": "Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Extended_Description": "A product that allows UNIX symbolic links (symlink) as part of paths whether in internal code or through user input can allow an attacker to spoof the symbolic link and traverse the file system to unintended locations or access arbitrary files. The symbolic link can permit an attacker to read/write/corrupt a file that they originally did not have permissions to access.", "Modes_Of_Introduction": "Implementation: These are typically reported for temporary files or privileged programs.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Symbolic link attacks often occur when a program creates a tmp directory that stores files/links. Access to the directory should be restricted to the program as to prevent attackers from manipulating the files.Architecture and Design : Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "59", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "Requires", "CWE_ID": "362", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "340", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "386", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "732", "View_ID": "1000", "Ordinal": null}]}, {"ID": "611", "Name": "Improper Restriction of XML External Entity Reference", "Description": "Many XML parsers and validators can be configured to disable external entity expansion.", "Extended_Description": "XML documents optionally contain a Document Type Definition (DTD), which, among other features, enables the definition of XML entities. It is possible to define an entity by providing a substitution string in the form of a URI. The XML parser can access the contents of this URI and embed these contents back into the XML document for further processing.By submitting an XML file that defines an external entity with a file:// URI, an attacker can cause the processing application to read the contents of a local file. For example, a URI such as \"file:///c:/winnt/win.ini\" designates (in Windows) the file C:\\Winnt\\win.ini, or file:///etc/passwd designates the password file in Unix-based systems. Using URIs with other schemes such as http://, the attacker can force the application to make outgoing requests to servers that the attacker cannot reach directly, which can be used to bypass firewall restrictions or hide the source of attacks such as port scanning.Once the content of the URI is read, it is fed back into the application that is processing the XML. This application may echo back the data (e.g. in an error message), thereby exposing the file contents.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Files or Directories. Note: If the attacker is able to include a crafted DTD and a default entity resolver is enabled, the attacker may be able to access arbitrary files on the system.Scopes: Integrity. Impacts: Bypass Protection Mechanism. Note: The DTD may include arbitrary HTTP requests that the server may execute. This could lead to other attacks leveraging the server's trust relationship with other entities.Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: The product could consume excessive CPU cycles or memory using a URI that points to a large file, or a device that always returns data such as /dev/random. Alternately, the URI could reference a file that contains many nested or recursive entity references to further slow down parsing.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Many XML parsers and validators can be configured to disable external entity expansion.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "441", "View_ID": "1000", "Ordinal": null}]}, {"ID": "612", "Name": "Improper Authorization of Index Containing Sensitive Information", "Description": "The product creates a search index of private or sensitive documents, but it does not properly limit index access to actors who are authorized to see the original information.", "Extended_Description": "Web sites and other document repositories may apply an indexing routine against a group of private documents to facilitate search.  If the index's results are available to parties who do not have access to the documents being indexed, then attackers could obtain portions of the documents by conducting targeted searches and reading the results.  The risk is especially dangerous if search results include surrounding text that was not part of the search query. This issue can appear in search engines that are not configured (or implemented) to ignore critical files that should remain hidden; even without permissions to download these files directly, the remote user could read them.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1230", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "613", "Name": "Insufficient Session Expiration", "Description": "Set sessions/credentials expiration date.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Set sessions/credentials expiration date.", "Demonstrative_Examples": ". The following snippet was taken from a J2EE web.xml deployment descriptor in which the session-timeout parameter is explicitly defined (the default value depends on the container). In this case the value is set to -1, which means that a session will never expire.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "287", "View_ID": "1000", "Ordinal": null}]}, {"ID": "614", "Name": "Sensitive Cookie in HTTPS Session Without 'Secure' Attribute", "Description": "Always set the secure attribute when the cookie should sent via HTTPS only.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Always set the secure attribute when the cookie should sent via HTTPS only.", "Demonstrative_Examples": ". The snippet of code below, taken from a servlet doPost() method, sets an accountID cookie (sensitive) without calling setSecure(true).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "319", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "615", "Name": "Inclusion of Sensitive Information in Source Code Comments", "Description": "Remove comments which have sensitive information about the design/implementation of the application. Some of the comments may be exposed to the user and affect the security posture of the application.", "Extended_Description": "An attacker who finds these comments can map the application's structure and files, expose hidden parts of the site, and study the fragments of code to reverse engineer the application, which may help develop further attacks against the site.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Distribution : Remove comments which have sensitive information about the design/implementation of the application. Some of the comments may be exposed to the user and affect the security posture of the application.", "Demonstrative_Examples": ". The following comment, embedded in a JSP, will be displayed in the resulting HTML output.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "540", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "546", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "616", "Name": "Incomplete Identification of Uploaded File Variables (PHP)", "Description": "For later PHP versions, reference uploaded files using the $HTTP_POST_FILES or $_FILES variables, and use is_uploaded_file() or move_uploaded_file() to ensure that you are dealing with an uploaded file.", "Extended_Description": "These global variables could be overwritten by POST requests, cookies, or other methods of populating or overwriting these variables. This could be used to read or process arbitrary files by providing values such as \"/etc/passwd\".", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use PHP 4 or later.Architecture and Design : If you must support older PHP versions, write your own version of is_uploaded_file() and run it against $HTTP_POST_FILES['userfile']))Implementation : For later PHP versions, reference uploaded files using the $HTTP_POST_FILES or $_FILES variables, and use is_uploaded_file() or move_uploaded_file() to ensure that you are dealing with an uploaded file.", "Demonstrative_Examples": "As of 2006, the \"four globals\" method is probably in sharp decline, but older PHP applications could have this issue.. In the \"four globals\" method, PHP sets the following 4 global variables (where \"varname\" is application-dependent):\"The global $_FILES exists as of PHP 4.1.0 (Use $HTTP_POST_FILES instead if using an earlier version). These arrays will contain all the uploaded file information.\". ** note: 'userfile' is the field name from the web form; this can vary.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "473", "View_ID": "1000", "Ordinal": null}]}, {"ID": "617", "Name": "Reachable Assertion", "Description": "Perform input validation on user data.", "Extended_Description": "While assertion is good for catching logic errors and reducing the chances of reaching more serious vulnerability conditions, it can still lead to a denial of service.For example, if a server handles multiple simultaneous connections, and an assert() occurs in one single connection that causes all other connections to be dropped, this is a reachable assertion that leads to a denial of service.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: An attacker that can trigger an assert statement can still lead to a denial of service if the relevant code can be triggered by an attacker, and if the scope of the assert() extends beyond the attacker's own session.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Make sensitive open/close operation non reachable by directly user-controlled data (e.g. open/close resources)Implementation : Perform input validation on user data.", "Demonstrative_Examples": ". In the excerpt below, an AssertionError (an unchecked exception) is thrown if the user hasn't entered an email address in an HTML form.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "670", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "670", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "749", "Name": "Exposed Dangerous Method or Function", "Description": "Identify all exposed functionality. Explicitly list all functionality that must be exposed to some user or set of users. Identify which functionality may be:\n                     \n                        accessible to all users\n                        restricted to a small set of privileged users\n                        prevented from being directly accessible at all\n                     \n                  Ensure that the implemented code follows these expectations. This includes setting the appropriate access modifiers where applicable (public, private, protected, etc.) or not marking ActiveX controls safe-for-scripting.", "Extended_Description": "This weakness can lead to a wide variety of resultant weaknesses, depending on the behavior of the exposed method. It can apply to any number of technologies and approaches, such as ActiveX controls, Java functions, IOCTLs, and so on.The exposure can occur in a few different ways:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityAccess ControlOther. Impacts: Gain Privileges or Assume IdentityRead Application DataModify Application DataExecute Unauthorized Code or CommandsOther. Note: Exposing critical functionality essentially provides an attacker with the privilege level of the exposed functionality. This could result in the modification or exposure of sensitive data or possibly even execution of arbitrary code.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : If you must expose a method, make sure to perform input validation on all arguments, limit access to authorized parties, and protect against all possible vulnerabilities.Architecture and Design : Identify all exposed functionality. Explicitly list all functionality that must be exposed to some user or set of users. Identify which functionality may be:\n                     \n                        accessible to all users\n                        restricted to a small set of privileged users\n                        prevented from being directly accessible at all\n                     \n                  Ensure that the implemented code follows these expectations. This includes setting the appropriate access modifiers where applicable (public, private, protected, etc.) or not marking ActiveX controls safe-for-scripting.", "Demonstrative_Examples": "In the following Java example the method removeDatabase will delete the database with the name specified in the input parameter.. The method in this example is declared public and therefore is exposed to any class in the application. Deleting a database should be considered a critical operation within an application and access to this potentially dangerous method should be restricted. Within Java this can be accomplished simply by declaring the method private thereby exposing it only to the enclosing class as in the following example.These Android and iOS applications intercept URL loading within a WebView and perform special actions if a particular URL scheme is used, thus allowing the Javascript within the WebView to communicate with the application:. A call into native code can then be initiated by passing parameters within the URL:This application uses a WebView to display websites, and creates a Javascript interface to a Java object to allow enhanced functionality on a trusted website:. Before Android 4.2 all methods, including inherited ones, are exposed to Javascript when using addJavascriptInterface(). This means that a malicious website loaded within this WebView can use reflection to acquire a reference to arbitrary Java objects. This will allow the website code to perform any action the parent application is authorized to.After Android 4.2, only methods annotated with @JavascriptInterface are available in JavaScript, protecting usage of getClass() by default, as in this example:. This code is not vulnerable to the above attack, but still may expose user info to malicious pages loaded in the WebView. Even malicious iframes loaded within a trusted page may access the exposed interface:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "284", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "618", "Name": "Exposed Unsafe ActiveX Method", "Description": "Where possible, avoid marking the control as safe for scripting.", "Extended_Description": "ActiveX controls can exercise far greater control over the operating system than typical Java or javascript. Exposed methods can be subject to various vulnerabilities, depending on the implemented behaviors of those methods, and whether input validation is performed on the provided arguments. If there is no integrity checking or origin validation, this method could be invoked by attackers.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : If you must expose a method, make sure to perform input validation on all arguments, and protect against all possible vulnerabilities.Architecture and Design : Use code signing, although this does not protect against any weaknesses that are already in the control.Architecture and Design : Where possible, avoid marking the control as safe for scripting.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "749", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "619", "Name": "Dangling Database Cursor ('Cursor Injection')", "Description": "Close cursors immediately after access to them is complete. Ensure that you close cursors if exceptions occur.", "Extended_Description": "For example, an improper dangling cursor could arise from unhandled exceptions. The impact of the issue depends on the cursor's role, but SQL injection attacks are commonly possible.", "Modes_Of_Introduction": "Implementation: This issue is currently reported for unhandled exceptions, but it is theoretically possible any time the programmer does not close the cursor at the proper time.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Close cursors immediately after access to them is complete. Ensure that you close cursors if exceptions occur.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "402", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "62", "Name": "UNIX Hard Link", "Description": "Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Extended_Description": "Failure for a system to check for hard links can result in vulnerability to different types of attacks. For example, an attacker can escalate their privileges if a file used by a privileged program is replaced with a hard link to a sensitive file (e.g. /etc/passwd). When the process opens the file, the attacker can assume the privileges of that process.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "59", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "620", "Name": "Unverified Password Change", "Description": "Do not use \"forgotten password\" functionality. But if you must, ensure that you are only providing information to the actual user, e.g. by using an email address or challenge question that the legitimate user already provided in the past; do not allow the current user to change this identity information until the correct password has been provided.", "Extended_Description": "This could be used by an attacker to change passwords for another user, thus gaining the privileges associated with that user.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : When prompting for a password change, force the user to provide the original password in addition to the new password.Architecture and Design : Do not use \"forgotten password\" functionality. But if you must, ensure that you are only providing information to the actual user, e.g. by using an email address or challenge question that the legitimate user already provided in the past; do not allow the current user to change this identity information until the correct password has been provided.", "Demonstrative_Examples": "This code changes a user's password.. While the code confirms that the requesting user typed the same new password twice, it does not confirm that the user requesting the password change is the same user whose password will be changed. An attacker can request a change of another user's password and gain control of the victim's account.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "914", "Name": "Improper Control of Dynamically-Identified Variables", "Description": "Refactor the code so that internal program variables do not need to be dynamically identified.", "Extended_Description": "Many languages offer powerful features that allow the programmer to access arbitrary variables that are specified by an input string. While these features can offer significant flexibility and reduce development time, they can be extremely dangerous if attackers can modify unintended variables that have security implications.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: An attacker could modify sensitive data or program variables.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : For any externally-influenced input, check the input against an allowlist of internal program variables that are allowed to be modified.Implementation : Refactor the code so that internal program variables do not need to be dynamically identified.", "Demonstrative_Examples": "This code uses the credentials sent in a POST request to login a user.. The call to extract() will overwrite the existing values of any variables defined previously, in this case $isAdmin. An attacker can send a POST request with an unexpected third value \"isAdmin\" equal to \"true\", thus gaining Admin privileges.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "99", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "913", "View_ID": "1000", "Ordinal": null}]}, {"ID": "621", "Name": "Variable Extraction Error", "Description": "In PHP, call extract() with options such as EXTR_SKIP and EXTR_PREFIX_ALL; call import_request_variables() with a prefix argument. Note that these capabilities are not present in all PHP versions.", "Extended_Description": "For example, in PHP, extraction can be used to provide functionality similar to register_globals, a dangerous functionality that is frequently disabled in production systems. Calling extract() or import_request_variables() without the proper arguments could allow arbitrary global variables to be overwritten, including superglobals.Similar functionality is possible in other interpreted languages, including custom languages.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Modify Application Data. Note: An attacker could modify sensitive data or program variables.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use allowlists of variable names that can be extracted.Implementation : Consider refactoring your code to avoid extraction routines altogether.Implementation : In PHP, call extract() with options such as EXTR_SKIP and EXTR_PREFIX_ALL; call import_request_variables() with a prefix argument. Note that these capabilities are not present in all PHP versions.", "Demonstrative_Examples": "This code uses the credentials sent in a POST request to login a user.. The call to extract() will overwrite the existing values of any variables defined previously, in this case $isAdmin. An attacker can send a POST request with an unexpected third value \"isAdmin\" equal to \"true\", thus gaining Admin privileges.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "914", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "471", "View_ID": "1000", "Ordinal": null}]}, {"ID": "622", "Name": "Improper Validation of Function Hook Arguments", "Description": "Drop privileges before invoking such functions, if possible.", "Extended_Description": "Such hooks can be used in defensive software that runs with privileges, such as anti-virus or firewall, which hooks kernel calls. When the arguments are not validated, they could be used to bypass the protection scheme or attack the product itself.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Ensure that all arguments are verified, as defined by the API you are protecting.Architecture and Design : Drop privileges before invoking such functions, if possible.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "623", "Name": "Unsafe ActiveX Control Marked Safe For Scripting", "Description": "After distribution, you can set the kill bit for the control so that it is not accessible from Internet Explorer.", "Extended_Description": "This might allow attackers to use dangerous functionality via a web page that accesses the control, which can lead to different resultant vulnerabilities, depending on the control's behavior.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : During development, do not mark it as safe for scripting.System Configuration : After distribution, you can set the kill bit for the control so that it is not accessible from Internet Explorer.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "267", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "618", "View_ID": "1000", "Ordinal": null}]}, {"ID": "77", "Name": "Improper Neutralization of Special Elements used in a Command ('Command Injection')", "Description": "Assign permissions that prevent the user from accessing/opening privileged files.", "Extended_Description": "Command injection vulnerabilities typically occur when:Many protocols and products have their own custom command language. While OS or shell command strings are frequently discovered and targeted, developers may not realize that these other command languages might also be vulnerable to attacks.Command injection is a common problem with wrapper programs.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: If a malicious user injects a character (such as a semi-colon) that delimits the end of one command and the beginning of another, it may be possible to then insert an entirely new and unrelated command that was not intended to be executed.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : If at all possible, use library calls rather than external processes to recreate the desired functionality.Implementation : If possible, ensure that all external commands called from the program are statically created.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Operation : Run time: Run time policy enforcement may be used in an allowlist fashion to prevent use of any non-sanctioned commands.System Configuration : Assign permissions that prevent the user from accessing/opening privileged files.", "Demonstrative_Examples": "The following simple program accepts a filename as a command line argument and displays the contents of the file back to the user. The program is installed setuid root because it is intended for use as a learning tool to allow system administrators in-training to inspect privileged system files without giving them the ability to modify them or damage the system.. Because the program runs with root privileges, the call to system() also executes with root privileges. If a user specifies a standard filename, the call works as expected. However, if an attacker passes a string of the form \";rm -rf /\", then the call to system() fails to execute cat due to a lack of arguments and then plows on to recursively delete the contents of the root partition.The following code is from an administrative web application designed to allow users to kick off a backup of an Oracle database using a batch-file wrapper around the rman utility and then run a cleanup.bat script to delete some temporary files. The script rmanDB.bat accepts a single command line parameter, which specifies what type of backup to perform. Because access to the database is restricted, the application runs the backup as a privileged user.. The problem here is that the program does not do any validation on the backuptype parameter read from the user. Typically the Runtime.exec() function will not execute multiple commands, but in this case the program first runs the cmd.exe shell in order to run multiple commands with a single call to Runtime.exec(). Once the shell is invoked, it will happily execute multiple commands separated by two ampersands. If an attacker passes a string of the form \"& del c:\\\\dbms\\\\*.*\", then the application will execute this command along with the others specified by the program. Because of the nature of the application, it runs with the privileges necessary to interact with the database, which means whatever command the attacker injects will run with those privileges as well.The following code from a system utility uses the system property APPHOME to determine the directory in which it is installed and then executes an initialization script based on a relative path from the specified directory.. The code above allows an attacker to execute arbitrary commands with the elevated privilege of the application by modifying the system property APPHOME to point to a different path containing a malicious version of INITCMD. Because the program does not validate the value read from the environment, if an attacker can control the value of the system property APPHOME, then they can fool the application into running malicious code and take control of the system.The following code is a wrapper around the UNIX command cat which prints the contents of a file to standard out. It is also injectable:. Used normally, the output is simply the contents of the file requested:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "624", "Name": "Executable Regular Expression Error", "Description": "The regular expression feature in some languages allows inputs to be quoted or escaped before insertion, such as \\Q and \\E in Perl.", "Extended_Description": "Case (2) is possible in the PHP preg_replace() function, and possibly in other languages when a user-controlled input is inserted into a string that is later parsed as a regular expression.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : The regular expression feature in some languages allows inputs to be quoted or escaped before insertion, such as \\Q and \\E in Perl.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "625", "Name": "Permissive Regular Expression", "Description": "When applicable, ensure that the regular expression marks beginning and ending string patterns, such as \"/^string$/\" for Perl.", "Extended_Description": "This effectively causes the regexp to accept substrings that match the pattern, which produces a partial comparison to the target. In some cases, this can lead to other weaknesses. Common errors include:", "Modes_Of_Introduction": "Implementation: This problem is frequently found when the regular expression is used in input validation or security features such as authentication.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : When applicable, ensure that the regular expression marks beginning and ending string patterns, such as \"/^string$/\" for Perl.", "Demonstrative_Examples": "The following code takes phone numbers as input, and uses a regular expression to reject invalid phone numbers.. An attacker could provide an argument such as: \"; ls -l ; echo 123-456\" This would pass the check, since \"123-456\" is sufficient to match the \"\\d+-\\d+\" portion of the regular expression.This code uses a regular expression to validate an IP string prior to using it in a call to the \"ping\" command.. Since the regular expression does not have anchors (CWE-777), i.e. is unbounded without ^ or $ characters, then prepending a 0 or 0x to the beginning of the IP address will still result in a matched regex pattern. Since the ping command supports octal and hex prepended IP addresses, it will use the unexpectedly valid IP address (CWE-1389). For example, \"0x63.63.63.63\" would be considered equivalent to \"99.63.63.63\". As a result, the attacker could potentially ping systems that the attacker cannot reach directly.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "185", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "187", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "184", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "183", "View_ID": "1000", "Ordinal": null}]}, {"ID": "626", "Name": "Null Byte Interaction Error (Poison Null Byte)", "Description": "Remove null bytes from all incoming strings.", "Extended_Description": "A null byte (NUL character) can have different meanings across representations or languages. For example, it is a string terminator in standard C libraries, but Perl and PHP strings do not treat it as a terminator. When two representations are crossed - such as when Perl or PHP invokes underlying C functionality - this can produce an interaction error with unexpected results. Similar issues have been reported for ASP. Other interpreters written in C might also be affected.The poison null byte is frequently useful in path traversal attacks by terminating hard-coded extensions that are added to a filename. It can play a role in regular expression processing in PHP.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Remove null bytes from all incoming strings.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "147", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": null}]}, {"ID": "627", "Name": "Dynamic Variable Evaluation", "Description": "For function names, ensure that you are only calling functions that accept the proper number of arguments, to avoid unexpected null arguments.", "Extended_Description": "The resultant vulnerabilities depend on the behavior of the application, both at the crossover point and in any control/data flow that is reachable by the related variables or functions.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Modify Application DataExecute Unauthorized Code or Commands. Note: An attacker could gain unauthorized access to internal program variables and execute arbitrary code.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Refactor the code to avoid dynamic variable evaluation whenever possible.Implementation : Use only allowlists of acceptable variable or function names.Implementation : For function names, ensure that you are only calling functions that accept the proper number of arguments, to avoid unexpected null arguments.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "914", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "183", "View_ID": "1000", "Ordinal": null}]}, {"ID": "628", "Name": "Function Call with Incorrectly Specified Arguments", "Description": "Make sure your API's are stable before you use them in production code.", "Extended_Description": "There are multiple ways in which this weakness can be introduced, including:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: OtherAccess Control. Impacts: Quality DegradationGain Privileges or Assume Identity. Note: This weakness can cause unintended behavior and can lead to additional weaknesses such as allowing an attacker to gain unintended access to system resources.", "Detection_Methods": "Method Name: Other. Description: Since these bugs typically introduce incorrect behavior that is obvious to users, they are found quickly, unless they occur in rarely-tested code paths. Managing the correct number of arguments can be made more difficult in cases where format strings are used, or when variable numbers of arguments are supported.", "Potential_Mitigations": "Build and Compilation : Once found, these issues are easy to fix. Use code inspection tools and relevant compiler features to identify potential violations. Pay special attention to code that is not likely to be exercised heavily during QA.Architecture and Design : Make sure your API's are stable before you use them in production code.", "Demonstrative_Examples": ". The following PHP method authenticates a user given a username/password combination but is called with the parameters in reverse order.. This Perl code intends to record whether a user authenticated successfully or not, and to exit if the user fails to authenticate. However, when it calls ReportAuth(), the third argument is specified as 0 instead of 1, so it does not exit.. In the following Java snippet, the accessGranted() method is accidentally called with the static ADMIN_ROLES array rather than the user roles.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "573", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "637", "Name": "Unnecessary Complexity in Protection Mechanism (Not Using 'Economy of Mechanism')", "Description": "Avoid complex security mechanisms when simpler ones would meet requirements. Avoid complex data models, and unnecessarily complex operations. Adopt architectures that provide guarantees, simplify understanding through elegance and abstraction, and that can be implemented similarly. Modularize, isolate and do not trust complex code, and apply other secure programming principles on these modules (e.g., least privilege) to mitigate vulnerabilities.", "Extended_Description": "Security mechanisms should be as simple as possible. Complex security mechanisms may engender partial implementations and compatibility problems, with resulting mismatches in assumptions and implemented security. A corollary of this principle is that data specifications should be as simple as possible, because complex data specifications result in complex validation code. Complex tasks and systems may also need to be guarded by complex security checks, so simple systems should be preferred.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid complex security mechanisms when simpler ones would meet requirements. Avoid complex data models, and unnecessarily complex operations. Adopt architectures that provide guarantees, simplify understanding through elegance and abstraction, and that can be implemented similarly. Modularize, isolate and do not trust complex code, and apply other secure programming principles on these modules (e.g., least privilege) to mitigate vulnerabilities.", "Demonstrative_Examples": ". The IPSEC specification is complex, which resulted in bugs, partial implementations, and incompatibilities between vendors.. HTTP Request Smuggling (CWE-444) attacks are feasible because there are not stringent requirements for how illegal or inconsistent HTTP headers should be handled. This can lead to inconsistent implementations in which a proxy or firewall interprets the same data stream as a different set of requests than the end points in that stream.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "64", "Name": "Windows Shortcut Following (.LNK)", "Description": "Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Extended_Description": "The shortcut (file with the .lnk extension) can permit an attacker to read/write a file that they originally did not have permissions to access.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "59", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "640", "Name": "Weak Password Recovery Mechanism for Forgotten Password", "Description": "Assign a new temporary password rather than revealing the original password.", "Extended_Description": "It is common for an application to have a mechanism that provides a means for a user to gain access to their account in the event they forget their password. Very often the password recovery mechanism is weak, which has the effect of making it more likely that it would be possible for a person other than the legitimate system user to gain access to that user's account. Weak password recovery schemes completely undermine a strong password authentication scheme.This weakness may be that the security question is too easy to guess or find an answer to (e.g. because the question is too common, or the answers can be found using social media). Or there might be an implementation weakness in the password recovery mechanism code that may for instance trick the system into e-mailing the new password to an e-mail account other than that of the user. There might be no throttling done on the rate of password resets so that a legitimate user can be denied service by an attacker if an attacker tries to recover their password in a rapid succession. The system may send the original password to the user rather than generating a new temporary password. In summary, password recovery functionality, if not carefully designed and implemented can often become the system's weakest link that can be misused in a way that would allow an attacker to gain unauthorized access to the system.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker could gain unauthorized access to the system by retrieving legitimate user's authentication credentials.Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: An attacker could deny service to legitimate system users by launching a brute force attack on the password recovery mechanism using user ids of legitimate users.Scopes: IntegrityOther. Impacts: Other. Note: The system's security functionality is turned against the system by the attacker.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Make sure that all input supplied by the user to the password recovery mechanism is thoroughly filtered and validated.Architecture and Design : Do not use standard weak security questions and use several security questions.Architecture and Design : Make sure that there is throttling on the number of incorrect answers to a security question. Disable the password recovery functionality after a certain (small) number of incorrect guesses.Architecture and Design : Require that the user properly answers the security question prior to resetting their password and sending the new password to the e-mail address of record.Architecture and Design : Never allow the user to control what e-mail address the new password will be sent to in the password recovery mechanism.Architecture and Design : Assign a new temporary password rather than revealing the original password.", "Demonstrative_Examples": ". A famous example of this type of weakness being exploited is the eBay attack. eBay always displays the user id of the highest bidder. In the final minutes of the auction, one of the bidders could try to log in as the highest bidder three times. After three incorrect log in attempts, eBay password throttling would kick in and lock out the highest bidder's account for some time. An attacker could then make their own bid and their victim would not have a chance to place the counter bid because they would be locked out. Thus an attacker could win the auction.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "99", "Name": "Improper Control of Resource Identifiers ('Resource Injection')", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, it can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "A resource injection issue occurs when the following two conditions are met:This may enable an attacker to access or modify otherwise protected system resources.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrity. Impacts: Read Application DataModify Application DataRead Files or DirectoriesModify Files or Directories. Note: An attacker could gain access to or modify sensitive data or system resources. This could allow access to protected files or directories including configuration files and files containing sensitive information.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, it can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": ". The following Java code uses input from an HTTP request to create a file name. The programmer has not considered the possibility that an attacker could provide a file name such as \"../../tomcat/conf/server.xml\", which causes the application to delete one of its own configuration files.The following code uses input from the command line to determine which file to open and echo back to the user. If the program runs with privileges and malicious users can create soft links to the file, they can use the program to read the first part of any file on the system.. The kind of resource the data affects indicates the kind of content that may be dangerous. For example, data containing special characters like period, slash, and backslash, are risky when used in methods that interact with the file system. (Resource injection, when it is related to file system resources, sometimes goes by the name \"path manipulation.\") Similarly, data that contains URLs and URIs is risky for functions that create remote connections.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "73", "View_ID": "1000", "Ordinal": null}]}, {"ID": "641", "Name": "Improper Restriction of Names for Files and Other Resources", "Description": "Make sure that technologies consuming the resources are not vulnerable (e.g. buffer overflow, format string, etc.) in a way that would allow code execution if the name of the resource is malformed.", "Extended_Description": "This may produce resultant weaknesses. For instance, if the names of these resources contain scripting characters, it is possible that a script may get executed in the client's browser if the application ever displays the name of the resource on a dynamically generated web page. Alternately, if the resources are consumed by some application parser, a specially crafted name can exploit some vulnerability internal to the parser, potentially resulting in execution of arbitrary code on the server machine. The problems will vary based on the context of usage of such malformed resource names and whether vulnerabilities are present in or assumptions are made by the targeted technology that would make code execution possible.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: Execution of arbitrary code in the context of usage of the resources with dangerous names.Scopes: ConfidentialityAvailability. Impacts: Read Application DataDoS: Crash, Exit, or Restart. Note: Crash of the consumer code of these resources resulting in information leakage or denial of service.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Do not allow users to control names of resources used on the server side.Architecture and Design : Perform allowlist input validation at entry points and also before consuming the resources. Reject bad file names rather than trying to cleanse them.Architecture and Design : Make sure that technologies consuming the resources are not vulnerable (e.g. buffer overflow, format string, etc.) in a way that would allow code execution if the name of the resource is malformed.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "99", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "943", "Name": "Improper Neutralization of Special Elements in Data Query Logic", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "Depending on the capabilities of the query language, an attacker could inject additional logic into the query to:The ability to execute additional commands or change which entities are returned has obvious risks. But when the product logic depends on the order or number of entities, this can also lead to vulnerabilities. For example, if the query expects to return only one entity that specifies an administrative user, but an attacker can change which entities are returned, this could cause the logic to return information for a regular user and incorrectly assume that the user has administrative privileges.While this weakness is most commonly associated with SQL injection, there are many other query languages that are also subject to injection attacks, including HTSQL, LDAP, DQL, XQuery, Xpath, and \"NoSQL\" languages.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "643", "Name": "Improper Neutralization of Data within XPath Expressions ('XPath Injection')", "Description": "Properly validate user input. Reject data where appropriate, filter where appropriate and escape where appropriate. Make sure input that will be used in XPath queries is safe in that context.", "Extended_Description": "The net effect is that the attacker will have control over the information selected from the XML database and may use that ability to control application flow, modify logic, retrieve unauthorized data, or bypass important checks (e.g. authentication).", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: Controlling application flow (e.g. bypassing authentication).Scopes: Confidentiality. Impacts: Read Application Data. Note: The attacker could read restricted XML content.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Use parameterized XPath queries (e.g. using XQuery). This will help ensure separation between data plane and control plane.Implementation : Properly validate user input. Reject data where appropriate, filter where appropriate and escape where appropriate. Make sure input that will be used in XPath queries is safe in that context.", "Demonstrative_Examples": "Consider the following simple XML document that stores authentication information and a snippet of Java code that uses XPath query to retrieve authentication information:. The Java code used to retrieve the home directory based on the provided credentials is:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "943", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "91", "View_ID": "1000", "Ordinal": null}]}, {"ID": "91", "Name": "XML Injection (aka Blind XPath Injection)", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "Within XML, special elements could include reserved words or characters such as \"<\", \">\", \"\"\", and \"&\", which could then be used to add new data or modify XML syntax.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "644", "Name": "Improper Neutralization of HTTP Headers for Scripting Syntax", "Description": "Disable script execution functionality in the clients' browser.", "Extended_Description": "An attacker may be able to conduct cross-site scripting and other attacks against users who have these components enabled.If a product does not neutralize user controlled data being placed in the header of an HTTP response coming from the server, the header may contain a script that will get executed in the client's browser context, potentially resulting in a cross site scripting vulnerability or possibly an HTTP response splitting attack. It is important to carefully control data that is being placed both in HTTP response header and in the HTTP response body to ensure that no scripting syntax is present, taking various encodings into account.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: Run arbitrary code.Scopes: Confidentiality. Impacts: Read Application Data. Note: Attackers may be able to obtain sensitive information.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Perform output validation in order to filter/escape/encode unsafe data that is being passed from the server in an HTTP response header.Architecture and Design : Disable script execution functionality in the clients' browser.", "Demonstrative_Examples": ". In the following Java example, user-controlled data is added to the HTTP headers and returned to the client. Given that the data is not subject to neutralization, a malicious user may be able to inject dangerous scripting tags that will lead to script execution in the client browser.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "116", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "645", "Name": "Overly Restrictive Account Lockout Mechanism", "Description": "Consider alternatives to account lockout that would still be effective against password brute force attacks, such as presenting the user machine with a puzzle to solve (makes it do some computation).", "Extended_Description": "Account lockout is a security feature often present in applications as a countermeasure to the brute force attack on the password based authentication mechanism of the system. After a certain number of failed login attempts, the users' account may be disabled for a certain period of time or until it is unlocked by an administrator. Other security events may also possibly trigger account lockout. However, an attacker may use this very security feature to deny service to legitimate system users. It is therefore important to ensure that the account lockout security mechanism is not overly restrictive.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: Users could be locked out of accounts.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Implement more intelligent password throttling mechanisms such as those which take IP address into account, in addition to the login name.Architecture and Design : Implement a lockout timeout that grows as the number of incorrect login attempts goes up, eventually resulting in a complete lockout.Architecture and Design : Consider alternatives to account lockout that would still be effective against password brute force attacks, such as presenting the user machine with a puzzle to solve (makes it do some computation).", "Demonstrative_Examples": ". A famous example of this type of weakness being exploited is the eBay attack. eBay always displays the user id of the highest bidder. In the final minutes of the auction, one of the bidders could try to log in as the highest bidder three times. After three incorrect log in attempts, eBay password throttling would kick in and lock out the highest bidder's account for some time. An attacker could then make their own bid and their victim would not have a chance to place the counter bid because they would be locked out. Thus an attacker could win the auction.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "287", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "646", "Name": "Reliance on File Name or Extension of Externally-Supplied File", "Description": "Make decisions on the server side based on file content and not on file name or extension.", "Extended_Description": "An application might use the file name or extension of a user-supplied file to determine the proper course of action, such as selecting the correct process to which control should be passed, deciding what data should be made available, or what resources should be allocated. If the attacker can cause the code to misclassify the supplied file, then the wrong action could occur. For example, an attacker could supply a file that ends in a \".php.gif\" extension that appears to be a GIF image, but would be processed as PHP code. In extreme cases, code execution is possible, but the attacker could also cause exhaustion of resources, denial of service, exposure of debug or system data (including application source code), or being bound to a particular server side process. This weakness may be due to a vulnerability in any of the technologies used by the web and application servers, due to misconfiguration, or resultant from another flaw in the application itself.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: An attacker may be able to read sensitive data.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: An attacker may be able to cause a denial of service.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker may be able to gain privileges.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Make decisions on the server side based on file content and not on file name or extension.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "647", "Name": "Use of Non-Canonical URL Paths for Authorization Decisions", "Description": "Reject all alternate path encodings that are not in the expected canonical form.", "Extended_Description": "If an application defines policy namespaces and makes authorization decisions based on the URL, but it does not require or convert to a canonical URL before making the authorization decision, then it opens the application to attack. For example, if the application only wants to allow access to http://www.example.com/mypage, then the attacker might be able to bypass this restriction using equivalent URLs such as:Therefore it is important to specify access control policy that is based on the path information in some canonical form with all alternate encodings rejected (which can be accomplished by a default deny rule).", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: An attacker may be able to bypass the authorization mechanism to gain access to the otherwise-protected URL.Scopes: Confidentiality. Impacts: Read Files or Directories. Note: If a non-canonical URL is used, the server may choose to return the contents of the file, instead of pre-processing the file (e.g. as a program).", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Make access control policy based on path information in canonical form. Use very restrictive regular expressions to validate that the path is in the expected form.Architecture and Design : Reject all alternate path encodings that are not in the expected canonical form.", "Demonstrative_Examples": ". Example from CAPEC (CAPEC ID: 4, \"Using Alternative IP Address Encodings\"). An attacker identifies an application server that applies a security policy based on the domain and application name, so the access control policy covers authentication and authorization for anyone accessing http://example.domain:8080/application. However, by putting in the IP address of the host the application authentication and authorization controls may be bypassed http://192.168.0.1:8080/application. The attacker relies on the victim applying policy to the namespace abstraction and not having a default deny policy in place to manage exceptions.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "863", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "648", "Name": "Incorrect Use of Privileged APIs", "Description": "Ensure that a failure or an error will not leave a system in a state where privileges are not properly shed and privilege escalation is possible (i.e. fail securely with regards to handling of privileges).", "Extended_Description": "When a product contains certain functions that perform operations requiring an elevated level of privilege, the caller of a privileged API must be careful to:If the caller of the API does not follow these requirements, then it may allow a malicious user or process to elevate their privilege, hijack the process, or steal sensitive data.For instance, it is important to know if privileged APIs do not shed their privileges before returning to the caller or if the privileged function might make certain assumptions about the data, context or state information passed to it by the caller. It is important to always know when and how privileged APIs can be called in order to ensure that their elevated level of privilege cannot be exploited.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker may be able to elevate privileges.Scopes: Confidentiality. Impacts: Read Application Data. Note: An attacker may be able to obtain sensitive information.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: An attacker may be able to execute code.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Before calling privileged APIs, always ensure that the assumptions made by the privileged code hold true prior to making the call.Architecture and Design : Know architecture and implementation weaknesses of the privileged APIs and make sure to account for these weaknesses before calling the privileged APIs to ensure that they can be called safely.Implementation : If privileged APIs make certain assumptions about data, context or state validity that are passed by the caller, the calling code must ensure that these assumptions have been validated prior to making the call.Implementation : If privileged APIs do not shed their privilege prior to returning to the calling code, then calling code needs to shed these privileges immediately and safely right after the call to the privileged APIs. In particular, the calling code needs to ensure that a privileged thread of execution will never be returned to the user or made available to user-controlled processes.Implementation : Only call privileged APIs from safe, consistent and expected state.Implementation : Ensure that a failure or an error will not leave a system in a state where privileges are not properly shed and privilege escalation is possible (i.e. fail securely with regards to handling of privileges).", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "269", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "649", "Name": "Reliance on Obfuscation or Encryption of Security-Relevant Inputs without Integrity Checking", "Description": "Obfuscation should not be relied upon. If encryption is used, it needs to be properly applied (i.e. proven algorithm and implementation, use padding, use random initialization vector, user proper encryption mode). Even with proper encryption where the ciphertext does not leak information about the plaintext or reveal its structure, compromising integrity is possible (although less likely) without the provision of the integrity service.", "Extended_Description": "When an application relies on obfuscation or incorrectly applied / weak encryption to protect client-controllable tokens or parameters, that may have an effect on the user state, system state, or some decision made on the server. Without protecting the tokens/parameters for integrity, the application is vulnerable to an attack where an adversary traverses the space of possible values of the said token/parameter in order to attempt to gain an advantage. The goal of the attacker is to find another admissible value that will somehow elevate their privileges in the system, disclose information or change the behavior of the system in some way beneficial to the attacker. If the application does not protect these critical tokens/parameters for integrity, it will not be able to determine that these values have been tampered with. Measures that are used to protect data for confidentiality should not be relied upon to provide the integrity service.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Integrity. Impacts: Unexpected State. Note: The inputs could be modified without detection, causing the product to have unexpected system state or make incorrect security decisions.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Protect important client controllable tokens/parameters for integrity using PKI methods (i.e. digital signatures) or other means, and checks for integrity on the server side.Architecture and Design : Repeated requests from a particular user that include invalid values of tokens/parameters (those that should not be changed manually by users) should result in the user account lockout.Architecture and Design : Client side tokens/parameters should not be such that it would be easy/predictable to guess another valid state.Architecture and Design : Obfuscation should not be relied upon. If encryption is used, it needs to be properly applied (i.e. proven algorithm and implementation, use padding, use random initialization vector, user proper encryption mode). Even with proper encryption where the ciphertext does not leak information about the plaintext or reveal its structure, compromising integrity is possible (although less likely) without the provision of the integrity service.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "65", "Name": "Windows Hard Link", "Description": "Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Extended_Description": "Failure for a system to check for hard links can result in vulnerability to different types of attacks. For example, an attacker can escalate their privileges if a file used by a privileged program is replaced with a hard link to a sensitive file (e.g. AUTOEXEC.BAT). When the process opens the file, the attacker can assume the privileges of that process, or prevent the program from accurately processing data.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Follow the principle of least privilege when assigning access rights to entities in a software system.\n                  Denying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "59", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "650", "Name": "Trusting HTTP Permission Methods on the Server Side", "Description": "Configure ACLs on the server side to ensure that proper level of access control is defined for each accessible resource representation.", "Extended_Description": "The HTTP GET method and some other methods are designed to retrieve resources and not to alter the state of the application or resources on the server side. Furthermore, the HTTP specification requires that GET requests (and other requests) should not have side effects. Believing that it will be enough to prevent unintended resource alterations, an application may disallow the HTTP requests to perform DELETE, PUT and POST operations on the resource representation. However, there is nothing in the HTTP protocol itself that actually prevents the HTTP GET method from performing more than just query of the data. Developers can easily code programs that accept a HTTP GET request that do in fact create, update or delete data on the server. For instance, it is a common practice with REST based Web Services to have HTTP GET requests modifying resources on the server side. However, whenever that happens, the access control needs to be properly enforced in the application. No assumptions should be made that only HTTP DELETE, PUT, POST, and other methods have the power to alter the representation of the resource being accessed in the request.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: An attacker could escalate privileges.Scopes: Integrity. Impacts: Modify Application Data. Note: An attacker could modify resources.Scopes: Confidentiality. Impacts: Read Application Data. Note: An attacker could obtain sensitive information.", "Detection_Methods": "", "Potential_Mitigations": "System Configuration : Configure ACLs on the server side to ensure that proper level of access control is defined for each accessible resource representation.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "651", "Name": "Exposure of WSDL File Containing Sensitive Information", "Description": "Do not use method names in WSDL that might help an adversary guess names of private methods/resources used by the service.", "Extended_Description": "An information exposure may occur if any of the following apply:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: The attacker may find sensitive information located in the WSDL file.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Limit access to the WSDL file as much as possible. If services are provided only to a limited number of entities, it may be better to provide WSDL privately to each of these entities than to publish WSDL publicly.Architecture and Design : Make sure that WSDL does not describe methods that should not be publicly accessible. Make sure to protect service methods that should not be publicly accessible with access controls.Architecture and Design : Do not use method names in WSDL that might help an adversary guess names of private methods/resources used by the service.", "Demonstrative_Examples": ". The WSDL for a service providing information on the best price of a certain item exposes the following method: float getBestPrice(String ItemID) An attacker might guess that there is a method setBestPrice (String ItemID, float Price) that is available and invoke that method to try and change the best price of a given item to their advantage. The attack may succeed if the attacker correctly guesses the name of the method, the method does not have proper access controls around it and the service itself has the functionality to update the best price of the item.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "538", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "652", "Name": "Improper Neutralization of Data within XQuery Expressions ('XQuery Injection')", "Description": "Properly validate user input. Reject data where appropriate, filter where appropriate and escape where appropriate. Make sure input that will be used in XQL queries is safe in that context.", "Extended_Description": "The net effect is that the attacker will have control over the information selected from the XML database and may use that ability to control application flow, modify logic, retrieve unauthorized data, or bypass important checks (e.g. authentication).", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: An attacker might be able to read sensitive information from the XML database.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use parameterized queries. This will help ensure separation between data plane and control plane.Implementation : Properly validate user input. Reject data where appropriate, filter where appropriate and escape where appropriate. Make sure input that will be used in XQL queries is safe in that context.", "Demonstrative_Examples": ". An attacker may pass XQuery expressions embedded in an otherwise standard XML document. The attacker tunnels through the application entry point to target the resource access layer. The string below is an example of an attacker accessing the accounts.xml to request the service provider send all user names back. doc(accounts.xml)//user[name='*'] The attacks that are possible through XQuery are difficult to predict, if the data is not validated prior to executing the XQL.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "943", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "91", "View_ID": "1000", "Ordinal": null}]}, {"ID": "655", "Name": "Insufficient Psychological Acceptability", "Description": "Make the security mechanism as seamless as possible, while also providing the user with sufficient details when a security decision produces unexpected results.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: By bypassing the security mechanism, a user might leave the system in a less secure state than intended by the administrator, making it more susceptible to compromise.", "Detection_Methods": "", "Potential_Mitigations": "Testing : Where possible, perform human factors and usability studies to identify where your product's security mechanisms are difficult to use, and why.Architecture and Design : Make the security mechanism as seamless as possible, while also providing the user with sufficient details when a security decision produces unexpected results.", "Demonstrative_Examples": ". In \"Usability of Security: A Case Study\" [REF-540], the authors consider human factors in a cryptography product. Some of the weakness relevant discoveries of this case study were: users accidentally leaked sensitive information, could not figure out how to perform some tasks, thought they were enabling a security option when they were not, and made improper trust decisions.. Enforcing complex and difficult-to-remember passwords that need to be frequently changed for access to trivial resources, e.g., to use a black-and-white printer. Complex password requirements can also cause users to store the passwords in an unsafe manner so they don't have to remember them, such as using a sticky note or saving them in an unencrypted file.. Some CAPTCHA utilities produce images that are too difficult for a human to read, causing user frustration.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": null}]}, {"ID": "656", "Name": "Reliance on Security Through Obscurity", "Description": "When available, use publicly-vetted algorithms and procedures, as these are more likely to undergo more extensive security analysis and testing. This is especially the case with encryption and authentication.", "Extended_Description": "This reliance on \"security through obscurity\" can produce resultant weaknesses if an attacker is able to reverse engineer the inner workings of the mechanism. Note that obscurity can be one small part of defense in depth, since it can create more work for an attacker; however, it is a significant risk if used as the primary means of protection.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityOther. Impacts: Other. Note: The security mechanism can be bypassed easily.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Always consider whether knowledge of your code or design is sufficient to break it. Reverse engineering is a highly successful discipline, and financially feasible for motivated adversaries. Black-box techniques are established for binary analysis of executables that use obfuscation, runtime analysis of proprietary protocols, inferring file formats, and others.Architecture and Design : When available, use publicly-vetted algorithms and procedures, as these are more likely to undergo more extensive security analysis and testing. This is especially the case with encryption and authentication.", "Demonstrative_Examples": ". The design of TCP relies on the secrecy of Initial Sequence Numbers (ISNs), as originally covered in CVE-1999-0077 [REF-542]. If ISNs can be guessed (due to predictability, CWE-330) or sniffed (due to lack of encryption during transmission, CWE-312), then an attacker can hijack or spoof connections. Many TCP implementations have had variations of this problem over the years, including CVE-2004-0641, CVE-2002-1463, CVE-2001-0751, CVE-2001-0328, CVE-2001-0288, CVE-2001-0163, CVE-2001-0162, CVE-2000-0916, and CVE-2000-0328.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "657", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "259", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "321", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "472", "View_ID": "1000", "Ordinal": null}]}, {"ID": "66", "Name": "Improper Handling of File Names that Identify Virtual Resources", "Description": "According to SOAR, the following detection techniques may be useful:", "Extended_Description": "Virtual file names are represented like normal file names, but they are effectively aliases for other resources that do not behave like normal files. Depending on their functionality, they could be alternate entities. They are not necessarily listed in directories.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "67", "Name": "Improper Handling of Windows Device Names", "Description": "Be familiar with the device names in the operating system where your system is deployed. Check input for these device names.", "Extended_Description": "Not properly handling virtual filenames (e.g. AUX, CON, PRN, COM1, LPT1) can result in different types of vulnerabilities. In some cases an attacker can request a device via injection of a virtual filename in a URL, which may cause an error that leads to a denial of service or an error page that reveals sensitive information. A product that allows device names to bypass filtering runs the risk of an attacker injecting malicious code in a file with the name of a device.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Be familiar with the device names in the operating system where your system is deployed. Check input for these device names.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "66", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "674", "Name": "Uncontrolled Recursion", "Description": "Increase the stack size.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: The uncontrolled recursion is often due to an improper or missing conditional", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: Resources including CPU, memory, and stack memory could be rapidly consumed or exhausted, eventually leading to an exit or crash.Scopes: Confidentiality. Impacts: Read Application Data. Note: In some cases, an application's interpreter might kill a process or thread that appears to be consuming too much resources, such as with PHP's memory_limit setting. When the interpreter kills the process/thread, it might report an error containing detailed information such as the application's installation path.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Ensure an end condition will be reached under all logic conditions.  The end condition may include testing against the depth of recursion and exiting with an error if the recursion goes too deep. The complexity of the end condition contributes to the effectiveness of this action.Implementation : Increase the stack size.", "Demonstrative_Examples": "In this example a mistake exists in the code where the exit condition contained in flg is never called. This results in the function calling itself over and over again until the stack is exhausted.. Note that the only difference between the Good and Bad examples is that the recursion flag will change value and cause the recursive call to return.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "834", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "676", "Name": "Use of Potentially Dangerous Function", "Description": "Identify a list of prohibited API functions and prohibit developers from using these functions, providing safer alternatives. In some cases, automatic code analysis tools or the compiler can be instructed to spot use of prohibited functions, such as the \"banned.h\" include file from Microsoft's SDL. [REF-554] [REF-7]", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: Varies by ContextQuality DegradationUnexpected State. Note: If the function is used incorrectly, then it could result in security problems.", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Build and Compilation : Identify a list of prohibited API functions and prohibit developers from using these functions, providing safer alternatives. In some cases, automatic code analysis tools or the compiler can be instructed to spot use of prohibited functions, such as the \"banned.h\" include file from Microsoft's SDL. [REF-554] [REF-7]", "Demonstrative_Examples": "The following code attempts to create a local copy of a buffer to perform some manipulations to the data.. However, the programmer does not ensure that the size of the data pointed to by string will fit in the local buffer and copies the data with the potentially dangerous strcpy() function. This may result in a buffer overflow condition if an attacker can influence the contents of the string parameter.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1177", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "680", "Name": "Integer Overflow to Buffer Overflow", "Description": "The product performs a calculation to determine how much memory to allocate, but an integer overflow can occur that causes less memory to be allocated than expected, leading to a buffer overflow.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "StartsWith", "CWE_ID": "190", "View_ID": "709", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "190", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "683", "Name": "Function Call With Incorrect Order of Arguments", "Description": "Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.", "Extended_Description": "While this weakness might be caught by the compiler in some languages, it can occur more frequently in cases in which the called function accepts variable numbers or types of arguments, such as format strings in C. It also can occur in languages or environments that do not enforce strong typing.", "Modes_Of_Introduction": "Implementation: This problem typically occurs when the programmer makes a typo, or copy and paste errors.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use the function, procedure, or routine as specified.Testing : Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.", "Demonstrative_Examples": ". The following PHP method authenticates a user given a username/password combination but is called with the parameters in reverse order.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "628", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "685", "Name": "Function Call With Incorrect Number of Arguments", "Description": "Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: This problem typically occurs when the programmer makes a typo, or copy and paste errors.", "Common_Consequences": "", "Detection_Methods": "Method Name: Other. Description: While this weakness might be caught by the compiler in some languages, it can occur more frequently in cases in which the called function accepts variable numbers of arguments, such as format strings in C. It also can occur in languages or environments that do not require that functions always be called with the correct number of arguments, such as Perl.", "Potential_Mitigations": "Testing : Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "628", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "686", "Name": "Function Call With Incorrect Argument Type", "Description": "Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.", "Extended_Description": "This weakness is most likely to occur in loosely typed languages, or in strongly typed languages in which the types of variable arguments cannot be enforced at compilation time, or where there is implicit casting.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "628", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "688", "Name": "Function Call With Incorrect Variable or Reference as Argument", "Description": "Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: This problem typically occurs when the programmer makes a typo, or copy and paste errors.", "Common_Consequences": "", "Detection_Methods": "Method Name: Other. Description: While this weakness might be caught by the compiler in some languages, it can occur more frequently in cases in which the called function accepts variable numbers of arguments, such as format strings in C. It also can occur in loosely typed languages or environments. This might require an understanding of intended program behavior or design to determine whether the value is incorrect.", "Potential_Mitigations": "Testing : Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.", "Demonstrative_Examples": ". In the following Java snippet, the accessGranted() method is accidentally called with the static ADMIN_ROLES array rather than the user roles.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "628", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "689", "Name": "Permission Race Condition During Resource Copy", "Description": "The product, while copying or cloning a resource, does not set the resource's permissions or access control until the copy is complete, leaving the resource exposed to other spheres while the copy is taking place.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: Common examples occur in file archive extraction, in which the product begins the extraction with insecure default permissions, then only sets the final permissions (as specified in the archive) once the copy is complete. The larger the archive, the larger the timing window for the race condition.This weakness has also occurred in some operating system utilities that perform copies of deeply nested directories containing a large number of files.This weakness can occur in any type of functionality that involves copying objects or resources in a multi-user environment, including at the application level. For example, a document management system might allow a user to copy a private document, but if it does not set the new copy to be private as soon as the copy begins, then other users might be able to view the document while the copy is still taking place.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "362", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "Requires", "CWE_ID": "362", "View_ID": "1000", "Ordinal": null}, {"Nature": "Requires", "CWE_ID": "732", "View_ID": "1000", "Ordinal": null}]}, {"ID": "69", "Name": "Improper Handling of Windows ::DATA Alternate Data Stream", "Description": "Ensure that the source code correctly parses the filename to read or write to the correct stream.", "Extended_Description": "An attacker can use an ADS to hide information about a file (e.g. size, the name of the process) from a system or file browser tools such as Windows Explorer and 'dir' at the command line utility. Alternately, the attacker might be able to bypass intended access restrictions for the associated data fork.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Testing : Software tools are capable of finding ADSs on your system.Implementation : Ensure that the source code correctly parses the filename to read or write to the correct stream.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "66", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "690", "Name": "Unchecked Return Value to NULL Pointer Dereference", "Description": "Code analysis can require knowledge of API behaviors for library functions that might return NULL, reducing the chances of detection when unknown libraries are used.", "Extended_Description": "While unchecked return value weaknesses are not limited to returns of NULL pointers (see the examples in CWE-252), functions often return NULL to indicate an error status. When this error condition is not checked, a NULL pointer dereference can occur.", "Modes_Of_Introduction": "Implementation: A typical occurrence of this weakness occurs when an application includes user-controlled input to a malloc() call. The related code might be correct with respect to preventing buffer overflows, but if a large value is provided, the malloc() will fail due to insufficient memory. This problem also frequently occurs when a parsing routine expects that certain elements will always be present. If malformed input is provided, the parser might return NULL. For example, strtok() can return NULL.", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or CommandsRead MemoryModify Memory. Note: In rare circumstances, when NULL is equivalent to the 0x0 memory address and privileged code can access it, then writing or reading memory is possible, which may lead to code execution.", "Detection_Methods": "Method Name: Black Box. Description: This typically occurs in rarely-triggered error conditions, reducing the chances of detection during black box testing. Method Name: White Box. Description: Code analysis can require knowledge of API behaviors for library functions that might return NULL, reducing the chances of detection when unknown libraries are used.", "Potential_Mitigations": "", "Demonstrative_Examples": ". The code below makes a call to the getUserName() function but doesn't check the return value before dereferencing (which may cause a NullPointerException).This example takes an IP address from a user, verifies that it is well formed and then looks up the hostname and copies it into a buffer.. If an attacker provides an address that appears to be well-formed, but the address does not resolve to a hostname, then the call to gethostbyaddr() will return NULL. Since the code does not check the return value from gethostbyaddr (CWE-252), a NULL pointer dereference (CWE-476) would then occur in the call to strcpy().", "Related_Weaknesses": [{"Nature": "StartsWith", "CWE_ID": "252", "View_ID": "709", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "252", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "692", "Name": "Incomplete Denylist to Cross-Site Scripting", "Description": "The product uses a denylist-based protection mechanism to defend against XSS attacks, but the denylist is incomplete, allowing XSS variants to succeed.", "Extended_Description": "While XSS might seem simple to prevent, web browsers vary so widely in how they parse web pages, that a denylist cannot keep track of all the variations. The \"XSS Cheat Sheet\" [REF-714] contains a large number of attacks that are intended to bypass incomplete denylists.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "StartsWith", "CWE_ID": "184", "View_ID": "709", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "184", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "698", "Name": "Execution After Redirect (EAR)", "Description": "This issue might not be detected if testing is performed using a web browser, because the browser might obey the redirect and move the user to a different page before the application has produced outputs that indicate something is amiss.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: OtherConfidentialityIntegrityAvailability. Impacts: Alter Execution LogicExecute Unauthorized Code or Commands. Note: This weakness could affect the control flow of the application and allow execution of untrusted code.", "Detection_Methods": "Method Name: Black Box. Description: This issue might not be detected if testing is performed using a web browser, because the browser might obey the redirect and move the user to a different page before the application has produced outputs that indicate something is amiss.", "Potential_Mitigations": "", "Demonstrative_Examples": "This code queries a server and displays its status when a request comes from an authorized IP address.. This code redirects unauthorized users, but continues to execute code after calling http_redirect(). This means even unauthorized users may be able to access the contents of the page or perform a DoS attack on the server being queried. Also, note that this code is vulnerable to an IP address spoofing attack (CWE-212).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "705", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "670", "View_ID": "1000", "Ordinal": null}]}, {"ID": "7", "Name": "J2EE Misconfiguration: Missing Custom Error Page", "Description": "Verify return values are correct and do not supply sensitive information about the system.", "Extended_Description": "A Web application must define a default error page for 4xx errors (e.g. 404), 5xx (e.g. 500) errors and catch java.lang.Throwable exceptions to prevent attackers from mining information from the application container's built-in error response.When an attacker explores a web site looking for vulnerabilities, the amount of information that the site provides is crucial to the eventual success or failure of any attempted attacks.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: A stack trace might show the attacker a malformed SQL query string, the type of database being used, and the version of the application container. This information enables the attacker to target known vulnerabilities in these components.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Handle exceptions appropriately in source code.Implementation : Always define appropriate error pages. The application configuration should specify a default error page in order to guarantee that the application will never leak error messages to an attacker. Handling standard HTTP error codes is useful and user-friendly in addition to being a good security practice, and a good configuration will also define a last-chance error handler that catches any exception that could possibly be thrown by the application.Implementation : Do not attempt to process an error or attempt to mask it.Implementation : Verify return values are correct and do not supply sensitive information about the system.", "Demonstrative_Examples": ". In the snippet below, an unchecked runtime exception thrown from within the try block may cause the container to display its default error page (which may contain a full stack trace, among other things).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "756", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "708", "Name": "Incorrect Ownership Assignment", "Description": "Use automated tools to check for privilege settings.", "Extended_Description": "This may allow the resource to be manipulated by actors outside of the intended control sphere.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrity. Impacts: Read Application DataModify Application Data. Note: An attacker could read and modify data for which they do not have permissions to access directly.", "Detection_Methods": "", "Potential_Mitigations": "Policy : Periodically review the privileges and their owners.Testing : Use automated tools to check for privilege settings.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "282", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "345", "View_ID": "1000", "Ordinal": null}]}, {"ID": "72", "Name": "Improper Handling of Apple HFS+ Alternate Data Stream Path", "Description": "The product does not properly handle special paths that may identify the data or resource fork of a file on the HFS+ file system.", "Extended_Description": "If the product chooses actions to take based on the file name, then if an attacker provides the data or resource fork, the product may take unexpected actions. Further, if the product intends to restrict access to a file, then an attacker might still be able to bypass intended access restrictions by requesting the data or resource fork for that file.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". A web server that interprets FILE.cgi as processing instructions could disclose the source code for FILE.cgi by requesting FILE.cgi/..namedfork/data. This might occur because the web server invokes the default handler which may return the contents of the file.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "66", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "75", "Name": "Failure to Sanitize Special Elements into a Different Plane (Special Element Injection)", "Description": "Utilize an appropriate mix of allowlist and denylist parsing to filter special element syntax from all input.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Programming languages and supporting technologies might be chosen which are not subject to these issues.Implementation : Utilize an appropriate mix of allowlist and denylist parsing to filter special element syntax from all input.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "757", "Name": "Selection of Less-Secure Algorithm During Negotiation ('Algorithm Downgrade')", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "When a security mechanism can be forced to downgrade to use a less secure algorithm, this can make it easier for attackers to compromise the product by exploiting weaker algorithm. The victim might not be aware that the less secure algorithm is being used. For example, if an attacker can force a communications channel to use cleartext instead of strongly-encrypted data, then the attacker could read the channel by sniffing, instead of going through extra effort of trying to decrypt the data using brute force techniques.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "916", "Name": "Use of Password Hash With Insufficient Computational Effort", "Description": "When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.", "Extended_Description": "Many password storage mechanisms compute a hash and store the hash, instead of storing the original password in plaintext. In this design, authentication involves accepting an incoming password, computing its hash, and comparing it to the stored hash.Many hash algorithms are designed to execute quickly with minimal overhead, even cryptographic hashes. However, this efficiency is a problem for password storage, because it can reduce an attacker's workload for brute-force password cracking. If an attacker can obtain the hashes through some other method (such as SQL injection on a database that stores hashes), then the attacker can store the hashes offline and use various techniques to crack the passwords by computing hashes efficiently. Without a built-in workload, modern attacks can compute large numbers of hashes, or even exhaust the entire space of all possible passwords, within a very short amount of time, using massively-parallel computing (such as cloud computing) and GPU, ASIC, or FPGA hardware. In such a scenario, an efficient hash algorithm helps the attacker.There are several properties of a hash scheme that are relevant to its strength against an offline, massively-parallel attack:Note that the security requirements for the product may vary depending on the environment and the value of the passwords. Different schemes might not provide all of these properties, yet may still provide sufficient security for the environment. Conversely, a solution might be very strong in preserving one property, which still being very weak for an attack against another property, or it might not be able to significantly reduce the efficiency of a massively-parallel attack.", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: If an attacker can gain access to the hashes, then the lack of sufficient computational effort will make it easier to conduct brute force attacks using techniques such as rainbow tables, or specialized hardware such as GPUs, which can be much faster than general-purpose CPUs for computing hashes.", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Use an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n                  Some hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n                  Note that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.Implementation : When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "328", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "327", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "759", "Name": "Use of a One-Way Hash without a Salt", "Description": "When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.", "Extended_Description": "This makes it easier for attackers to pre-compute the hash value using dictionary attack techniques such as rainbow tables.It should be noted that, despite common perceptions, the use of a good salt with a hash does not sufficiently increase the effort for an attacker who is targeting an individual password, or who has a large amount of computing resources available, such as with cloud-based services or specialized, inexpensive hardware. Offline password cracking can still be effective if the hash function is not expensive to compute; many cryptographic functions are designed to be efficient and can be vulnerable to attacks using massive computing resources, even if the hash is cryptographically strong. The use of a salt only slightly increases the computing requirements for an attacker compared to other strategies such as adaptive hash functions. See CWE-916 for more details.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: If an attacker can gain access to the hashes, then the lack of a salt makes it easier to conduct brute force attacks using techniques such as rainbow tables.", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Use an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n                  Some hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n                  Note that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.Architecture and Design : If a technique that requires extra computational effort can not be implemented, then for each password that is processed, generate a new random salt using a strong random number generator with unpredictable seeds. Add the salt to the plaintext password before hashing it. When storing the hash, also store the salt. Do not use the same salt for every password.Implementation : When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.", "Demonstrative_Examples": "In both of these examples, a user is logged in if their given password matches a stored password:. This code relies exclusively on a password mechanism (CWE-309) using only one factor of authentication (CWE-308). If an attacker can steal or guess a user's password, they are given full access to their account. Note this code also uses SHA-1, which is a weak hash (CWE-328).  It also does not use a salt (CWE-759).In this example, a new user provides a new username and password to create an account. The program hashes the new user's password then stores it in a database.. While it is good to avoid storing a cleartext password, the program does not provide a salt to the hashing function, thus increasing the chances of an attacker being able to reverse the hash and discover the original password if the database is compromised.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "916", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "76", "Name": "Improper Neutralization of Equivalent Special Elements", "Description": "Utilize an appropriate mix of allowlist and denylist parsing to filter equivalent special element syntax from all input.", "Extended_Description": "The product may have a fixed list of special characters it believes is complete. However, there may be alternate encodings, or representations that also have the same meaning. For example, the product may filter out a leading slash (/) to prevent absolute path names, but does not account for a tilde (~) followed by a user name, which on some *nix systems could be expanded to an absolute pathname. Alternately, the product might filter a dangerous \"-e\" command-line switch when calling an external program, but it might not account for \"--exec\" or other switches that have the same semantics.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Requirements : Programming languages and supporting technologies might be chosen which are not subject to these issues.Implementation : Utilize an appropriate mix of allowlist and denylist parsing to filter equivalent special element syntax from all input.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "75", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "760", "Name": "Use of a One-Way Hash with a Predictable Salt", "Description": "If a technique that requires extra computational effort can not be implemented, then for each password that is processed, generate a new random salt using a strong random number generator with unpredictable seeds. Add the salt to the plaintext password before hashing it. When storing the hash, also store the salt. Do not use the same salt for every password.", "Extended_Description": "This makes it easier for attackers to pre-compute the hash value using dictionary attack techniques such as rainbow tables, effectively disabling the protection that an unpredictable salt would provide.It should be noted that, despite common perceptions, the use of a good salt with a hash does not sufficiently increase the effort for an attacker who is targeting an individual password, or who has a large amount of computing resources available, such as with cloud-based services or specialized, inexpensive hardware. Offline password cracking can still be effective if the hash function is not expensive to compute; many cryptographic functions are designed to be efficient and can be vulnerable to attacks using massive computing resources, even if the hash is cryptographically strong. The use of a salt only slightly increases the computing requirements for an attacker compared to other strategies such as adaptive hash functions. See CWE-916 for more details.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n                  Some hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n                  Note that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.Implementation : If a technique that requires extra computational effort can not be implemented, then for each password that is processed, generate a new random salt using a strong random number generator with unpredictable seeds. Add the salt to the plaintext password before hashing it. When storing the hash, also store the salt. Do not use the same salt for every password.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "916", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "763", "Name": "Release of Invalid Pointer or Reference", "Description": "Use a tool that dynamically detects memory management problems, such as valgrind.", "Extended_Description": "This weakness can take several forms, such as:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityAvailabilityConfidentiality. Impacts: Modify MemoryDoS: Crash, Exit, or RestartExecute Unauthorized Code or Commands. Note: This weakness may result in the corruption of memory, and perhaps instructions, possibly leading to a crash. If the corrupted memory can be effectively controlled, it may be possible to execute arbitrary code.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.", "Potential_Mitigations": "Implementation : Only call matching memory management functions. Do not mix and match routines. For example, when you allocate a buffer with malloc(), dispose of the original pointer with free().Implementation : When programming in C++, consider using smart pointers provided by the boost library to help correctly and consistently manage memory.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, glibc in Linux provides protection against free of invalid pointers.Architecture and Design : Use a language that provides abstractions for memory allocation and deallocation.Testing : Use a tool that dynamically detects memory management problems, such as valgrind.", "Demonstrative_Examples": "This code attempts to tokenize a string and place it into an array using the strsep function, which inserts a \\0 byte in place of whitespace or a tab character. After finishing the loop, each string in the AP array points to a location within the input string.. Since strsep is not allocating any new memory, freeing an element in the middle of the array is equivalent to free a pointer in the middle of inputstring.This example allocates a BarObj object using the new operator in C++, however, the programmer then deallocates the object using free(), which may lead to unexpected behavior.. Instead, the programmer should have either created the object with one of the malloc family functions, or else deleted the object with the delete operator.In this example, the programmer dynamically allocates a buffer to hold a string and then searches for a specific character. After completing the search, the programmer attempts to release the allocated memory and return SUCCESS or FAILURE to the caller. Note: for simplification, this example uses a hard-coded \"Search Me!\" string and a constant string length of 20.. However, if the character is not at the beginning of the string, or if it is not in the string at all, then the pointer will not be at the start of the buffer when the programmer frees it.Consider the following code in the context of a parsing application to extract commands out of user data. The intent is to parse each command and add it to a queue of commands to be executed, discarding each malformed entry.. While the above code attempts to free memory associated with bad commands, since the memory was all allocated in one chunk, it must all be freed together.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "761", "Name": "Free of Pointer not at Start of Buffer", "Description": "Use a tool that dynamically detects memory management problems, such as valgrind.", "Extended_Description": "This can cause the product to crash, or in some cases, modify critical program variables or execute code.This weakness often occurs when the memory is allocated explicitly on the heap with one of the malloc() family functions and free() is called, but pointer arithmetic has caused the pointer to be in the interior or end of the buffer.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : When utilizing pointer arithmetic to traverse a buffer, use a separate variable to track progress through memory and preserve the originally allocated address for later freeing.Implementation : When programming in C++, consider using smart pointers provided by the boost library to help correctly and consistently manage memory.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, glibc in Linux provides protection against free of invalid pointers.Architecture and Design : Use a language that provides abstractions for memory allocation and deallocation.Testing : Use a tool that dynamically detects memory management problems, such as valgrind.", "Demonstrative_Examples": "In this example, the programmer dynamically allocates a buffer to hold a string and then searches for a specific character. After completing the search, the programmer attempts to release the allocated memory and return SUCCESS or FAILURE to the caller. Note: for simplification, this example uses a hard-coded \"Search Me!\" string and a constant string length of 20.. However, if the character is not at the beginning of the string, or if it is not in the string at all, then the pointer will not be at the start of the buffer when the programmer frees it.This code attempts to tokenize a string and place it into an array using the strsep function, which inserts a \\0 byte in place of whitespace or a tab character. After finishing the loop, each string in the AP array points to a location within the input string.. Since strsep is not allocating any new memory, freeing an element in the middle of the array is equivalent to free a pointer in the middle of inputstring.Consider the following code in the context of a parsing application to extract commands out of user data. The intent is to parse each command and add it to a queue of commands to be executed, discarding each malformed entry.. While the above code attempts to free memory associated with bad commands, since the memory was all allocated in one chunk, it must all be freed together.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "763", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "764", "Name": "Multiple Locks of a Critical Resource", "Description": "When locking and unlocking a resource, try to be sure that all control paths through the code in which the resource is locked one or more times correspond to exactly as many unlocks. If the software acquires a lock and then determines it is not able to perform its intended behavior, be sure to release the lock(s) before waiting for conditions to improve. Reacquire the lock(s) before trying again.", "Extended_Description": "When a product is operating in a concurrent environment and repeatedly locks a critical resource, the consequences will vary based on the type of lock, the lock's implementation, and the resource being protected. In some situations such as with semaphores, the resources are pooled and extra locking calls will reduce the size of the total available pool, possibly leading to degraded performance or a denial of service. If this can be triggered by an attacker, it will be similar to an unrestricted lock (CWE-412). In the context of a binary lock, it is likely that any duplicate locking attempts will never succeed since the lock is already held and progress may not be possible.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : When locking and unlocking a resource, try to be sure that all control paths through the code in which the resource is locked one or more times correspond to exactly as many unlocks. If the software acquires a lock and then determines it is not able to perform its intended behavior, be sure to release the lock(s) before waiting for conditions to improve. Reacquire the lock(s) before trying again.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "675", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "765", "Name": "Multiple Unlocks of a Critical Resource", "Description": "When locking and unlocking a resource, try to be sure that all control paths through the code in which the resource is locked one or more times correspond to exactly as many unlocks. If the product acquires a lock and then determines it is not able to perform its intended behavior, be sure to release the lock(s) before waiting for conditions to improve. Reacquire the lock(s) before trying again.", "Extended_Description": "When the product is operating in a concurrent environment and repeatedly unlocks a critical resource, the consequences will vary based on the type of lock, the lock's implementation, and the resource being protected. In some situations such as with semaphores, the resources are pooled and extra calls to unlock will increase the count for the number of available resources, likely resulting in a crash or unpredictable behavior when the system nears capacity.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : When locking and unlocking a resource, try to be sure that all control paths through the code in which the resource is locked one or more times correspond to exactly as many unlocks. If the product acquires a lock and then determines it is not able to perform its intended behavior, be sure to release the lock(s) before waiting for conditions to improve. Reacquire the lock(s) before trying again.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "675", "View_ID": "1000", "Ordinal": null}]}, {"ID": "766", "Name": "Critical Data Element Declared Public", "Description": "Data should be private, static, and final whenever possible. This will assure that your code is protected by instantiating early, preventing access, and preventing tampering.", "Extended_Description": "This issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Read Application DataModify Application Data. Note: Making a critical variable public allows anyone with access to the object in which the variable is contained to alter or read the value.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Data should be private, static, and final whenever possible. This will assure that your code is protected by instantiating early, preventing access, and preventing tampering.", "Demonstrative_Examples": "The following example declares a critical variable public, making it accessible to anyone with access to the object in which it is contained.. Instead, the critical data should be declared private.The following example shows a basic user account class that includes member variables for the username and password as well as a public constructor for the class and a public method to authorize access to the user account.. However, the member variables username and password are declared public and therefore will allow access and changes to the member variables to anyone with access to the object. These member variables should be declared private as shown below to prevent unauthorized access and changes.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "732", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1061", "View_ID": "1000", "Ordinal": null}]}, {"ID": "767", "Name": "Access to Critical Private Variable via Public Method", "Description": "Use class accessor and mutator methods appropriately. Perform validation when accepting data from a public method that is intended to modify a critical private variable. Also be sure that appropriate access controls are being applied when a public method interfaces with critical data.", "Extended_Description": "If an attacker modifies the variable to contain unexpected values, this could violate assumptions from other parts of the code. Additionally, if an attacker can read the private variable, it may expose sensitive information or make it easier to launch further attacks.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use class accessor and mutator methods appropriately. Perform validation when accepting data from a public method that is intended to modify a critical private variable. Also be sure that appropriate access controls are being applied when a public method interfaces with critical data.", "Demonstrative_Examples": ". The following example declares a critical variable to be private, and then allows the variable to be modified by public methods.The following example could be used to implement a user forum where a single user (UID) can switch between multiple profiles (PID).. The programmer implemented setPID with the intention of modifying the PID variable, but due to a typo. accidentally specified the critical variable UID instead. If the program allows profile IDs to be between 1 and 10, but a UID of 1 means the user is treated as an admin, then a user could gain administrative privileges as a result of this typo.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "768", "Name": "Incorrect Short Circuit Evaluation", "Description": "Minimizing the number of statements in a conditional that produce side effects will help to prevent the likelihood of short circuit evaluation to alter control flow in an unexpected way.", "Extended_Description": "Usage of short circuit evaluation, though well-defined in the C standard, may alter control flow in a way that introduces logic errors that are difficult to detect, possibly causing errors later during the product's execution. If an attacker can discover such an inconsistency, it may be exploitable to gain arbitrary control over a system.If the first condition of an \"or\" statement is assumed to be true under normal circumstances, or if the first condition of an \"and\" statement is assumed to be false, then any subsequent conditional may contain its own logic errors that are not detected during code review or testing.Finally, the usage of short circuit evaluation may decrease the maintainability of the code.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: . Note: Widely varied consequences are possible if an attacker is aware of an unexpected state in the product after a conditional. It may lead to information exposure, a system crash, or even complete attacker control of the system.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Minimizing the number of statements in a conditional that produce side effects will help to prevent the likelihood of short circuit evaluation to alter control flow in an unexpected way.", "Demonstrative_Examples": "The following function attempts to take a size value from a user and allocate an array of that size (we ignore bounds checking for simplicity). The function tries to initialize each spot with the value of its index, that is, A[len-1] = len - 1; A[len-2] = len - 2; ... A[1] = 1; A[0] = 0; However, since the programmer uses the prefix decrement operator, when the conditional is evaluated with i == 1, the decrement will result in a 0 value for the first part of the predicate, causing the second portion to be bypassed via short-circuit evaluation. This means we cannot be sure of what value will be in A[0] when we return the array to the user.. When compiled and run, the above code will output a privilege level of 1, or PRIV_REGULAR for every user but the user with id 0 since the prefix increment operator used in the if statement will reach zero and short circuit before setting the 0th user's privilege level. Since we used calloc, this privilege will be set to 0, or PRIV_ADMIN.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "771", "Name": "Missing Reference to Active Allocated Resource", "Description": "Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Extended_Description": "This does not necessarily apply in languages or frameworks that automatically perform garbage collection, since the removal of all references may act as a signal that the resource is ready to be reclaimed.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: An attacker that can influence the allocation of resources that are not properly maintained could deplete the available resource pool and prevent all other processes from accessing the same type of resource.", "Detection_Methods": "", "Potential_Mitigations": "Operation : Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "773", "Name": "Missing Reference to Active File Descriptor or Handle", "Description": "Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Extended_Description": "This can cause the product to consume all available file descriptors or handles, which can prevent other processes from performing critical file processing operations.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: An attacker that can influence the allocation of resources that are not properly maintained could deplete the available resource pool and prevent all other processes from accessing the same type of resource.", "Detection_Methods": "", "Potential_Mitigations": "Operation : Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "771", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "774", "Name": "Allocation of File Descriptors or Handles Without Limits or Throttling", "Description": "Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Extended_Description": "This can cause the product to consume all available file descriptors or handles, which can prevent other processes from performing critical file processing operations.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: When allocating resources without limits, an attacker could prevent all other processes from accessing the same type of resource.", "Detection_Methods": "", "Potential_Mitigations": "Operation : Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "770", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "775", "Name": "Missing Release of File Descriptor or Handle after Effective Lifetime", "Description": "Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Extended_Description": "When a file descriptor or handle is not released after use (typically by explicitly closing it), attackers can cause a denial of service by consuming all available file descriptors/handles, or otherwise preventing other system processes from obtaining their own file descriptors/handles.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: An attacker that can influence the allocation of resources that are not properly released could deplete the available resource pool and prevent all other processes from accessing the same type of resource.", "Detection_Methods": "", "Potential_Mitigations": "Operation : Use resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n                  When the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n                  Ensure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "772", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "404", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "776", "Name": "Improper Restriction of Recursive Entity References in DTDs ('XML Entity Expansion')", "Description": "Before parsing XML files with associated DTDs, scan for recursive entity declarations and do not continue parsing potentially explosive content.", "Extended_Description": "If the DTD contains a large number of nested or recursive entities, this can lead to explosive growth of data when parsed, causing a denial of service.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: If parsed, recursive entity references allow the attacker to expand data exponentially, quickly consuming all system resources.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Operation : If possible, prohibit the use of DTDs or use an XML parser that limits the expansion of recursive DTD entities.Implementation : Before parsing XML files with associated DTDs, scan for recursive entity declarations and do not continue parsing potentially explosive content.", "Demonstrative_Examples": ". The DTD and the very brief XML below illustrate what is meant by an XML bomb. The ZERO entity contains one character, the letter A. The choice of entity name ZERO is being used to indicate length equivalent to that exponent on two, that is, the length of ZERO is 2^0. Similarly, ONE refers to ZERO twice, therefore the XML parser will expand ONE to a length of 2, or 2^1. Ultimately, we reach entity THIRTYTWO, which will expand to 2^32 characters in length, or 4 GB, probably consuming far more data than expected.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "674", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "674", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "405", "View_ID": "1000", "Ordinal": null}]}, {"ID": "777", "Name": "Regular Expression without Anchors", "Description": "Be sure to understand both what will be matched and what will not be matched by a regular expression. Anchoring the ends of the expression will allow the programmer to define an allowlist strictly limited to what is matched by the text in the regular expression. If you are using a package that only matches one line by default, ensure that you can match multi-line inputs if necessary.", "Extended_Description": "When performing tasks such as validating against a set of allowed inputs (allowlist), data is examined and possibly modified to ensure that it is well-formed and adheres to a list of safe values. If the regular expression is not anchored, malicious or malformed data may be included before or after any string matching the regular expression. The type of malicious data that is allowed will depend on the context of the application and which anchors are omitted from the regular expression.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityConfidentialityAccess Control. Impacts: Bypass Protection Mechanism. Note: An unanchored regular expression in the context of an allowlist will possibly result in a protection mechanism failure, allowing malicious or malformed data to enter trusted regions of the program. The specific consequences will depend on what functionality the allowlist was protecting.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Be sure to understand both what will be matched and what will not be matched by a regular expression. Anchoring the ends of the expression will allow the programmer to define an allowlist strictly limited to what is matched by the text in the regular expression. If you are using a package that only matches one line by default, ensure that you can match multi-line inputs if necessary.", "Demonstrative_Examples": "Consider a web application that supports multiple languages. It selects messages for an appropriate language by using the lang parameter.. The previous code attempts to match only alphanumeric values so that language values such as \"english\" and \"french\" are valid while also protecting against path traversal, CWE-22. However, the regular expression anchors are omitted, so any text containing at least one alphanumeric character will now pass the validation step. For example, the attack string below will match the regular expression.This code uses a regular expression to validate an IP string prior to using it in a call to the \"ping\" command.. Since the regular expression does not have anchors (CWE-777), i.e. is unbounded without ^ or $ characters, then prepending a 0 or 0x to the beginning of the IP address will still result in a matched regex pattern. Since the ping command supports octal and hex prepended IP addresses, it will use the unexpectedly valid IP address (CWE-1389). For example, \"0x63.63.63.63\" would be considered equivalent to \"99.63.63.63\". As a result, the attacker could potentially ping systems that the attacker cannot reach directly.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "625", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "778", "Name": "Insufficient Logging", "Description": "To enable storage logging using Azure's Portal, navigate to the name of the Storage Account, locate Monitoring (CLASSIC) section, and select Diagnostic settings (classic). For each of the various properties (blob, file, table, queue), ensure the status is properly set for the desired logging data. If using PowerShell, the Set-AzStorageServiceLoggingProperty command could be called using appropriate -ServiceType, -LoggingOperations, and -RetentionDays arguments.", "Extended_Description": "When security-critical events are not logged properly, such as a failed login attempt, this can make malicious behavior more difficult to detect and may hinder forensic analysis after an attack succeeds.As organizations adopt cloud storage resources, these technologies often require configuration changes to enable detailed logging information, since detailed logging can incur additional costs. This could lead to telemetry gaps in critical audit logs. For example, in Azure, the default value for logging is disabled.", "Modes_Of_Introduction": "Operation: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: Non-Repudiation. Impacts: Hide Activities. Note: If security critical information is not recorded, there will be no trail for forensic analysis and discovering the cause of problems or the source of attacks may become more difficult or impossible.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Use a centralized logging mechanism that supports multiple levels of detail.Implementation : Ensure that all security-related successes and failures can be logged. When storing data in the cloud (e.g., AWS S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to enable and capture detailed logging information.Operation : Be sure to set the level of logging appropriately in a production environment. Sufficient data should be logged to enable system administrators to detect attacks, diagnose errors, and recover from attacks. At the same time, logging too much data (CWE-779) can cause the same problems, including unexpected costs when using a cloud environment.Operation : To enable storage logging using Azure's Portal, navigate to the name of the Storage Account, locate Monitoring (CLASSIC) section, and select Diagnostic settings (classic). For each of the various properties (blob, file, table, queue), ensure the status is properly set for the desired logging data. If using PowerShell, the Set-AzStorageServiceLoggingProperty command could be called using appropriate -ServiceType, -LoggingOperations, and -RetentionDays arguments.", "Demonstrative_Examples": "The example below shows a configuration for the service security audit feature in the Windows Communication Foundation (WCF).. The previous configuration file has effectively disabled the recording of security-critical events, which would force the administrator to look to other sources during debug or recovery efforts.In the following Java example the code attempts to authenticate the user. If the login fails a retry is made. Proper restrictions on the number of login attempts are of course part of the retry functionality. Unfortunately, the failed login is not recorded and there would be no record of an adversary attempting to brute force the program.. It is recommended to log the failed login action. Note that unneutralized usernames should not be part of the log message, and passwords should never be part of the log message.Consider this command for updating Azure's Storage Logging for Blob service, adapted from [REF-1307]:. The \"--log d\" portion of the command says to log deletes. However, the argument does not include the logging of writes and reads. Adding the \"rw\" arguments to the -log parameter will fix the issue:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "223", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "693", "View_ID": "1000", "Ordinal": null}]}, {"ID": "779", "Name": "Logging of Excessive Data", "Description": "Adjust configurations appropriately when the product is transitioned from a debug state to production.", "Extended_Description": "While logging is a good practice in general, and very high levels of logging are appropriate for debugging stages of development, too much logging in a production environment might hinder a system administrator's ability to detect anomalous conditions. This can provide cover for an attacker while attempting to penetrate a system, clutter the audit trail for forensic analysis, or make it more difficult to debug problems in a production environment.", "Modes_Of_Introduction": "Operation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Other). Note: Log files can become so large that they consume excessive resources, such as disk and CPU, which can hinder the performance of the system.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: Logging too much information can make the log files of less use to forensics analysts and developers when trying to diagnose a problem or recover from an attack.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: If system administrators are unable to effectively process log files, attempted attacks may go undetected, possibly leading to eventual system compromise.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Suppress large numbers of duplicate log messages and replace them with periodic summaries. For example, syslog may include an entry that states \"last message repeated X times\" when recording repeated events.Architecture and Design : Support a maximum size for the log file that can be controlled by the administrator. If the maximum size is reached, the admin should be notified. Also, consider reducing functionality of the product. This may result in a denial-of-service to legitimate product users, but it will prevent the product from adversely impacting the entire system.Implementation : Adjust configurations appropriately when the product is transitioned from a debug state to production.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "78", "Name": "Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')", "Description": "When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.", "Extended_Description": "This could allow attackers to execute unexpected, dangerous commands directly on the operating system. This weakness can lead to a vulnerability in environments in which the attacker does not have direct access to the operating system, such as in web applications. Alternately, if the weakness occurs in a privileged program, it could allow the attacker to specify commands that normally would not be accessible, or to call alternate commands with privileges that the attacker does not have. The problem is exacerbated if the compromised process does not follow the principle of least privilege, because the attacker-controlled commands may run with special system privileges that increases the amount of damage.There are at least two subtypes of OS command injection:From a weakness standpoint, these variants represent distinct programmer errors. In the first variant, the programmer clearly intends that input from untrusted parties will be part of the arguments in the command to be executed. In the second variant, the programmer does not intend for the command to be accessible to any untrusted party, but the programmer probably has not accounted for alternate ways in which malicious attackers can provide input.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityNon-Repudiation. Impacts: Execute Unauthorized Code or CommandsDoS: Crash, Exit, or RestartRead Files or DirectoriesModify Files or DirectoriesRead Application DataModify Application DataHide Activities. Note: Attackers could execute unauthorized commands, which could then be used to disable the product, or read and modify data for which the attacker does not have permissions to access directly. Since the targeted application is directly executing the commands instead of the attacker, any malicious activities may appear to come from the application or the application's owner.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.Automated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or require any code changes.Automated static analysis might not be able to detect the usage of custom API functions or third-party libraries that indirectly invoke OS commands, leading to false negatives - especially if the API/library code is not available for analysis. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Static Analysis. Description: Since this weakness does not typically appear frequently within a single software package, manual white box techniques may be able to provide sufficient code coverage and reduction of false positives if all potentially-vulnerable operations can be assessed within limited time constraints. Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Automated Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : If at all possible, use library calls rather than external processes to recreate the desired functionality.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.Architecture and Design : For any data that will be used to generate a command to be executed, keep as much of that data out of external control as possible. For example, in web applications, this may require storing the data locally in the session's state instead of sending it out to the client in a hidden form field.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using the ESAPI Encoding control [REF-45] or a similar tool, library, or framework. These will help the programmer encode outputs in a manner less prone to error.Implementation : While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).Implementation : If the program to be executed allows arguments to be specified within an input file or from standard input, then consider using that mode to pass arguments instead of the command line.Architecture and Design : If available, use structured mechanisms that automatically enforce the separation between data and code. These mechanisms may be able to provide the relevant quoting, encoding, and validation automatically, instead of relying on the developer to provide this capability at every point where output is generated.\n                  Some languages offer multiple functions that can be used to invoke commands. Where possible, identify any function that invokes a command shell using a single string, and replace it with a function that requires individual arguments. These functions typically perform appropriate quoting and filtering of arguments. For example, in C, the system() function accepts a string that contains the entire command to be executed, whereas execl(), execve(), and others require an array of strings, one for each argument. In Windows, CreateProcess() only accepts one command at a time. In Perl, if system() is provided with an array of arguments, then it will quote each of the arguments.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When constructing OS command strings, use stringent allowlists that limit the character set based on the expected value of the parameter in the request. This will indirectly limit the scope of an attack, but this technique is less important than proper output encoding and escaping.\n                  Note that proper output encoding, escaping, and quoting is the most effective solution for preventing OS command injection, although input validation may provide some defense-in-depth. This is because it effectively limits what will appear in output. Input validation will not always prevent OS command injection, especially if you are required to support free-form text fields that could contain arbitrary characters. For example, when invoking a mail program, you might need to allow the subject field to contain otherwise-dangerous inputs like \";\" and \">\" characters, which would need to be escaped or otherwise handled. In this case, stripping the character might reduce the risk of OS command injection, but it would produce incorrect behavior because the subject field would not be recorded as the user intended. This might seem to be a minor inconvenience, but it could be more important when the program relies on well-structured subject lines in order to pass messages to other components.\n                  Even if you make a mistake in your validation (such as forgetting one out of 100 input fields), appropriate encoding is still likely to protect you from injection-based attacks. As long as it is not done in isolation, input validation is still a useful technique, since it may significantly reduce your attack surface, allow you to detect some attacks, and provide other security benefits that proper encoding does not address.Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.Operation : Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).Operation : Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).Implementation : Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n                  If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\t\t  Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n                  In the context of OS Command Injection, error information passed back to the user might reveal whether an OS command is being executed and possibly which command is being used.Operation : Use runtime policy enforcement to create an allowlist of allowable commands, then prevent use of any command that does not appear in the allowlist. Technologies such as AppArmor are available to do this.Operation : Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Operation : When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.", "Demonstrative_Examples": "This example code intends to take the name of a user and list the contents of that user's home directory. It is subject to the first variant of OS command injection.. The $userName variable is not checked for malicious input. An attacker could set the $userName variable to an arbitrary OS command such as:The following simple program accepts a filename as a command line argument and displays the contents of the file back to the user. The program is installed setuid root because it is intended for use as a learning tool to allow system administrators in-training to inspect privileged system files without giving them the ability to modify them or damage the system.. Because the program runs with root privileges, the call to system() also executes with root privileges. If a user specifies a standard filename, the call works as expected. However, if an attacker passes a string of the form \";rm -rf /\", then the call to system() fails to execute cat due to a lack of arguments and then plows on to recursively delete the contents of the root partition.This example is a web application that intends to perform a DNS lookup of a user-supplied domain name. It is subject to the first variant of OS command injection.. Suppose an attacker provides a domain name like this:The example below reads the name of a shell script to execute from the system properties. It is subject to the second variant of OS command injection.. If an attacker has control over this property, then they could modify the property to point to a dangerous program.In the example below, a method is used to transform geographic coordinates from latitude and longitude format to UTM format. The method gets the input coordinates from a user through a HTTP request and executes a program local to the application server that performs the transformation. The method passes the latitude and longitude coordinates as a command-line option to the external program and will perform some processing to retrieve the results of the transformation and return the resulting UTM coordinates.. However, the method does not verify that the contents of the coordinates input parameter includes only correctly-formatted latitude and longitude coordinates. If the input coordinates were not validated prior to the call to this method, a malicious user could execute another program local to the application server by appending '&' followed by the command for another program to the end of the coordinate string. The '&' instructs the Windows operating system to execute another program.The following code is from an administrative web application designed to allow users to kick off a backup of an Oracle database using a batch-file wrapper around the rman utility and then run a cleanup.bat script to delete some temporary files. The script rmanDB.bat accepts a single command line parameter, which specifies what type of backup to perform. Because access to the database is restricted, the application runs the backup as a privileged user.. The problem here is that the program does not do any validation on the backuptype parameter read from the user. Typically the Runtime.exec() function will not execute multiple commands, but in this case the program first runs the cmd.exe shell in order to run multiple commands with a single call to Runtime.exec(). Once the shell is invoked, it will happily execute multiple commands separated by two ampersands. If an attacker passes a string of the form \"& del c:\\\\dbms\\\\*.*\", then the application will execute this command along with the others specified by the program. Because of the nature of the application, it runs with the privileges necessary to interact with the database, which means whatever command the attacker injects will run with those privileges as well.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "88", "View_ID": "1000", "Ordinal": null}]}, {"ID": "780", "Name": "Use of RSA Algorithm without OAEP", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "Padding schemes are often used with cryptographic algorithms to make the plaintext less predictable and complicate attack efforts. The OAEP scheme is often used with RSA to nullify the impact of predictable common text.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: Without OAEP in RSA encryption, it will take less work for an attacker to decrypt the data or to infer patterns from the ciphertext.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "The example below attempts to build an RSA cipher.. While the previous code successfully creates an RSA cipher, the cipher does not use padding. The following code creates an RSA cipher using OAEP.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "327", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "781", "Name": "Improper Address Validation in IOCTL with METHOD_NEITHER I/O Control Code", "Description": "If the IOCTL is part of a driver that is only intended to be accessed by trusted users, then use proper access control for the associated device or device namespace. See References.", "Extended_Description": "When an IOCTL uses the METHOD_NEITHER option for I/O control, it is the responsibility of the IOCTL to validate the addresses that have been supplied to it. If validation is missing or incorrect, attackers can supply arbitrary memory addresses, leading to code execution or a denial of service.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityAvailabilityConfidentiality. Impacts: Modify MemoryRead MemoryExecute Unauthorized Code or CommandsDoS: Crash, Exit, or Restart. Note: An attacker may be able to access memory that belongs to another process or user. If the attacker can control the contents that the IOCTL writes, it may lead to code execution at high privilege levels. At the least, a crash can occur.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : If METHOD_NEITHER is required for the IOCTL, then ensure that all user-space addresses are properly validated before they are first accessed. The ProbeForRead and ProbeForWrite routines are available for this task. Also properly protect and manage the user-supplied buffers, since the I/O Manager does not do this when METHOD_NEITHER is being used. See References.Architecture and Design : If possible, avoid using METHOD_NEITHER in the IOCTL and select methods that effectively control the buffer size, such as METHOD_BUFFERED, METHOD_IN_DIRECT, or METHOD_OUT_DIRECT.Architecture and Design : If the IOCTL is part of a driver that is only intended to be accessed by trusted users, then use proper access control for the associated device or device namespace. See References.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1285", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "822", "View_ID": "1000", "Ordinal": null}]}, {"ID": "782", "Name": "Exposed IOCTL with Insufficient Access Control", "Description": "In Windows environments, use proper access control for the associated device or device namespace. See References.", "Extended_Description": "When an IOCTL contains privileged functionality and is exposed unnecessarily, attackers may be able to access this functionality by invoking the IOCTL. Even if the functionality is benign, if the programmer has assumed that the IOCTL would only be accessed by a trusted process, there may be little or no validation of the incoming data, exposing weaknesses that would never be reachable if the attacker cannot call the IOCTL directly.The implementations of IOCTLs will differ between operating system types and versions, so the methods of attack and prevention may vary widely.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityAvailabilityConfidentiality. Impacts: . Note: Attackers can invoke any functionality that the IOCTL offers. Depending on the functionality, the consequences may include code execution, denial-of-service, and theft of data.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : In Windows environments, use proper access control for the associated device or device namespace. See References.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "749", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "781", "View_ID": "1000", "Ordinal": null}]}, {"ID": "783", "Name": "Operator Precedence Logic Error", "Description": "Regularly wrap sub-expressions in parentheses, especially in security-critical code.", "Extended_Description": "While often just a bug, operator precedence logic errors can have serious consequences if they are used in security-critical code, such as making an authentication decision.", "Modes_Of_Introduction": "Implementation: Logic errors related to operator precedence may cause problems even during normal operation, so they are probably discovered quickly during the testing phase. If testing is incomplete or there is a strong reliance on manual review of the code, then these errors may not be discovered before the software is deployed.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Varies by ContextUnexpected State. Note: The consequences will vary based on the context surrounding the incorrect precedence. In a security decision, integrity or confidentiality are the most likely results. Otherwise, a crash may occur due to the software reaching an unexpected state.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Regularly wrap sub-expressions in parentheses, especially in security-critical code.", "Demonstrative_Examples": "In the following example, the method validateUser makes a call to another method to authenticate a username and password for a user and returns a success or failure code.. However, the method that authenticates the username and password is called within an if statement with incorrect operator precedence logic. Because the comparison operator \"==\" has a higher precedence than the assignment operator \"=\", the comparison operator will be evaluated first and if the method returns FAIL then the comparison will be true, the return variable will be set to true and SUCCESS will be returned. This operator precedence logic error can be easily resolved by properly using parentheses within the expression of the if statement, as shown below.In this example, the method calculates the return on investment for an accounting/financial application. The return on investment is calculated by subtracting the initial investment costs from the current value and then dividing by the initial investment costs.. However, the return on investment calculation will not produce correct results because of the incorrect operator precedence logic in the equation. The divide operator has a higher precedence than the minus operator, therefore the equation will divide the initial investment costs by the initial investment costs which will only subtract one from the current value. Again this operator precedence logic error can be resolved by the correct use of parentheses within the equation, as shown below.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "670", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "784", "Name": "Reliance on Cookies without Validation and Integrity Checking in a Security Decision", "Description": "Protect critical cookies from replay attacks, since cross-site scripting or other attacks may allow attackers to steal a strongly-encrypted cookie that also passes integrity checks. This mitigation applies to cookies that should only be valid during a single transaction or session. By enforcing timeouts, you may limit the scope of an attack. As part of your integrity check, use an unpredictable, server-side value that is not exposed to the client.", "Extended_Description": "Attackers can easily modify cookies, within the browser or by implementing the client-side code outside of the browser. Attackers can bypass protection mechanisms such as authorization and authentication by modifying the cookie to contain an expected value.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: It is dangerous to use cookies to set a user's privileges. The cookie can be manipulated to claim a high level of authorization, or to claim that successful authentication has occurred.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Avoid using cookie data for a security-related decision.Implementation : Perform thorough input validation (i.e.: server side validation) on the cookie data if you're going to use it for a security related decision.Architecture and Design : Add integrity checks to detect tampering.Architecture and Design : Protect critical cookies from replay attacks, since cross-site scripting or other attacks may allow attackers to steal a strongly-encrypted cookie that also passes integrity checks. This mitigation applies to cookies that should only be valid during a single transaction or session. By enforcing timeouts, you may limit the scope of an attack. As part of your integrity check, use an unpredictable, server-side value that is not exposed to the client.", "Demonstrative_Examples": ". The following code excerpt reads a value from a browser cookie to determine the role of the user.The following code could be for a medical records application. It performs authentication by checking if a cookie has been set.. The programmer expects that the AuthenticateUser() check will always be applied, and the \"authenticated\" cookie will only be set when authentication succeeds. The programmer even diligently specifies a 2-hour expiration for the cookie.. In the following example, an authentication flag is read from a browser cookie, thus allowing for external control of user state data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "807", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "565", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "785", "Name": "Use of Path Manipulation Function without Maximum-sized Buffer", "Description": "Always specify output buffers large enough to handle the maximum-size possible result from path manipulation functions.", "Extended_Description": "Passing an inadequately-sized output buffer to a path manipulation function can result in a buffer overflow. Such functions include realpath(), readlink(), PathAppend(), and others.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Always specify output buffers large enough to handle the maximum-size possible result from path manipulation functions.", "Demonstrative_Examples": "In this example the function creates a directory named \"output\\<name>\" in the current directory and returns a heap-allocated copy of its name.. For most values of the current directory and the name parameter, this function will work properly. However, if the name parameter is particularly long, then the second call to PathAppend() could overflow the outputDirectoryName buffer, which is smaller than MAX_PATH bytes.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "676", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "120", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "20", "View_ID": "700", "Ordinal": "Primary"}]}, {"ID": "789", "Name": "Memory Allocation with Excessive Size Value", "Description": "Run your program using system-provided resource limits for memory. This might still cause the program to crash or exit, but the impact to the rest of the system will be minimized.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Memory). Note: Not controlling memory allocation can result in a request for too much system memory, possibly leading to a crash of the application due to out-of-memory conditions, or the consumption of a large amount of memory on the system.", "Detection_Methods": "Method Name: Fuzzing. Description: Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues. Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Perform adequate input validation against any value that influences the amount of memory that is allocated. Define an appropriate strategy for handling requests that exceed the limit, and consider supporting a configuration option so that the administrator can extend the amount of memory to be used if necessary.Operation : Run your program using system-provided resource limits for memory. This might still cause the program to crash or exit, but the impact to the rest of the system will be minimized.", "Demonstrative_Examples": "Consider the following code, which accepts an untrusted size value and allocates a buffer to contain a string of the given size.. Suppose an attacker provides a size value of:Consider the following code, which accepts an untrusted size value and uses the size as an initial capacity for a HashMap.. The HashMap constructor will verify that the initial capacity is not negative, however there is no check in place to verify that sufficient memory is present. If the attacker provides a large enough value, the application will run into an OutOfMemoryError.This code performs a stack allocation based on a length calculation.. Since a and b are declared as signed ints, the \"a - b\" subtraction gives a negative result (-1). However, since len is declared to be unsigned, len is cast to an extremely large positive number (on 32-bit systems - 4294967295). As a result, the buffer buf[len] declaration uses an extremely large size to allocate on the stack, very likely more than the entire computer's memory space.This example shows a typical attempt to parse a string with an error resulting from a difference in assumptions between the caller to a function and the function's action.. The buffer length ends up being -1, resulting in a blown out stack. The space character after the colon is included in the function calculation, but not in the caller's calculation. This, unfortunately, is not usually so obvious but exists in an obtuse series of calculations.The following code obtains an untrusted number that is used as an index into an array of messages.. The index is not validated at all (CWE-129), so it might be possible for an attacker to modify an element in @messages that was not intended. If an index is used that is larger than the current size of the array, the Perl interpreter automatically expands the array so that the large index works.. This example shows a typical attempt to parse a string with an error resulting from a difference in assumptions between the caller to a function and the function's action. The buffer length ends up being -1 resulting in a blown out stack. The space character after the colon is included  in the function calculation, but not in the caller's calculation. This, unfortunately, is not usually so obvious but exists in an obtuse series of calculations.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "770", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "476", "View_ID": "1000", "Ordinal": null}]}, {"ID": "79", "Name": "Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')", "Description": "When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.", "Extended_Description": "Cross-site scripting (XSS) vulnerabilities occur when:There are three main kinds of XSS:Once the malicious script is injected, the attacker can perform a variety of malicious activities. The attacker could transfer private information, such as cookies that may include session information, from the victim's machine to the attacker. The attacker could send malicious requests to a web site on behalf of the victim, which could be especially dangerous to the site if the victim has administrator privileges to manage that site. Phishing attacks could be used to emulate trusted web sites and trick the victim into entering a password, allowing the attacker to compromise the victim's account on that web site. Finally, the script could exploit a vulnerability in the web browser itself possibly taking over the victim's machine, sometimes referred to as \"drive-by hacking.\"In many cases, the attack can be launched without the victim even being aware of it. Even with careful users, attackers frequently use a variety of methods to encode the malicious portion of the attack, such as URL encoding or Unicode, so the request looks less suspicious.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlConfidentiality. Impacts: Bypass Protection MechanismRead Application Data. Note: The most common attack performed with cross-site scripting involves the disclosure of information stored in user cookies. Typically, a malicious user will craft a client-side script, which -- when parsed by a web browser -- performs some activity (such as sending all site cookies to a given E-mail address). This script will be loaded and run by each user visiting the web site. Since the site requesting to run the script has access to the cookies in question, the malicious script does also.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: In some circumstances it may be possible to run arbitrary code on a victim's computer when cross-site scripting is combined with other flaws.Scopes: ConfidentialityIntegrityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsBypass Protection MechanismRead Application Data. Note: The consequence of an XSS attack is the same regardless of whether it is stored or reflected. The difference is in how the payload arrives at the server. XSS can cause a variety of problems for the end user that range in severity from an annoyance to complete account compromise. Some cross-site scripting vulnerabilities can be exploited to manipulate or steal cookies, create requests that can be mistaken for those of a valid user, compromise confidential information, or execute malicious code on the end user systems for a variety of nefarious purposes. Other damaging attacks include the disclosure of end user files, installation of Trojan horse programs, redirecting the user to some other page or site, running \"Active X\" controls (under Microsoft Internet Explorer) from sites that a user perceives as trustworthy, and modifying presentation of content.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible, especially when multiple components are involved. Method Name: Black Box. Description: Use the XSS Cheat Sheet [REF-714] or automated test-generation tools to help launch a wide variety of attacks against your web application. The Cheat Sheet contains many subtle XSS variations that are specifically targeted against weak XSS defenses.", "Potential_Mitigations": "Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Examples of libraries and frameworks that make it easier to generate properly encoded output include Microsoft's Anti-XSS library, the OWASP ESAPI Encoding module, and Apache Wicket.Implementation : Understand the context in which your data will be used and the encoding that will be expected. This is especially important when transmitting data between different components, or when generating outputs that can contain multiple encodings at the same time, such as web pages or multi-part mail messages. Study all expected communication protocols and data representations to determine the required encoding strategies.\n                  For any data that will be output to another web page, especially any data that was received from external inputs, use the appropriate encoding on all non-alphanumeric characters.\n                  Parts of the same output document may require different encodings, which will vary depending on whether the output is in the:\n                     \n                        HTML body\n                        Element attributes (such as src=\"XYZ\")\n                        URIs\n                        JavaScript sections\n                        Cascading Style Sheets and style property\n                     \n                  etc. Note that HTML Entity Encoding is only appropriate for the HTML body.\n                  Consult the XSS Prevention Cheat Sheet [REF-724] for more details on the types of encoding and escaping that are needed.Architecture and Design : Understand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Architecture and Design : If available, use structured mechanisms that automatically enforce the separation between data and code. These mechanisms may be able to provide the relevant quoting, encoding, and validation automatically, instead of relying on the developer to provide this capability at every point where output is generated.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : With Struts, write all data from form beans with the bean's filter attribute set to true.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When dynamically constructing web pages, use stringent allowlists that limit the character set based on the expected value of the parameter in the request. All input should be validated and cleansed, not just parameters that the user is supposed to specify, but all data in the request, including hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. It is common to see data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.\n                  Note that proper output encoding, escaping, and quoting is the most effective solution for preventing XSS, although input validation may provide some defense-in-depth. This is because it effectively limits what will appear in output. Input validation will not always prevent XSS, especially if you are required to support free-form text fields that could contain arbitrary characters. For example, in a chat application, the heart emoticon (\"<3\") would likely pass the validation step, since it is commonly used. However, it cannot be directly inserted into the web page because it contains the \"<\" character, which would need to be escaped or otherwise handled. In this case, stripping the \"<\" might reduce the risk of XSS, but it would produce incorrect behavior because the emoticon would not be recorded. This might seem to be a minor inconvenience, but it would be more important in a mathematical forum that wants to represent inequalities.\n                  Even if you make a mistake in your validation (such as forgetting one out of 100 input fields), appropriate encoding is still likely to protect you from injection-based attacks. As long as it is not done in isolation, input validation is still a useful technique, since it may significantly reduce your attack surface, allow you to detect some attacks, and provide other security benefits that proper encoding does not address.\n                  Ensure that you perform input validation at well-defined interfaces within the application. This will help protect the application even if a component is reused or moved elsewhere.Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.Operation : Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.Operation : When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.", "Demonstrative_Examples": "The following code displays a welcome message on a web page based on the HTTP GET username parameter (covers a Reflected XSS (Type 1) scenario).. Because the parameter can be arbitrary, the url of the page could be modified so $username contains scripting syntax, such asThe following code displays a Reflected XSS (Type 1) scenario.. The following JSP code segment reads an employee ID, eid, from an HTTP request and displays it to the user.The following code displays a Stored XSS (Type 2) scenario.. The following JSP code segment queries a database for an employee with a given ID and prints the corresponding employee's name.The following code consists of two separate pages in a web application, one devoted to creating user accounts and another devoted to listing active users currently logged in. It also displays a Stored XSS (Type 2) scenario.. CreateUser.phpThe following code is a simplistic message board that saves messages in HTML format and appends them to a file.  When a new user arrives in the room, it makes an announcement:. An attacker may be able to perform an HTML injection (Type 2 XSS) attack by setting a cookie to a value like:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "494", "View_ID": "1000", "Ordinal": null}, {"Nature": "PeerOf", "CWE_ID": "352", "View_ID": "1000", "Ordinal": null}]}, {"ID": "790", "Name": "Improper Filtering of Special Elements", "Description": "The product receives data from an upstream component, but does not filter or incorrectly filters special elements before sending it to a downstream component.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code takes untrusted input and uses a regular expression to filter \"../\" from the input. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the regular expression does not have the /g global match modifier, it only removes the first instance of \"../\" it comes across. So an input value such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "138", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "791", "Name": "Incomplete Filtering of Special Elements", "Description": "The product receives data from an upstream component, but does not completely filter special elements before sending it to a downstream component.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code takes untrusted input and uses a regular expression to filter \"../\" from the input. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the regular expression does not have the /g global match modifier, it only removes the first instance of \"../\" it comes across. So an input value such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "790", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "792", "Name": "Incomplete Filtering of One or More Instances of Special Elements", "Description": "The product receives data from an upstream component, but does not completely filter one or more instances of special elements before sending it to a downstream component.", "Extended_Description": "Incomplete filtering of this nature involves either:", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code takes untrusted input and uses a regular expression to filter \"../\" from the input. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the regular expression does not have the /g global match modifier, it only removes the first instance of \"../\" it comes across. So an input value such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "791", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "793", "Name": "Only Filtering One Instance of a Special Element", "Description": "The product receives data from an upstream component, but only filters a single instance of a special element before sending it to a downstream component.", "Extended_Description": "Incomplete filtering of this nature may be location-dependent, as in only the first or last element is filtered.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code takes untrusted input and uses a regular expression to filter \"../\" from the input. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the regular expression does not have the /g global match modifier, it only removes the first instance of \"../\" it comes across. So an input value such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "792", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "794", "Name": "Incomplete Filtering of Multiple Instances of Special Elements", "Description": "The product receives data from an upstream component, but does not filter all instances of a special element before sending it to a downstream component.", "Extended_Description": "Incomplete filtering of this nature may be applied to:", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code takes untrusted input and uses a regular expression to filter \"../\" from the input. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the regular expression does not have the /g global match modifier, it only removes the first instance of \"../\" it comes across. So an input value such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "792", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "795", "Name": "Only Filtering Special Elements at a Specified Location", "Description": "The product receives data from an upstream component, but only accounts for special elements at a specified location, thereby missing remaining special elements that may exist before sending it to a downstream component.", "Extended_Description": "A filter might only account for instances of special elements when they occur:This may leave special elements in the data that did not match the filter position, but still may be dangerous.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code takes untrusted input and uses a regular expression to filter a \"../\" element located at the beginning of the input string. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the regular expression is only looking for an instance of \"../\" at the beginning of the string, it only removes the first \"../\" element. So an input value such as:The following code takes untrusted input and uses a substring function to filter a 3-character \"../\" element located at the 0-index position of the input string. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the if function is only looking for a substring of \"../\" between the 0 and 2 position, it only removes that specific \"../\" element. So an input value such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "791", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "796", "Name": "Only Filtering Special Elements Relative to a Marker", "Description": "The product receives data from an upstream component, but only accounts for special elements positioned relative to a marker (e.g. \"at the beginning/end of a string; the second argument\"), thereby missing remaining special elements that may exist before sending it to a downstream component.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code takes untrusted input and uses a regular expression to filter a \"../\" element located at the beginning of the input string. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the regular expression is only looking for an instance of \"../\" at the beginning of the string, it only removes the first \"../\" element. So an input value such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "795", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "797", "Name": "Only Filtering Special Elements at an Absolute Position", "Description": "The product receives data from an upstream component, but only accounts for special elements at an absolute position (e.g. \"byte number 10\"), thereby missing remaining special elements that may exist before sending it to a downstream component.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code takes untrusted input and uses a substring function to filter a 3-character \"../\" element located at the 0-index position of the input string. It then appends this result to the /home/user/ directory and attempts to read the file in the final resulting path.. Since the if function is only looking for a substring of \"../\" between the 0 and 2 position, it only removes that specific \"../\" element. So an input value such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "795", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "8", "Name": "J2EE Misconfiguration: Entity Bean Declared Remote", "Description": "Declare Java beans \"local\" when possible. When a bean must be remotely accessible, make sure that sensitive information is not exposed, and ensure that the application logic performs appropriate validation of any data that might be modified by an attacker.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Declare Java beans \"local\" when possible. When a bean must be remotely accessible, make sure that sensitive information is not exposed, and ensure that the application logic performs appropriate validation of any data that might be modified by an attacker.", "Demonstrative_Examples": ". The following example demonstrates the weakness.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "80", "Name": "Improper Neutralization of Script-Related HTML Tags in a Web Page (Basic XSS)", "Description": "To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Extended_Description": "This may allow such characters to be treated as control characters, which are executed client-side in the context of the user's session. Although this can be classified as an injection problem, the more pertinent issue is the improper conversion of such special characters to respective context-appropriate entities before displaying them to the user.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : With Struts, write all data from form beans with the bean's filter attribute set to true.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Demonstrative_Examples": ". In the following example, a guestbook comment isn't properly encoded, filtered, or otherwise neutralized for script-related tags before being displayed in a client browser.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "79", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "804", "Name": "Guessable CAPTCHA", "Description": "The product uses a CAPTCHA challenge, but the challenge can be guessed or automatically recognized by a non-human actor.", "Extended_Description": "An automated attacker could bypass the intended protection of the CAPTCHA challenge and perform actions at a higher frequency than humanly possible, such as launching spam attacks.There can be several different causes of a guessable CAPTCHA:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Access ControlOther. Impacts: Bypass Protection MechanismOther. Note: When authorization, authentication, or another protection mechanism relies on CAPTCHA entities to ensure that only human actors can access certain functionality, then an automated attacker such as a bot may access the restricted functionality by guessing the CAPTCHA.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "863", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": null}]}, {"ID": "805", "Name": "Buffer Access with Incorrect Length Value", "Description": "Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Extended_Description": "When the length value exceeds the size of the destination, a buffer overflow could occur.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Read MemoryModify MemoryExecute Unauthorized Code or Commands. Note: Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy. This can often be used to subvert any other security service.Scopes: Availability. Impacts: Modify MemoryDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU). Note: Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.Automated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges. Method Name: Automated Dynamic Analysis. Description: This weakness can be detected using dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results. Method Name: Manual Analysis. Description: Manual analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. This becomes difficult for weaknesses that must be considered for all inputs, since the attack surface can be too large.", "Potential_Mitigations": "Requirements : Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, many languages that perform their own memory management, such as Java and Perl, are not subject to buffer overflows. Other languages, such as Ada and C#, typically provide overflow protection, but the protection can be disabled by the programmer.\n                  Be wary that a language's interface to native code may still be subject to overflows, even if the language itself is theoretically safe.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  Examples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57], and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer versions of overflow-prone string-handling functions.Operation : Use automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking.  \n\t\t D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail.Implementation : Consider adhering to the following rules when allocating and managing an application's memory:\n                     \n                        Double check that the buffer is as large as specified.\n                        When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string.\n                        Check buffer boundaries if accessing the buffer in a loop and make sure there is no danger of writing past the allocated space.\n                        If necessary, truncate all input strings to a reasonable length before passing them to the copy and concatenation functions.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Operation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t\t  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].Operation : Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment.   \n\t          For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336].Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the product or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.", "Demonstrative_Examples": "This example takes an IP address from a user, verifies that it is well formed and then looks up the hostname and copies it into a buffer.. This function allocates a buffer of 64 bytes to store the hostname under the assumption that the maximum length value of hostname is 64 bytes, however there is no guarantee that the hostname will not be larger than 64 bytes. If an attacker specifies an address which resolves to a very large hostname, then the function may overwrite sensitive data or even relinquish control flow to the attacker.In the following example, it is possible to request that memcpy move a much larger segment of memory than assumed:. If returnChunkSize() happens to encounter an error it will return -1. Notice that the return value is not checked before the memcpy operation (CWE-252), so -1 can be passed as the size argument to memcpy() (CWE-805). Because memcpy() assumes that the value is unsigned, it will be interpreted as MAXINT-1 (CWE-195), and therefore will copy far more memory than is likely available to the destination buffer (CWE-787, CWE-788).In the following example, the source character string is copied to the dest character string using the method strncpy.. However, in the call to strncpy the source character string is used within the sizeof call to determine the number of characters to copy. This will create a buffer overflow as the size of the source character string is greater than the dest character string. The dest character string should be used within the sizeof call to ensure that the correct number of characters are copied, as shown below.In this example, the method outputFilenameToLog outputs a filename to a log file. The method arguments include a pointer to a character string containing the file name and an integer for the number of characters in the string. The filename is copied to a buffer where the buffer size is set to a maximum size for inputs to the log file. The method then calls another method to save the contents of the buffer to the log file.. However, in this case the string copy method, strncpy, mistakenly uses the length method argument to determine the number of characters to copy rather than using the size of the local character string, buf. This can lead to a buffer overflow if the number of characters contained in character string pointed to by filename is larger then the number of characters allowed for the local character string. The string copy method should use the buf character string within a sizeof call to ensure that only characters up to the size of the buf array are copied to avoid a buffer overflow, as shown below.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "806", "Name": "Buffer Access Using Size of Source Buffer", "Description": "Most mitigating technologies at the compiler or OS level to date address only a subset of buffer overflow problems and rarely provide complete protection against even that subset. It is good practice to implement strategies to increase the workload of an attacker, such as leaving the attacker to guess an unknown value that changes every program execution.", "Extended_Description": "When the size of the destination is smaller than the size of the source, a buffer overflow could occur.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: Modify MemoryDoS: Crash, Exit, or RestartDoS: Resource Consumption (CPU). Note: Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.Scopes: IntegrityConfidentialityAvailability. Impacts: Read MemoryModify MemoryExecute Unauthorized Code or Commands. Note: Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: When the consequence is arbitrary code execution, this can often be used to subvert any other security service.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use an abstraction library to abstract away risky APIs. Examples include the Safe C String Library (SafeStr) by Viega, and the Strsafe.h library from Microsoft. This is not a complete solution, since many buffer overflows are not related to strings.Operation : Use automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking.  \n\t\t D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail.Implementation : Programmers should adhere to the following rules when allocating and managing their applications memory: Double check that your buffer is as large as you specify. When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string. Check buffer boundaries if calling this function in a loop and make sure there is no danger of writing past the allocated space. Truncate all input strings to a reasonable length before passing them to the copy and concatenation functionsOperation : Run or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code.  \n\t\t  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking.  \n\t\t  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335].Operation : Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment.   \n\t          For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336].Build and Compilation : Most mitigating technologies at the compiler or OS level to date address only a subset of buffer overflow problems and rarely provide complete protection against even that subset. It is good practice to implement strategies to increase the workload of an attacker, such as leaving the attacker to guess an unknown value that changes every program execution.", "Demonstrative_Examples": "In the following example, the source character string is copied to the dest character string using the method strncpy.. However, in the call to strncpy the source character string is used within the sizeof call to determine the number of characters to copy. This will create a buffer overflow as the size of the source character string is greater than the dest character string. The dest character string should be used within the sizeof call to ensure that the correct number of characters are copied, as shown below.In this example, the method outputFilenameToLog outputs a filename to a log file. The method arguments include a pointer to a character string containing the file name and an integer for the number of characters in the string. The filename is copied to a buffer where the buffer size is set to a maximum size for inputs to the log file. The method then calls another method to save the contents of the buffer to the log file.. However, in this case the string copy method, strncpy, mistakenly uses the length method argument to determine the number of characters to copy rather than using the size of the local character string, buf. This can lead to a buffer overflow if the number of characters contained in character string pointed to by filename is larger then the number of characters allowed for the local character string. The string copy method should use the buf character string within a sizeof call to ensure that only characters up to the size of the buf array are copied to avoid a buffer overflow, as shown below.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "805", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "81", "Name": "Improper Neutralization of Script in an Error Message Web Page", "Description": "To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Extended_Description": "Error pages may include customized 403 Forbidden or 404 Not Found pages.When an attacker can trigger an error that contains script syntax within the attacker's input, then cross-site scripting attacks may be possible.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Do not write user-controlled input to error pages.Implementation : Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : With Struts, write all data from form beans with the bean's filter attribute set to true.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "79", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanAlsoBe", "CWE_ID": "209", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "390", "View_ID": "1000", "Ordinal": null}]}, {"ID": "83", "Name": "Improper Neutralization of Script in Attributes in a Web Page", "Description": "To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including tag attributes, hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : With Struts, write all data from form beans with the bean's filter attribute set to true.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "79", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "82", "Name": "Improper Neutralization of Script in Attributes of IMG Tags in a Web Page", "Description": "To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Extended_Description": "Attackers can embed XSS exploits into the values for IMG attributes (e.g. SRC) that is streamed and then executed in a victim's browser. Note that when the page is loaded into a user's browsers, the exploit will automatically execute.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "83", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "822", "Name": "Untrusted Pointer Dereference", "Description": "The product obtains a value from an untrusted source, converts this value to a pointer, and dereferences the resulting pointer.", "Extended_Description": "An attacker can supply a pointer for memory locations that the product is not expecting. If the pointer is dereferenced for a write operation, the attack might allow modification of critical state variables, cause a crash, or execute code. If the dereferencing operation is for a read, then the attack might allow reading of sensitive data, cause a crash, or set a variable to an unexpected value (since the value will be read from an unexpected memory location).There are several variants of this weakness, including but not necessarily limited to:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Memory. Note: If the untrusted pointer is used in a read operation, an attacker might be able to read sensitive portions of memory.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: If the untrusted pointer references a memory location that is not accessible to the product, or points to a location that is \"malformed\" or larger than expected by a read or write operation, the application may terminate unexpectedly.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or CommandsModify Memory. Note: If the untrusted pointer is used in a function call, or points to unexpected data in a write operation, then code execution may be possible.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "125", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "787", "View_ID": "1000", "Ordinal": null}]}, {"ID": "823", "Name": "Use of Out-of-range Pointer Offset", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "While a pointer can contain a reference to any arbitrary memory location, a program typically only intends to use the pointer to access limited portions of memory, such as contiguous memory used to access an individual array.Programs may use offsets in order to access fields or sub-elements stored within structured data. The offset might be out-of-range if it comes from an untrusted source, is the result of an incorrect calculation, or occurs because of another error.If an attacker can control or influence the offset so that it points outside of the intended boundaries of the structure, then the attacker may be able to read or write to memory locations that are used elsewhere in the product. As a result, the attack might change the state of the product as accessed through program variables, cause a crash or instable behavior, and possibly lead to code execution.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Memory. Note: If the untrusted pointer is used in a read operation, an attacker might be able to read sensitive portions of memory.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: If the untrusted pointer references a memory location that is not accessible to the program, or points to a location that is \"malformed\" or larger than expected by a read or write operation, the application may terminate unexpectedly.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or CommandsModify Memory. Note: If the untrusted pointer is used in a function call, or points to unexpected data in a write operation, then code execution may be possible.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "125", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "787", "View_ID": "1000", "Ordinal": null}]}, {"ID": "824", "Name": "Access of Uninitialized Pointer", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "If the pointer contains an uninitialized value, then the value might not point to a valid memory location. This could cause the product to read from or write to unexpected memory locations, leading to a denial of service. If the uninitialized pointer is used as a function call, then arbitrary functions could be invoked. If an attacker can influence the portion of uninitialized memory that is contained in the pointer, this weakness could be leveraged to execute code or perform other attacks.Depending on memory layout, associated memory management behaviors, and product operation, the attacker might be able to influence the contents of the uninitialized pointer, thus gaining more fine-grained control of the memory location to be accessed.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Memory. Note: If the uninitialized pointer is used in a read operation, an attacker might be able to read sensitive portions of memory.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: If the uninitialized pointer references a memory location that is not accessible to the product, or points to a location that is \"malformed\" (such as NULL) or larger than expected by a read or write operation, then a crash may occur.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: If the uninitialized pointer is used in a function call, or points to unexpected data in a write operation, then code execution may be possible.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "119", "View_ID": "1340", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "125", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "787", "View_ID": "1000", "Ordinal": null}]}, {"ID": "826", "Name": "Premature Release of Resource During Expected Lifetime", "Description": "The product releases a resource that is still intended to be used by itself or another actor.", "Extended_Description": "This weakness focuses on errors in which the product should not release a resource, but performs the release anyway. This is different than a weakness in which the product releases a resource at the appropriate time, but it maintains a reference to the resource, which it later accesses. For this weakness, the resource should still be valid upon the subsequent access.When a product releases a resource that is still being used, it is possible that operations will still be taken on this resource, which may have been repurposed in the meantime, leading to issues similar to CWE-825. Consequences may include denial of service, information exposure, or code execution.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Memory. Note: If the released resource is subsequently reused or reallocated, then a read operation on the original resource might access sensitive data that is associated with a different user or entity.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: When the resource is released, the software might modify some of its structure, or close associated channels (such as a file descriptor). When the software later accesses the resource as if it is valid, the resource might not be in an expected state, leading to resultant errors that may lead to a crash.Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or CommandsModify Application DataModify Memory. Note: When the resource is released, the software might modify some of its structure. This might affect logic in the sections of code that still assume the resource is active. If the released resource is related to memory and is used in a function call, or points to unexpected data in a write operation, then code execution may be possible upon subsequent accesses.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "666", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "672", "View_ID": "1000", "Ordinal": null}]}, {"ID": "827", "Name": "Improper Control of Document Type Definition", "Description": "The product does not restrict a reference to a Document Type Definition (DTD) to the intended control sphere. This might allow attackers to reference arbitrary DTDs, possibly causing the product to expose files, consume excessive system resources, or execute arbitrary http requests on behalf of the attacker.", "Extended_Description": "As DTDs are processed, they might try to read or include files on the machine performing the parsing. If an attacker is able to control the DTD, then the attacker might be able to specify sensitive resources or requests or provide malicious content.For example, the SOAP specification prohibits SOAP messages from containing DTDs.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or Directories. Note: If the attacker is able to include a crafted DTD and a default entity resolver is enabled, the attacker may be able to access arbitrary files on the system.Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory). Note: The DTD may cause the parser to consume excessive CPU cycles or memory using techniques such as nested or recursive entity references (CWE-776).Scopes: IntegrityConfidentialityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsGain Privileges or Assume Identity. Note: The DTD may include arbitrary HTTP requests that the server may execute. This could lead to other attacks leveraging the server's trust relationship with other entities.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "829", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "776", "View_ID": "1000", "Ordinal": null}]}, {"ID": "829", "Name": "Inclusion of Functionality from Untrusted Control Sphere", "Description": "Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.", "Extended_Description": "When including third-party functionality, such as a web widget, library, or other source of functionality, the product must effectively trust that functionality. Without sufficient protection mechanisms, the functionality could be malicious in nature (either by coming from an untrusted source, being spoofed, or being modified in transit from a trusted source). The functionality might also contain its own weaknesses, or grant access to additional functionality and state information that should be kept private to the base system, such as system state information, sensitive application data, or the DOM of a web application.This might lead to many different consequences depending on the included functionality, but some examples include injection of malware, information exposure by granting excessive privileges or permissions to the untrusted functionality, DOM-based XSS vulnerabilities, stealing user's cookies, or open redirect to malware (CWE-601).", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: An attacker could insert malicious functionality into the program by causing the program to download code that the attacker has placed into the untrusted control sphere, such as a malicious web site.", "Detection_Methods": "Method Name: Automated Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Binary or Bytecode. Description: According to SOAR, the following detection techniques may be useful: Method Name: Dynamic Analysis with Manual Results Interpretation. Description: According to SOAR, the following detection techniques may be useful: Method Name: Manual Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Automated Static Analysis - Source Code. Description: According to SOAR, the following detection techniques may be useful: Method Name: Architecture or Design Review. Description: According to SOAR, the following detection techniques may be useful:", "Potential_Mitigations": "Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n                  For example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\". Features such as the ESAPI AccessReferenceMap [REF-45] provide this capability.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Architecture and Design : Store library, include, and utility files outside of the web document root, if possible. Otherwise, store them in a separate directory and use the web server's access control capabilities to prevent attackers from directly requesting them. One common practice is to define a fixed constant in each calling program, then check for the existence of the constant in the library/include file; if the constant does not exist, then the file was directly requested, and it can exit immediately.\n                  This significantly reduces the chance of an attacker being able to bypass any protection mechanisms that are in the base program but not in the include files. It will also reduce the attack surface.Architecture and Design : Understand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n                  Many file inclusion problems occur because the programmer assumed that certain inputs could not be modified, especially for cookies and URL components.Operation : Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.", "Demonstrative_Examples": "This login webpage includes a weather widget from an external website:. This webpage is now only as secure as the external domain it is including functionality from. If an attacker compromised the external domain and could add malicious scripts to the weatherwidget.js file, the attacker would have complete control, as seen in any XSS weakness (CWE-79).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "669", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "830", "Name": "Inclusion of Web Functionality from an Untrusted Source", "Description": "The product includes web functionality (such as a web widget) from another domain, which causes it to operate within the domain of the product, potentially granting total access and control of the product to the untrusted source.", "Extended_Description": "Including third party functionality in a web-based environment is risky, especially if the source of the functionality is untrusted.Even if the third party is a trusted source, the product may still be exposed to attacks and malicious behavior if that trusted source is compromised, or if the code is modified in transmission from the third party to the product.This weakness is common in \"mashup\" development on the web, which may include source functionality from other domains. For example, Javascript-based web widgets may be inserted by using '<SCRIPT SRC=\"http://other.domain.here\">' tags, which causes the code to run in the domain of the product, not the remote site from which the widget was loaded. As a result, the included code has access to the local DOM, including cookies and other data that the developer might not want the remote site to be able to access.Such dependencies may be desirable, or even required, but sometimes programmers are not aware that a dependency exists.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This login webpage includes a weather widget from an external website:. This webpage is now only as secure as the external domain it is including functionality from. If an attacker compromised the external domain and could add malicious scripts to the weatherwidget.js file, the attacker would have complete control, as seen in any XSS weakness (CWE-79).", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "829", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "831", "Name": "Signal Handler Function Associated with Multiple Signals", "Description": "The product defines a function that is used as a handler for more than one signal.", "Extended_Description": "While sometimes intentional and safe, when the same function is used to handle multiple signals, a race condition could occur if the function uses any state outside of its local declaration, such as global variables or non-reentrant functions, or has any side effects.An attacker could send one signal that invokes the handler function; in many OSes, this will typically prevent the same signal from invoking the handler again, at least until the handler function has completed execution. However, the attacker could then send a different signal that is associated with the same handler function. This could interrupt the original handler function while it is still executing. If there is shared state, then the state could be corrupted. This can lead to a variety of potential consequences depending on context, including denial of service and code execution.Another rarely-explored possibility arises when the signal handler is only designed to be executed once (if at all). By sending multiple signals, an attacker could invoke the function more than once. This may generate extra, unintended side effects. A race condition might not even be necessary; the attacker could send one signal, wait until it is handled, then send the other signal.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityIntegrityConfidentialityAccess ControlOther. Impacts: DoS: Crash, Exit, or RestartExecute Unauthorized Code or CommandsRead Application DataGain Privileges or Assume IdentityBypass Protection MechanismVaries by Context. Note: The most common consequence will be a corruption of the state of the product, possibly leading to a crash or exit. However, if the signal handler is operating on state variables for security relevant libraries or protection mechanisms, the consequences can be far more severe, including protection mechanism bypass, privilege escalation, or information exposure.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": ". This code registers the same signal handler function with two different signals.This code registers the same signal handler function with two different signals (CWE-831). If those signals are sent to the process, the handler creates a log message (specified in the first argument to the program) and exits.. The handler function uses global state (globalVar and logMessage), and it can be called by both the SIGHUP and SIGTERM signals. An attack scenario might follow these lines:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "364", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "832", "Name": "Unlock of a Resource that is not Locked", "Description": "The product attempts to unlock a resource that is not locked.", "Extended_Description": "Depending on the locking functionality, an unlock of a non-locked resource might cause memory corruption or other modification to the resource (or its associated metadata that is used for tracking locks).", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailabilityOther. Impacts: DoS: Crash, Exit, or RestartExecute Unauthorized Code or CommandsModify MemoryOther. Note: Depending on the locking being used, an unlock operation might not have any adverse effects. When effects exist, the most common consequence will be a corruption of the state of the product, possibly leading to a crash or exit; depending on the implementation of the unlocking, memory corruption or code execution could occur.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "833", "Name": "Deadlock", "Description": "The product contains multiple threads or executable segments that are waiting for each other to release a necessary lock, resulting in deadlock.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Other)DoS: Crash, Exit, or Restart. Note: Each thread of execution will \"hang\" and prevent tasks from completing. In some cases, CPU consumption may occur if a lock check occurs in a tight loop.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "667", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "662", "View_ID": "1305", "Ordinal": "Primary"}]}, {"ID": "835", "Name": "Loop with Unreachable Exit Condition ('Infinite Loop')", "Description": "The product contains an iteration or loop with an exit condition that cannot be reached, i.e., an infinite loop.", "Extended_Description": "If the loop can be influenced by an attacker, this weakness could allow attackers to consume excessive resources such as CPU or memory.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (CPU)DoS: Resource Consumption (Memory)DoS: Amplification. Note: An infinite loop will cause unexpected consumption of resources, such as CPU cycles or memory. The software's operation may slow down, or cause a long time to respond.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "In the following code the method processMessagesFromServer attempts to establish a connection to a server and read and process messages from the server. The method uses a do/while loop to continue trying to establish the connection to the server when an attempt fails.. However, this will create an infinite loop if the server does not respond. This infinite loop will consume system resources and can be used to create a denial of service attack. To resolve this a counter should be used to limit the number of attempts to establish a connection to the server, as in the following code.For this example the method isReorderNeeded as part of a bookstore application that determines if a particular book needs to be reordered based on the current inventory count and the rate at which the book is being sold.. However, the while loop will become an infinite loop if the rateSold input parameter has a value of zero since the inventoryCount will never fall below the minimumCount. In this case the input parameter should be validated to ensure that a value of zero does not cause an infinite loop,as in the following code.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "834", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "834", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "836", "Name": "Use of Password Hash Instead of Password for Authentication", "Description": "The product records password hashes in a data store, receives a hash of a password from a client, and compares the supplied hash to the hash obtained from the data store.", "Extended_Description": "Some authentication mechanisms rely on the client to generate the hash for a password, possibly to reduce load on the server or avoid sending the password across the network. However, when the client is used to generate the hash, an attacker can bypass the authentication by obtaining a copy of the hash, e.g. by using SQL injection to compromise a database of authentication credentials, or by exploiting an information exposure. The attacker could then use a modified client to replay the stolen hash without having knowledge of the original password.As a result, the server-side comparison against a client-side hash does not provide any more security than the use of passwords without hashing.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access Control. Impacts: Bypass Protection MechanismGain Privileges or Assume Identity. Note: An attacker could bypass the authentication routine without knowing the original password.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1390", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "602", "View_ID": "1000", "Ordinal": null}]}, {"ID": "837", "Name": "Improper Enforcement of a Single, Unique Action", "Description": "The product requires that an actor should only be able to perform an action once, or to have only one unique action, but the product does not enforce or improperly enforces this restriction.", "Extended_Description": "In various applications, a user is only expected to perform a certain action once, such as voting, requesting a refund, or making a purchase. When this restriction is not enforced, sometimes this can have security implications. For example, in a voting application, an attacker could attempt to \"stuff the ballot box\" by voting multiple times. If these votes are counted separately, then the attacker could directly affect who wins the vote. This could have significant business impact depending on the purpose of the product.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Other. Impacts: . Note: An attacker might be able to gain advantage over other users by performing the action multiple times, or affect the correctness of the product.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "799", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "838", "Name": "Inappropriate Encoding for Output Context", "Description": "Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using the ESAPI Encoding control [REF-45] or a similar tool, library, or framework. These will help the programmer encode outputs in a manner less prone to error.\n                  Note that some template mechanisms provide built-in support for the appropriate encoding.", "Extended_Description": "This weakness can cause the downstream component to use a decoding method that produces different data than what the product intended to send. When the wrong encoding is used - even if closely related - the downstream component could decode the data incorrectly. This can have security consequences when the provided boundaries between control and data are inadvertently broken, because the resulting data could introduce control characters or special elements that were not sent by the product. The resulting data could then be used to bypass protection mechanisms such as input validation, and enable injection attacks.While using output encoding is essential for ensuring that communications between components are accurate, the use of the wrong encoding - even if closely related - could cause the downstream component to misinterpret the output.For example, HTML entity encoding is used for elements in the HTML body of a web page. However, a programmer might use entity encoding when generating output for that is used within an attribute of an HTML tag, which could contain functional Javascript that is not affected by the HTML encoding.While web applications have received the most attention for this problem, this weakness could potentially apply to any type of product that uses a communications stream that could support multiple encodings.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Modify Application DataExecute Unauthorized Code or Commands. Note: An attacker could modify the structure of the message or data being sent to the downstream component, possibly injecting commands.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Use context-aware encoding. That is, understand which encoding is being used by the downstream component, and ensure that this encoding is used. If an encoding can be specified, do so, instead of assuming that the default encoding is the same as the default being assumed by the downstream component.Architecture and Design : Where possible, use communications protocols or data formats that provide strict boundaries between control and data. If this is not feasible, ensure that the protocols or formats allow the communicating components to explicitly state which encoding/decoding method is being used. Some template frameworks provide built-in support.Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n                  For example, consider using the ESAPI Encoding control [REF-45] or a similar tool, library, or framework. These will help the programmer encode outputs in a manner less prone to error.\n                  Note that some template mechanisms provide built-in support for the appropriate encoding.", "Demonstrative_Examples": "This code dynamically builds an HTML page using POST data:. The programmer attempts to avoid XSS exploits (CWE-79) by encoding the POST values so they will not be interpreted as valid HTML. However, the htmlentities() encoding is not appropriate when the data are used as HTML attributes, allowing more attributes to be injected.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "116", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "116", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "839", "Name": "Numeric Range Comparison Without Minimum Check", "Description": "If the number to be used could have a negative value based on the specification (thus requiring a signed value), but the number should only be positive to preserve code correctness, then include a check to ensure that the value is positive.", "Extended_Description": "Some products use signed integers or floats even when their values are only expected to be positive or 0. An input validation check might assume that the value is positive, and only check for the maximum value. If the value is negative, but the code assumes that the value is positive, this can produce an error. The error may have security consequences if the negative value is used for memory allocation, array access, buffer access, etc. Ultimately, the error could lead to a buffer overflow or other type of memory corruption.The use of a negative number in a positive-only context could have security implications for other types of resources. For example, a shopping cart might check that the user is not requesting more than 10 items, but a request for -3 items could cause the application to calculate a negative price and credit the attacker's account.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Modify Application DataExecute Unauthorized Code or Commands. Note: An attacker could modify the structure of the message or data being sent to the downstream component, possibly injecting commands.Scopes: Availability. Impacts: DoS: Resource Consumption (Other). Note: in some contexts, a negative value could lead to resource consumption.Scopes: ConfidentialityIntegrity. Impacts: Modify MemoryRead Memory. Note: If a negative value is used to access memory, buffers, or other indexable structures, it could access memory outside the bounds of the buffer.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : If the number to be used is always expected to be positive, change the variable type from signed to unsigned or size_t.Implementation : If the number to be used could have a negative value based on the specification (thus requiring a signed value), but the number should only be positive to preserve code correctness, then include a check to ensure that the value is positive.", "Demonstrative_Examples": "The following code is intended to read an incoming packet from a socket and extract one or more headers.. The code performs a check to make sure that the packet does not contain too many headers. However, numHeaders is defined as a signed int, so it could be negative. If the incoming packet specifies a value such as -3, then the malloc calculation will generate a negative number (say, -300 if each header can be a maximum of 100 bytes). When this result is provided to malloc(), it is first converted to a size_t type. This conversion then produces a large value such as 4294966996, which may cause malloc() to fail or to allocate an extremely large amount of memory (CWE-195). With the appropriate negative numbers, an attacker could trick malloc() into using a very small positive number, which then allocates a buffer that is much smaller than expected, potentially leading to a buffer overflow.The following code reads a maximum size and performs a sanity check on that size. It then performs a strncpy, assuming it will not exceed the boundaries of the array. While the use of \"short s\" is forced in this particular example, short int's are frequently used within real-world code, such as code that processes structured data.. This code first exhibits an example of CWE-839, allowing \"s\" to be a negative number. When the negative short \"s\" is converted to an unsigned integer, it becomes an extremely large positive integer. When this converted integer is used by strncpy() it will lead to a buffer overflow (CWE-119).In the following code, the method retrieves a value from an array at a specific array index location that is given as an input parameter to the method. However, this method only verifies that the given array index is less than the maximum length of the array but does not check for the minimum value (CWE-839). This will allow a negative value to be accepted as the input array index, which will result in a out of bounds read (CWE-125) and may allow access to sensitive memory. The input array index should be checked to verify that is within the maximum and minimum range required for the array (CWE-129). In this example the if statement should be modified to include a minimum range check, as shown below.The following code shows a simple BankAccount class with deposit and withdraw methods.. The withdraw method includes a check to ensure that the withdrawal amount does not exceed the maximum limit allowed, however the method does not check to ensure that the withdrawal amount is greater than a minimum value (CWE-129). Performing a range check on a value that does not include a minimum check can have significant security implications, in this case not including a minimum range check can allow a negative value to be used which would cause the financial application using this class to deposit money into the user account rather than withdrawing. In this example the if statement should the modified to include a minimum range check, as shown below.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "1023", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "195", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "682", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "124", "View_ID": "1000", "Ordinal": null}]}, {"ID": "84", "Name": "Improper Neutralization of Encoded URI Schemes in a Web Page", "Description": "To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Resolve all URIs to absolute or canonical representations before processing.Implementation : Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including tag attributes, hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : With Struts, write all data from form beans with the bean's filter attribute set to true.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "79", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "841", "Name": "Improper Enforcement of Behavioral Workflow", "Description": "The product supports a session in which more than one behavior must be performed by an actor, but it does not properly ensure that the actor performs the behaviors in the required sequence.", "Extended_Description": "By performing actions in an unexpected order, or by omitting steps, an attacker could manipulate the business logic of the product or cause it to enter an invalid state. In some cases, this can also expose resultant weaknesses.For example, a file-sharing protocol might require that an actor perform separate steps to provide a username, then a password, before being able to transfer files. If the file-sharing server accepts a password command followed by a transfer command, without any username being provided, the product might still perform the transfer.Note that this is different than CWE-696, which focuses on when the product performs actions in the wrong sequence; this entry is closely related, but it is focused on ensuring that the actor performs actions in the correct sequence.Workflow-related behaviors include:", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Other. Impacts: Alter Execution Logic. Note: An attacker could cause the product to skip critical steps or perform them in the wrong order, bypassing its intended business logic. This can sometimes have security implications.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This code is part of an FTP server and deals with various commands that could be sent by a user. It is intended that a user must successfully login before performing any other action such as retrieving or listing files.. The server correctly avoids sending files to a user that isn't logged in and doesn't own the file. However, the server will incorrectly list the files in any directory without confirming the command came from an authenticated user, and that the user is authorized to see the directory's contents.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "691", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "842", "Name": "Placement of User into Incorrect Group", "Description": "The product or the administrator places a user into an incorrect group.", "Extended_Description": "If the incorrect group has more access or privileges than the intended group, the user might be able to bypass intended security policy to access unexpected resources or perform unexpected actions. The access-control system might not be able to detect malicious usage of this group membership.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "286", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "843", "Name": "Access of Resource Using Incompatible Type ('Type Confusion')", "Description": "The product allocates or initializes a resource such as a pointer, object, or variable using one type, but it later accesses that resource using a type that is incompatible with the original type.", "Extended_Description": "When the product accesses the resource using an incompatible type, this could trigger logical errors because the resource does not have expected properties. In languages without memory safety, such as C and C++, type confusion can lead to out-of-bounds memory access.While this weakness is frequently associated with unions when parsing data with many different embedded object types in C, it can be present in any application that can interpret the same variable or memory location in multiple ways.This weakness is not unique to C and C++. For example, errors in PHP applications can be triggered by providing array parameters when scalars are expected, or vice versa. Languages such as Perl, which perform automatic conversion of a variable of one type when it is accessed as if it were another type, can also contain these issues.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityIntegrityConfidentiality. Impacts: Read MemoryModify MemoryExecute Unauthorized Code or CommandsDoS: Crash, Exit, or Restart. Note: When a memory buffer is accessed using the wrong type, it could read or write memory out of the bounds of the buffer, if the allocated buffer is smaller than the type that the code is attempting to access, leading to a crash and possibly code execution.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "The following code uses a union to support the representation of different types of messages. It formats messages differently, depending on their type.. The code intends to process the message as a NAME_TYPE, and sets the default message to \"Hello World.\" However, since both buf.name and buf.nameID are part of the same union, they can act as aliases for the same memory location, depending on memory layout after compilation.The following PHP code accepts a value, adds 5, and prints the sum.. When called with the following query string:The following Perl code is intended to look up the privileges for user ID's between 0 and 3, by performing an access of the $UserPrivilegeArray reference. It is expected that only userID 3 is an admin (since this is listed in the third element of the array).. In this case, the programmer intended to use \"$UserPrivilegeArray->{$userID}\" to access the proper position in the array. But because the subscript was omitted, the \"user\" string was compared to the scalar representation of the $UserPrivilegeArray reference, which might be of the form \"ARRAY(0x229e8)\" or similar.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "704", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "704", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "119", "View_ID": "1000", "Ordinal": null}]}, {"ID": "85", "Name": "Doubled Character XSS Manipulations", "Description": "To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Resolve all filtered input to absolute or canonical representations before processing.Implementation : Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including tag attributes, hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : With Struts, write all data from form beans with the bean's filter attribute set to true.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "79", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "675", "View_ID": "1000", "Ordinal": null}]}, {"ID": "86", "Name": "Improper Neutralization of Invalid Characters in Identifiers in Web Pages", "Description": "To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Extended_Description": "Some web browsers may remove these sequences, resulting in output that may have unintended control implications. For example, the product may attempt to remove a \"javascript:\" URI scheme, but a \"java%00script:\" URI may bypass this check and still be rendered as active javascript by some browsers, allowing XSS or other attacks.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "79", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "184", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "436", "View_ID": "1000", "Ordinal": null}]}, {"ID": "87", "Name": "Improper Neutralization of Alternate XSS Syntax", "Description": "To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Extended_Description": "N/A", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Resolve all input to absolute or canonical representations before processing.Implementation : Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including tag attributes, hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.Implementation : Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n                  The problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.Implementation : With Struts, write all data from form beans with the bean's filter attribute set to true.Implementation : To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.", "Demonstrative_Examples": "In the following example, an XSS neutralization method intends to replace script tags in user-supplied input with a safe equivalent:. The code only works when the \"script\" tag is in all lower-case, forming an incomplete denylist (CWE-184). Equivalent tags such as \"SCRIPT\" or \"ScRiPt\" will not be neutralized by this method, allowing an XSS attack.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "79", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "88", "Name": "Improper Neutralization of Argument Delimiters in a Command ('Argument Injection')", "Description": "Use dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.", "Extended_Description": "When creating commands using interpolation into a string, developers may assume that only the arguments/options that they specify will be processed.  This assumption may be even stronger when the programmer has encoded the command in a way that prevents separate commands from being provided maliciously, e.g. in the case of shell metacharacters.  When constructing the command, the developer may use whitespace or other delimiters that are required to separate arguments when the command. However, if an attacker can provide an untrusted input that contains argument-separating delimiters, then the resulting command will have more arguments than intended by the developer.  The attacker may then be able to change the behavior of the command.  Depending on the functionality supported by the extraneous arguments, this may have security-relevant consequences.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityOther. Impacts: Execute Unauthorized Code or CommandsAlter Execution LogicRead Application DataModify Application Data. Note: An attacker could include arguments that allow unintended commands or code to be executed, allow sensitive data to be read or modified or could cause other unintended behavior.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Where possible, avoid building a single string that contains the command and its arguments.  Some languages or frameworks have functions that support specifying independent arguments, e.g. as an array, which is used to automatically perform the appropriate quoting or escaping while building the command.  For example, in PHP, escapeshellarg() can be used to escape a single argument to system(), or exec() can be called with an array of arguments.  In C, code can often be refactored from using system() - which accepts a single string - to using exec(), which requires separate function arguments for each parameter.Architecture and Design : Understand all the potential areas where untrusted inputs can enter your product: parameters or arguments, cookies, anything read from the network, environment variables, request headers as well as content, URL components, e-mail, files, databases, and any external systems that provide data to the application. Perform input validation at well-defined interfaces.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Directly convert your input type into the expected data type, such as using a conversion function that translates a string into a number. After converting to the expected data type, ensure that the input's values fall within the expected range of allowable values and that multi-field consistencies are maintained.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180, CWE-181). Make sure that your application does not inadvertently decode the same input twice (CWE-174). Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization control.\n                  Consider performing repeated canonicalization until your input does not change any more. This will avoid double-decoding and similar scenarios, but it might inadvertently modify inputs that are allowed to contain properly-encoded dangerous content.Implementation : When exchanging data between components, ensure that both components are using the same character encoding. Ensure that the proper encoding is applied at each interface. Explicitly set the encoding you are using whenever the protocol allows you to do so.Implementation : When your application combines data from multiple sources, perform the validation after the sources have been combined. The individual data elements may pass the validation step but violate the intended restrictions after they have been combined.Testing : Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.Testing : Use dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.", "Demonstrative_Examples": "Consider the following program. It intends to perform an \"ls -l\" on an input filename. The validate_name() subroutine performs validation on the input to make sure that only alphanumeric and \"-\" characters are allowed, which avoids path traversal (CWE-22) and OS command injection (CWE-78) weaknesses. Only filenames like \"abc\" or \"d-e-f\" are intended to be allowed.. However, validate_name() allows\n               filenames that begin with a \"-\". An adversary could\n               supply a filename like \"-aR\", producing the \"ls -l -aR\"\n               command (CWE-88), thereby getting a full recursive\n               listing of the entire directory and all of its\n               sub-directories.There are a couple possible mitigations for this\n\t       weakness. One would be to refactor the code to avoid\n\t       using system() altogether, instead relying on internal\n\t       functions.Another option could be to add a \"--\" argument\n\t       to the ls command, such as \"ls -l --\", so that any\n\t       remaining arguments are treated as filenames, causing\n\t       any leading \"-\" to be treated as part of a filename\n\t       instead of another option.Another fix might be to change the regular expression used in validate_name to force the first character of the filename to be a letter or number, such as:CVE-2016-10033 / [REF-1249] provides a useful real-world example of this weakness within PHPMailer.. The program calls PHP's mail() function to compose and send mail. The fifth argument to mail() is a set of parameters. The program intends to provide a \"-fSENDER\" parameter, where SENDER is expected to be a well-formed email address. The program has already validated the e-mail address before invoking mail(), but there is a lot of flexibility in what constitutes a well-formed email address, including whitespace. With some additional allowed characters to perform some escaping, the adversary can specify an additional \"-o\" argument (listing an output file) and a \"-X\" argument (giving a program to execute). Additional details for this kind of exploit are in [REF-1250].", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "9", "Name": "J2EE Misconfiguration: Weak Access Permissions for EJB Methods", "Description": "Follow the principle of least privilege when assigning access rights to EJB methods. Permission to invoke EJB methods should not be granted to the ANYONE role.", "Extended_Description": "If the EJB deployment descriptor contains one or more method permissions that grant access to the special ANYONE role, it indicates that access control for the application has not been fully thought through or that the application is structured in such a way that reasonable access control restrictions are impossible.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Follow the principle of least privilege when assigning access rights to EJB methods. Permission to invoke EJB methods should not be granted to the ANYONE role.", "Demonstrative_Examples": ". The following deployment descriptor grants ANYONE permission to invoke the Employee EJB's method named getSalary().", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "266", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "90", "Name": "Improper Neutralization of Special Elements used in an LDAP Query ('LDAP Injection')", "Description": "Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailability. Impacts: Execute Unauthorized Code or CommandsRead Application DataModify Application Data. Note: An attacker could include input that changes the LDAP query which allows unintended commands or code to be executed, allows sensitive data to be read or modified or causes other unintended behavior.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.", "Demonstrative_Examples": "The code below constructs an LDAP query using user input address data:. Because the code fails to neutralize the address string used to construct the query, an attacker can supply an address that includes additional LDAP queries.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "943", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "910", "Name": "Use of Expired File Descriptor", "Description": "The product uses or accesses a file descriptor after it has been closed.", "Extended_Description": "After a file descriptor for a particular file or device has been released, it can be reused. The code might not write to the original file, since the reused file descriptor might reference a different file or device.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or Directories. Note: The program could read data from the wrong file.Scopes: Availability. Impacts: DoS: Crash, Exit, or Restart. Note: Accessing a file descriptor that has been closed can cause a crash.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "672", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "911", "Name": "Improper Update of Reference Count", "Description": "The product uses a reference count to manage a resource, but it does not update or incorrectly updates the reference count.", "Extended_Description": "Reference counts can be used when tracking how many objects contain a reference to a particular resource, such as in memory management or garbage collection. When the reference count reaches zero, the resource can be de-allocated or reused because there are no more objects that use it. If the reference count accidentally reaches zero, then the resource might be released too soon, even though it is still in use. If all objects no longer use the resource, but the reference count is not zero, then the resource might not ever be released.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "664", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "672", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "772", "View_ID": "1000", "Ordinal": null}]}, {"ID": "917", "Name": "Improper Neutralization of Special Elements used in an Expression Language Statement ('Expression Language Injection')", "Description": "The framework or tooling might allow the developer to disable or deactivate the processing of EL expressions, such as setting the isELIgnored attribute for a JSP page to \"true\".", "Extended_Description": "Frameworks such as Java Server Page (JSP) allow a developer to insert executable expressions within otherwise-static content. When the developer is not aware of the executable nature of these expressions and/or does not disable them, then if an attacker can inject expressions, this could lead to code execution or other unexpected behaviors.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Avoid adding user-controlled data into an expression interpreter when possible.Implementation : If user-controlled data must be added to an expression interpreter, one or more of the following should be performed:\n                     \n                        Validate that the user input will not evaluate as an expression\n                        Encode the user input in a way that ensures it is not evaluated as an expressionSystem Configuration : The framework or tooling might allow the developer to disable or deactivate the processing of EL expressions, such as setting the isELIgnored attribute for a JSP page to \"true\".", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "PeerOf", "CWE_ID": "1336", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "74", "View_ID": "1003", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1305", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "77", "View_ID": "1340", "Ordinal": "Primary"}]}, {"ID": "918", "Name": "Server-Side Request Forgery (SSRF)", "Description": "Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Extended_Description": "By providing URLs to unexpected hosts or ports, attackers can make it appear that the server is sending the request, possibly bypassing access controls such as firewalls that prevent the attackers from accessing the URLs directly. The server can be used as a proxy to conduct port scanning of hosts in internal networks, use other URLs such as that can access documents on the system (using file://), or use other protocols such as gopher:// or tftp://, which may provide greater control over the contents of requests.", "Modes_Of_Introduction": "", "Common_Consequences": "", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "441", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "610", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "920", "Name": "Improper Restriction of Power Consumption", "Description": "The product operates in an environment in which power is a limited resource that cannot be automatically replenished, but the product does not properly restrict the amount of power that its operation consumes.", "Extended_Description": "In environments such as embedded or mobile devices, power can be a limited resource such as a battery, which cannot be automatically replenished by the product itself, and the device might not always be directly attached to a reliable power source. If the product uses too much power too quickly, then this could cause the device (and subsequently, the product) to stop functioning until power is restored, or increase the financial burden on the device owner because of increased power costs.Normal operation of an application will consume power. However, in some cases, an attacker could cause the application to consume more power than intended, using components such as:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Availability. Impacts: DoS: Resource Consumption (Other)DoS: Crash, Exit, or Restart. Note: The power source could be drained, causing the application - and the entire device - to cease functioning.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "400", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "921", "Name": "Storage of Sensitive Data in a Mechanism without Access Control", "Description": "The product stores sensitive information in a file system or device that does not have built-in access control.", "Extended_Description": "While many modern file systems or devices utilize some form of access control in order to restrict access to data, not all storage mechanisms have this capability. For example, memory cards, floppy disks, CDs, and USB devices are typically made accessible to any user within the system. This can become a problem when sensitive data is stored in these mechanisms in a multi-user environment, because anybody on the system can read or write this data.On Android devices, external storage is typically globally readable and writable by other applications on the device. External storage may also be easily accessible through the mobile device's USB connection or physically accessible through the device's memory card port.", "Modes_Of_Introduction": "Architecture and Design: OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application DataRead Files or Directories. Note: Attackers can read sensitive information by accessing the unrestricted storage mechanism.Scopes: Integrity. Impacts: Modify Application DataModify Files or Directories. Note: Attackers can modify or delete sensitive information by accessing the unrestricted storage mechanism.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "922", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "924", "Name": "Improper Enforcement of Message Integrity During Transmission in a Communication Channel", "Description": "The product establishes a communication channel with an endpoint and receives a message from that endpoint, but it does not sufficiently ensure that the message was not modified during transmission.", "Extended_Description": "Attackers might be able to modify the message and spoof the endpoint by interfering with the data as it crosses the network or by redirecting the connection to a system under their control.", "Modes_Of_Introduction": "Architecture and Design: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityConfidentiality. Impacts: Gain Privileges or Assume Identity. Note: If an attackers can spoof the endpoint, the attacker gains all the privileges that were intended for the original endpoint.", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "345", "View_ID": "1003", "Ordinal": "Primary"}]}, {"ID": "940", "Name": "Improper Verification of Source of a Communication Channel", "Description": "Use a mechanism that can validate the identity of the source, such as a certificate, and validate the integrity of data to ensure that it cannot be modified in transit using an Adversary-in-the-Middle (AITM) attack.\n                  When designing functionality of actions in the URL scheme, consider whether the action should be accessible to all mobile applications, or if an allowlist of applications to interface with is appropriate.", "Extended_Description": "When an attacker can successfully establish a communication channel from an untrusted origin, the attacker may be able to gain privileges and access unexpected functionality.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: Access ControlOther. Impacts: Gain Privileges or Assume IdentityVaries by Context. Note: An attacker can access any functionality that is inadvertently accessible to the source.", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Use a mechanism that can validate the identity of the source, such as a certificate, and validate the integrity of data to ensure that it cannot be modified in transit using an Adversary-in-the-Middle (AITM) attack.\n                  When designing functionality of actions in the URL scheme, consider whether the action should be accessible to all mobile applications, or if an allowlist of applications to interface with is appropriate.", "Demonstrative_Examples": "This Android application will remove a user account when it receives an intent to do so:. This application does not check the origin of the intent, thus allowing any malicious application to remove a user. Always check the origin of an intent, or create an allowlist of trusted applications using the manifest.xml file.These Android and iOS applications intercept URL loading within a WebView and perform special actions if a particular URL scheme is used, thus allowing the Javascript within the WebView to communicate with the application:. A call into native code can then be initiated by passing parameters within the URL:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "346", "View_ID": "1000", "Ordinal": null}]}, {"ID": "925", "Name": "Improper Verification of Intent by Broadcast Receiver", "Description": "Before acting on the Intent, check the Intent Action to make sure it matches the expected System action.", "Extended_Description": "Certain types of Intents, identified by action string, can only be broadcast by the operating system itself, not by third-party applications. However, when an application registers to receive these implicit system intents, it is also registered to receive any explicit intents. While a malicious application cannot send an implicit system intent, it can send an explicit intent to the target application, which may assume that any received intent is a valid implicit system intent and not an explicit intent from another application. This may lead to unintended behavior.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Integrity. Impacts: Gain Privileges or Assume Identity. Note: Another application can impersonate the operating system and cause the software to perform an unintended action.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Before acting on the Intent, check the Intent Action to make sure it matches the expected System action.", "Demonstrative_Examples": "The following example demonstrates the weakness.. The ShutdownReceiver class will handle the intent:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "940", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "926", "Name": "Improper Export of Android Application Components", "Description": "Limit Content Provider permissions (read/write) as appropriate.", "Extended_Description": "The attacks and consequences of improperly exporting a component may depend on the exported component:", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: AvailabilityIntegrity. Impacts: Unexpected StateDoS: Crash, Exit, or RestartDoS: InstabilityVaries by Context. Note: Other applications, possibly untrusted, can launch the Activity.Scopes: AvailabilityIntegrity. Impacts: Unexpected StateGain Privileges or Assume IdentityDoS: Crash, Exit, or RestartDoS: InstabilityVaries by Context. Note: Other applications, possibly untrusted, can bind to the Service.Scopes: ConfidentialityIntegrity. Impacts: Read Application DataModify Application Data. Note: Other applications, possibly untrusted, can read or modify the data that is offered by the Content Provider.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Build and Compilation : If they do not need to be shared by other applications, explicitly mark components with android:exported=\"false\" in the application manifest.Build and Compilation : If you only intend to use exported components between related apps under your control, use android:protectionLevel=\"signature\" in the xml manifest to restrict access to applications signed by you.Build and Compilation : Limit Content Provider permissions (read/write) as appropriate.Build and Compilation : Limit Content Provider permissions (read/write) as appropriate.", "Demonstrative_Examples": "This application is exporting an activity and a service in its manifest.xml:. Because these components have intent filters but have not explicitly set 'android:exported=false' elsewhere in the manifest, they are automatically exported so that any other application can launch them. This may lead to unintended behavior or exploits.This application has created a content provider to enable custom search suggestions within the application:. Because this content provider is only intended to be used within the application, it does not need to be exported. However, in Android before 4.2, it is automatically exported thus potentially allowing malicious applications to access sensitive information.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "927", "Name": "Use of Implicit Intent for Sensitive Communication", "Description": "If the application only requires communication with its own components, then the destination is always known, and an explicit intent could be used.", "Extended_Description": "Since an implicit intent does not specify a particular application to receive the data, any application can process the intent by using an Intent Filter for that intent. This can allow untrusted applications to obtain sensitive data. There are two variations on the standard broadcast intent, ordered and sticky.Ordered broadcast intents are delivered to a series of registered receivers in order of priority as declared by the Receivers. A malicious receiver can give itself a high priority and cause a denial of service by stopping the broadcast from propagating further down the chain. There is also the possibility of malicious data modification, as a receiver may also alter the data within the Intent before passing it on to the next receiver. The downstream components have no way of asserting that the data has not been altered earlier in the chain.Sticky broadcast intents remain accessible after the initial broadcast. An old sticky intent will be broadcast again to any new receivers that register for it in the future, greatly increasing the chances of information exposure over time. Also, sticky broadcasts cannot be protected by permissions that may apply to other kinds of intents.In addition, any broadcast intent may include a URI that references data that the receiving component does not normally have the privileges to access. The sender of the intent can include special privileges that grant the receiver read or write access to the specific URI included in the intent. A malicious receiver that intercepts this intent will also gain those privileges and be able to read or write the resource at the specified URI.", "Modes_Of_Introduction": "", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Application Data. Note: Other applications, possibly untrusted, can read the data that is offered through the Intent.Scopes: Integrity. Impacts: Varies by Context. Note: The application may handle responses from untrusted applications on the device, which could cause it to perform unexpected or unauthorized actions.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Implementation : If the application only requires communication with its own components, then the destination is always known, and an explicit intent could be used.", "Demonstrative_Examples": "This application wants to create a user account in several trusted applications using one broadcast intent:. This application assumes only the trusted applications will be listening for the action. A malicious application can register for this action and intercept the user's login information, as below:This application interfaces with a web service that requires a separate user login. It creates a sticky intent, so that future trusted applications that also use the web service will know who the current user is:. Sticky broadcasts can be read by any application at any time, and so should never contain sensitive information such as a username.This application is sending an ordered broadcast, asking other applications to open a URL:. Any application in the broadcast chain may alter the data within the intent. This malicious application is altering the URL to point to an attack site:This application sends a special intent with a flag that allows the receiving application to read a data file for backup purposes.. Any malicious application can register to receive this intent. Because of the FLAG_GRANT_READ_URI_PERMISSION included with the intent, the malicious receiver code can read the user's data.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "285", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "668", "View_ID": "1000", "Ordinal": null}]}, {"ID": "939", "Name": "Improper Authorization in Handler for Custom URL Scheme", "Description": "Utilize a user prompt pop-up to authorize potentially harmful actions such as those modifying data or dealing with sensitive information.\n                  When designing functionality of actions in the URL scheme, consider whether the action should be accessible to all mobile applications, or if an allowlist of applications to interface with is appropriate.", "Extended_Description": "Mobile platforms and other architectures allow the use of custom URL schemes to facilitate communication between applications. In the case of iOS, this is the only method to do inter-application communication. The implementation is at the developer's discretion which may open security flaws in the application. An example could be potentially dangerous functionality such as modifying files through a custom URL scheme.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "Architecture and Design : Utilize a user prompt pop-up to authorize potentially harmful actions such as those modifying data or dealing with sensitive information.\n                  When designing functionality of actions in the URL scheme, consider whether the action should be accessible to all mobile applications, or if an allowlist of applications to interface with is appropriate.", "Demonstrative_Examples": "This iOS application uses a custom URL scheme. The replaceFileText action in the URL scheme allows an external application to interface with the file incomingMessage.txt and replace the contents with the text field of the query string.. External ApplicationThese Android and iOS applications intercept URL loading within a WebView and perform special actions if a particular URL scheme is used, thus allowing the Javascript within the WebView to communicate with the application:. A call into native code can then be initiated by passing parameters within the URL:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "862", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "941", "Name": "Incorrectly Specified Destination in a Communication Channel", "Description": "The product creates a communication channel to initiate an outgoing request to an actor, but it does not correctly specify the intended destination for that actor.", "Extended_Description": "Attackers at the destination may be able to spoof trusted servers to steal data or cause a denial of service.There are at least two distinct weaknesses that can cause the product to communicate with an unintended destination:", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "This code listens on a port for DNS requests and sends the result to the requesting address.. This code sends a DNS record to a requesting IP address. UDP allows the source IP address to be easily changed ('spoofed'), thus allowing an attacker to redirect responses to a target, which may be then be overwhelmed by the network traffic.", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "406", "View_ID": "1000", "Ordinal": null}]}, {"ID": "942", "Name": "Permissive Cross-domain Policy with Untrusted Domains", "Description": "For Flash, modify crossdomain.xml to use meta-policy options such as 'master-only' or 'none' to reduce the possibility of an attacker planting extraneous cross-domain policy files on a server.", "Extended_Description": "A cross-domain policy file (\"crossdomain.xml\" in Flash and \"clientaccesspolicy.xml\" in Silverlight) defines a list of domains from which a server is allowed to make cross-domain requests. When making a cross-domain request, the Flash or Silverlight client will first look for the policy file on the target server. If it is found, and the domain hosting the application is explicitly allowed to make requests, the request is made.Therefore, if a cross-domain policy file includes domains that should not be trusted, such as when using wildcards, then the application could be attacked by these untrusted domains.An overly permissive policy file allows many of the same attacks seen in Cross-Site Scripting (CWE-79). Once the user has executed a malicious Flash or Silverlight application, they are vulnerable to a variety of attacks. The attacker could transfer private information, such as cookies that may include session information, from the victim's machine to the attacker. The attacker could send malicious requests to a web site on behalf of the victim, which could be especially dangerous to the site if the victim has administrator privileges to manage that site.In many cases, the attack can be launched without the victim even being aware of it.", "Modes_Of_Introduction": "Architecture and Design: COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.", "Common_Consequences": "Scopes: ConfidentialityIntegrityAvailabilityAccess Control. Impacts: Execute Unauthorized Code or CommandsBypass Protection MechanismRead Application DataVaries by Context. Note: An attacker may be able to bypass the web browser's same-origin policy. An attacker can exploit the weakness to manipulate or steal cookies, create requests that can be mistaken for those of a valid user, compromise confidential information, or execute malicious code on the end user systems for a variety of nefarious purposes. Other damaging attacks include the disclosure of end user files, installation of Trojan horse programs, redirecting the user to some other page or site, running ActiveX controls (under Microsoft Internet Explorer) from sites that a user perceives as trustworthy, and modifying presentation of content.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : Avoid using wildcards in the cross-domain policy file. Any domain matching the wildcard expression will be implicitly trusted, and can perform two-way interaction with the target server.Architecture and Design : For Flash, modify crossdomain.xml to use meta-policy options such as 'master-only' or 'none' to reduce the possibility of an attacker planting extraneous cross-domain policy files on a server.Architecture and Design : For Flash, modify crossdomain.xml to use meta-policy options such as 'master-only' or 'none' to reduce the possibility of an attacker planting extraneous cross-domain policy files on a server.", "Demonstrative_Examples": "These cross-domain policy files mean to allow Flash and Silverlight applications hosted on other domains to access its data:. Flash crossdomain.xml :", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "863", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "ChildOf", "CWE_ID": "923", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "183", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanPrecede", "CWE_ID": "668", "View_ID": "1000", "Ordinal": null}]}, {"ID": "95", "Name": "Improper Neutralization of Directives in Dynamically Evaluated Code ('Eval Injection')", "Description": "Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180, CWE-181). Make sure that your application does not inadvertently decode the same input twice (CWE-174). Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization control.\n                  Consider performing repeated canonicalization until your input does not change any more. This will avoid double-decoding and similar scenarios, but it might inadvertently modify inputs that are allowed to contain properly-encoded dangerous content.", "Extended_Description": "This may allow an attacker to execute arbitrary code, or at least modify what code can be executed.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.Implementation: This weakness is prevalent in handler/dispatch procedures that might want to invoke a large number of functions, or set a large number of variables.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or DirectoriesRead Application Data. Note: The injected code could access restricted data / files.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: In some cases, injectable code controls authentication; this may lead to a remote vulnerability.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Injected code can access resources that the attacker is directly prevented from accessing.Scopes: IntegrityConfidentialityAvailabilityOther. Impacts: Execute Unauthorized Code or Commands. Note: Code injection attacks can lead to loss of data integrity in nearly all cases as the control-plane data injected is always incidental to data recall or writing. Additionally, code injection can often result in the execution of arbitrary code.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: Often the actions performed by injected control code are unlogged.", "Detection_Methods": "Method Name: Automated Static Analysis. Description: Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)", "Potential_Mitigations": "Architecture and Design : If possible, refactor your code so that it does not need to use eval() at all.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180, CWE-181). Make sure that your application does not inadvertently decode the same input twice (CWE-174). Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization control.\n                  Consider performing repeated canonicalization until your input does not change any more. This will avoid double-decoding and similar scenarios, but it might inadvertently modify inputs that are allowed to contain properly-encoded dangerous content.", "Demonstrative_Examples": "edit-config.pl: This CGI script is used to modify settings in a configuration file.. The script intends to take the 'action' parameter and invoke one of a variety of functions based on the value of that parameter - config_file_add_key(), config_file_set_key(), or config_file_delete_key(). It could set up a conditional to invoke each function separately, but eval() is a powerful way of doing the same thing in fewer lines of code, especially when a large number of functions or variables are involved. Unfortunately, in this case, the attacker can provide other values in the action parameter, such as:This simple script asks a user to supply a list of numbers as input and adds them together.. The eval() function can take the user-supplied list and convert it into a Python list object, therefore allowing the programmer to use list comprehension methods to work with the data. However, if code is supplied to the eval() function, it will execute that code. For example, a malicious user could supply the following string:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "94", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "96", "Name": "Improper Neutralization of Directives in Statically Saved Code ('Static Code Injection')", "Description": "Perform proper output validation and escaping to neutralize all code syntax from data written to code files.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.Implementation: This issue is frequently found in PHP applications that allow users to set configuration variables that are stored within executable PHP files. Technically, this could also be performed in some compiled code (e.g., by byte-patching an executable), although it is highly unlikely.", "Common_Consequences": "Scopes: Confidentiality. Impacts: Read Files or DirectoriesRead Application Data. Note: The injected code could access restricted data / files.Scopes: Access Control. Impacts: Bypass Protection Mechanism. Note: In some cases, injectable code controls authentication; this may lead to a remote vulnerability.Scopes: Access Control. Impacts: Gain Privileges or Assume Identity. Note: Injected code can access resources that the attacker is directly prevented from accessing.Scopes: IntegrityConfidentialityAvailabilityOther. Impacts: Execute Unauthorized Code or Commands. Note: Code injection attacks can lead to loss of data integrity in nearly all cases as the control-plane data injected is always incidental to data recall or writing. Additionally, code injection can often result in the execution of arbitrary code.Scopes: Non-Repudiation. Impacts: Hide Activities. Note: Often the actions performed by injected control code are unlogged.", "Detection_Methods": "", "Potential_Mitigations": "Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.Implementation : Perform proper output validation and escaping to neutralize all code syntax from data written to code files.", "Demonstrative_Examples": "This example attempts to write user messages to a message file and allow users to view them.. While the programmer intends for the MessageFile to only include data, an attacker can provide a message such as:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "94", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "97", "Name": "Improper Neutralization of Server-Side Includes (SSI) Within a Web Page", "Description": "The product generates a web page, but does not neutralize or incorrectly neutralizes user-controllable input that could be interpreted as a server-side include (SSI) directive.", "Extended_Description": "N/A", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "", "Detection_Methods": "", "Potential_Mitigations": "", "Demonstrative_Examples": "", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "96", "View_ID": "1000", "Ordinal": "Primary"}]}, {"ID": "98", "Name": "Improper Control of Filename for Include/Require Statement in PHP Program ('PHP Remote File Inclusion')", "Description": "Set allow_url_fopen to false, which limits the ability to include files from remote locations.", "Extended_Description": "In certain versions and configurations of PHP, this can allow an attacker to specify a URL to a remote location from which the product will obtain the code to execute. In other cases in association with path traversal, the attacker can specify a local file that may contain executable statements that can be parsed by PHP.", "Modes_Of_Introduction": "Implementation: REALIZATION: This weakness is caused during implementation of an architectural security tactic.", "Common_Consequences": "Scopes: IntegrityConfidentialityAvailability. Impacts: Execute Unauthorized Code or Commands. Note: The attacker may be able to specify arbitrary code to be executed from a remote location. Alternatively, it may be possible to use normal program behavior to insert php code into files on the local machine which can then be included and force the code to execute since php ignores everything in the file except for the content between php specifiers.", "Detection_Methods": "Method Name: Manual Analysis. Description: Manual white-box analysis can be very effective for finding this issue, since there is typically a relatively small number of include or require statements in each program. Method Name: Automated Static Analysis. Description: The external control or influence of filenames can often be detected using automated static analysis that models data flow within the product.Automated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or require any code changes. If the program uses a customized input validation library, then some tools may allow the analyst to create custom signatures to detect usage of those routines.", "Potential_Mitigations": "Architecture and Design : Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.Architecture and Design : When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n                  For example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\". Features such as the ESAPI AccessReferenceMap [REF-185] provide this capability.Architecture and Design : For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.Architecture and Design : Run the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n                  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n                  This may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n                  Be careful to avoid CWE-243 and other weaknesses related to jails.Architecture and Design : Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.Implementation : Assume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n                  When performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n                  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n                  When validating filenames, use stringent lists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n                  Do not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.Architecture and Design : Store library, include, and utility files outside of the web document root, if possible. Otherwise, store them in a separate directory and use the web server's access control capabilities to prevent attackers from directly requesting them. One common practice is to define a fixed constant in each calling program, then check for the existence of the constant in the library/include file; if the constant does not exist, then the file was directly requested, and it can exit immediately.\n                  This significantly reduces the chance of an attacker being able to bypass any protection mechanisms that are in the base program but not in the include files. It will also reduce the attack surface.Architecture and Design : Understand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n                  Many file inclusion problems occur because the programmer assumed that certain inputs could not be modified, especially for cookies and URL components.Operation : Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.Operation : Develop and run your code in the most recent versions of PHP available, preferably PHP 6 or later. Many of the highly risky features in earlier PHP interpreters have been removed, restricted, or disabled by default.Operation : When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n                  Often, programmers do not protect direct access to files intended only to be included by core programs. These include files may assume that critical variables have already been initialized by the calling program. As a result, the use of register_globals combined with the ability to directly access the include file may allow attackers to conduct file inclusion attacks. This remains an extremely common pattern as of 2009.Operation : Set allow_url_fopen to false, which limits the ability to include files from remote locations.", "Demonstrative_Examples": "The following code, victim.php, attempts to include a function contained in a separate PHP page on the server. It builds the path to the file by using the supplied 'module_name' parameter and appending the string '/function.php' to it.. The problem with the above code is that the value of $dir is not restricted in any way, and a malicious user could manipulate the 'module_name' parameter to force inclusion of an unanticipated file. For example, an attacker could request the above PHP page (example.php) with a 'module_name' of \"http://malicious.example.com\" by using the following request string:", "Related_Weaknesses": [{"Nature": "ChildOf", "CWE_ID": "706", "View_ID": "1000", "Ordinal": null}, {"Nature": "ChildOf", "CWE_ID": "829", "View_ID": "1000", "Ordinal": "Primary"}, {"Nature": "CanPrecede", "CWE_ID": "94", "View_ID": "1000", "Ordinal": null}, {"Nature": "CanAlsoBe", "CWE_ID": "426", "View_ID": "1000", "Ordinal": null}]}], "links": [{"source": "732", "target": "1004"}, {"source": "451", "target": "1007"}, {"source": "694", "target": "102"}, {"source": "1173", "target": "102"}, {"source": "20", "target": "102"}, {"source": "441", "target": "1021"}, {"source": "610", "target": "1021"}, {"source": "451", "target": "1021"}, {"source": "266", "target": "1022"}, {"source": "697", "target": "1023"}, {"source": "697", "target": "1024"}, {"source": "697", "target": "1025"}, {"source": "573", "target": "103"}, {"source": "20", "target": "103"}, {"source": "1038", "target": "1037"}, {"source": "435", "target": "1038"}, {"source": "758", "target": "1038"}, {"source": "693", "target": "1039"}, {"source": "697", "target": "1039"}, {"source": "573", "target": "104"}, {"source": "20", "target": "104"}, {"source": "710", "target": "1041"}, {"source": "1176", "target": "1042"}, {"source": "1093", "target": "1043"}, {"source": "710", "target": "1044"}, {"source": "1076", "target": "1045"}, {"source": "1176", "target": "1046"}, {"source": "1120", "target": "1047"}, {"source": "710", "target": "1048"}, {"source": "1176", "target": "1049"}, {"source": "1173", "target": "105"}, {"source": "20", "target": "105"}, {"source": "405", "target": "1050"}, {"source": "665", "target": "1051"}, {"source": "665", "target": "1052"}, {"source": "1059", "target": "1053"}, {"source": "1061", "target": "1054"}, {"source": "1093", "target": "1055"}, {"source": "1120", "target": "1056"}, {"source": "1061", "target": "1057"}, {"source": "662", "target": "1058"}, {"source": "662", "target": "1058"}, {"source": "662", "target": "1058"}, {"source": "710", "target": "1059"}, {"source": "1173", "target": "106"}, {"source": "20", "target": "106"}, {"source": "1120", "target": "1060"}, {"source": "710", "target": "1061"}, {"source": "1061", "target": "1062"}, {"source": "1176", "target": "1063"}, {"source": "1120", "target": "1064"}, {"source": "710", "target": "1065"}, {"source": "710", "target": "1066"}, {"source": "1176", "target": "1067"}, {"source": "710", "target": "1068"}, {"source": "1071", "target": "1069"}, {"source": "1164", "target": "107"}, {"source": "20", "target": "107"}, {"source": "710", "target": "1070"}, {"source": "1164", "target": "1071"}, {"source": "405", "target": "1072"}, {"source": "405", "target": "1073"}, {"source": "1093", "target": "1074"}, {"source": "1120", "target": "1075"}, {"source": "710", "target": "1076"}, {"source": "697", "target": "1077"}, {"source": "1076", "target": "1078"}, {"source": "1076", "target": "1079"}, {"source": "1173", "target": "108"}, {"source": "20", "target": "108"}, {"source": "1120", "target": "1080"}, {"source": "1076", "target": "1082"}, {"source": "1061", "target": "1083"}, {"source": "405", "target": "1084"}, {"source": "1078", "target": "1085"}, {"source": "1093", "target": "1086"}, {"source": "1076", "target": "1087"}, {"source": "821", "target": "1088"}, {"source": "405", "target": "1089"}, {"source": "1173", "target": "109"}, {"source": "20", "target": "109"}, {"source": "1061", "target": "1090"}, {"source": "772", "target": "1091"}, {"source": "1076", "target": "1091"}, {"source": "710", "target": "1092"}, {"source": "710", "target": "1093"}, {"source": "405", "target": "1094"}, {"source": "1120", "target": "1095"}, {"source": "820", "target": "1096"}, {"source": "662", "target": "1096"}, {"source": "662", "target": "1096"}, {"source": "1076", "target": "1097"}, {"source": "595", "target": "1097"}, {"source": "1076", "target": "1098"}, {"source": "1078", "target": "1099"}, {"source": "489", "target": "11"}, {"source": "1164", "target": "110"}, {"source": "20", "target": "110"}, {"source": "1061", "target": "1100"}, {"source": "710", "target": "1101"}, {"source": "758", "target": "1102"}, {"source": "758", "target": "1103"}, {"source": "1357", "target": "1104"}, {"source": "758", "target": "1105"}, {"source": "1061", "target": "1105"}, {"source": "1078", "target": "1106"}, {"source": "1078", "target": "1107"}, {"source": "1076", "target": "1108"}, {"source": "1078", "target": "1109"}, {"source": "695", "target": "111"}, {"source": "20", "target": "111"}, {"source": "1059", "target": "1110"}, {"source": "1059", "target": "1111"}, {"source": "1059", "target": "1112"}, {"source": "1078", "target": "1113"}, {"source": "1078", "target": "1114"}, {"source": "1078", "target": "1115"}, {"source": "1078", "target": "1116"}, {"source": "1078", "target": "1117"}, {"source": "1059", "target": "1118"}, {"source": "1120", "target": "1119"}, {"source": "1286", "target": "112"}, {"source": "20", "target": "112"}, {"source": "710", "target": "1120"}, {"source": "1120", "target": "1121"}, {"source": "1120", "target": "1122"}, {"source": "1120", "target": "1123"}, {"source": "1120", "target": "1124"}, {"source": "1120", "target": "1125"}, {"source": "710", "target": "1126"}, {"source": "710", "target": "1127"}, {"source": "93", "target": "113"}, {"source": "20", "target": "113"}, {"source": "436", "target": "113"}, {"source": "73", "target": "114"}, {"source": "20", "target": "114"}, {"source": "436", "target": "115"}, {"source": "707", "target": "116"}, {"source": "710", "target": "1164"}, {"source": "116", "target": "117"}, {"source": "20", "target": "117"}, {"source": "20", "target": "1173"}, {"source": "1173", "target": "1174"}, {"source": "405", "target": "1176"}, {"source": "710", "target": "1177"}, {"source": "664", "target": "118"}, {"source": "665", "target": "1188"}, {"source": "665", "target": "1188"}, {"source": "653", "target": "1189"}, {"source": "668", "target": "1189"}, {"source": "118", "target": "119"}, {"source": "20", "target": "119"}, {"source": "696", "target": "1190"}, {"source": "284", "target": "1191"}, {"source": "657", "target": "1192"}, {"source": "696", "target": "1193"}, {"source": "756", "target": "12"}, {"source": "119", "target": "120"}, {"source": "119", "target": "120"}, {"source": "119", "target": "120"}, {"source": "119", "target": "120"}, {"source": "20", "target": "120"}, {"source": "330", "target": "1204"}, {"source": "710", "target": "1209"}, {"source": "788", "target": "121"}, {"source": "787", "target": "121"}, {"source": "788", "target": "122"}, {"source": "787", "target": "122"}, {"source": "284", "target": "1220"}, {"source": "665", "target": "1221"}, {"source": "1220", "target": "1222"}, {"source": "362", "target": "1223"}, {"source": "284", "target": "1224"}, {"source": "664", "target": "1229"}, {"source": "787", "target": "123"}, {"source": "119", "target": "123"}, {"source": "119", "target": "123"}, {"source": "285", "target": "1230"}, {"source": "284", "target": "1231"}, {"source": "667", "target": "1232"}, {"source": "284", "target": "1233"}, {"source": "667", "target": "1233"}, {"source": "667", "target": "1234"}, {"source": "400", "target": "1235"}, {"source": "74", "target": "1236"}, {"source": "74", "target": "1236"}, {"source": "226", "target": "1239"}, {"source": "226", "target": "1239"}, {"source": "786", "target": "124"}, {"source": "787", "target": "124"}, {"source": "327", "target": "1240"}, {"source": "330", "target": "1241"}, {"source": "284", "target": "1242"}, {"source": "1263", "target": "1243"}, {"source": "863", "target": "1244"}, {"source": "684", "target": "1245"}, {"source": "400", "target": "1246"}, {"source": "1384", "target": "1247"}, {"source": "693", "target": "1248"}, {"source": "1250", "target": "1249"}, {"source": "119", "target": "125"}, {"source": "119", "target": "125"}, {"source": "119", "target": "125"}, {"source": "119", "target": "125"}, {"source": "664", "target": "1250"}, {"source": "1250", "target": "1251"}, {"source": "284", "target": "1252"}, {"source": "693", "target": "1253"}, {"source": "208", "target": "1254"}, {"source": "697", "target": "1254"}, {"source": "1300", "target": "1255"}, {"source": "285", "target": "1256"}, {"source": "284", "target": "1257"}, {"source": "212", "target": "1258"}, {"source": "200", "target": "1258"}, {"source": "284", "target": "1259"}, {"source": "1294", "target": "1259"}, {"source": "125", "target": "126"}, {"source": "788", "target": "126"}, {"source": "284", "target": "1260"}, {"source": "1384", "target": "1261"}, {"source": "284", "target": "1262"}, {"source": "284", "target": "1263"}, {"source": "821", "target": "1264"}, {"source": "691", "target": "1265"}, {"source": "404", "target": "1266"}, {"source": "284", "target": "1267"}, {"source": "284", "target": "1268"}, {"source": "693", "target": "1269"}, {"source": "125", "target": "127"}, {"source": "786", "target": "127"}, {"source": "284", "target": "1270"}, {"source": "1294", "target": "1270"}, {"source": "909", "target": "1271"}, {"source": "226", "target": "1272"}, {"source": "200", "target": "1273"}, {"source": "284", "target": "1274"}, {"source": "923", "target": "1275"}, {"source": "284", "target": "1276"}, {"source": "1329", "target": "1277"}, {"source": "693", "target": "1278"}, {"source": "665", "target": "1279"}, {"source": "682", "target": "128"}, {"source": "696", "target": "1280"}, {"source": "284", "target": "1280"}, {"source": "691", "target": "1281"}, {"source": "668", "target": "1282"}, {"source": "284", "target": "1283"}, {"source": "20", "target": "1284"}, {"source": "20", "target": "1284"}, {"source": "20", "target": "1285"}, {"source": "20", "target": "1286"}, {"source": "20", "target": "1287"}, {"source": "20", "target": "1288"}, {"source": "20", "target": "1289"}, {"source": "1285", "target": "129"}, {"source": "20", "target": "129"}, {"source": "284", "target": "1290"}, {"source": "1294", "target": "1290"}, {"source": "693", "target": "1291"}, {"source": "284", "target": "1292"}, {"source": "1294", "target": "1292"}, {"source": "345", "target": "1293"}, {"source": "284", "target": "1294"}, {"source": "200", "target": "1295"}, {"source": "284", "target": "1296"}, {"source": "285", "target": "1297"}, {"source": "362", "target": "1298"}, {"source": "420", "target": "1299"}, {"source": "288", "target": "1299"}, {"source": "260", "target": "13"}, {"source": "240", "target": "130"}, {"source": "119", "target": "130"}, {"source": "119", "target": "130"}, {"source": "203", "target": "1300"}, {"source": "203", "target": "1300"}, {"source": "226", "target": "1301"}, {"source": "1294", "target": "1302"}, {"source": "1189", "target": "1303"}, {"source": "203", "target": "1303"}, {"source": "284", "target": "1304"}, {"source": "682", "target": "131"}, {"source": "682", "target": "131"}, {"source": "682", "target": "131"}, {"source": "682", "target": "131"}, {"source": "1329", "target": "1310"}, {"source": "284", "target": "1311"}, {"source": "284", "target": "1312"}, {"source": "284", "target": "1313"}, {"source": "862", "target": "1314"}, {"source": "284", "target": "1315"}, {"source": "284", "target": "1316"}, {"source": "284", "target": "1317"}, {"source": "693", "target": "1318"}, {"source": "693", "target": "1319"}, {"source": "284", "target": "1320"}, {"source": "915", "target": "1321"}, {"source": "913", "target": "1321"}, {"source": "834", "target": "1322"}, {"source": "284", "target": "1323"}, {"source": "770", "target": "1325"}, {"source": "693", "target": "1326"}, {"source": "668", "target": "1327"}, {"source": "285", "target": "1328"}, {"source": "1357", "target": "1329"}, {"source": "664", "target": "1329"}, {"source": "1301", "target": "1330"}, {"source": "1301", "target": "1330"}, {"source": "653", "target": "1331"}, {"source": "668", "target": "1331"}, {"source": "1384", "target": "1332"}, {"source": "407", "target": "1333"}, {"source": "407", "target": "1333"}, {"source": "284", "target": "1334"}, {"source": "682", "target": "1335"}, {"source": "94", "target": "1336"}, {"source": "693", "target": "1338"}, {"source": "682", "target": "1339"}, {"source": "668", "target": "134"}, {"source": "668", "target": "134"}, {"source": "20", "target": "134"}, {"source": "675", "target": "1341"}, {"source": "226", "target": "1342"}, {"source": "226", "target": "1342"}, {"source": "682", "target": "135"}, {"source": "1384", "target": "1351"}, {"source": "710", "target": "1357"}, {"source": "707", "target": "138"}, {"source": "703", "target": "1384"}, {"source": "346", "target": "1385"}, {"source": "59", "target": "1386"}, {"source": "704", "target": "1389"}, {"source": "287", "target": "1390"}, {"source": "1390", "target": "1391"}, {"source": "1391", "target": "1392"}, {"source": "1392", "target": "1393"}, {"source": "1392", "target": "1394"}, {"source": "657", "target": "1395"}, {"source": "733", "target": "14"}, {"source": "138", "target": "140"}, {"source": "140", "target": "141"}, {"source": "140", "target": "142"}, {"source": "140", "target": "143"}, {"source": "140", "target": "144"}, {"source": "140", "target": "145"}, {"source": "140", "target": "146"}, {"source": "138", "target": "147"}, {"source": "138", "target": "148"}, {"source": "138", "target": "149"}, {"source": "642", "target": "15"}, {"source": "610", "target": "15"}, {"source": "20", "target": "15"}, {"source": "138", "target": "150"}, {"source": "138", "target": "151"}, {"source": "138", "target": "152"}, {"source": "138", "target": "153"}, {"source": "138", "target": "154"}, {"source": "138", "target": "155"}, {"source": "138", "target": "156"}, {"source": "138", "target": "157"}, {"source": "138", "target": "158"}, {"source": "138", "target": "159"}, {"source": "138", "target": "160"}, {"source": "160", "target": "161"}, {"source": "138", "target": "162"}, {"source": "162", "target": "163"}, {"source": "138", "target": "164"}, {"source": "164", "target": "165"}, {"source": "159", "target": "166"}, {"source": "703", "target": "166"}, {"source": "159", "target": "167"}, {"source": "703", "target": "167"}, {"source": "159", "target": "168"}, {"source": "703", "target": "168"}, {"source": "707", "target": "170"}, {"source": "20", "target": "170"}, {"source": "707", "target": "172"}, {"source": "172", "target": "173"}, {"source": "172", "target": "174"}, {"source": "675", "target": "174"}, {"source": "172", "target": "175"}, {"source": "172", "target": "176"}, {"source": "172", "target": "177"}, {"source": "706", "target": "178"}, {"source": "706", "target": "178"}, {"source": "20", "target": "179"}, {"source": "696", "target": "179"}, {"source": "179", "target": "180"}, {"source": "179", "target": "181"}, {"source": "693", "target": "182"}, {"source": "697", "target": "183"}, {"source": "693", "target": "184"}, {"source": "1023", "target": "184"}, {"source": "697", "target": "185"}, {"source": "185", "target": "186"}, {"source": "1023", "target": "187"}, {"source": "1105", "target": "188"}, {"source": "435", "target": "188"}, {"source": "682", "target": "190"}, {"source": "682", "target": "190"}, {"source": "20", "target": "190"}, {"source": "682", "target": "191"}, {"source": "682", "target": "191"}, {"source": "681", "target": "192"}, {"source": "682", "target": "193"}, {"source": "682", "target": "193"}, {"source": "681", "target": "194"}, {"source": "681", "target": "194"}, {"source": "681", "target": "194"}, {"source": "681", "target": "195"}, {"source": "681", "target": "195"}, {"source": "681", "target": "195"}, {"source": "681", "target": "196"}, {"source": "681", "target": "196"}, {"source": "681", "target": "196"}, {"source": "681", "target": "197"}, {"source": "681", "target": "197"}, {"source": "681", "target": "197"}, {"source": "188", "target": "198"}, {"source": "707", "target": "20"}, {"source": "668", "target": "200"}, {"source": "200", "target": "201"}, {"source": "1230", "target": "202"}, {"source": "200", "target": "203"}, {"source": "200", "target": "203"}, {"source": "203", "target": "204"}, {"source": "203", "target": "205"}, {"source": "205", "target": "206"}, {"source": "205", "target": "207"}, {"source": "203", "target": "208"}, {"source": "200", "target": "209"}, {"source": "200", "target": "209"}, {"source": "755", "target": "209"}, {"source": "209", "target": "210"}, {"source": "209", "target": "211"}, {"source": "669", "target": "212"}, {"source": "669", "target": "212"}, {"source": "200", "target": "213"}, {"source": "497", "target": "214"}, {"source": "200", "target": "215"}, {"source": "552", "target": "219"}, {"source": "706", "target": "22"}, {"source": "706", "target": "22"}, {"source": "668", "target": "22"}, {"source": "552", "target": "220"}, {"source": "664", "target": "221"}, {"source": "221", "target": "222"}, {"source": "221", "target": "223"}, {"source": "221", "target": "224"}, {"source": "459", "target": "226"}, {"source": "212", "target": "226"}, {"source": "703", "target": "228"}, {"source": "707", "target": "228"}, {"source": "228", "target": "229"}, {"source": "22", "target": "23"}, {"source": "22", "target": "23"}, {"source": "22", "target": "23"}, {"source": "229", "target": "230"}, {"source": "229", "target": "231"}, {"source": "229", "target": "232"}, {"source": "228", "target": "233"}, {"source": "233", "target": "234"}, {"source": "233", "target": "235"}, {"source": "233", "target": "236"}, {"source": "228", "target": "237"}, {"source": "237", "target": "238"}, {"source": "237", "target": "239"}, {"source": "23", "target": "24"}, {"source": "237", "target": "240"}, {"source": "707", "target": "240"}, {"source": "228", "target": "241"}, {"source": "1177", "target": "242"}, {"source": "573", "target": "243"}, {"source": "669", "target": "243"}, {"source": "226", "target": "244"}, {"source": "695", "target": "245"}, {"source": "695", "target": "246"}, {"source": "705", "target": "248"}, {"source": "755", "target": "248"}, {"source": "703", "target": "248"}, {"source": "703", "target": "248"}, {"source": "23", "target": "25"}, {"source": "657", "target": "250"}, {"source": "269", "target": "250"}, {"source": "754", "target": "252"}, {"source": "754", "target": "252"}, {"source": "573", "target": "253"}, {"source": "754", "target": "253"}, {"source": "522", "target": "256"}, {"source": "522", "target": "257"}, {"source": "260", "target": "258"}, {"source": "521", "target": "258"}, {"source": "798", "target": "259"}, {"source": "798", "target": "259"}, {"source": "798", "target": "259"}, {"source": "23", "target": "26"}, {"source": "522", "target": "260"}, {"source": "522", "target": "261"}, {"source": "1390", "target": "262"}, {"source": "1390", "target": "263"}, {"source": "269", "target": "266"}, {"source": "269", "target": "267"}, {"source": "269", "target": "268"}, {"source": "284", "target": "269"}, {"source": "23", "target": "27"}, {"source": "269", "target": "270"}, {"source": "269", "target": "271"}, {"source": "271", "target": "272"}, {"source": "754", "target": "273"}, {"source": "754", "target": "273"}, {"source": "271", "target": "273"}, {"source": "755", "target": "274"}, {"source": "269", "target": "274"}, {"source": "732", "target": "276"}, {"source": "732", "target": "276"}, {"source": "732", "target": "277"}, {"source": "732", "target": "278"}, {"source": "732", "target": "279"}, {"source": "23", "target": "28"}, {"source": "755", "target": "280"}, {"source": "732", "target": "281"}, {"source": "732", "target": "281"}, {"source": "284", "target": "282"}, {"source": "282", "target": "283"}, {"source": "284", "target": "285"}, {"source": "284", "target": "285"}, {"source": "284", "target": "286"}, {"source": "284", "target": "287"}, {"source": "284", "target": "287"}, {"source": "306", "target": "288"}, {"source": "284", "target": "288"}, {"source": "1390", "target": "289"}, {"source": "23", "target": "29"}, {"source": "1390", "target": "290"}, {"source": "287", "target": "290"}, {"source": "290", "target": "291"}, {"source": "923", "target": "291"}, {"source": "471", "target": "291"}, {"source": "290", "target": "293"}, {"source": "1390", "target": "294"}, {"source": "287", "target": "294"}, {"source": "287", "target": "295"}, {"source": "287", "target": "295"}, {"source": "295", "target": "296"}, {"source": "573", "target": "296"}, {"source": "923", "target": "297"}, {"source": "295", "target": "297"}, {"source": "295", "target": "298"}, {"source": "672", "target": "298"}, {"source": "295", "target": "299"}, {"source": "404", "target": "299"}, {"source": "23", "target": "30"}, {"source": "923", "target": "300"}, {"source": "1390", "target": "301"}, {"source": "1390", "target": "302"}, {"source": "807", "target": "302"}, {"source": "1390", "target": "303"}, {"source": "303", "target": "304"}, {"source": "573", "target": "304"}, {"source": "1390", "target": "305"}, {"source": "287", "target": "306"}, {"source": "287", "target": "306"}, {"source": "1390", "target": "307"}, {"source": "287", "target": "307"}, {"source": "799", "target": "307"}, {"source": "1390", "target": "308"}, {"source": "654", "target": "308"}, {"source": "1390", "target": "309"}, {"source": "654", "target": "309"}, {"source": "23", "target": "31"}, {"source": "693", "target": "311"}, {"source": "311", "target": "312"}, {"source": "311", "target": "312"}, {"source": "922", "target": "312"}, {"source": "312", "target": "313"}, {"source": "312", "target": "314"}, {"source": "312", "target": "315"}, {"source": "312", "target": "316"}, {"source": "312", "target": "317"}, {"source": "312", "target": "318"}, {"source": "311", "target": "319"}, {"source": "311", "target": "319"}, {"source": "23", "target": "32"}, {"source": "798", "target": "321"}, {"source": "798", "target": "321"}, {"source": "798", "target": "321"}, {"source": "306", "target": "322"}, {"source": "344", "target": "323"}, {"source": "672", "target": "324"}, {"source": "573", "target": "325"}, {"source": "693", "target": "326"}, {"source": "693", "target": "327"}, {"source": "326", "target": "328"}, {"source": "327", "target": "328"}, {"source": "1204", "target": "329"}, {"source": "573", "target": "329"}, {"source": "23", "target": "33"}, {"source": "693", "target": "330"}, {"source": "330", "target": "331"}, {"source": "330", "target": "331"}, {"source": "331", "target": "332"}, {"source": "331", "target": "333"}, {"source": "703", "target": "333"}, {"source": "330", "target": "334"}, {"source": "330", "target": "335"}, {"source": "330", "target": "335"}, {"source": "335", "target": "336"}, {"source": "335", "target": "337"}, {"source": "330", "target": "338"}, {"source": "330", "target": "338"}, {"source": "335", "target": "339"}, {"source": "23", "target": "34"}, {"source": "330", "target": "340"}, {"source": "340", "target": "341"}, {"source": "340", "target": "342"}, {"source": "340", "target": "343"}, {"source": "330", "target": "344"}, {"source": "693", "target": "345"}, {"source": "345", "target": "346"}, {"source": "345", "target": "346"}, {"source": "284", "target": "346"}, {"source": "345", "target": "347"}, {"source": "345", "target": "347"}, {"source": "345", "target": "348"}, {"source": "345", "target": "349"}, {"source": "23", "target": "35"}, {"source": "290", "target": "350"}, {"source": "807", "target": "350"}, {"source": "345", "target": "351"}, {"source": "345", "target": "352"}, {"source": "345", "target": "352"}, {"source": "345", "target": "353"}, {"source": "345", "target": "354"}, {"source": "345", "target": "354"}, {"source": "754", "target": "354"}, {"source": "221", "target": "356"}, {"source": "693", "target": "357"}, {"source": "573", "target": "358"}, {"source": "693", "target": "358"}, {"source": "200", "target": "359"}, {"source": "22", "target": "36"}, {"source": "22", "target": "36"}, {"source": "22", "target": "36"}, {"source": "345", "target": "360"}, {"source": "691", "target": "362"}, {"source": "367", "target": "363"}, {"source": "362", "target": "364"}, {"source": "362", "target": "366"}, {"source": "662", "target": "366"}, {"source": "662", "target": "366"}, {"source": "362", "target": "367"}, {"source": "362", "target": "367"}, {"source": "362", "target": "368"}, {"source": "682", "target": "369"}, {"source": "682", "target": "369"}, {"source": "682", "target": "369"}, {"source": "682", "target": "369"}, {"source": "36", "target": "37"}, {"source": "160", "target": "37"}, {"source": "299", "target": "370"}, {"source": "664", "target": "372"}, {"source": "668", "target": "374"}, {"source": "668", "target": "375"}, {"source": "668", "target": "377"}, {"source": "377", "target": "378"}, {"source": "377", "target": "379"}, {"source": "36", "target": "38"}, {"source": "705", "target": "382"}, {"source": "695", "target": "383"}, {"source": "610", "target": "384"}, {"source": "610", "target": "384"}, {"source": "514", "target": "385"}, {"source": "706", "target": "386"}, {"source": "36", "target": "39"}, {"source": "755", "target": "390"}, {"source": "754", "target": "391"}, {"source": "703", "target": "391"}, {"source": "703", "target": "391"}, {"source": "755", "target": "392"}, {"source": "684", "target": "392"}, {"source": "703", "target": "392"}, {"source": "703", "target": "392"}, {"source": "684", "target": "393"}, {"source": "703", "target": "393"}, {"source": "754", "target": "394"}, {"source": "705", "target": "395"}, {"source": "755", "target": "395"}, {"source": "705", "target": "396"}, {"source": "755", "target": "396"}, {"source": "221", "target": "396"}, {"source": "705", "target": "397"}, {"source": "221", "target": "397"}, {"source": "703", "target": "397"}, {"source": "36", "target": "40"}, {"source": "664", "target": "400"}, {"source": "772", "target": "401"}, {"source": "404", "target": "401"}, {"source": "404", "target": "401"}, {"source": "668", "target": "402"}, {"source": "402", "target": "403"}, {"source": "664", "target": "404"}, {"source": "400", "target": "405"}, {"source": "405", "target": "406"}, {"source": "405", "target": "407"}, {"source": "405", "target": "408"}, {"source": "696", "target": "408"}, {"source": "405", "target": "409"}, {"source": "706", "target": "41"}, {"source": "664", "target": "410"}, {"source": "667", "target": "412"}, {"source": "667", "target": "413"}, {"source": "667", "target": "414"}, {"source": "825", "target": "415"}, {"source": "1341", "target": "415"}, {"source": "672", "target": "415"}, {"source": "672", "target": "415"}, {"source": "672", "target": "415"}, {"source": "666", "target": "415"}, {"source": "825", "target": "416"}, {"source": "672", "target": "416"}, {"source": "672", "target": "416"}, {"source": "672", "target": "416"}, {"source": "923", "target": "419"}, {"source": "41", "target": "42"}, {"source": "162", "target": "42"}, {"source": "923", "target": "420"}, {"source": "420", "target": "421"}, {"source": "362", "target": "421"}, {"source": "420", "target": "422"}, {"source": "360", "target": "422"}, {"source": "693", "target": "424"}, {"source": "638", "target": "424"}, {"source": "862", "target": "425"}, {"source": "862", "target": "425"}, {"source": "288", "target": "425"}, {"source": "424", "target": "425"}, {"source": "642", "target": "426"}, {"source": "668", "target": "426"}, {"source": "673", "target": "426"}, {"source": "668", "target": "427"}, {"source": "668", "target": "427"}, {"source": "668", "target": "428"}, {"source": "668", "target": "428"}, {"source": "42", "target": "43"}, {"source": "163", "target": "43"}, {"source": "691", "target": "430"}, {"source": "691", "target": "431"}, {"source": "364", "target": "432"}, {"source": "219", "target": "433"}, {"source": "669", "target": "434"}, {"source": "669", "target": "434"}, {"source": "435", "target": "436"}, {"source": "436", "target": "437"}, {"source": "435", "target": "439"}, {"source": "41", "target": "44"}, {"source": "684", "target": "440"}, {"source": "610", "target": "441"}, {"source": "436", "target": "444"}, {"source": "436", "target": "444"}, {"source": "684", "target": "446"}, {"source": "446", "target": "447"}, {"source": "671", "target": "447"}, {"source": "446", "target": "448"}, {"source": "446", "target": "449"}, {"source": "44", "target": "45"}, {"source": "165", "target": "45"}, {"source": "357", "target": "450"}, {"source": "684", "target": "451"}, {"source": "221", "target": "451"}, {"source": "1188", "target": "453"}, {"source": "665", "target": "454"}, {"source": "665", "target": "455"}, {"source": "705", "target": "455"}, {"source": "636", "target": "455"}, {"source": "909", "target": "456"}, {"source": "665", "target": "456"}, {"source": "665", "target": "456"}, {"source": "908", "target": "457"}, {"source": "665", "target": "457"}, {"source": "665", "target": "457"}, {"source": "404", "target": "459"}, {"source": "404", "target": "459"}, {"source": "41", "target": "46"}, {"source": "162", "target": "46"}, {"source": "459", "target": "460"}, {"source": "755", "target": "460"}, {"source": "694", "target": "462"}, {"source": "707", "target": "463"}, {"source": "138", "target": "464"}, {"source": "119", "target": "466"}, {"source": "20", "target": "466"}, {"source": "131", "target": "467"}, {"source": "682", "target": "468"}, {"source": "682", "target": "469"}, {"source": "41", "target": "47"}, {"source": "913", "target": "470"}, {"source": "913", "target": "470"}, {"source": "610", "target": "470"}, {"source": "20", "target": "470"}, {"source": "664", "target": "471"}, {"source": "642", "target": "472"}, {"source": "471", "target": "472"}, {"source": "471", "target": "473"}, {"source": "758", "target": "474"}, {"source": "573", "target": "475"}, {"source": "710", "target": "476"}, {"source": "754", "target": "476"}, {"source": "754", "target": "476"}, {"source": "710", "target": "477"}, {"source": "1023", "target": "478"}, {"source": "828", "target": "479"}, {"source": "663", "target": "479"}, {"source": "41", "target": "48"}, {"source": "670", "target": "480"}, {"source": "480", "target": "481"}, {"source": "480", "target": "482"}, {"source": "670", "target": "483"}, {"source": "710", "target": "484"}, {"source": "670", "target": "484"}, {"source": "1025", "target": "486"}, {"source": "664", "target": "487"}, {"source": "668", "target": "488"}, {"source": "710", "target": "489"}, {"source": "41", "target": "49"}, {"source": "162", "target": "49"}, {"source": "668", "target": "491"}, {"source": "668", "target": "492"}, {"source": "668", "target": "493"}, {"source": "345", "target": "494"}, {"source": "669", "target": "494"}, {"source": "669", "target": "494"}, {"source": "664", "target": "495"}, {"source": "664", "target": "496"}, {"source": "200", "target": "497"}, {"source": "668", "target": "498"}, {"source": "668", "target": "499"}, {"source": "319", "target": "5"}, {"source": "41", "target": "50"}, {"source": "161", "target": "50"}, {"source": "493", "target": "500"}, {"source": "664", "target": "501"}, {"source": "913", "target": "502"}, {"source": "913", "target": "502"}, {"source": "912", "target": "506"}, {"source": "506", "target": "507"}, {"source": "507", "target": "508"}, {"source": "507", "target": "509"}, {"source": "41", "target": "51"}, {"source": "506", "target": "510"}, {"source": "506", "target": "511"}, {"source": "506", "target": "512"}, {"source": "1229", "target": "514"}, {"source": "514", "target": "515"}, {"source": "41", "target": "52"}, {"source": "163", "target": "52"}, {"source": "266", "target": "520"}, {"source": "1391", "target": "521"}, {"source": "287", "target": "521"}, {"source": "1390", "target": "522"}, {"source": "287", "target": "522"}, {"source": "668", "target": "522"}, {"source": "522", "target": "523"}, {"source": "668", "target": "524"}, {"source": "524", "target": "525"}, {"source": "312", "target": "526"}, {"source": "552", "target": "527"}, {"source": "552", "target": "528"}, {"source": "552", "target": "529"}, {"source": "41", "target": "53"}, {"source": "165", "target": "53"}, {"source": "552", "target": "530"}, {"source": "540", "target": "531"}, {"source": "538", "target": "532"}, {"source": "200", "target": "532"}, {"source": "211", "target": "535"}, {"source": "211", "target": "536"}, {"source": "211", "target": "537"}, {"source": "200", "target": "538"}, {"source": "552", "target": "539"}, {"source": "41", "target": "54"}, {"source": "162", "target": "54"}, {"source": "538", "target": "540"}, {"source": "540", "target": "541"}, {"source": "820", "target": "543"}, {"source": "662", "target": "543"}, {"source": "662", "target": "543"}, {"source": "755", "target": "544"}, {"source": "1078", "target": "546"}, {"source": "1078", "target": "547"}, {"source": "497", "target": "548"}, {"source": "522", "target": "549"}, {"source": "41", "target": "55"}, {"source": "209", "target": "550"}, {"source": "863", "target": "551"}, {"source": "696", "target": "551"}, {"source": "668", "target": "552"}, {"source": "668", "target": "552"}, {"source": "285", "target": "552"}, {"source": "552", "target": "553"}, {"source": "1173", "target": "554"}, {"source": "260", "target": "555"}, {"source": "266", "target": "556"}, {"source": "663", "target": "558"}, {"source": "41", "target": "56"}, {"source": "155", "target": "56"}, {"source": "687", "target": "560"}, {"source": "1164", "target": "561"}, {"source": "758", "target": "562"}, {"source": "1164", "target": "563"}, {"source": "89", "target": "564"}, {"source": "89", "target": "564"}, {"source": "89", "target": "564"}, {"source": "642", "target": "565"}, {"source": "669", "target": "565"}, {"source": "602", "target": "565"}, {"source": "639", "target": "566"}, {"source": "820", "target": "567"}, {"source": "662", "target": "567"}, {"source": "662", "target": "567"}, {"source": "573", "target": "568"}, {"source": "459", "target": "568"}, {"source": "41", "target": "57"}, {"source": "710", "target": "570"}, {"source": "710", "target": "571"}, {"source": "821", "target": "572"}, {"source": "710", "target": "573"}, {"source": "695", "target": "574"}, {"source": "821", "target": "574"}, {"source": "695", "target": "575"}, {"source": "695", "target": "576"}, {"source": "573", "target": "577"}, {"source": "573", "target": "578"}, {"source": "573", "target": "579"}, {"source": "41", "target": "58"}, {"source": "664", "target": "580"}, {"source": "573", "target": "580"}, {"source": "573", "target": "581"}, {"source": "697", "target": "581"}, {"source": "668", "target": "582"}, {"source": "668", "target": "583"}, {"source": "705", "target": "584"}, {"source": "1071", "target": "585"}, {"source": "1076", "target": "586"}, {"source": "344", "target": "587"}, {"source": "758", "target": "587"}, {"source": "704", "target": "588"}, {"source": "758", "target": "588"}, {"source": "474", "target": "589"}, {"source": "706", "target": "59"}, {"source": "706", "target": "59"}, {"source": "762", "target": "590"}, {"source": "413", "target": "591"}, {"source": "666", "target": "593"}, {"source": "1390", "target": "593"}, {"source": "710", "target": "594"}, {"source": "1025", "target": "595"}, {"source": "595", "target": "597"}, {"source": "595", "target": "597"}, {"source": "480", "target": "597"}, {"source": "201", "target": "598"}, {"source": "295", "target": "599"}, {"source": "334", "target": "6"}, {"source": "248", "target": "600"}, {"source": "610", "target": "601"}, {"source": "610", "target": "601"}, {"source": "693", "target": "602"}, {"source": "1390", "target": "603"}, {"source": "602", "target": "603"}, {"source": "675", "target": "605"}, {"source": "666", "target": "605"}, {"source": "1284", "target": "606"}, {"source": "471", "target": "607"}, {"source": "668", "target": "608"}, {"source": "667", "target": "609"}, {"source": "59", "target": "61"}, {"source": "664", "target": "610"}, {"source": "610", "target": "611"}, {"source": "610", "target": "611"}, {"source": "1230", "target": "612"}, {"source": "672", "target": "613"}, {"source": "672", "target": "613"}, {"source": "319", "target": "614"}, {"source": "540", "target": "615"}, {"source": "345", "target": "616"}, {"source": "670", "target": "617"}, {"source": "670", "target": "617"}, {"source": "749", "target": "618"}, {"source": "402", "target": "619"}, {"source": "59", "target": "62"}, {"source": "1390", "target": "620"}, {"source": "914", "target": "621"}, {"source": "20", "target": "622"}, {"source": "267", "target": "623"}, {"source": "77", "target": "624"}, {"source": "77", "target": "624"}, {"source": "77", "target": "624"}, {"source": "185", "target": "625"}, {"source": "147", "target": "626"}, {"source": "436", "target": "626"}, {"source": "914", "target": "627"}, {"source": "573", "target": "628"}, {"source": "657", "target": "636"}, {"source": "755", "target": "636"}, {"source": "657", "target": "637"}, {"source": "657", "target": "638"}, {"source": "862", "target": "638"}, {"source": "863", "target": "639"}, {"source": "863", "target": "639"}, {"source": "284", "target": "639"}, {"source": "59", "target": "64"}, {"source": "1390", "target": "640"}, {"source": "287", "target": "640"}, {"source": "99", "target": "641"}, {"source": "668", "target": "642"}, {"source": "943", "target": "643"}, {"source": "91", "target": "643"}, {"source": "116", "target": "644"}, {"source": "287", "target": "645"}, {"source": "345", "target": "646"}, {"source": "863", "target": "647"}, {"source": "269", "target": "648"}, {"source": "345", "target": "649"}, {"source": "59", "target": "65"}, {"source": "436", "target": "650"}, {"source": "538", "target": "651"}, {"source": "943", "target": "652"}, {"source": "91", "target": "652"}, {"source": "657", "target": "653"}, {"source": "693", "target": "653"}, {"source": "657", "target": "654"}, {"source": "693", "target": "654"}, {"source": "657", "target": "655"}, {"source": "693", "target": "655"}, {"source": "657", "target": "656"}, {"source": "693", "target": "656"}, {"source": "710", "target": "657"}, {"source": "706", "target": "66"}, {"source": "664", "target": "662"}, {"source": "691", "target": "662"}, {"source": "662", "target": "663"}, {"source": "664", "target": "665"}, {"source": "664", "target": "666"}, {"source": "662", "target": "667"}, {"source": "662", "target": "667"}, {"source": "662", "target": "667"}, {"source": "662", "target": "667"}, {"source": "664", "target": "668"}, {"source": "664", "target": "669"}, {"source": "66", "target": "67"}, {"source": "691", "target": "670"}, {"source": "657", "target": "671"}, {"source": "666", "target": "672"}, {"source": "664", "target": "673"}, {"source": "834", "target": "674"}, {"source": "573", "target": "675"}, {"source": "1177", "target": "676"}, {"source": "190", "target": "680"}, {"source": "704", "target": "681"}, {"source": "704", "target": "681"}, {"source": "628", "target": "683"}, {"source": "710", "target": "684"}, {"source": "628", "target": "685"}, {"source": "628", "target": "686"}, {"source": "628", "target": "687"}, {"source": "628", "target": "688"}, {"source": "362", "target": "689"}, {"source": "66", "target": "69"}, {"source": "252", "target": "690"}, {"source": "184", "target": "692"}, {"source": "99", "target": "694"}, {"source": "573", "target": "694"}, {"source": "573", "target": "695"}, {"source": "691", "target": "696"}, {"source": "705", "target": "698"}, {"source": "670", "target": "698"}, {"source": "756", "target": "7"}, {"source": "664", "target": "704"}, {"source": "691", "target": "705"}, {"source": "664", "target": "706"}, {"source": "282", "target": "708"}, {"source": "66", "target": "72"}, {"source": "642", "target": "73"}, {"source": "610", "target": "73"}, {"source": "20", "target": "73"}, {"source": "285", "target": "732"}, {"source": "668", "target": "732"}, {"source": "1038", "target": "733"}, {"source": "707", "target": "74"}, {"source": "284", "target": "749"}, {"source": "74", "target": "75"}, {"source": "703", "target": "754"}, {"source": "703", "target": "755"}, {"source": "755", "target": "756"}, {"source": "693", "target": "757"}, {"source": "710", "target": "758"}, {"source": "916", "target": "759"}, {"source": "75", "target": "76"}, {"source": "916", "target": "760"}, {"source": "763", "target": "761"}, {"source": "404", "target": "761"}, {"source": "763", "target": "762"}, {"source": "404", "target": "762"}, {"source": "404", "target": "763"}, {"source": "404", "target": "763"}, {"source": "404", "target": "763"}, {"source": "667", "target": "764"}, {"source": "675", "target": "764"}, {"source": "662", "target": "764"}, {"source": "662", "target": "764"}, {"source": "667", "target": "765"}, {"source": "675", "target": "765"}, {"source": "732", "target": "766"}, {"source": "1061", "target": "766"}, {"source": "668", "target": "767"}, {"source": "691", "target": "768"}, {"source": "74", "target": "77"}, {"source": "74", "target": "77"}, {"source": "400", "target": "770"}, {"source": "665", "target": "770"}, {"source": "400", "target": "770"}, {"source": "400", "target": "771"}, {"source": "404", "target": "772"}, {"source": "404", "target": "772"}, {"source": "404", "target": "772"}, {"source": "404", "target": "772"}, {"source": "771", "target": "773"}, {"source": "770", "target": "774"}, {"source": "772", "target": "775"}, {"source": "404", "target": "775"}, {"source": "404", "target": "775"}, {"source": "674", "target": "776"}, {"source": "674", "target": "776"}, {"source": "405", "target": "776"}, {"source": "625", "target": "777"}, {"source": "223", "target": "778"}, {"source": "693", "target": "778"}, {"source": "400", "target": "779"}, {"source": "77", "target": "78"}, {"source": "74", "target": "78"}, {"source": "77", "target": "78"}, {"source": "77", "target": "78"}, {"source": "327", "target": "780"}, {"source": "1285", "target": "781"}, {"source": "749", "target": "782"}, {"source": "670", "target": "783"}, {"source": "807", "target": "784"}, {"source": "565", "target": "784"}, {"source": "676", "target": "785"}, {"source": "120", "target": "785"}, {"source": "20", "target": "785"}, {"source": "119", "target": "786"}, {"source": "119", "target": "786"}, {"source": "119", "target": "786"}, {"source": "119", "target": "787"}, {"source": "119", "target": "787"}, {"source": "119", "target": "787"}, {"source": "119", "target": "787"}, {"source": "119", "target": "788"}, {"source": "119", "target": "788"}, {"source": "119", "target": "788"}, {"source": "770", "target": "789"}, {"source": "74", "target": "79"}, {"source": "74", "target": "79"}, {"source": "138", "target": "790"}, {"source": "790", "target": "791"}, {"source": "791", "target": "792"}, {"source": "792", "target": "793"}, {"source": "792", "target": "794"}, {"source": "791", "target": "795"}, {"source": "795", "target": "796"}, {"source": "795", "target": "797"}, {"source": "1391", "target": "798"}, {"source": "287", "target": "798"}, {"source": "344", "target": "798"}, {"source": "671", "target": "798"}, {"source": "691", "target": "799"}, {"source": "668", "target": "8"}, {"source": "79", "target": "80"}, {"source": "863", "target": "804"}, {"source": "1390", "target": "804"}, {"source": "119", "target": "805"}, {"source": "119", "target": "805"}, {"source": "119", "target": "805"}, {"source": "805", "target": "806"}, {"source": "693", "target": "807"}, {"source": "79", "target": "81"}, {"source": "83", "target": "82"}, {"source": "662", "target": "820"}, {"source": "662", "target": "820"}, {"source": "662", "target": "820"}, {"source": "662", "target": "821"}, {"source": "662", "target": "821"}, {"source": "662", "target": "821"}, {"source": "119", "target": "822"}, {"source": "119", "target": "822"}, {"source": "119", "target": "822"}, {"source": "119", "target": "823"}, {"source": "119", "target": "823"}, {"source": "119", "target": "823"}, {"source": "119", "target": "824"}, {"source": "119", "target": "824"}, {"source": "119", "target": "824"}, {"source": "119", "target": "824"}, {"source": "119", "target": "825"}, {"source": "119", "target": "825"}, {"source": "119", "target": "825"}, {"source": "672", "target": "825"}, {"source": "666", "target": "826"}, {"source": "706", "target": "827"}, {"source": "829", "target": "827"}, {"source": "364", "target": "828"}, {"source": "669", "target": "829"}, {"source": "669", "target": "829"}, {"source": "79", "target": "83"}, {"source": "829", "target": "830"}, {"source": "364", "target": "831"}, {"source": "667", "target": "832"}, {"source": "667", "target": "833"}, {"source": "662", "target": "833"}, {"source": "691", "target": "834"}, {"source": "834", "target": "835"}, {"source": "834", "target": "835"}, {"source": "1390", "target": "836"}, {"source": "799", "target": "837"}, {"source": "116", "target": "838"}, {"source": "116", "target": "838"}, {"source": "1023", "target": "839"}, {"source": "79", "target": "84"}, {"source": "691", "target": "841"}, {"source": "286", "target": "842"}, {"source": "704", "target": "843"}, {"source": "704", "target": "843"}, {"source": "79", "target": "85"}, {"source": "79", "target": "86"}, {"source": "436", "target": "86"}, {"source": "285", "target": "862"}, {"source": "284", "target": "862"}, {"source": "285", "target": "863"}, {"source": "284", "target": "863"}, {"source": "79", "target": "87"}, {"source": "77", "target": "88"}, {"source": "74", "target": "88"}, {"source": "77", "target": "88"}, {"source": "77", "target": "88"}, {"source": "943", "target": "89"}, {"source": "74", "target": "89"}, {"source": "266", "target": "9"}, {"source": "943", "target": "90"}, {"source": "665", "target": "908"}, {"source": "665", "target": "908"}, {"source": "665", "target": "909"}, {"source": "665", "target": "909"}, {"source": "74", "target": "91"}, {"source": "74", "target": "91"}, {"source": "672", "target": "910"}, {"source": "664", "target": "911"}, {"source": "684", "target": "912"}, {"source": "664", "target": "913"}, {"source": "99", "target": "914"}, {"source": "913", "target": "914"}, {"source": "913", "target": "915"}, {"source": "328", "target": "916"}, {"source": "327", "target": "916"}, {"source": "77", "target": "917"}, {"source": "74", "target": "917"}, {"source": "77", "target": "917"}, {"source": "77", "target": "917"}, {"source": "441", "target": "918"}, {"source": "610", "target": "918"}, {"source": "400", "target": "920"}, {"source": "400", "target": "920"}, {"source": "922", "target": "921"}, {"source": "664", "target": "922"}, {"source": "284", "target": "923"}, {"source": "345", "target": "924"}, {"source": "345", "target": "924"}, {"source": "940", "target": "925"}, {"source": "285", "target": "926"}, {"source": "285", "target": "927"}, {"source": "668", "target": "927"}, {"source": "74", "target": "93"}, {"source": "862", "target": "939"}, {"source": "74", "target": "94"}, {"source": "74", "target": "94"}, {"source": "913", "target": "94"}, {"source": "923", "target": "940"}, {"source": "346", "target": "940"}, {"source": "923", "target": "941"}, {"source": "863", "target": "942"}, {"source": "923", "target": "942"}, {"source": "183", "target": "942"}, {"source": "74", "target": "943"}, {"source": "94", "target": "95"}, {"source": "94", "target": "96"}, {"source": "96", "target": "97"}, {"source": "706", "target": "98"}, {"source": "829", "target": "98"}, {"source": "74", "target": "99"}]}